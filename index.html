<!doctype html>



  


<html class="theme-next mist use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="salty fish jojo23333&apos;s personal page">
<meta property="og:type" content="website">
<meta property="og:title" content="JonassenLi">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="JonassenLi">
<meta property="og:description" content="salty fish jojo23333&apos;s personal page">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="JonassenLi">
<meta name="twitter:description" content="salty fish jojo23333&apos;s personal page">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> JonassenLi </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JonassenLi</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Kategorien
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/15/machinelearning/tensorflow_notes/style_transfer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/04/15/machinelearning/tensorflow_notes/style_transfer/" itemprop="url">
                  Image Style Transfer based on CNN
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-15T20:18:00+08:00">
                2018-04-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="实验提要"><a href="#实验提要" class="headerlink" title="实验提要"></a>实验提要</h2><p>刚做完CS20的assignmet 2，因为是第一个tensorflow项目，虽然很多不知道怎么做借鉴了别人的代码，整个代码框架大致是搞懂了，姑且留个记录。</p>
<p>整个实验基本上是对<a href="https://arxiv.org/pdf/1508.06576.pdf" target="_blank" rel="external">A Neural Algorithm of Artistic Style</a><br>这篇文章的一个实现。实验提供了一些框架代码，可以在<a href="https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/02_style_transfer" target="_blank" rel="external">git上这里</a>找到</p>
<h2 id="原论文以及主要观点"><a href="#原论文以及主要观点" class="headerlink" title="原论文以及主要观点"></a>原论文以及主要观点</h2><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>A Neural Algorithm of Artistic Style 这篇文章发表2016，还算比较新的文章。<br>文章的主要点在于它发现了在CNN当中图片的内容和图片的风格是可以分离的，因而可以独立的处理这些表示生成新的有意义的图片（虽然我也没完全弄懂他的意思），原文如下：</p>
<blockquote>
<p>“The key finding of this paper is that the representations of content and style in the Convolutional Neural Network are separable. That is, we can manipulate both representations independently to produce new, perceptually meaningful images.”</p>
</blockquote>
<h3 id="VGG-Network-结构"><a href="#VGG-Network-结构" class="headerlink" title="VGG-Network 结构"></a>VGG-Network 结构</h3><p>文章使用的实现方法基于VGG-Network，在cs231n的<a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">这个课件</a>里有对VGG-Net的简要介绍    </p>
<blockquote>
<p>VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, <strong>features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end.</strong> Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.</p>
</blockquote>
<p>VGGnet的网络参数如图所示  </p>
<p><img src="./images/tf/VGGNet.png" alt="VGGNet achitecture"></p>
<h3 id="基于VGGnet-的实现"><a href="#基于VGGnet-的实现" class="headerlink" title="基于VGGnet 的实现"></a>基于VGGnet 的实现</h3><p>文章使用了VGGNet当中的16层卷积层和5层pooling层,去掉了全连接层，并使用average pooling策略替换max pooling策略</p>
<h4 id="lose-function"><a href="#lose-function" class="headerlink" title="lose function"></a>lose function</h4><p>关于怎么定义loss function,想法比较自然<br>在图像内容附近通过白噪声初始化一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正。<br><strong>content loss</strong><br>设置一个白点噪声的初始图像和原图像输入网络，在某一层的输出$l$处,F和P分别为其特征表述，则取其方差为content loss</p>
<p>$$ L_{content}(\vec p,\vec x, l) = \frac{1}{2}\sum_{i,j}(F_{ij}^{l}-P_{ij}^{l})^2 $$</p>
<p><strong>Gram矩阵</strong></p>
<p>Gram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）<br>协方差矩阵可写成：</p>
<p>$$ \sum  = E[(X-E(X))(X-E(X))^T]$$<br>Gram矩阵可写成</p>
<p>$$ G = A * A^{T} $$</p>
<p><strong>style loss</strong>  </p>
<p>在CNN每一层反馈的基础上，对每一层的激励结果求其Gram矩阵,同样是对生成图像和原图像，在某一层l生成的两个Gram矩阵G、A<br>这一层loss贡献为：</p>
<p>$$ E_l = \frac{1}{4N_l^2M_l^2}\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$$</p>
<p>对每一层的loss进行加权求和，得到总的loss为</p>
<p>$$ L_{style}(\vec a,\vec x) = \sum_{l=0}^Lw_lE_l$$</p>
<p>给定content loss和style loss分别的权重为$\alpha$和$\beta$，总的优化目标为</p>
<p>$$ L_{total}(\vec p,\vec a,\vec x)=\alpha L_{content}(\vec p,\vec x)+\beta L_{style}(\vec a,\vec x)$$</p>
<p><strong>思考</strong><br>有关于为什么要使用gram matrix来度量风格，当同一个维度上面的值相乘的时候原来越小酒变得更小，原来越大就变得越大，二不同维度上的关系也在相乘的表达当中表示出来,因而gram matrix能有效度量各个维度自己的特性以及各个维度之间的关系</p>
<h2 id="基于tensorflow的实现"><a href="#基于tensorflow的实现" class="headerlink" title="基于tensorflow的实现"></a>基于tensorflow的实现</h2><h3 id="代码框架"><a href="#代码框架" class="headerlink" title="代码框架"></a>代码框架</h3><ul>
<li>utils.py  一些辅助函数</li>
<li>load_vgg.py  从已经训练好的参数当中加载vggnet</li>
<li>style_transfer.py 构建风格转化的模型</li>
</ul>
<h3 id="load-vgg-py"><a href="#load-vgg-py" class="headerlink" title="load_vgg.py"></a>load_vgg.py</h3><p>这个模块中的主要任务是搭建vggnet，在load方法当中调用conv2d_relu生成卷积层，调用avgpool生成pooling层<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d_relu</span><span class="params">(self, prev_layer, layer_idx, layer_name)</span>:</span></div><div class="line">    <span class="keyword">with</span> tf.variable_scope(layer_name):</div><div class="line">                w, b = self._weights(layer_idx, layer_name)</div><div class="line">                w = tf.constant(w, name=<span class="string">"weight"</span>)</div><div class="line">                b = tf.constant(b, name=<span class="string">"bais"</span>)</div><div class="line">                conv2d = tf.nn.conv2d(input = prev_layer,</div><div class="line">                                    filter = w,</div><div class="line">                                    strides = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                                    padding = <span class="string">"SAME"</span>,</div><div class="line">                                    name = layer_name)</div><div class="line">                out = tf.nn.relu(conv2d + b)</div><div class="line">        setattr(self, layer_name, out)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">avgpool</span><span class="params">(self, prev_layer, layer_name)</span>:</span></div><div class="line"></div><div class="line">        <span class="keyword">with</span> tf.variable_scope(layer_name):</div><div class="line">            out = tf.nn.avg_pool(prev_layer,</div><div class="line">                                ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],</div><div class="line">                                strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],</div><div class="line">                                padding=<span class="string">"SAME"</span>)</div><div class="line"></div><div class="line">        setattr(self, layer_name, out)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(self)</span>:</span></div><div class="line">        self.conv2d_relu(self.input_img, <span class="number">0</span>, <span class="string">'conv1_1'</span>)</div><div class="line">        self.conv2d_relu(self.conv1_1, <span class="number">2</span>, <span class="string">'conv1_2'</span>)</div><div class="line">        self.avgpool(self.conv1_2, <span class="string">'avgpool1'</span>)</div><div class="line">        self.conv2d_relu(self.avgpool1, <span class="number">5</span>, <span class="string">'conv2_1'</span>)</div><div class="line">        self.conv2d_relu(self.conv2_1, <span class="number">7</span>, <span class="string">'conv2_2'</span>)</div><div class="line">        self.avgpool(self.conv2_2, <span class="string">'avgpool2'</span>)</div><div class="line">        self.conv2d_relu(self.avgpool2, <span class="number">10</span>, <span class="string">'conv3_1'</span>)</div><div class="line">        self.conv2d_relu(self.conv3_1, <span class="number">12</span>, <span class="string">'conv3_2'</span>)</div><div class="line">        self.conv2d_relu(self.conv3_2, <span class="number">14</span>, <span class="string">'conv3_3'</span>)</div><div class="line">        self.conv2d_relu(self.conv3_3, <span class="number">16</span>, <span class="string">'conv3_4'</span>)</div><div class="line">        self.avgpool(self.conv3_4, <span class="string">'avgpool3'</span>)</div><div class="line">        self.conv2d_relu(self.avgpool3, <span class="number">19</span>, <span class="string">'conv4_1'</span>)</div><div class="line">        self.conv2d_relu(self.conv4_1, <span class="number">21</span>, <span class="string">'conv4_2'</span>)</div><div class="line">        self.conv2d_relu(self.conv4_2, <span class="number">23</span>, <span class="string">'conv4_3'</span>)</div><div class="line">        self.conv2d_relu(self.conv4_3, <span class="number">25</span>, <span class="string">'conv4_4'</span>)</div><div class="line">        self.avgpool(self.conv4_4, <span class="string">'avgpool4'</span>)</div><div class="line">        self.conv2d_relu(self.avgpool4, <span class="number">28</span>, <span class="string">'conv5_1'</span>)</div><div class="line">        self.conv2d_relu(self.conv5_1, <span class="number">30</span>, <span class="string">'conv5_2'</span>)</div><div class="line">        self.conv2d_relu(self.conv5_2, <span class="number">32</span>, <span class="string">'conv5_3'</span>)</div><div class="line">        self.conv2d_relu(self.conv5_3, <span class="number">34</span>, <span class="string">'conv5_4'</span>)</div><div class="line">        self.avgpool(self.conv5_4, <span class="string">'avgpool5'</span>)</div></pre></td></tr></table></figure></p>
<p>有关conv2d的参数解释见之前笔记和<a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" target="_blank" rel="external">这里</a></p>
<h3 id="style-transfer"><a href="#style-transfer" class="headerlink" title="style_transfer"></a>style_transfer</h3><p>总体分为两部，第一步创建tensorflow图结构，这其中包括：</p>
<ol>
<li>使用create_input创建空白图作为输入</li>
<li>加载vggnet结构</li>
<li>创建loss</li>
<li>根据loss创建optimizer</li>
<li>创建统计数据<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self)</span>:</span></div><div class="line">    self.create_input()</div><div class="line">    self.load_vgg()</div><div class="line">    self.losses()</div><div class="line">    self.optimize()</div><div class="line">    self.create_summary()</div></pre></td></tr></table></figure>
</li>
</ol>
<p>第二步执行训练:  </p>
<ol>
<li>初始化全局变量sess.run(tf.global_variables_initializer())</li>
<li>创建FileWriter (用于TensorBoard)</li>
<li>创建输入  sess.run(self.input_img.assign(self.initial_img))</li>
<li>创建checkpoint检查是否要恢复</li>
<li>循环迭代n次</li>
<li>最优化opt</li>
<li>每特定次循环计算保存summary，保存断点<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, n_iters)</span>:</span></div><div class="line">    skip_step = <span class="number">1</span></div><div class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">        <span class="comment"># 1. initialize</span></div><div class="line">        sess.run(tf.global_variables_initializer())</div><div class="line">        <span class="comment"># 2. create writer</span></div><div class="line">        writer = tf.summary.FileWriter(<span class="string">"graphs/style_transfer"</span>, sess.graph)</div><div class="line">        <span class="comment"># 3. assign input</span></div><div class="line">        sess.run(self.input_img.assign(self.initial_img))</div><div class="line">        <span class="comment"># 4. create checkpoint &amp; restore previous</span></div><div class="line">        saver = tf.train.Saver()</div><div class="line">        ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class="string">'checkpoints/style_transfer/checkpoint'</span>))</div><div class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</div><div class="line">            saver.restore(sess, ckpt.model_checkpoint_path)</div><div class="line"></div><div class="line">        initial_step = self.gstep.eval()</div><div class="line">        start_time = time.time()</div><div class="line">        <span class="comment"># 5. iterate for n_iters time</span></div><div class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(initial_step, n_iters):</div><div class="line">            <span class="keyword">if</span> index &gt;= <span class="number">5</span> <span class="keyword">and</span> index &lt; <span class="number">20</span>:</div><div class="line">                skip_step = <span class="number">10</span></div><div class="line">            <span class="keyword">elif</span> index &gt;= <span class="number">20</span>:</div><div class="line">                skip_step = <span class="number">20</span></div><div class="line">            <span class="comment"># 6. run optimization</span></div><div class="line">            sess.run(self.opt)</div><div class="line">            <span class="comment"># 7. add summary info \ save checkpoint every number of certain layers</span></div><div class="line">            <span class="keyword">if</span> (index + <span class="number">1</span>) % skip_step == <span class="number">0</span>:</div><div class="line">                gen_image, total_loss, summary = sess.run([self.input_img,</div><div class="line">                                                        self.total_loss,</div><div class="line">                                                        self.summary_op])</div><div class="line">                gen_image = gen_image + self.vgg.mean_pixels </div><div class="line">                writer.add_summary(summary, global_step=index)</div><div class="line">            <span class="comment">#...</span></div><div class="line">            <span class="keyword">if</span> (index + <span class="number">1</span>) % <span class="number">20</span> == <span class="number">0</span>:</div><div class="line">                saver.save (sess, <span class="string">'checkpoints/style_stranfer/style_transfer'</span>, index)</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="个人在做完之后的一点思考"><a href="#个人在做完之后的一点思考" class="headerlink" title="个人在做完之后的一点思考"></a>个人在做完之后的一点思考</h3><p>首先这个任务和传统的学习任务不一样。这次学习的对象是需要生成的图像，待生成的图像像素点作为变量在最优化的时候同时被训练。而网络的模型采用他人训练好的参数。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/machinelearning/tensorflow_notes/note_CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/04/12/machinelearning/tensorflow_notes/note_CNN/" itemprop="url">
                  Convolutional Nerual Networks for Visual Recongnition
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-12T22:58:00+08:00">
                2018-04-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Convolutional-Nerual-Networks-CNNs-ConvNets"><a href="#Convolutional-Nerual-Networks-CNNs-ConvNets" class="headerlink" title="Convolutional Nerual Networks (CNNs/ConvNets)"></a>Convolutional Nerual Networks (CNNs/ConvNets)</h1><h2 id="Over-view"><a href="#Over-view" class="headerlink" title="Over view"></a>Over view</h2><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>首先为啥会有CNN这个东西呢？<br>一个普通的神经网络的示意图如下所示<br><img src="./images/tf/simple_neural_net.jpeg" alt=""><br>可见，这种神经网络层与层之间是全连接的，对于minist这种数据集使用，假设输入图像为32<em>32</em>3 = 3072个节点，勉强可以处理。但是对于更大的输入图像，200<em>200</em>3 = 120000个神经元节点，这种神经网络处理起来就比较费力。<br>很显然，这种时候全连接就显得比较无用和浪费，大量的参数不仅难以优化，而且会快速的导致网络的过拟合。  </p>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>卷积神经网络同样由许多层构成，其中主要的有三种：</p>
<ol>
<li>Concoluntional Layer (卷积层)</li>
<li>Polling Layer ()</li>
<li>Full-Connected Layer ()</li>
</ol>
<p>一个较为典型的架构是：[INPUT-CONV-RELU-POOL-FC]</p>
<ul>
<li>INPUT: 3-d [width <em> height </em> color-channels]</li>
<li>CONV : 卷积层</li>
<li>RELU : Rectified Linear Unit (线性整流函数) 常用的有斜坡函数(max(0,x))</li>
<li>POOL : 对输入进行下降抽样（输出向量的前两位小于输入）</li>
<li>FC: 全连接的层  </li>
</ul>
<p>其中只有CONV层和FC层是包含所需要优化的参数的。</p>
<h2 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h2><h3 id="Convolutional-Layer-卷积层"><a href="#Convolutional-Layer-卷积层" class="headerlink" title="Convolutional Layer (卷积层)"></a>Convolutional Layer (卷积层)</h3><p>我们知道在高维度的输入下，全连接不太实际。取而代之的是，可以对每个节点和输入的某个局部的区域连接。而如何选择这个区域，由一组超参数（hyperparameter）决定，这被称为神经元的（receptive field），也就是filter size.</p>
<h4 id="输出维度（spatial-arrangement）"><a href="#输出维度（spatial-arrangement）" class="headerlink" title="输出维度（spatial-arrangement）"></a>输出维度（spatial-arrangement）</h4><p>输出的空间维度由三个超参数决定：</p>
<ul>
<li>Depth: 输出的深度等于用到的filter的个数。可以理解为：不同的filter试图在数据里面找到不同的特征。</li>
<li>Stride: Stride可以理解为对filter滑动的间距。当Stride较大的时候，输出的维度较小。（通常情况下1、2）</li>
<li>Zero-padding: 有时候在特定Stride值下，不能整除的时候周围输入就要补零。</li>
</ul>
<p>$W =$ input volume size<br>$P =$ receptive field size of the conv layer nerons<br>$S =$ stride<br>$P =$ amount of zero-padding<br>则有：<br>$(W-F+2P)/S + 1$则为一个filter所对应的CONV Layer的节点数。</p>
<h4 id="参数共享（parameter-sharing）"><a href="#参数共享（parameter-sharing）" class="headerlink" title="参数共享（parameter sharing）"></a>参数共享（parameter sharing）</h4><p>在Conv Layer Local connectivity的情况下，假设输入向量大小为[a<em> b </em> c], 输出[x <em> y</em> z], filter [n <em> m </em> c]。那么Conv Layer一共有xyz个节点，每一个节点有nmc个参数，一共有xyznmc个参数，取x = 55, y = 55, z = 96,n = 11,m = 11, c = 3。这种数量级仍然是难以接受的。</p>
<p>可以通过一个合理的假设大量减少参数的数量，可以认为如果某个特征在某一点是有效的，那么在其它点其是同样有效的。也就是说，限制Conv layer在每一个filter（depth）下的神经元使用同样的参数和bias，总的参数数量可以快速减少到zmnc。（在back propogation当中，同意深度下使用相同参数的神经元的贡献会被相加）</p>
<p>Conv Layer 的计算过程如图所示：<br><img src="./images/tf/convolution.png" alt=""></p>
<h4 id="Two-key-insights："><a href="#Two-key-insights：" class="headerlink" title="Two key insights："></a>Two key insights：</h4><p>关于CONV Layer的两个关键点<br>1) Features are hierarchical<br>Composing high-complexity features out of low-complexity features is more<br>efficient than learning high-complexity features directly.<br>e.g.: having an “circle” detector is useful for detecting faces… and basketballs<br>2) Features are translationally invariant<br>If a feature is useful to compute at (x, y) it is useful to compute that feature at<br>(x’, y’) as well</p>
<p>ps: 为何叫卷积层呢：因为其与两个信号的卷积类似。  </p>
<h3 id="Pooling-Layer-不知道咋翻译"><a href="#Pooling-Layer-不知道咋翻译" class="headerlink" title="Pooling Layer (不知道咋翻译..)"></a>Pooling Layer (不知道咋翻译..)</h3><p>Pooling Layer常被加在连续的Conv Layer当中，它的主要作用是逐步减少空间大小来减少参数的数量，从而控制过拟合。  </p>
<p>Pooling层独立的作用于各个depth slice。</p>
<p>一个常见的例子是使用2*2的filter，stride为2,使用max function，取四激励中最大的，从而忽略掉75%的激励</p>
<p>当然还有一些其它pooling的方法，如average pooling和L2-norm pooling在此mark以后深入研究。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/11/machinelearning/tensorflow_notes/note3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/04/11/machinelearning/tensorflow_notes/note3/" itemprop="url">
                  TensorFlow 学习笔记3 Manage EXperiments
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-11T20:59:00+08:00">
                2018-04-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Tensorflow-学习笔记-3"><a href="#Tensorflow-学习笔记-3" class="headerlink" title="Tensorflow 学习笔记 #3"></a>Tensorflow 学习笔记 #3</h1><p><strong>keywords</strong> :  model base, variable sharing, model sharing</p>
<h2 id="构建tensorflow模型的一般步骤"><a href="#构建tensorflow模型的一般步骤" class="headerlink" title="构建tensorflow模型的一般步骤"></a>构建tensorflow模型的一般步骤</h2><p>Phase1: <strong>assenmble graph</strong> </p>
<ol>
<li>Import Data</li>
<li>Define the weigths</li>
<li>Define the inferece model</li>
<li>Define loss function</li>
<li>Define optimizer</li>
</ol>
<p>Phase2: <strong>execute the computation</strong></p>
<ol>
<li>initialize all model variables for the first time</li>
<li>Initialize iterator / feed training data</li>
<li>Excecute the inference model on the training data</li>
<li>compute cost</li>
<li>Adjust model parameters to minimize cost </li>
</ol>
<p>利用python面向对象的性质为自己的模型简历一个类：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, params)</span>:</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_import_data</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">""" Step 1: import data """</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_embedding</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">""" Step 2: in word2vec, it's actually the weights that we care about """</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_loss</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">""" Step 3 + 4: define the inference + the loss function """</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_optimizer</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">""" Step 5: define optimizer """</span></div><div class="line">        <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<h2 id="Variable-Sharing"><a href="#Variable-Sharing" class="headerlink" title="Variable Sharing"></a>Variable Sharing</h2><h3 id="Name-Scope"><a href="#Name-Scope" class="headerlink" title="Name Scope"></a>Name Scope</h3><pre><code>为了能够在tensor board上较为清晰的辨识出节点之间的关系，引入name_scope可将其分组
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.name_scope(name_of_that_scope):</div><div class="line">    <span class="comment"># declare op1</span></div><div class="line">    <span class="comment"># declare op2</span></div><div class="line">    <span class="comment"># declare op3</span></div></pre></td></tr></table></figure>
<h3 id="Variable-Scope"><a href="#Variable-Scope" class="headerlink" title="Variable Scope"></a>Variable Scope</h3><pre><code>使用Varibale scope来做到变量共享，在variable_scope中使用get_variable方法来获取之前创建的变量而不是新的一个变量
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"xxx"</span>) <span class="keyword">as</span> scope:</div><div class="line">    <span class="comment"># a = tf.get_variable("x",.)..</span></div></pre></td></tr></table></figure>
<h2 id="tensorflow-实验管理"><a href="#tensorflow-实验管理" class="headerlink" title="tensorflow 实验管理"></a>tensorflow 实验管理</h2><h3 id="使用checkpoint保存训练中间结果"><a href="#使用checkpoint保存训练中间结果" class="headerlink" title="使用checkpoint保存训练中间结果"></a>使用checkpoint保存训练中间结果</h3><p>对于一个需要较长时间训练的模型来说，断点恢复能力是十分必要的。<br>tensorflow也设置了相应的机制，即为checkpoint，可以用来周期性的保存当前模型的参数等数据。<br>实现这一点的是tf.train.Sacer() 类，它会将图的变量保存在二进制文件当中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">tf.train.Saver.save(</div><div class="line">    sess,</div><div class="line">    save_path,</div><div class="line">    global_step=<span class="keyword">None</span>,</div><div class="line">    latest_filename=<span class="keyword">None</span>,</div><div class="line">    meta_graph_suffix=<span class="string">'meta'</span>,</div><div class="line">    write_meta_graph=<span class="keyword">True</span>,</div><div class="line">    write_state=<span class="keyword">True</span></div><div class="line">)</div></pre></td></tr></table></figure></p>
<p>常用的保存checkpoint的方法如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define model</span></div><div class="line"></div><div class="line"><span class="comment"># create a saver object</span></div><div class="line">saver = tf.train.Saver()</div><div class="line"></div><div class="line"><span class="comment"># launch a session to execute the computation</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="comment"># actual training loop</span></div><div class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(training_steps): </div><div class="line">	sess.run([optimizer])</div><div class="line">	<span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">	   saver.save(sess, <span class="string">'checkpoint_directory/model_name'</span>, global_step=global_step)</div><div class="line">``` </div><div class="line">这里的global_step是一个用来记录图训练了多少步的变量，创建其的时候需要设置其不能被训练。</div><div class="line">（optimizer默认训练所有变量）</div><div class="line">```python</div><div class="line">global_step = tf.Variable(<span class="number">0</span>, dtype=tf.int32, trainable=<span class="keyword">False</span>, name=<span class="string">'global_step'</span>)</div></pre></td></tr></table></figure></p>
<p>optimizer一般也接收一个global_step变量的输入，每一次优化更新之后会将global_step的值自增<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss,global_step=global_step)</div></pre></td></tr></table></figure></p>
<p>tensorflow还支持在一个文件夹里面找checkpoint,如果有合法的，恢复checkpoint,否则继续执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class="string">'checkpoints/checkpoint'</span>))</div><div class="line"><span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</div><div class="line">     saver.restore(sess, ckpt.model_checkpoint_path)</div></pre></td></tr></table></figure></p>
<h3 id="使用tf-summary可视化训练数据"><a href="#使用tf-summary可视化训练数据" class="headerlink" title="使用tf.summary可视化训练数据"></a>使用tf.summary可视化训练数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_create_summaries</span><span class="params">(self)</span>:</span></div><div class="line">     <span class="keyword">with</span> tf.name_scope(<span class="string">"summaries"</span>):</div><div class="line">            tf.summary.scalar(<span class="string">"loss"</span>, self.loss)</div><div class="line">            tf.summary.scalar(<span class="string">"accuracy"</span>, self.accuracy)            </div><div class="line">            tf.summary.histogram(<span class="string">"histogram loss"</span>, self.loss)</div><div class="line">            <span class="comment"># because you have several summaries, we should merge them all</span></div><div class="line">            <span class="comment"># into one op to make it easier to manage</span></div><div class="line">            self.summary_op = tf.summary.merge_all()</div></pre></td></tr></table></figure>
<p>summary_op和其它operation一样，需要在sess中运行得到结果。<br>得到结果之后使用add_summary把结果写入writer当中，就可以在tensorbord中看到add_summary的图的各种曲线啦<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">writer.add_summary(summary, global_step=step)</div></pre></td></tr></table></figure></p>
<p>summary的用法参考<a href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard" target="_blank" rel="external">这里</a></p>
<h3 id="control-randomization"><a href="#control-randomization" class="headerlink" title="control randomization"></a>control randomization</h3><h3 id="Auto-diff"><a href="#Auto-diff" class="headerlink" title="Auto diff"></a>Auto diff</h3>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/31/machinelearning/tensorflow_notes/tf_minist/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/03/31/machinelearning/tensorflow_notes/tf_minist/" itemprop="url">
                  Using tensorflow on Minist
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-31T11:31:00+08:00">
                2018-03-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="使用卷积神经网络预测minist手写数字"><a href="#使用卷积神经网络预测minist手写数字" class="headerlink" title="使用卷积神经网络预测minist手写数字"></a>使用卷积神经网络预测minist手写数字</h1><p>minist是一个入门的标准cv集。<br>详细注释见minist当中注释<br>直接上代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""Convolutional Neural Network Estimator for MNIST, built with tf.layers."""</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">tf.logging.set_verbosity(tf.logging.INFO)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cnn_model_fn</span><span class="params">(features, labels, mode)</span>:</span></div><div class="line">  <span class="string">"""Model function for CNN."""</span></div><div class="line">  <span class="comment"># Input Layer</span></div><div class="line">  <span class="comment"># Reshape X to 4-D tensor: [batch_size, width, height, channels]</span></div><div class="line">  <span class="comment"># MNIST images are 28x28 pixels, and have one color channel</span></div><div class="line">  input_layer = tf.reshape(features[<span class="string">"x"</span>], [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</div><div class="line"></div><div class="line">  <span class="comment"># Convolutional Layer #1</span></div><div class="line">  <span class="comment"># Computes 32 features using a 5x5 filter with ReLU activation.</span></div><div class="line">  <span class="comment"># Padding is added to preserve width and height.</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 28, 28, 1]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 28, 28, 32]</span></div><div class="line">  conv1 = tf.layers.conv2d(</div><div class="line">      inputs=input_layer,</div><div class="line">      filters=<span class="number">32</span>,</div><div class="line">      kernel_size=[<span class="number">5</span>, <span class="number">5</span>],</div><div class="line">      padding=<span class="string">"same"</span>,</div><div class="line">      activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Pooling Layer #1</span></div><div class="line">  <span class="comment"># First max pooling layer with a 2x2 filter and stride of 2</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 28, 28, 32]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 14, 14, 32]</span></div><div class="line">  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Convolutional Layer #2</span></div><div class="line">  <span class="comment"># Computes 64 features using a 5x5 filter.</span></div><div class="line">  <span class="comment"># Padding is added to preserve width and height.</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 14, 14, 32]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 14, 14, 64]</span></div><div class="line">  conv2 = tf.layers.conv2d(</div><div class="line">      inputs=pool1,</div><div class="line">      filters=<span class="number">64</span>,</div><div class="line">      kernel_size=[<span class="number">5</span>, <span class="number">5</span>],</div><div class="line">      padding=<span class="string">"same"</span>,</div><div class="line">      activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Pooling Layer #2</span></div><div class="line">  <span class="comment"># Second max pooling layer with a 2x2 filter and stride of 2</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 14, 14, 64]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 7, 7, 64]</span></div><div class="line">  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Flatten tensor into a batch of vectors</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 7, 7, 64]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 7 * 7 * 64]</span></div><div class="line">  pool2_flat = tf.reshape(pool2, [<span class="number">-1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])</div><div class="line"></div><div class="line">  <span class="comment"># Dense Layer</span></div><div class="line">  <span class="comment"># Densely connected layer with 1024 neurons</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 7 * 7 * 64]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 1024]</span></div><div class="line">  dense = tf.layers.dense(inputs=pool2_flat, units=<span class="number">1024</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Add dropout operation; 0.6 probability that element will be kept</span></div><div class="line">  dropout = tf.layers.dropout(</div><div class="line">      inputs=dense, rate=<span class="number">0.4</span>, training=mode == tf.estimator.ModeKeys.TRAIN)</div><div class="line"></div><div class="line">  <span class="comment"># Logits layer</span></div><div class="line">  <span class="comment"># Input Tensor Shape: [batch_size, 1024]</span></div><div class="line">  <span class="comment"># Output Tensor Shape: [batch_size, 10]</span></div><div class="line">  logits = tf.layers.dense(inputs=dropout, units=<span class="number">10</span>)</div><div class="line"></div><div class="line">  predictions = &#123;</div><div class="line">      <span class="comment"># Generate predictions (for PREDICT and EVAL mode)</span></div><div class="line">      <span class="string">"classes"</span>: tf.argmax(input=logits, axis=<span class="number">1</span>),</div><div class="line">      <span class="comment"># Add `softmax_tensor` to the graph. It is used for PREDICT and by the</span></div><div class="line">      <span class="comment"># `logging_hook`.</span></div><div class="line">      <span class="string">"probabilities"</span>: tf.nn.softmax(logits, name=<span class="string">"softmax_tensor"</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> mode == tf.estimator.ModeKeys.PREDICT:</div><div class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)</div><div class="line"></div><div class="line">  <span class="comment"># Calculate Loss (for both TRAIN and EVAL modes)</span></div><div class="line">  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)</div><div class="line"></div><div class="line">  <span class="comment"># Configure the Training Op (for TRAIN mode)</span></div><div class="line">  <span class="keyword">if</span> mode == tf.estimator.ModeKeys.TRAIN:</div><div class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.001</span>)</div><div class="line">    train_op = optimizer.minimize(</div><div class="line">        loss=loss,</div><div class="line">        global_step=tf.train.get_global_step())</div><div class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)</div><div class="line"></div><div class="line">  <span class="comment"># Add evaluation metrics (for EVAL mode)</span></div><div class="line">  eval_metric_ops = &#123;</div><div class="line">      <span class="string">"accuracy"</span>: tf.metrics.accuracy(</div><div class="line">          labels=labels, predictions=predictions[<span class="string">"classes"</span>])&#125;</div><div class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(</div><div class="line">      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(unused_argv)</span>:</span></div><div class="line">  <span class="comment"># Load training and eval data</span></div><div class="line">  mnist = tf.contrib.learn.datasets.load_dataset(<span class="string">"mnist"</span>)</div><div class="line">  train_data = mnist.train.images  <span class="comment"># Returns np.array</span></div><div class="line">  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)</div><div class="line">  eval_data = mnist.test.images  <span class="comment"># Returns np.array</span></div><div class="line">  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)</div><div class="line"></div><div class="line">  <span class="comment"># Create the Estimator</span></div><div class="line">  mnist_classifier = tf.estimator.Estimator(</div><div class="line">      model_fn=cnn_model_fn, model_dir=<span class="string">"/tmp/mnist_convnet_model"</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Set up logging for predictions</span></div><div class="line">  <span class="comment"># Log the values in the "Softmax" tensor with label "probabilities"</span></div><div class="line">  tensors_to_log = &#123;<span class="string">"probabilities"</span>: <span class="string">"softmax_tensor"</span>&#125;</div><div class="line">  logging_hook = tf.train.LoggingTensorHook(</div><div class="line">      tensors=tensors_to_log, every_n_iter=<span class="number">50</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Train the model</span></div><div class="line">  train_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class="line">      x=&#123;<span class="string">"x"</span>: train_data&#125;,</div><div class="line">      y=train_labels,</div><div class="line">      batch_size=<span class="number">100</span>,</div><div class="line">      num_epochs=<span class="keyword">None</span>,</div><div class="line">      shuffle=<span class="keyword">True</span>)</div><div class="line">  mnist_classifier.train(</div><div class="line">      input_fn=train_input_fn,</div><div class="line">      steps=<span class="number">20000</span>,</div><div class="line">      hooks=[logging_hook])</div><div class="line"></div><div class="line">  <span class="comment"># Evaluate the model and print results</span></div><div class="line">  eval_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class="line">      x=&#123;<span class="string">"x"</span>: eval_data&#125;,</div><div class="line">      y=eval_labels,</div><div class="line">      num_epochs=<span class="number">1</span>,</div><div class="line">      shuffle=<span class="keyword">False</span>)</div><div class="line">  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)</div><div class="line">  print(eval_results)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  tf.app.run()</div></pre></td></tr></table></figure></p>
<p>目前我没弄懂的一点在于，这个框架没用session 也没用eager mode是怎么跑起来的， 如果我想可视化地观察一下这个卷积神经网络的结构又该怎么做呢？</p>
<p>有点明白了，官方的doc当中有这么一句话：<br>Estimators build the graph for you. In other words, you don’t have to build the graph.  </p>
<p>其实在一开始应该早就说明白过了，tensorflow的api是分层级的:<br><img src="./images/tf/tf_api.png" alt=""></p>
<p>如上图estimator 和eager mode是同一层级的，它会自动的帮你构建整个图</p>
<p>TODO: 试着跑一遍代码，用log记录下图的结构，然后在tensorboard里面打开康康。  </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/30/machinelearning/tensorflow_notes/note2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/03/30/machinelearning/tensorflow_notes/note2/" itemprop="url">
                  TensorFlow 学习笔记2
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-30T11:31:00+08:00">
                2018-03-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TensorFlow-学习笔记-2"><a href="#TensorFlow-学习笔记-2" class="headerlink" title="TensorFlow 学习笔记 #2"></a>TensorFlow 学习笔记 #2</h1><p>先来看一个简单的线性回归的代码例子，再来看在其基础上可以做出什么改进<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="keyword">import</span> utils</div><div class="line"></div><div class="line">DATA_FILE = <span class="string">"data/birth_life_2010.txt"</span></div><div class="line"></div><div class="line"><span class="comment"># Step 1: read in data from the .txt file</span></div><div class="line"><span class="comment"># data is a numpy array of shape (190, 2), each row is a datapoint</span></div><div class="line">data, n_samples = utils.read_birth_life_data(DATA_FILE)</div><div class="line"></div><div class="line"><span class="comment"># Step 2: create placeholders for X (birth rate) and Y (life expectancy)</span></div><div class="line">X = tf.placeholder(tf.float32, name=<span class="string">'X'</span>)</div><div class="line">Y = tf.placeholder(tf.float32, name=<span class="string">'Y'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Step 3: create weight and bias, initialized to 0</span></div><div class="line">w = tf.get_variable(<span class="string">'weights'</span>, initializer=tf.constant(<span class="number">0.0</span>))</div><div class="line">b = tf.get_variable(<span class="string">'bias'</span>, initializer=tf.constant(<span class="number">0.0</span>))</div><div class="line"></div><div class="line"><span class="comment"># Step 4: construct model to predict Y (life expectancy from birth rate)</span></div><div class="line">Y_predicted = w * X + b </div><div class="line"></div><div class="line"><span class="comment"># Step 5: use the square error as the loss function</span></div><div class="line">loss = tf.square(Y - Y_predicted, name=<span class="string">'loss'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Step 6: using gradient descent with learning rate of 0.01 to minimize loss</span></div><div class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.001</span>).minimize(loss)</div><div class="line"> </div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	<span class="comment"># Step 7: initialize the necessary variables, in this case, w and b</span></div><div class="line">	sess.run(tf.global_variables_initializer()) </div><div class="line">	</div><div class="line">	<span class="comment"># Step 8: train the model</span></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>): <span class="comment"># run 100 epochs</span></div><div class="line">		<span class="keyword">for</span> x, y <span class="keyword">in</span> data:</div><div class="line">			<span class="comment"># Session runs train_op to minimize loss</span></div><div class="line">			sess.run(optimizer, feed_dict=&#123;X: x, Y:y&#125;) </div><div class="line">	</div><div class="line">	<span class="comment"># Step 9: output the values of w and b</span></div><div class="line">	w_out, b_out = sess.run([w, b])</div></pre></td></tr></table></figure></p>
<h2 id="tensorflow-控制流"><a href="#tensorflow-控制流" class="headerlink" title="tensorflow 控制流"></a>tensorflow 控制流</h2><p>观察上面线性回归所使用的loss function，是个简单的二次函数<br>分析离群点，假设有一个离样本较远的离群点，那么这个离群点造成的loss fuction上的损失较大，会大大影响整个模型的建模。</p>
<p><strong>使用<a href="https://en.wikipedia.org/wiki/Huber_loss" target="_blank" rel="external">huber loss</a>代替原来简单的loss fuction</strong><br>其定义如下所示    </p>
<p>$$<br>L_\delta(y,f(x))=\left{<br>\begin{array}{ll}<br>\frac12(y-f(x))^2,&amp;\textrm{for }|y-f(x)|\leq\delta\\<br>\delta\cdot(|y-f(x)|-\delta/2),&amp; \textrm{otherwise.}<br>\end{array}<br>\right.<br>$$</p>
<p>Huber loss给离群点设置了相对更小的权重,因而提升了拟合的效果。</p>
<p>一个显然的事实是由于tensorflow 定义和执行的分离，我们不能用python的条件分支语句来控制optimizer使用哪一种loss function,tensor flow提供了分支控制的方法</p>
<table>
<thead>
<tr>
<th style="text-align:left">Ops</th>
<th style="text-align:left">Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Control Flow Ops</td>
<td style="text-align:left">tf.count_up_to, tf.cond, tf.case, tf.while_loop, tf.group …</td>
</tr>
<tr>
<td style="text-align:left">Comparison Ops</td>
<td style="text-align:left">tf.equal, tf.not_equal, tf.less, tf.greater, tf.where, …</td>
</tr>
<tr>
<td style="text-align:left">Logical Ops</td>
<td style="text-align:left">tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor</td>
</tr>
<tr>
<td style="text-align:left">Debugging Ops</td>
<td style="text-align:left">tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print, …</td>
</tr>
</tbody>
</table>
<p>huber_loss：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_loss</span><span class="params">(labels, predictions, delta=<span class="number">14.0</span>)</span>:</span></div><div class="line">    residual = tf.abs(labels - predictions)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f1</span><span class="params">()</span>:</span> <span class="keyword">return</span> <span class="number">0.5</span> * tf.square(residual)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f2</span><span class="params">()</span>:</span> <span class="keyword">return</span> delta * residual - <span class="number">0.5</span> * tf.square(delta)</div><div class="line">    <span class="keyword">return</span> tf.cond(residual &lt; delta, f1, f2)</div></pre></td></tr></table></figure></p>
<h2 id="tensorflow-输入"><a href="#tensorflow-输入" class="headerlink" title="tensorflow 输入"></a>tensorflow 输入</h2><h3 id="placeholder-amp-feed-dict"><a href="#placeholder-amp-feed-dict" class="headerlink" title="placeholder &amp; feed_dict"></a>placeholder &amp; feed_dict</h3><p>note1跳过了对tensorflow基本输入方式的叙述。实际上由于graph在定义的时候不需要考虑实际输入数据的特性。一般创建输入变量的时候实际上是为要输入的变量预留位置，使用tf.placeholder定义,如下是一个使用的例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = tf.placeholder(dtype, shape=<span class="keyword">None</span>, name=<span class="keyword">None</span>)</div><div class="line">...</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">   sess.run(something, feed_dict = &#123;a:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;)</div></pre></td></tr></table></figure></p>
<p>shape参数制定了传入的tensor的结构，shape为None意味着任意结构的tensor都能被接收（可能潜在地会引入bug）</p>
<h3 id="tf-data"><a href="#tf-data" class="headerlink" title="tf.data"></a>tf.data</h3><p>placeholder让数据的处理和带入图中运算分开，在tensorflow框架之外完成（完全可以用numpy等工具处理），不过这样带来的不好的地方之一在于，数据处理被放在了python的单一线程当中，会让数据处理较慢。（大量数据要从外部一个个装载到place_holder处）  </p>
<p>如上述代码当中看起来就不优雅的一段：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>): <span class="comment"># run 100 epochs</span></div><div class="line">	<span class="keyword">for</span> x, y <span class="keyword">in</span> data:</div><div class="line">		<span class="comment"># Session runs train_op to minimize loss</span></div><div class="line">		sess.run(optimizer, feed_dict=&#123;X: x, Y:y&#125;)</div></pre></td></tr></table></figure></p>
<p>将数据分100次载入place_holder当中实际上较大的拖慢了程序的速度。还需要考虑的是在并行计算的时候载入feed_dict可能阻碍了其它操作的执行。</p>
<p>tensorflow提供的解决方案是将数据存储在tf.data.Dataset object当中<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tf.data.Dataset.from_tensor_slices((features, labels))</div><div class="line"><span class="comment"># can use numpy arrays as features and labels</span></div></pre></td></tr></table></figure></p>
<p>之后使用迭代器来访问dataset当中的每一个数据<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># we use make_initializable_iterator for multiple epochs</span></div><div class="line">iterator = dataset.make_initializable_iterator()</div><div class="line">X, Y = iterator.get_next() </div><div class="line">···</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>): </div><div class="line">        <span class="comment"># reset where iterator point to</span></div><div class="line">        sess.run(iterator.initializer)</div><div class="line">        total_loss = <span class="number">0</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">                sess.run([optimizer]) </div><div class="line">        <span class="keyword">except</span> tf.errors.OutOfRangeError:</div><div class="line">            <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<p>dataset 也支持许多原生的对数据集的操作来改变数据集或是生成新的数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">dataset = dataset.shuffle(<span class="number">1000</span>)</div><div class="line">dataset = dataset.repeat(<span class="number">100</span>)</div><div class="line">dataset = dataset.batch(<span class="number">128</span>)</div><div class="line">dataset = dataset.map(<span class="keyword">lambda</span> x: tf.one_hot(x, <span class="number">10</span>)) </div><div class="line"><span class="comment"># convert each element of dataset to one_hot vector</span></div></pre></td></tr></table></figure></p>
<h2 id="Optimizers"><a href="#Optimizers" class="headerlink" title="Optimizers"></a>Optimizers</h2><p>默认情况下optimizer在每一轮迭代的过程中自动更新loss function所依赖的所有变量，若有不想更新的变量，在定义的时候加上参数trainable=False</p>
<p>(to do: add contont about more detailed control of model trains using tf.gradient)</p>
<h2 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h2><p><a href="https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit#" target="_blank" rel="external">03_Lecture note_Linear and Logistic Regression</a><br><a href="https://en.wikipedia.org/wiki/Huber_loss" target="_blank" rel="external">Huber Loss</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/26/machinelearning/tensorflow_notes/note1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/03/26/machinelearning/tensorflow_notes/note1/" itemprop="url">
                  TensorFlow 学习笔记1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-26T10:10:32+08:00">
                2018-03-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TensorFlow-学习笔记-1"><a href="#TensorFlow-学习笔记-1" class="headerlink" title="TensorFlow 学习笔记 #1"></a>TensorFlow 学习笔记 #1</h1><h2 id="TensorFlow-Basics"><a href="#TensorFlow-Basics" class="headerlink" title="TensorFlow Basics"></a>TensorFlow Basics</h2><h3 id="Graphs-and-Sessions"><a href="#Graphs-and-Sessions" class="headerlink" title="Graphs and Sessions"></a>Graphs and Sessions</h3><p>首先，需要和普通python程序区别出来的是，tensorflow将计算的定义和具体执行过程分离开来，个人认为这有点像函数式中的求值运算。  </p>
<p>不过tensorflow的特点在于其把所依赖的所有计算转换成一个数据流图（dag）</p>
<p><img src="./images/tf/tensor_data_flow_graph.png" alt="数据流图"></p>
<ol>
<li>根据输入构成数据流图</li>
<li>创建会话，执行操作</li>
</ol>
<p>用图的优点有如下几个：  </p>
<ol>
<li>能够保存计算结果。只会运行你所期望得到值的子图。</li>
<li>易于分布任务，进行分布式的计算</li>
<li>Break computation into small, differential pieces to facilitate auto-differentiation</li>
<li>Many common machine learning models are taught and visualized as directed graphs</li>
</ol>
<p><strong>何为TensorFlow?</strong><br><strong>Tensor</strong>: An n-dimensional array<br>0-d tensor: scalar (number)<br>1-d tensor: vector<br>2-d tensor: matrix  </p>
<h2 id="Tensorflow-ops"><a href="#Tensorflow-ops" class="headerlink" title="Tensorflow ops"></a>Tensorflow ops</h2><h3 id="TensorBorad"><a href="#TensorBorad" class="headerlink" title="TensorBorad"></a>TensorBorad</h3><p>Tensorborad 使用通过将图的节点信息和图中的操作记入event files当中来完成整个流程的可视化，使用如下代码创建event files以及停止记录<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># use tf.get_default_graph() to get default graph</span></div><div class="line">writer = tf.summary.FileWriter([logdir], [graph])</div><div class="line"><span class="comment"># ...</span></div><div class="line">writer.close()</div></pre></td></tr></table></figure></p>
<p>之后运行python代码并打开tensorboard<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ python3 [my_program.py] </div><div class="line">$ tensorboard --logdir=<span class="string">"./graphs"</span> --port 6006</div></pre></td></tr></table></figure></p>
<p>但是我们此时看到的图每个节点我们无法对上名字，这就要在定义图的时候给出其的名字<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">a = tf.constant(<span class="number">2</span>, name=<span class="string">"a"</span>)</div><div class="line">b = tf.constant(<span class="number">2</span>, name=<span class="string">"b"</span>)</div><div class="line">x = tf.add(a, b, name=<span class="string">"add"</span>)</div></pre></td></tr></table></figure></p>
<h3 id="Some-useful-tricks"><a href="#Some-useful-tricks" class="headerlink" title="Some useful tricks"></a>Some useful tricks</h3><h4 id="查看protobuf"><a href="#查看protobuf" class="headerlink" title="查看protobuf"></a>查看protobuf</h4><p>常数存储在函数的定义当中，通过查看图的protobuf(protocol buffer)来查看图定义当中的内容。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">my_const = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>], name=<span class="string">"my_const"</span>)</div><div class="line">print(tf.get_default_graph().as_graph_def())</div></pre></td></tr></table></figure></p>
<p>Output :<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">node &#123;</div><div class="line">  name: "my_const"</div><div class="line">  op: "Const"</div><div class="line">  attr &#123;</div><div class="line">    key: "dtype"</div><div class="line">    value &#123;</div><div class="line">      type: DT_FLOAT</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  attr &#123;</div><div class="line">    key: "value"</div><div class="line">    value &#123;</div><div class="line">      tensor &#123;</div><div class="line">        dtype: DT_FLOAT</div><div class="line">        tensor_shape &#123;</div><div class="line">          dim &#123;</div><div class="line">            size: 2</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">        tensor_content: "\000\000\200?\000\000\000@"</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">versions &#123;</div><div class="line">  producer: 24</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="变量的声明和初始化"><a href="#变量的声明和初始化" class="headerlink" title="变量的声明和初始化"></a>变量的声明和初始化</h4><p>为了变量共享的方便 官方推荐使用tf.get_variable方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">s = tf.get_variable(<span class="string">"scalar"</span>, initializer=tf.constant(<span class="number">2</span>)) </div><div class="line">m = tf.get_variable(<span class="string">"matrix"</span>, initializer=tf.constant([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]]))</div><div class="line">W = tf.get_variable(<span class="string">"big_matrix"</span>, shape=(<span class="number">784</span>, <span class="number">10</span>), initializer=tf.zeros_initializer())</div></pre></td></tr></table></figure></p>
<p>同时可以较简单的初始化变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	sess.run(tf.global_variables_initializer())</div></pre></td></tr></table></figure></p>
<h4 id="Assign-a-variable"><a href="#Assign-a-variable" class="headerlink" title="Assign a variable"></a>Assign a variable</h4><p>观察如下程序<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(<span class="number">10</span>)</div><div class="line">W.assign(<span class="number">100</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	sess.run(W.initializer)</div><div class="line">	print(W.eval()) <span class="comment"># &gt;&gt; 10</span></div></pre></td></tr></table></figure></p>
<p>结果输出是10，但为什么不是100呢。注意的是，之前也说过，tensorflow的声明和运行是分离的，W.assign(100)创建了一个assign操作，但是我们并没有运行它，所以应该按照如下写<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(<span class="number">10</span>)</div><div class="line">assign_op = W.assign(<span class="number">100</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	sess.run(assign_op)</div><div class="line">	print(W.eval()) <span class="comment"># &gt;&gt; 100</span></div></pre></td></tr></table></figure></p>
<h4 id="Sessions"><a href="#Sessions" class="headerlink" title="Sessions"></a>Sessions</h4><p>会话独自保存值，因而假如有两个不同的会话对同一个变量进行操作，其得到最终的值也有可能不相同。<br>有时候为了方便可以使用interactive session来隐式地run session<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sess = tf.InteractiveSession()</div><div class="line">a = tf.constant(<span class="number">5.0</span>)</div><div class="line">b = tf.constant(<span class="number">6.0</span>)</div><div class="line">c = a * b</div><div class="line">print(c.eval()) <span class="comment"># we can use 'c.eval()' without explicitly stating a session</span></div><div class="line">sess.close()</div></pre></td></tr></table></figure></p>
<p>tf.get_default_session()返回当前进程的默认session</p>
<h4 id="the-trap-of-lazy-loading"><a href="#the-trap-of-lazy-loading" class="headerlink" title="the trap of lazy loading"></a>the trap of lazy loading</h4><p>考虑如下代码有什么不好的地方<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">x = tf.Variable(10, name=&apos;x&apos;)</div><div class="line">y = tf.Variable(20, name=&apos;y&apos;)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">	sess.run(tf.global_variables_initializer())</div><div class="line">	writer = tf.summary.FileWriter(&apos;graphs/lazy_loading&apos;, sess.graph)</div><div class="line">	for _ in range(10):</div><div class="line">		sess.run(tf.add(x, y))</div><div class="line">	print(tf.get_default_graph().as_graph_def()) </div><div class="line">	writer.close()</div></pre></td></tr></table></figure></p>
<p>sess.run(tf.add(x, y))这一句会将tf.add(x,y)这个操作创建10次，造成网络的大量冗余<br>考虑解决方案：</p>
<ol>
<li>总是将操作的定义与执行分离开来</li>
<li>使用python的@property来保证你的函数只被调用一次</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/22/开关反转问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/09/22/开关反转问题/" itemprop="url">
                  开关反转问题
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-22T04:19:25+08:00">
                2017-09-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstring&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXN 50</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> sc(x) scanf(<span class="meta-string">"%d"</span>,&amp;(x))</span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> INF = <span class="number">0x3f3f3f3f</span>;</div><div class="line"><span class="keyword">int</span> a[MAXN][MAXN];</div><div class="line"><span class="keyword">int</span> p[MAXN][MAXN];</div><div class="line"><span class="keyword">int</span> f[MAXN][MAXN][MAXN];</div><div class="line"><span class="keyword">int</span> x[MAXN];</div><div class="line"><span class="keyword">int</span> mark[MAXN];</div><div class="line"><span class="keyword">int</span> M,N;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">gauss</span><span class="params">(<span class="keyword">int</span> equ,<span class="keyword">int</span> vars)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> i=<span class="number">0</span>,j=<span class="number">0</span>;</div><div class="line">	<span class="built_in">memset</span>(mark,<span class="number">0</span>,<span class="keyword">sizeof</span>(mark));</div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>,j=<span class="number">0</span>; i&lt;equ &amp;&amp; j&lt;vars; i++,j++)&#123;</div><div class="line">		<span class="keyword">int</span> max_r = i;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> k=i+<span class="number">1</span>; k&lt;equ; k++)</div><div class="line">			<span class="keyword">if</span>(a[k][j]&gt;a[max_r][j])</div><div class="line">				max_r = k;</div><div class="line">        <span class="keyword">if</span>(max_r!=i)</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>; k&lt;=vars; k++)</div><div class="line">                swap(a[i][k],a[max_r][k]);</div><div class="line">        <span class="keyword">if</span>(a[i][j]==<span class="number">0</span>)&#123;</div><div class="line">            mark[j] = <span class="number">1</span>;</div><div class="line">            i--;	<span class="keyword">continue</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> k=i+<span class="number">1</span>; k&lt;equ; k++)&#123;</div><div class="line">            <span class="keyword">if</span>(a[k][j])</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> m=j; m&lt;=vars; m++)</div><div class="line">                    a[k][m] = a[k][m]^a[i][m];</div><div class="line">        &#125;</div><div class="line">	&#125;</div><div class="line">	i--;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> k=vars<span class="number">-1</span>; k&gt;=<span class="number">0</span>; k--)&#123;</div><div class="line">		<span class="keyword">if</span>(mark[k])&#123;</div><div class="line">			x[k] = <span class="number">1</span>;	<span class="keyword">continue</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span>(i&lt;<span class="number">0</span>) <span class="keyword">break</span>;</div><div class="line">		<span class="keyword">int</span> res = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> m=k+<span class="number">1</span>; m&lt;vars; m++)</div><div class="line">			res ^= a[i][m]&amp;x[m];</div><div class="line">		x[i--] = res;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j,<span class="keyword">int</span> k)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> ans = f[i][j][k] + f[i<span class="number">-1</span>][j][k] + f[i][j<span class="number">-1</span>][k] + f[i][j+<span class="number">1</span>][k];</div><div class="line">	<span class="keyword">return</span> ans%<span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">getans</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> ans = p[i][j] + p[i<span class="number">-1</span>][j] + p[i][j<span class="number">-1</span>] + p[i][j+<span class="number">1</span>];</div><div class="line">	<span class="keyword">return</span> ans%<span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> t;</div><div class="line">	sc(t);</div><div class="line">	<span class="keyword">while</span>(t--)&#123;</div><div class="line">		sc(N),sc(M);</div><div class="line">		<span class="built_in">memset</span>(a,<span class="number">0</span>,<span class="keyword">sizeof</span>(a));</div><div class="line">		<span class="built_in">memset</span>(p,<span class="number">0</span>,<span class="keyword">sizeof</span>(p));</div><div class="line">		<span class="built_in">memset</span>(f,<span class="number">0</span>,<span class="keyword">sizeof</span>(f));</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">1</span>; k&lt;=M; k++)</div><div class="line">		&#123;</div><div class="line">			f[<span class="number">1</span>][k][k] = <span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;=N+<span class="number">1</span>; i++)</div><div class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=M; j++)</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">1</span>; k&lt;=M; k++)</div><div class="line">                    f[i][j][k] = get(i<span class="number">-1</span>,j,k);</div><div class="line"></div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;M; i++)</div><div class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;M; j++)</div><div class="line">				a[i][j] = f[N+<span class="number">1</span>][i+<span class="number">1</span>][j+<span class="number">1</span>];</div><div class="line">		gauss(M,M);</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=M; i++)</div><div class="line">			p[<span class="number">1</span>][i] = x[i<span class="number">-1</span>];</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;=N; i++)</div><div class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=M; j++)</div><div class="line">				p[i][j] = getans(i<span class="number">-1</span>,j);</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=N; i++)&#123;</div><div class="line">			<span class="built_in">printf</span>(<span class="string">"%d"</span>,p[i][<span class="number">1</span>]);</div><div class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">2</span>; j&lt;=M; j++)</div><div class="line">				<span class="built_in">printf</span>(<span class="string">" %d"</span>,p[i][j]);</div><div class="line">			<span class="built_in">printf</span>(<span class="string">"\n"</span>);</div><div class="line"> 	    &#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/21/高斯消元求解带模方程组/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/09/21/高斯消元求解带模方程组/" itemprop="url">
                  高斯消元求解带模方程组
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-21T02:26:04+08:00">
                2017-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/acm/" itemprop="url" rel="index">
                    <span itemprop="name">ACM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>HDU-5755<br>一类开关问题<br>做法是设第一行各个位置操作为x1~xn次那么就可以最后一直推下去<br>推出第n+1行所需要的操作个数一定都为0,这样就得到了一个n个变量的方程组<br>用高斯消元求出解都推出来就行</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> MOD = <span class="number">3</span>;</div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> INF = <span class="number">0x3f3f3f3f</span>;</div><div class="line"><span class="keyword">int</span> a[MAXN][MAXN];</div><div class="line"><span class="keyword">int</span> x[MAXN];</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">gcd</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> t;</div><div class="line">	<span class="keyword">while</span>(b != <span class="number">0</span>)&#123;</div><div class="line">		t = b;</div><div class="line">		b = a%b;</div><div class="line">		a = t;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> a;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">exgcd</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b,<span class="keyword">int</span> &amp;x,<span class="keyword">int</span> &amp;y,<span class="keyword">int</span> &amp;d)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">if</span>(b==<span class="number">0</span>)&#123;</div><div class="line">		x = <span class="number">1</span>; y=<span class="number">0</span>; d = a;	<span class="keyword">return</span>;</div><div class="line">	&#125;</div><div class="line">	exgcd(b,a%b,x,y,d);</div><div class="line">	<span class="keyword">int</span> t = x;</div><div class="line">	x = y;</div><div class="line">	y = t - (a/b)*y;</div><div class="line">	<span class="keyword">return</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">lcm</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</div><div class="line">	<span class="keyword">return</span> a*b/gcd(a,b);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">inv</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> mod)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> x,y,d;</div><div class="line">	exgcd(a,mod,x,y,d);</div><div class="line">	<span class="keyword">return</span> (x+mod)%mod;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">gauss</span><span class="params">(<span class="keyword">int</span> rows,<span class="keyword">int</span> var)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> col,k,max_r;</div><div class="line">	<span class="keyword">for</span>(col=<span class="number">0</span>,k=<span class="number">0</span>; col&lt;var &amp;&amp; k&lt;rows; col++,k++)&#123;</div><div class="line">		max_r = k;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=k+<span class="number">1</span>; i&lt;rows; i++)</div><div class="line">			<span class="keyword">if</span>(<span class="built_in">abs</span>(a[i][col])&gt;<span class="built_in">abs</span>(a[k][col]))</div><div class="line">				max_r = i;</div><div class="line">		<span class="keyword">if</span>(a[max_r][col]==<span class="number">0</span>)&#123;</div><div class="line">			k--; <span class="keyword">continue</span>;	<span class="comment">//Jump to next variable</span></div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span>(max_r!=k)</div><div class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;var+<span class="number">1</span>; i++)</div><div class="line">				swap(a[k][i],a[max_r][i]);</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=k+<span class="number">1</span>; i&lt;rows; i++)&#123;</div><div class="line">			<span class="keyword">if</span>(a[i][col]!=<span class="number">0</span>)&#123;</div><div class="line">				<span class="keyword">int</span> LCM = lcm(a[k][col],a[i][col]);</div><div class="line">				<span class="keyword">int</span> tk = LCM/a[k][col];</div><div class="line">				<span class="keyword">int</span> ti = LCM/a[i][col];</div><div class="line">				<span class="keyword">for</span>(<span class="keyword">int</span> j=col; j&lt;var+<span class="number">1</span>; j++)</div><div class="line">					a[i][j] = ((a[i][j]*ti - a[k][j]*tk)%MOD+MOD)%MOD;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=k; i&lt;rows; i++)</div><div class="line">		<span class="keyword">if</span>(a[i][col]!=<span class="number">0</span>)</div><div class="line">			<span class="keyword">return</span> <span class="number">-1</span>;				<span class="comment">//</span></div><div class="line">	<span class="keyword">if</span>(rows&lt;var) <span class="keyword">return</span> rows-var;	<span class="comment">//</span></div><div class="line"></div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=var<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)&#123;</div><div class="line">		<span class="keyword">int</span> temp = a[i][var];</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> j=i+<span class="number">1</span>; j&lt;var; j++)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">if</span>(a[i][j]!=<span class="number">0</span>)&#123;</div><div class="line">				temp -= a[i][j]*x[j];</div><div class="line">				temp = (temp%MOD+MOD)%MOD;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		x[i] = (temp*inv(a[i][i],MOD))%MOD;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">int</span> T,N,M;</div><div class="line"><span class="keyword">int</span> m[<span class="number">50</span>][<span class="number">50</span>];</div><div class="line"><span class="keyword">int</span> f[<span class="number">50</span>][<span class="number">50</span>][<span class="number">50</span>];</div><div class="line"><span class="keyword">int</span> p[<span class="number">50</span>][<span class="number">50</span>];</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j,<span class="keyword">int</span> k)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">int</span> ans = (f[i][j<span class="number">-1</span>][k]+<span class="number">2</span>*f[i][j][k]+f[i][j+<span class="number">1</span>][k]+f[i<span class="number">-1</span>][j][k])%MOD;</div><div class="line">    <span class="keyword">return</span> ((<span class="number">3</span>-ans)%MOD+MOD)%MOD;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">getans</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">int</span> ans = (p[i][j<span class="number">-1</span>]+<span class="number">2</span>*p[i][j]+p[i][j+<span class="number">1</span>]+p[i<span class="number">-1</span>][j]+m[i][j])%MOD;</div><div class="line">    <span class="keyword">return</span> ((<span class="number">3</span>-ans)%MOD+MOD)%MOD;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">	sc(T);</div><div class="line">	<span class="keyword">while</span>(T--)&#123;</div><div class="line">		sc(N);	sc(M);</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=N; i++)</div><div class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=M; j++)</div><div class="line">				sc(m[i][j]);</div><div class="line">		<span class="built_in">memset</span>(a,<span class="number">0</span>,<span class="keyword">sizeof</span>(a));</div><div class="line">        <span class="built_in">memset</span>(f,<span class="number">0</span>,<span class="keyword">sizeof</span>(f));</div><div class="line">        <span class="built_in">memset</span>(p,<span class="number">0</span>,<span class="keyword">sizeof</span>(p));</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=M; i++)</div><div class="line">			f[<span class="number">0</span>][i][i] = <span class="number">1</span>;</div><div class="line">		<span class="keyword">int</span> cur = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=N; i++)&#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=M; j++)&#123;</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">1</span>; k&lt;=M; k++)</div><div class="line">                    f[i][j][k] = get(i<span class="number">-1</span>,j,k);</div><div class="line">                f[i][j][M+<span class="number">1</span>] = (<span class="number">3</span> - m[i][j] + get(i<span class="number">-1</span>,j,M+<span class="number">1</span>))%MOD;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;M; i++)&#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;M; j++)</div><div class="line">                a[i][j] = f[N][i+<span class="number">1</span>][j+<span class="number">1</span>];</div><div class="line">            a[i][M] = (<span class="number">3</span>-f[N][i+<span class="number">1</span>][M+<span class="number">1</span>])%MOD;</div><div class="line">		&#125;</div><div class="line">        gauss(M,M);</div><div class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=M; i++)</div><div class="line">            p[<span class="number">1</span>][i] = x[i<span class="number">-1</span>],ans += p[<span class="number">1</span>][i];</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;=N; i++)</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=M; j++)</div><div class="line">                p[i][j] = getans(i<span class="number">-1</span>,j),ans += p[i][j];</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,ans);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=N; i++)</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=M; j++)</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>; k&lt;p[i][j]; k++)</div><div class="line">                    <span class="built_in">printf</span>(<span class="string">"%d %d\n"</span>,i,j);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/18/求最小割最少边数/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/09/18/求最小割最少边数/" itemprop="url">
                  求最小割最少边数
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-18T22:01:39+08:00">
                2017-09-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/acm/" itemprop="url" rel="index">
                    <span itemprop="name">ACM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>给有向图，求一个最小割，它的边数也最小<br>搜了原题题解，发现一堆假算法==<br>假算法说什么将满流边置为1 其它边置为INF 感觉不科学<br>因为考虑有不同种最大流情况的图，不同的最大流情况会导致算出来的结果不一样。</p>
<p>AC的解法是对于每条边的容量乘上一个大于边数的数+1,最后再模上这个数。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstring&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXN 5000</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> sc(x) scanf(<span class="meta-string">"%d"</span>,&amp;(x))</span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> INF = <span class="number">0x3f3f3f3f</span>;</div><div class="line"></div><div class="line"><span class="keyword">struct</span> edge&#123;</div><div class="line">	<span class="keyword">int</span> t,cap,next;</div><div class="line">&#125;;</div><div class="line">edge e[MAXN];</div><div class="line"><span class="keyword">int</span> cnt;</div><div class="line"><span class="keyword">int</span> head[MAXN];</div><div class="line"><span class="keyword">int</span> n,m,s,t;</div><div class="line"><span class="keyword">int</span> iter[MAXN],level[MAXN];</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_edge</span><span class="params">(<span class="keyword">int</span> f,<span class="keyword">int</span> t,<span class="keyword">int</span> cap)</span></span>&#123;</div><div class="line">	e[cnt].t = t;	e[cnt].cap = cap;	e[cnt].next = head[f];</div><div class="line">	head[f] = cnt++;</div><div class="line">	e[cnt].t = f;	e[cnt].cap = <span class="number">0</span>;	e[cnt].next = head[t];</div><div class="line">	head[t] = cnt++;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bfs</span><span class="params">(<span class="keyword">int</span> s,<span class="keyword">int</span> t)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="built_in">memset</span>(level,<span class="number">-1</span>,<span class="keyword">sizeof</span>(level));</div><div class="line">	level[s] = <span class="number">0</span>;</div><div class="line">	<span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</div><div class="line">	q.push(s);</div><div class="line">	<span class="keyword">while</span>(!q.empty())&#123;</div><div class="line">		<span class="keyword">int</span> cur = q.front(); q.pop();</div><div class="line">		<span class="keyword">if</span>(cur==t) <span class="keyword">break</span>;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=head[cur]; i!=<span class="number">-1</span>; i=e[i].next)&#123;</div><div class="line">			<span class="keyword">int</span> v = e[i].t;</div><div class="line">			<span class="keyword">if</span>(level[v]&lt;<span class="number">0</span> &amp;&amp; e[i].cap&gt;<span class="number">0</span>)&#123;</div><div class="line">				level[v] = level[cur] + <span class="number">1</span>;</div><div class="line">				q.push(v);</div><div class="line">			&#125;	</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> u,<span class="keyword">int</span> t,<span class="keyword">int</span> flow)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">if</span>(u==t) <span class="keyword">return</span> flow;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> &amp;i=iter[u]; i!=<span class="number">-1</span>; i=e[i].next)&#123;</div><div class="line">		<span class="keyword">int</span> v = e[i].t;</div><div class="line">		<span class="keyword">if</span>(level[v]&gt;level[u] &amp;&amp; e[i].cap&gt;<span class="number">0</span>)&#123;</div><div class="line">			<span class="keyword">int</span> val = dfs(v,t,min(flow,e[i].cap));</div><div class="line">			<span class="keyword">if</span>(val&gt;<span class="number">0</span>)&#123;</div><div class="line">				e[i].cap -= val;</div><div class="line">				e[i^<span class="number">1</span>].cap +=val;</div><div class="line">				<span class="keyword">return</span> val;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">Dinic</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> ans = <span class="number">0</span>;</div><div class="line">	<span class="keyword">while</span>(<span class="number">1</span>)&#123;</div><div class="line">		bfs(s,t);</div><div class="line">	<span class="comment">//	for(int i=1; i&lt;=n; i++)</span></div><div class="line">	<span class="comment">//		cout&lt;&lt;"level "&lt;&lt;i&lt;&lt;": "&lt;&lt;level[i]&lt;&lt;endl;</span></div><div class="line">		<span class="keyword">if</span>(level[t]&lt;<span class="number">0</span>) <span class="keyword">break</span>;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; i++)</div><div class="line">			iter[i] = head[i];</div><div class="line">		<span class="keyword">int</span> val;</div><div class="line">		<span class="keyword">while</span>(val=dfs(s,t,INF))&#123;</div><div class="line">			<span class="comment">//cout&lt;&lt;"val: "&lt;&lt;val&lt;&lt;endl;</span></div><div class="line">			ans += val;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> ans;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> T;</div><div class="line">	sc(T);</div><div class="line">	<span class="keyword">while</span>(T--)&#123;</div><div class="line">		sc(n); sc(m);</div><div class="line">		sc(s); sc(t);</div><div class="line">		cnt = <span class="number">0</span>;</div><div class="line">		<span class="built_in">memset</span>(head,<span class="number">-1</span>,<span class="keyword">sizeof</span>(head));</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;m; i++)&#123;</div><div class="line">			<span class="keyword">int</span> u,v,w;</div><div class="line">			sc(u); sc(v); sc(w);</div><div class="line">			add_edge(u,v,w*<span class="number">1000</span>+<span class="number">1</span>);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">int</span> ans = Dinic();</div><div class="line">		<span class="built_in">cout</span>&lt;&lt;ans%<span class="number">1000</span>&lt;&lt;<span class="built_in">endl</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/14/沈阳网络赛2017/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="muchenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JonassenLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/09/14/沈阳网络赛2017/" itemprop="url">
                  沈阳网络赛2017
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-14T16:11:20+08:00">
                2017-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/acm/" itemprop="url" rel="index">
                    <span itemprop="name">ACM</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>hdu 6199 dp<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">ll dp[<span class="number">2</span>][<span class="number">350</span>][<span class="number">220</span>];</div><div class="line">ll sum[<span class="number">40020</span>];</div><div class="line">ll v[<span class="number">40020</span>];</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">int</span> t,n;</div><div class="line">    sc(t);</div><div class="line">    <span class="keyword">while</span>(t--)&#123;</div><div class="line">        sc(n);</div><div class="line">        sum[<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; i++)&#123;</div><div class="line">            <span class="built_in">scanf</span>(<span class="string">"%lld"</span>,v+i);</div><div class="line">            sum[i] = sum[i<span class="number">-1</span>]+v[i];</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">memset</span>(dp,<span class="number">0</span>,<span class="keyword">sizeof</span>(dp));</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=n; i&gt;=<span class="number">1</span>; i--)&#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>; j*j&lt;=<span class="number">2</span>*i; j++)&#123;</div><div class="line">                <span class="keyword">if</span>(i+j==n+<span class="number">1</span>)&#123;</div><div class="line">                    dp[<span class="number">0</span>][i&amp;mod][j] = sum[n]-sum[i<span class="number">-1</span>];</div><div class="line">                    dp[<span class="number">1</span>][i&amp;mod][j] = sum[i<span class="number">-1</span>] - sum[n];</div><div class="line">                    <span class="keyword">break</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span>(i+j&gt;n+<span class="number">1</span>) <span class="keyword">continue</span>;</div><div class="line">                dp[<span class="number">0</span>][i&amp;mod][j] = max(dp[<span class="number">1</span>][(i+j)&amp;mod][j], dp[<span class="number">1</span>][(i+j+<span class="number">1</span>)&amp;mod][j+<span class="number">1</span>]+v[i+j]) + sum[i+j<span class="number">-1</span>] - sum[i<span class="number">-1</span>];</div><div class="line">                dp[<span class="number">1</span>][i&amp;mod][j] = min(dp[<span class="number">0</span>][(i+j)&amp;mod][j], dp[<span class="number">0</span>][(i+j+<span class="number">1</span>)&amp;mod][j+<span class="number">1</span>]-v[i+j]) - sum[i+j<span class="number">-1</span>] + sum[i<span class="number">-1</span>];</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">cout</span>&lt;&lt;dp[<span class="number">0</span>][<span class="number">1</span>][<span class="number">1</span>]&lt;&lt;<span class="built_in">endl</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>hdu 6201 树上DP<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> node&#123;</div><div class="line">    <span class="keyword">int</span> to,cost,next;</div><div class="line">&#125;e[MAXN];</div><div class="line"><span class="keyword">int</span> head[MAXN];</div><div class="line"><span class="keyword">int</span> val[MAXN];</div><div class="line"><span class="keyword">int</span> dp[<span class="number">2</span>][MAXN];</div><div class="line"><span class="keyword">int</span> cnt = <span class="number">0</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_edge</span><span class="params">(<span class="keyword">int</span> f,<span class="keyword">int</span> t,<span class="keyword">int</span> c)</span></span></div><div class="line">&#123;</div><div class="line">    e[cnt].to = t;</div><div class="line">    e[cnt].cost = c;</div><div class="line">    e[cnt].next = head[f];</div><div class="line">    head[f] = cnt;</div><div class="line">    cnt++;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> u,<span class="keyword">int</span> pre)</span></span></div><div class="line">&#123;</div><div class="line">    dp[<span class="number">0</span>][u] = -val[u];</div><div class="line">    dp[<span class="number">1</span>][u] = val[u];</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=head[u]; i!=<span class="number">-1</span>; i=e[i].next)&#123;</div><div class="line">        <span class="keyword">int</span> v = e[i].to;</div><div class="line">        <span class="keyword">int</span> cost = e[i].cost;</div><div class="line">        <span class="keyword">if</span>(pre==v) <span class="keyword">continue</span>;</div><div class="line">        dfs(v,u);</div><div class="line">        dp[<span class="number">0</span>][u] = max(dp[<span class="number">0</span>][u],dp[<span class="number">0</span>][v]-cost);</div><div class="line">        dp[<span class="number">1</span>][u] = max(dp[<span class="number">1</span>][u],dp[<span class="number">1</span>][v]-cost);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">int</span> t,n;</div><div class="line">    sc(t);</div><div class="line">    <span class="keyword">while</span>(t--)&#123;</div><div class="line">        sc(n);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; i++) sc(val[i]);</div><div class="line">        <span class="built_in">memset</span>(head,<span class="number">-1</span>,<span class="keyword">sizeof</span>(head));</div><div class="line">        <span class="built_in">memset</span>(dp,<span class="number">0</span>,<span class="keyword">sizeof</span>(dp));</div><div class="line">        cnt = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;n; i++)&#123;</div><div class="line">            <span class="keyword">int</span> f,t,c;</div><div class="line">            sc(f);  sc(t); sc(c);</div><div class="line">            add_edge(f,t,c);</div><div class="line">            add_edge(t,f,c);</div><div class="line">        &#125;</div><div class="line">        dfs(<span class="number">1</span>,<span class="number">-1</span>);</div><div class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; i++)&#123;</div><div class="line">            ans = max(ans,dp[<span class="number">0</span>][i]+dp[<span class="number">1</span>][i]);</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,ans);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/cat.jpg"
               alt="muchenli" />
          <p class="site-author-name" itemprop="name">muchenli</p>
           
              <p class="site-description motion-element" itemprop="description">salty fish jojo23333's personal page</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">30</span>
                <span class="site-state-item-name">Artikel</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">Kategorien</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/jojo23333" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">muchenli</span>
</div>


<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


  

</body>
</html>
