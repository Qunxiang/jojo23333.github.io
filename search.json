[{"title":"STTN tf Implementation","url":"/2018/09/17/sensetime/STTN-tf-Implementation/","content":"# STTN tensorflow 实现\n## 前要\n这篇文章是论文 [Spatio-Temporal Transformer Network for Video Restoration.](http://openaccess.thecvf.com/content_ECCV_2018/html/Tae_Hyun_Kim_Spatio-temporal_Transformer_Network_ECCV_2018_paper.html)的实现，之前有写过这篇论文的解析 [传送门](../STTN-论文笔记)\n第一次尝试用tensorflow复现论文..（；´д｀）ゞ而且还是从头写，虽然之前也片片段段的写过一点，不过从头写感觉就是不一样啊,这里先贴一点我用到的资料吧。  \n* 我发现tensorflow所有文档里面除了api以外..[guide](https://tensorflow.google.cn/programmers_guide/)最好用..\n* STN --> STNN STN Offical Repo: https://github.com/kevinzakka/spatial-transformer-network\n* 尝试理解一个构造模式也不错，由于原论文refer到了我参考了VDSR 的 tensorflow-repo: https://github.com/Jongchan/tensorflow-vdsr\n\n## network architecture\n虽然network architecture在之前一篇文章里面也有提到过，这里就提一些细节吧，整体的网络结构和\n* U—net 包括下采样层和上采样层两个部分，与U-net论文里提到的U-net不同，这里的U-net下采样通过stride=2的卷积层来做到，而不是池化层。而上采样使用的是双线性插值。（这里面的两点区别有待仔细考虑，例如用反卷积会怎么样？）\n* Spatio-Temporal Sampler 实现类似于STN（其实觉得这种能自动算gradient很神奇，有时间仔细观察一下tensorboard理解一下这里咋back propoagate）\n* Image proccesing part 我就简单的使用了他video restoration network 里面的resnet-9\n\ntensorboard 可视化之后结果大概这样：  \n\n| unet部分 | res9部分 |\n| :-  | :-  |\n| ![](/images/sttn/unet.png) | ![](/images/sttn/res9.png) |\n\n\n## 有关数据集\n### Self-made VideoScenes 数据集\n这个论文既不公开代码也不公开数据集=。=。我参考了这篇论文refer的一些论文用的数据集，发现很多都是通过下载网站上的HD Video来搞的。然后同样是参考了这篇论文refer的论文的一些数据。发现它download的一些数据集大多是一些运动类的高清数据集。于是我也采用了类似的数据集（不过video还是自己手动一个一个去download的）。  \n下好20多个时长在5~10分钟不等的video后，我发现一个严重的问题，那就是这些视频大多数由多个连续镜头剪辑在一起形成。而且有的还有片头片尾，我必须要考虑如下的一些事情：\n1. **场景分割**。 不能简单地把视频转化为帧，必须要考虑场景和场景之间在哪切分，不然训练到场景切换之间地数据就有问题\n幸运的是，python有一个scenedetect的工具来处理这个问题，具体涉及到一些阈值的处理方式啥的可以参考[文档](https://pyscenedetect.readthedocs.io/en/latest/)\n\n2. **分割间隔**。 视频取帧怎么设置间隔？  \n我觉得这是个很难说的问题，因为有缓慢地视角移动也有快速的视角移动，但是按理来说，STTN的optical flow estimation Network应该是要能学到光流中包含的这些信息的，暂时来说我是取了0.1s为间隔\n\n3. **数据清洗**  \n有一些渐暗的视频切换效果比较难鉴别到，也有一些制作人表之类的Scene需要自己去掉\n\n4. **数据加噪**\n宇哥跟我建议先加高斯噪声试试..我就先每个frame resize之后加的高斯噪声..我觉得之后需要加上blur和down sample弄复杂一点..\n\n意思意思贴一点数据处理的代码，估计以后还用的上PySceneDetect这个工具\n```python\ndef split_video_by_scene(video):\n    video_name = video.split('.')[-2].split('/')[-1]\n    os.system(\"scenedetect --input \\\"\" + video +  \"\\\" list-scenes detect-content -t 25\")\n\n    scene = pd.read_csv(video_name + \"-Scenes.csv\", skiprows=1)\n    scene_begin = list(scene[\"Start Time (seconds)\"])\n    scene_end = list(scene[\"End Time (seconds)\"])\n    end_frame = scene_end[-1]\n    save_scene_images(video, scene_begin, scene_end, end_frame)\n```\n\n### GoPR 数据集\n这个数据集是CVPR2017的一篇论文用到的数据集，具体戳 https://github.com/SeungjunNah/DeepDeblur_release\n大概有2k张连续帧，1k多张测试用，其实很小了..\n更大的数据集估计能有1w张清晰图，之后参考那个\n\n\n## 实现当中踩过的一些坑和问题\n### \n\n## Train过程中遇到的问题汇总\n1. 一开始Train不起来 :(   \n可能太年轻，一个1280* 720 * 3 的tensor,其对应的一个conv2d没想到竟然会占到450M的显存，分分钟爆掉11G的1080Ti....,batch_size=1才勉强能跑。无奈只好downsize输入，1280 * 720 -> 640 * 360。   \n为了保证训练的数据集像素不变，每次训练随机地crop 640*360大小的图片出来然后feed进去。由于数据集本身不是很大，这种方法应该也从某种意义上扩大了数据集？（在原数据集上random crop）\n2. 能训练了之后，针对自己的数据集训练的第一版效果不是很好，很多有噪声的地方被模糊化了，估计是optical flow network没有训练好。用tensorboard加上了一些输出信息，观察到正则loss占了很大部分比重，减小正则项，同时使用decayrate 来减少有时候出现的diverge现象。以上均属于hyperparameter finetuning 过程。\n3. 用并行输入优化，尝试加快训练过程。由于现在仍是在单卡上训练，后续考虑tensorflow的多卡数据并行训练。\n4. 怀疑之前的问题很大程度是光流网络输出的问题。尝试visualize光流网络的训练结果。同时考虑替换后续image processing network为densenet。\n5. 有关loss, 论文里没明确给loss的表达式子，现在是joint train两个loss ,xt~ yt~相对于ground_truth的loss ,xt~ yt~如下图\n![](/images/sttn/architecture2.png)\n\n## 训练结果记录\n### GoPR数据集第一批的训练结果\npsnr基本在25上下，下面是一个结果截图\n![一个效果一般的结果](/images/sttn/result_analyze1.png)\n1. 效果一般，但是可以看到网络似乎是学到了通过预测光流用其它帧来补偿模糊(人脚那一块的模糊)\n2. 考虑改善后处理网络\n3. 我plot了一下total loss 和每训练一个epoch得到的test loss如下图所示  \n\n| train_mse | test_mse |\n|:-|:-|\n| ![](/images/sttn/total_mse.png)| ![](/images/sttn/test_mse.png) |\n\n\n","tags":["tensorflow","deeplearning","computer vision"]},{"title":"STTN-论文笔记","url":"/2018/09/15/sensetime/STTN-论文笔记/","content":"# 论文笔记-STTN ECCV 2018 \n## 前要\n刚来sensetime的第一天，在工位上不知所措，下午挑了几篇单目深度估计的文章来看，然后...宇哥晚上跟我说来来来你把这篇文章看一看吧，然后就有了第一个任务。  \n## 简介\n这篇文章是ECCV2018的一篇文章 [Spatio-Temporal Transformer Network for Video Restoration.](http://openaccess.thecvf.com/content_ECCV_2018/html/Tae_Hyun_Kim_Spatio-temporal_Transformer_Network_ECCV_2018_paper.html)  \n现在state of art的Video Restoration Method 通常使用了optical flow network来优化视频中帧与帧之间的短时的信息。然而这些方法大多数只关注相邻的一对帧之间的联系，从而忽略了视频中较长距离的帧之间的联系。这篇文章提出了一种网络结构（Spatio-Temporal Transformer Network）能够一次性处理多帧，从而解决了视频中的遮挡问题，也可以应用于视频超分辨率和视频去模糊等其它问题。\n\n## Main Idea\n这篇文章的Inspiration来自于Google的一篇文章[Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)   \nSTN网络的实质就是训练了一个Grid Generator 来对原图进行变化，或者说对原图重新Sample  \n见下图与对应公式，这样做的好处在于，弥补了神经网络对空间不变性的缺陷(spatial invariant),比如说对于下图的手写数字，重新采样后的图片一定程度上恢复了数字的旋转压缩，这让后面神经网络的准确率大大增加。\n\nSTTN采用了STN的思想，把二维扩展到了三维。原STN是通过预测一个二维的grid generator来生成采样点，而STTN则是通过预测多帧之间的Flow(可以理解为光流？)来确定一个在多帧之间的采样点。\n有关STN 可以参考这里：https://kevinzakka.github.io/2017/01/18/stn-part2/\n\n## Architect Detail\nSTTN network 的网络结构如下图所示\n![STTN 网络结构](/images/sttn/architecture.png)\n### spatio-Temporal Flow Estimation Network\n传统的预测光流的方法常用相邻两张图像比较，比较多次之后得到结果，一是计算耗时，二是不可靠。  \nSTTN使用了一种[U-net](https://arxiv.org/abs/1505.04597v1)的网络结构，将所有帧stack到一起（H*W*C*T）作为网络的输入，输出(u,v,w)->(H*W*3)的光流\nU-net的网络结构如下所示\n\n### Differentiable Spatio-Temporal Sampler\n这一块和STN中的Grid Generator相同，根据得到的Optical Flow对原图进行采样。公式如下\n![](/images/sttn/formu_1.png)\n这个公式看着唬人，实际上比STN的思想还要暴力简单,展开之后\n![](/images/sttn/formu_2.png)\n实际上想一想，就是把每一个点(x,y,t) 分别加上(u,v,w)的偏移量之后得到的新点，根据到其空间内最近四个点的距离加权求和\n\n### Image Processing part\n原图给了一个Video restoration的例子，使用的了Resblock*9? sttn结构这个东西好像可以配合各种网络用上，如下图所示。\n![](/images/sttn/architecture2.png)\n\n## 补充\n这一篇文章目前好像还没有放出官方代码，数据集也不见踪影,更坑爹的是loss function和各种Test data给的十分不详细...然鹅宇哥让我实现一下(- ▽ -)\"...  \nTensorflow实现与分析见另一篇文章 [传送门](../STTN-tf-Implementation/)","tags":["deeplearning","computer vision"],"categories":["论文笔记"]},{"title":"Image Style Transfer based on CNN","url":"/2018/04/15/machinelearning/tensorflow_notes/style_transfer/","content":"## 实验提要\n刚做完CS20的assignmet 2，因为是第一个tensorflow项目，虽然很多不知道怎么做借鉴了别人的代码，整个代码框架大致是搞懂了，姑且留个记录。\n\n整个实验基本上是对[A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf)\n这篇文章的一个实现。实验提供了一些框架代码，可以在[git上这里](https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/02_style_transfer)找到\n\n## 原论文以及主要观点\n### 特点\nA Neural Algorithm of Artistic Style 这篇文章发表2016，还算比较新的文章。 \n文章的主要点在于它发现了在CNN当中图片的内容和图片的风格是可以分离的，因而可以独立的处理这些表示生成新的有意义的图片（虽然我也没完全弄懂他的意思），原文如下：\n\n> “The key finding of this paper is that the representations of content and style in the Convolutional Neural Network are separable. That is, we can manipulate both representations independently to produce new, perceptually meaningful images.”\n\n### VGG-Network 结构\n文章使用的实现方法基于VGG-Network，在cs231n的[这个课件](http://cs231n.github.io/convolutional-networks/)里有对VGG-Net的简要介绍    \n\n> VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, **features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end.** Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.\n\nVGGnet的网络参数如图所示  \n\n![VGGNet achitecture](/images/tf/VGGNet.png)\n\n### 基于VGGnet 的实现\n文章使用了VGGNet当中的16层卷积层和5层pooling层,去掉了全连接层，并使用average pooling策略替换max pooling策略\n\n#### lose function\n关于怎么定义loss function,想法比较自然  \n在图像内容附近通过白噪声初始化一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正。  \n**content loss**  \n设置一个白点噪声的初始图像和原图像输入网络，在某一层的输出$l$处,F和P分别为其特征表述，则取其方差为content loss\n\n$$ L_{content}(\\vec p,\\vec x, l) = \\frac{1}{2}\\sum_{i,j}(F_{ij}^{l}-P_{ij}^{l})^2 $$\n \n**Gram矩阵**\n\nGram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）  \n协方差矩阵可写成：\n\n$$ \\sum  = E[(X-E(X))(X-E(X))^T]$$\nGram矩阵可写成\n\n$$ G = A * A^{T} $$\n\n**style loss**  \n\n在CNN每一层反馈的基础上，对每一层的激励结果求其Gram矩阵,同样是对生成图像和原图像，在某一层l生成的两个Gram矩阵G、A  \n这一层loss贡献为：\n\n$$ E_l = \\frac{1}{4N_l^2M_l^2}\\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$$\n\n对每一层的loss进行加权求和，得到总的loss为\n\n$$ L_{style}(\\vec a,\\vec x) = \\sum_{l=0}^Lw_lE_l$$\n\n\n\n给定content loss和style loss分别的权重为$\\alpha$和$\\beta$，总的优化目标为\n\n$$ L_{total}(\\vec p,\\vec a,\\vec x)=\\alpha L_{content}(\\vec p,\\vec x)+\\beta L_{style}(\\vec a,\\vec x)$$\n\n**思考**  \n有关于为什么要使用gram matrix来度量风格，当同一个维度上面的值相乘的时候原来越小酒变得更小，原来越大就变得越大，二不同维度上的关系也在相乘的表达当中表示出来,因而gram matrix能有效度量各个维度自己的特性以及各个维度之间的关系\n\n## 基于tensorflow的实现\n### 代码框架\n* utils.py  一些辅助函数\n* load_vgg.py  从已经训练好的参数当中加载vggnet\n* style_transfer.py 构建风格转化的模型\n\n### load_vgg.py\n这个模块中的主要任务是搭建vggnet，在load方法当中调用conv2d_relu生成卷积层，调用avgpool生成pooling层\n```python\ndef conv2d_relu(self, prev_layer, layer_idx, layer_name):\n    with tf.variable_scope(layer_name):\n                w, b = self._weights(layer_idx, layer_name)\n                w = tf.constant(w, name=\"weight\")\n                b = tf.constant(b, name=\"bais\")\n                conv2d = tf.nn.conv2d(input = prev_layer,\n                                    filter = w,\n                                    strides = [1,1,1,1],\n                                    padding = \"SAME\",\n                                    name = layer_name)\n                out = tf.nn.relu(conv2d + b)\n        setattr(self, layer_name, out)\n\ndef avgpool(self, prev_layer, layer_name):\n\n        with tf.variable_scope(layer_name):\n            out = tf.nn.avg_pool(prev_layer,\n                                ksize=[1,2,2,1],\n                                strides=[1,2,2,1],\n                                padding=\"SAME\")\n\n        setattr(self, layer_name, out)\n\ndef load(self):\n        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n        self.avgpool(self.conv1_2, 'avgpool1')\n        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n        self.avgpool(self.conv2_2, 'avgpool2')\n        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n        self.avgpool(self.conv3_4, 'avgpool3')\n        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n        self.avgpool(self.conv4_4, 'avgpool4')\n        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n        self.avgpool(self.conv5_4, 'avgpool5')\n```\n有关conv2d的参数解释见之前笔记和[这里](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)\n\n### style_transfer\n\n总体分为两部，第一步创建tensorflow图结构，这其中包括：\n1. 使用create_input创建空白图作为输入\n2. 加载vggnet结构\n3. 创建loss\n4. 根据loss创建optimizer\n5. 创建统计数据\n```python\ndef build(self):\n    self.create_input()\n    self.load_vgg()\n    self.losses()\n    self.optimize()\n    self.create_summary()\n```\n\n第二步执行训练:  \n1. 初始化全局变量sess.run(tf.global_variables_initializer())\n2. 创建FileWriter (用于TensorBoard)\n3. 创建输入  sess.run(self.input_img.assign(self.initial_img))\n4. 创建checkpoint检查是否要恢复\n5. 循环迭代n次\n6. 最优化opt\n7. 每特定次循环计算保存summary，保存断点\n```python\n    def train(self, n_iters):\n        skip_step = 1\n        with tf.Session() as sess:\n            # 1. initialize\n            sess.run(tf.global_variables_initializer())\n            # 2. create writer\n            writer = tf.summary.FileWriter(\"graphs/style_transfer\", sess.graph)\n            # 3. assign input\n            sess.run(self.input_img.assign(self.initial_img))\n            # 4. create checkpoint & restore previous\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/style_transfer/checkpoint'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n\n            initial_step = self.gstep.eval()\n            start_time = time.time()\n            # 5. iterate for n_iters time\n            for index in range(initial_step, n_iters):\n                if index >= 5 and index < 20:\n                    skip_step = 10\n                elif index >= 20:\n                    skip_step = 20\n                # 6. run optimization\n                sess.run(self.opt)\n                # 7. add summary info \\ save checkpoint every number of certain layers\n                if (index + 1) % skip_step == 0:\n                    gen_image, total_loss, summary = sess.run([self.input_img,\n                                                            self.total_loss,\n                                                            self.summary_op])\n                    gen_image = gen_image + self.vgg.mean_pixels \n                    writer.add_summary(summary, global_step=index)\n                #...\n                if (index + 1) % 20 == 0:\n                    saver.save (sess, 'checkpoints/style_stranfer/style_transfer', index)\n\n```\n\n\n### 个人在做完之后的一点思考\n首先这个任务和传统的学习任务不一样。这次学习的对象是需要生成的图像，待生成的图像像素点作为变量在最优化的时候同时被训练。而网络的模型采用他人训练好的参数。","tags":["CNN，tensorflow"]},{"title":"Convolutional Nerual Networks for Visual Recongnition","url":"/2018/04/12/machinelearning/tensorflow_notes/note_CNN/","content":"\n# Convolutional Nerual Networks (CNNs/ConvNets)\n\n## Over view\n### 引入\n首先为啥会有CNN这个东西呢？  \n一个普通的神经网络的示意图如下所示  \n![](./images/tf/simple_neural_net.jpeg)\n可见，这种神经网络层与层之间是全连接的，对于minist这种数据集使用，假设输入图像为32*32*3 = 3072个节点，勉强可以处理。但是对于更大的输入图像，200*200*3 = 120000个神经元节点，这种神经网络处理起来就比较费力。  \n很显然，这种时候全连接就显得比较无用和浪费，大量的参数不仅难以优化，而且会快速的导致网络的过拟合。  \n\n### Architecture\n卷积神经网络同样由许多层构成，其中主要的有三种：\n1. Concoluntional Layer (卷积层)\n2. Polling Layer ()\n3. Full-Connected Layer ()\n\n一个较为典型的架构是：[INPUT-CONV-RELU-POOL-FC]\n* INPUT: 3-d [width * height * color-channels]\n* CONV : 卷积层\n* RELU : Rectified Linear Unit (线性整流函数) 常用的有斜坡函数(max(0,x))\n* POOL : 对输入进行下降抽样（输出向量的前两位小于输入）\n* FC: 全连接的层  \n\n其中只有CONV层和FC层是包含所需要优化的参数的。\n\n## Layers\n### Convolutional Layer (卷积层)\n我们知道在高维度的输入下，全连接不太实际。取而代之的是，可以对每个节点和输入的某个局部的区域连接。而如何选择这个区域，由一组超参数（hyperparameter）决定，这被称为神经元的（receptive field），也就是filter size.\n\n#### 输出维度（spatial-arrangement）\n输出的空间维度由三个超参数决定：\n* Depth: 输出的深度等于用到的filter的个数。可以理解为：不同的filter试图在数据里面找到不同的特征。\n* Stride: Stride可以理解为对filter滑动的间距。当Stride较大的时候，输出的维度较小。（通常情况下1、2）\n* Zero-padding: 有时候在特定Stride值下，不能整除的时候周围输入就要补零。\n\n$W =$ input volume size  \n$P =$ receptive field size of the conv layer nerons  \n$S =$ stride  \n$P =$ amount of zero-padding  \n则有：  \n$(W-F+2P)/S + 1$则为一个filter所对应的CONV Layer的节点数。\n\n#### 参数共享（parameter sharing）\n在Conv Layer Local connectivity的情况下，假设输入向量大小为[a* b * c], 输出[x * y* z], filter [n * m * c]。那么Conv Layer一共有xyz个节点，每一个节点有nmc个参数，一共有xyznmc个参数，取x = 55, y = 55, z = 96,n = 11,m = 11, c = 3。这种数量级仍然是难以接受的。\n\n可以通过一个合理的假设大量减少参数的数量，可以认为如果某个特征在某一点是有效的，那么在其它点其是同样有效的。也就是说，限制Conv layer在每一个filter（depth）下的神经元使用同样的参数和bias，总的参数数量可以快速减少到zmnc。（在back propogation当中，同意深度下使用相同参数的神经元的贡献会被相加）\n\nConv Layer 的计算过程如图所示：  \n![](./images/tf/convolution.png)\n\n#### Two key insights：\n关于CONV Layer的两个关键点  \n1) Features are hierarchical\nComposing high-complexity features out of low-complexity features is more\nefficient than learning high-complexity features directly.\ne.g.: having an “circle” detector is useful for detecting faces… and basketballs\n2) Features are translationally invariant\nIf a feature is useful to compute at (x, y) it is useful to compute that feature at\n(x’, y’) as well\n\nps: 为何叫卷积层呢：因为其与两个信号的卷积类似。  \n\n\n\n### Pooling Layer (不知道咋翻译..)\nPooling Layer常被加在连续的Conv Layer当中，它的主要作用是逐步减少空间大小来减少参数的数量，从而控制过拟合。  \n\nPooling层独立的作用于各个depth slice。\n\n一个常见的例子是使用2*2的filter，stride为2,使用max function，取四激励中最大的，从而忽略掉75%的激励\n\n当然还有一些其它pooling的方法，如average pooling和L2-norm pooling在此mark以后深入研究。\n\n","tags":["CNN","DeepLearning"]},{"title":"TensorFlow 学习笔记3 Manage EXperiments","url":"/2018/04/11/machinelearning/tensorflow_notes/note3/","content":"# Tensorflow 学习笔记 #3\n\n**keywords** :  model base, variable sharing, model sharing\n\n## 构建tensorflow模型的一般步骤\nPhase1: **assenmble graph** \n1. Import Data\n2. Define the weigths\n3. Define the inferece model\n4. Define loss function\n5. Define optimizer\n\n\nPhase2: **execute the computation**\n1. initialize all model variables for the first time\n2. Initialize iterator / feed training data\n3. Excecute the inference model on the training data\n4. compute cost\n5. Adjust model parameters to minimize cost \n\n利用python面向对象的性质为自己的模型简历一个类：\n```python\nclass Model:\n    def __init__(self, params):\n        pass\n\n    def _import_data(self):\n        \"\"\" Step 1: import data \"\"\"\n        pass\n\n    def _create_embedding(self):\n        \"\"\" Step 2: in word2vec, it's actually the weights that we care about \"\"\"\n        pass\n\n    def _create_loss(self):\n        \"\"\" Step 3 + 4: define the inference + the loss function \"\"\"\n        pass\n\n    def _create_optimizer(self):\n        \"\"\" Step 5: define optimizer \"\"\"\n        pass\n```\n\n\n## Variable Sharing\n### Name Scope\n    为了能够在tensor board上较为清晰的辨识出节点之间的关系，引入name_scope可将其分组\n```python\nwith tf.name_scope(name_of_that_scope):\n    # declare op1\n    # declare op2\n    # declare op3\n```\n\n### Variable Scope\n    使用Varibale scope来做到变量共享，在variable_scope中使用get_variable方法来获取之前创建的变量而不是新的一个变量\n```python\nwith tf.variable_scope(\"xxx\") as scope:\n    # a = tf.get_variable(\"x\",.)..\n```\n\n## tensorflow 实验管理\n### 使用checkpoint保存训练中间结果\n对于一个需要较长时间训练的模型来说，断点恢复能力是十分必要的。  \ntensorflow也设置了相应的机制，即为checkpoint，可以用来周期性的保存当前模型的参数等数据。  \n实现这一点的是tf.train.Sacer() 类，它会将图的变量保存在二进制文件当中。 \n```python\ntf.train.Saver.save(\n    sess,\n    save_path,\n    global_step=None,\n    latest_filename=None,\n    meta_graph_suffix='meta',\n    write_meta_graph=True,\n    write_state=True\n)\n```\n常用的保存checkpoint的方法如下所示：\n```python\n# define model\n\n# create a saver object\nsaver = tf.train.Saver()\n\n# launch a session to execute the computation\nwith tf.Session() as sess:\n    # actual training loop\n    for step in range(training_steps): \n\tsess.run([optimizer])\n\tif (step + 1) % 1000 == 0:\n\t   saver.save(sess, 'checkpoint_directory/model_name', global_step=global_step)\n``` \n这里的global_step是一个用来记录图训练了多少步的变量，创建其的时候需要设置其不能被训练。\n（optimizer默认训练所有变量）\n```python\nglobal_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n```\noptimizer一般也接收一个global_step变量的输入，每一次优化更新之后会将global_step的值自增\n```python\noptimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss,global_step=global_step)\n```\n\ntensorflow还支持在一个文件夹里面找checkpoint,如果有合法的，恢复checkpoint,否则继续执行\n```python\nckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\nif ckpt and ckpt.model_checkpoint_path:\n     saver.restore(sess, ckpt.model_checkpoint_path)\n```\n\n### 使用tf.summary可视化训练数据\n\n```python\ndef _create_summaries(self):\n     with tf.name_scope(\"summaries\"):\n            tf.summary.scalar(\"loss\", self.loss)\n            tf.summary.scalar(\"accuracy\", self.accuracy)            \n            tf.summary.histogram(\"histogram loss\", self.loss)\n            # because you have several summaries, we should merge them all\n            # into one op to make it easier to manage\n            self.summary_op = tf.summary.merge_all()\n```\nsummary_op和其它operation一样，需要在sess中运行得到结果。  \n得到结果之后使用add_summary把结果写入writer当中，就可以在tensorbord中看到add_summary的图的各种曲线啦  \n```python\nwriter.add_summary(summary, global_step=step)\n```\nsummary的用法参考[这里](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)\n\n### control randomization\n\n### Auto diff\n","tags":["tensorflow"]},{"title":"Using tensorflow on Minist","url":"/2018/03/31/machinelearning/tensorflow_notes/tf_minist/","content":"# 使用卷积神经网络预测minist手写数字\nminist是一个入门的标准cv集。 \n详细注释见minist当中注释  \n直接上代码\n```python\n\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n  # MNIST images are 28x28 pixels, and have one color channel\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  # Computes 32 features using a 5x5 filter with ReLU activation.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 28, 28, 1]\n  # Output Tensor Shape: [batch_size, 28, 28, 32]\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  # First max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 28, 28, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 32]\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2\n  # Computes 64 features using a 5x5 filter.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 14, 14, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 64]\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #2\n  # Second max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 14, 14, 64]\n  # Output Tensor Shape: [batch_size, 7, 7, 64]\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Flatten tensor into a batch of vectors\n  # Input Tensor Shape: [batch_size, 7, 7, 64]\n  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n  # Dense Layer\n  # Densely connected layer with 1024 neurons\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n  # Output Tensor Shape: [batch_size, 1024]\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  # Logits layer\n  # Input Tensor Shape: [batch_size, 1024]\n  # Output Tensor Shape: [batch_size, 10]\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=20000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data},\n      y=eval_labels,\n      num_epochs=1,\n      shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n```\n目前我没弄懂的一点在于，这个框架没用session 也没用eager mode是怎么跑起来的， 如果我想可视化地观察一下这个卷积神经网络的结构又该怎么做呢？\n \n有点明白了，官方的doc当中有这么一句话：  \nEstimators build the graph for you. In other words, you don't have to build the graph.  \n\n其实在一开始应该早就说明白过了，tensorflow的api是分层级的:  \n![](./images/tf/tf_api.png)\n\n如上图estimator 和eager mode是同一层级的，它会自动的帮你构建整个图\n\nTODO: 试着跑一遍代码，用log记录下图的结构，然后在tensorboard里面打开康康。  \n\n\n\n","tags":["tensorflow","CV","ML"]},{"title":"TensorFlow 学习笔记2","url":"/2018/03/30/machinelearning/tensorflow_notes/note2/","content":"# TensorFlow 学习笔记 #2\n  \n先来看一个简单的线性回归的代码例子，再来看在其基础上可以做出什么改进\n```python\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = \"data/birth_life_2010.txt\"\n\n# Step 1: read in data from the .txt file\n# data is a numpy array of shape (190, 2), each row is a datapoint\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\nX = tf.placeholder(tf.float32, name='X')\nY = tf.placeholder(tf.float32, name='Y')\n\n# Step 3: create weight and bias, initialized to 0\nw = tf.get_variable('weights', initializer=tf.constant(0.0))\nb = tf.get_variable('bias', initializer=tf.constant(0.0))\n\n# Step 4: construct model to predict Y (life expectancy from birth rate)\nY_predicted = w * X + b \n\n# Step 5: use the square error as the loss function\nloss = tf.square(Y - Y_predicted, name='loss')\n\n# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n \nwith tf.Session() as sess:\n\t# Step 7: initialize the necessary variables, in this case, w and b\n\tsess.run(tf.global_variables_initializer()) \n\t\n\t# Step 8: train the model\n\tfor i in range(100): # run 100 epochs\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op to minimize loss\n\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y}) \n\t\n\t# Step 9: output the values of w and b\n\tw_out, b_out = sess.run([w, b])\n```\n\n## tensorflow 控制流\n观察上面线性回归所使用的loss function，是个简单的二次函数  \n分析离群点，假设有一个离样本较远的离群点，那么这个离群点造成的loss fuction上的损失较大，会大大影响整个模型的建模。\n\n**使用[huber loss](https://en.wikipedia.org/wiki/Huber_loss)代替原来简单的loss fuction**  \n其定义如下所示    \n\n$$\nL_\\delta(y,f(x))=\\left\\{\n\\begin{array}{ll}\n\\frac12(y-f(x))^2,&\\textrm{for }|y-f(x)|\\leq\\delta\\\\\n\\delta\\cdot(|y-f(x)|-\\delta/2),& \\textrm{otherwise.}\n\\end{array}\n\\right.\n$$\n\nHuber loss给离群点设置了相对更小的权重,因而提升了拟合的效果。\n\n一个显然的事实是由于tensorflow 定义和执行的分离，我们不能用python的条件分支语句来控制optimizer使用哪一种loss function,tensor flow提供了分支控制的方法\n\nOps | Methods\n:-|:-\nControl Flow Ops | tf.count_up_to, tf.cond, tf.case, tf.while_loop, tf.group ...\nComparison Ops | tf.equal, tf.not_equal, tf.less, tf.greater, tf.where, ...\nLogical Ops | tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor\nDebugging Ops | tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print, ...\n\nhuber_loss：\n```python\ndef huber_loss(labels, predictions, delta=14.0):\n    residual = tf.abs(labels - predictions)\n    def f1(): return 0.5 * tf.square(residual)\n    def f2(): return delta * residual - 0.5 * tf.square(delta)\n    return tf.cond(residual < delta, f1, f2)\n```\n## tensorflow 输入\n### placeholder & feed_dict\nnote1跳过了对tensorflow基本输入方式的叙述。实际上由于graph在定义的时候不需要考虑实际输入数据的特性。一般创建输入变量的时候实际上是为要输入的变量预留位置，使用tf.placeholder定义,如下是一个使用的例子\n```python\na = tf.placeholder(dtype, shape=None, name=None)\n...\nwith tf.Session() as sess:\n   sess.run(something, feed_dict = {a:[1,2,3]})\n```\nshape参数制定了传入的tensor的结构，shape为None意味着任意结构的tensor都能被接收（可能潜在地会引入bug）\n\n### tf.data\nplaceholder让数据的处理和带入图中运算分开，在tensorflow框架之外完成（完全可以用numpy等工具处理），不过这样带来的不好的地方之一在于，数据处理被放在了python的单一线程当中，会让数据处理较慢。（大量数据要从外部一个个装载到place_holder处）  \n\n如上述代码当中看起来就不优雅的一段：\n```python\n\tfor i in range(100): # run 100 epochs\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op to minimize loss\n\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y}) \n```\n将数据分100次载入place_holder当中实际上较大的拖慢了程序的速度。还需要考虑的是在并行计算的时候载入feed_dict可能阻碍了其它操作的执行。\n\ntensorflow提供的解决方案是将数据存储在tf.data.Dataset object当中\n```python\ntf.data.Dataset.from_tensor_slices((features, labels))\n# can use numpy arrays as features and labels \n```\n\n之后使用迭代器来访问dataset当中的每一个数据\n```python\n# we use make_initializable_iterator for multiple epochs\niterator = dataset.make_initializable_iterator()\nX, Y = iterator.get_next() \n···\nfor i in range(100): \n        # reset where iterator point to\n        sess.run(iterator.initializer)\n        total_loss = 0\n        try:\n            while True:\n                sess.run([optimizer]) \n        except tf.errors.OutOfRangeError:\n            pass\n```\n\ndataset 也支持许多原生的对数据集的操作来改变数据集或是生成新的数据集\n```python\ndataset = dataset.shuffle(1000)\ndataset = dataset.repeat(100)\ndataset = dataset.batch(128)\ndataset = dataset.map(lambda x: tf.one_hot(x, 10)) \n# convert each element of dataset to one_hot vector\n```\n## Optimizers\n默认情况下optimizer在每一轮迭代的过程中自动更新loss function所依赖的所有变量，若有不想更新的变量，在定义的时候加上参数trainable=False\n\n(to do: add contont about more detailed control of model trains using tf.gradient)\n\n## Refs\n[03_Lecture note_Linear and Logistic Regression](https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit#)  \n[Huber Loss](https://en.wikipedia.org/wiki/Huber_loss)\n","tags":["tensorflow"]},{"title":"TensorFlow 学习笔记1","url":"/2018/03/26/machinelearning/tensorflow_notes/note1/","content":"# TensorFlow 学习笔记 #1\n## TensorFlow Basics\n### Graphs and Sessions\n首先，需要和普通python程序区别出来的是，tensorflow将计算的定义和具体执行过程分离开来，个人认为这有点像函数式中的求值运算。  \n\n不过tensorflow的特点在于其把所依赖的所有计算转换成一个数据流图（dag）\n\n![数据流图](./images/tf/tensor_data_flow_graph.png)\n\n1. 根据输入构成数据流图\n2. 创建会话，执行操作\n\n用图的优点有如下几个：  \n1. 能够保存计算结果。只会运行你所期望得到值的子图。\n2.  易于分布任务，进行分布式的计算\n3.  Break computation into small, differential pieces to facilitate auto-differentiation\n4.  Many common machine learning models are taught and visualized as directed graphs\n\n**何为TensorFlow?**  \n**Tensor**: An n-dimensional array  \n0-d tensor: scalar (number)   \n1-d tensor: vector  \n2-d tensor: matrix  \n\n## Tensorflow ops\n### TensorBorad\nTensorborad 使用通过将图的节点信息和图中的操作记入event files当中来完成整个流程的可视化，使用如下代码创建event files以及停止记录\n```python\n# use tf.get_default_graph() to get default graph\nwriter = tf.summary.FileWriter([logdir], [graph])\n# ...\nwriter.close()\n```\n之后运行python代码并打开tensorboard\n```bash\n$ python3 [my_program.py] \n$ tensorboard --logdir=\"./graphs\" --port 6006\n```\n但是我们此时看到的图每个节点我们无法对上名字，这就要在定义图的时候给出其的名字\n```python\na = tf.constant(2, name=\"a\")\nb = tf.constant(2, name=\"b\")\nx = tf.add(a, b, name=\"add\")\n```\n\n### Some useful tricks\n#### 查看protobuf\n常数存储在函数的定义当中，通过查看图的protobuf(protocol buffer)来查看图定义当中的内容。\n```python\nimport tensorflow as tf\n\nmy_const = tf.constant([1.0, 2.0], name=\"my_const\")\nprint(tf.get_default_graph().as_graph_def())\n```\nOutput :\n```json\nnode {\n  name: \"my_const\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"\n      }\n    }\n  }\n}\nversions {\n  producer: 24\n}\n```\n\n#### 变量的声明和初始化\n为了变量共享的方便 官方推荐使用tf.get_variable方法\n```python\ns = tf.get_variable(\"scalar\", initializer=tf.constant(2)) \nm = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\nW = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n```\n同时可以较简单的初始化变量\n```python\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n```\n\n#### Assign a variable\n观察如下程序\n```python\nW = tf.Variable(10)\nW.assign(100)\nwith tf.Session() as sess:\n\tsess.run(W.initializer)\n\tprint(W.eval()) # >> 10\n```\n结果输出是10，但为什么不是100呢。注意的是，之前也说过，tensorflow的声明和运行是分离的，W.assign(100)创建了一个assign操作，但是我们并没有运行它，所以应该按照如下写\n```python\nW = tf.Variable(10)\nassign_op = W.assign(100)\nwith tf.Session() as sess:\n\tsess.run(assign_op)\n\tprint(W.eval()) # >> 100\n```\n\n#### Sessions\n会话独自保存值，因而假如有两个不同的会话对同一个变量进行操作，其得到最终的值也有可能不相同。  \n有时候为了方便可以使用interactive session来隐式地run session\n```python\nsess = tf.InteractiveSession()\na = tf.constant(5.0)\nb = tf.constant(6.0)\nc = a * b\nprint(c.eval()) # we can use 'c.eval()' without explicitly stating a session\nsess.close()\n```\ntf.get_default_session()返回当前进程的默认session\n\n#### the trap of lazy loading\n考虑如下代码有什么不好的地方\n```\nx = tf.Variable(10, name='x')\ny = tf.Variable(20, name='y')\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter('graphs/lazy_loading', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(tf.add(x, y))\n\tprint(tf.get_default_graph().as_graph_def()) \n\twriter.close()\n```\nsess.run(tf.add(x, y))这一句会将tf.add(x,y)这个操作创建10次，造成网络的大量冗余\n考虑解决方案：\n1. 总是将操作的定义与执行分离开来\n2. 使用python的@property来保证你的函数只被调用一次","tags":["tensorflow"]},{"title":"开关反转问题","url":"/2017/09/22/acm/开关反转问题/","content":"```c++\n#include <cstdio>\n#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <utility>\n#include <queue>\n#define MAXN 50\n#define sc(x) scanf(\"%d\",&(x))\n\nusing namespace std;\n\nconst int INF = 0x3f3f3f3f;\nint a[MAXN][MAXN];\nint p[MAXN][MAXN];\nint f[MAXN][MAXN][MAXN];\nint x[MAXN];\nint mark[MAXN];\nint M,N;\n\nint gauss(int equ,int vars)\n{\n\tint i=0,j=0;\n\tmemset(mark,0,sizeof(mark));\n\tfor(i=0,j=0; i<equ && j<vars; i++,j++){\n\t\tint max_r = i;\n\t\tfor(int k=i+1; k<equ; k++)\n\t\t\tif(a[k][j]>a[max_r][j])\n\t\t\t\tmax_r = k;\n        if(max_r!=i)\n            for(int k=0; k<=vars; k++)\n                swap(a[i][k],a[max_r][k]);\n        if(a[i][j]==0){\n            mark[j] = 1;\n            i--;\tcontinue;\n        }\n        for(int k=i+1; k<equ; k++){\n            if(a[k][j])\n                for(int m=j; m<=vars; m++)\n                    a[k][m] = a[k][m]^a[i][m];\n        }\n\t}\n\ti--;\n\tfor(int k=vars-1; k>=0; k--){\n\t\tif(mark[k]){\n\t\t\tx[k] = 1;\tcontinue;\n\t\t}\n\t\tif(i<0) break;\n\t\tint res = 0;\n\t\tfor(int m=k+1; m<vars; m++)\n\t\t\tres ^= a[i][m]&x[m];\n\t\tx[i--] = res;\n\t}\n\treturn 0;\n}\n\nint get(int i,int j,int k)\n{\n\tint ans = f[i][j][k] + f[i-1][j][k] + f[i][j-1][k] + f[i][j+1][k];\n\treturn ans%2;\n}\n\nint getans(int i,int j)\n{\n\tint ans = p[i][j] + p[i-1][j] + p[i][j-1] + p[i][j+1];\n\treturn ans%2;\n}\n\n\nint main()\n{\n\tint t;\n\tsc(t);\n\twhile(t--){\n\t\tsc(N),sc(M);\n\t\tmemset(a,0,sizeof(a));\n\t\tmemset(p,0,sizeof(p));\n\t\tmemset(f,0,sizeof(f));\n\t\tfor(int k=1; k<=M; k++)\n\t\t{\n\t\t\tf[1][k][k] = 1;\n\t\t}\n\t\tfor(int i=2; i<=N+1; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n                for(int k=1; k<=M; k++)\n                    f[i][j][k] = get(i-1,j,k);\n\n\t\tfor(int i=0; i<M; i++)\n\t\t\tfor(int j=0; j<M; j++)\n\t\t\t\ta[i][j] = f[N+1][i+1][j+1];\n\t\tgauss(M,M);\n\t\tfor(int i=1; i<=M; i++)\n\t\t\tp[1][i] = x[i-1];\n\t\tfor(int i=2; i<=N; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n\t\t\t\tp[i][j] = getans(i-1,j);\n\t\tfor(int i=1; i<=N; i++){\n\t\t\tprintf(\"%d\",p[i][1]);\n\t\t\tfor(int j=2; j<=M; j++)\n\t\t\t\tprintf(\" %d\",p[i][j]);\n\t\t\tprintf(\"\\n\");\n \t    }\n\t}\n\treturn 0;\n}\n\n```"},{"title":"高斯消元求解带模方程组","url":"/2017/09/21/acm/高斯消元求解带模方程组/","content":"\nHDU-5755  \n一类开关问题  \n做法是设第一行各个位置操作为x1~xn次那么就可以最后一直推下去  \n推出第n+1行所需要的操作个数一定都为0,这样就得到了一个n个变量的方程组  \n用高斯消元求出解都推出来就行\n\n\n```c++\nconst int MOD = 3;\nconst int INF = 0x3f3f3f3f;\nint a[MAXN][MAXN];\nint x[MAXN];\n\ninline int gcd(int a,int b)\n{\n\tint t;\n\twhile(b != 0){\n\t\tt = b;\n\t\tb = a%b;\n\t\ta = t;\n\t}\n\treturn a;\n}\n\ninline void exgcd(int a,int b,int &x,int &y,int &d)\n{\n\tif(b==0){\n\t\tx = 1; y=0; d = a;\treturn;\n\t}\n\texgcd(b,a%b,x,y,d);\n\tint t = x;\n\tx = y;\n\ty = t - (a/b)*y;\n\treturn;\n}\n\nint lcm(int a,int b){\n\treturn a*b/gcd(a,b);\n}\n\nint inv(int a,int mod)\n{\n\tint x,y,d;\n\texgcd(a,mod,x,y,d);\n\treturn (x+mod)%mod;\n}\n\nint gauss(int rows,int var)\n{\n\tint col,k,max_r;\n\tfor(col=0,k=0; col<var && k<rows; col++,k++){\n\t\tmax_r = k;\n\t\tfor(int i=k+1; i<rows; i++)\n\t\t\tif(abs(a[i][col])>abs(a[k][col]))\n\t\t\t\tmax_r = i;\n\t\tif(a[max_r][col]==0){\n\t\t\tk--; continue;\t//Jump to next variable\n\t\t}\n\t\tif(max_r!=k)\n\t\t\tfor(int i=0; i<var+1; i++)\n\t\t\t\tswap(a[k][i],a[max_r][i]);\n\t\tfor(int i=k+1; i<rows; i++){\n\t\t\tif(a[i][col]!=0){\n\t\t\t\tint LCM = lcm(a[k][col],a[i][col]);\n\t\t\t\tint tk = LCM/a[k][col];\n\t\t\t\tint ti = LCM/a[i][col];\n\t\t\t\tfor(int j=col; j<var+1; j++)\n\t\t\t\t\ta[i][j] = ((a[i][j]*ti - a[k][j]*tk)%MOD+MOD)%MOD;\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i=k; i<rows; i++)\n\t\tif(a[i][col]!=0)\n\t\t\treturn -1;\t\t\t\t//\n\tif(rows<var) return rows-var;\t//\n\n\tfor(int i=var-1; i>=0; i--){\n\t\tint temp = a[i][var];\n\t\tfor(int j=i+1; j<var; j++)\n\t\t{\n\t\t\tif(a[i][j]!=0){\n\t\t\t\ttemp -= a[i][j]*x[j];\n\t\t\t\ttemp = (temp%MOD+MOD)%MOD;\n\t\t\t}\n\t\t}\n\t\tx[i] = (temp*inv(a[i][i],MOD))%MOD;\n\t}\n\treturn 0;\n}\n\nint T,N,M;\nint m[50][50];\nint f[50][50][50];\nint p[50][50];\n\nint get(int i,int j,int k)\n{\n    int ans = (f[i][j-1][k]+2*f[i][j][k]+f[i][j+1][k]+f[i-1][j][k])%MOD;\n    return ((3-ans)%MOD+MOD)%MOD;\n}\n\nint getans(int i,int j)\n{\n    int ans = (p[i][j-1]+2*p[i][j]+p[i][j+1]+p[i-1][j]+m[i][j])%MOD;\n    return ((3-ans)%MOD+MOD)%MOD;\n}\n\nint main()\n{\n\tsc(T);\n\twhile(T--){\n\t\tsc(N);\tsc(M);\n\t\tfor(int i=1; i<=N; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n\t\t\t\tsc(m[i][j]);\n\t\tmemset(a,0,sizeof(a));\n        memset(f,0,sizeof(f));\n        memset(p,0,sizeof(p));\n\t\tfor(int i=1; i<=M; i++)\n\t\t\tf[0][i][i] = 1;\n\t\tint cur = 0;\n        for(int i=1; i<=N; i++){\n            for(int j=1; j<=M; j++){\n                for(int k=1; k<=M; k++)\n                    f[i][j][k] = get(i-1,j,k);\n                f[i][j][M+1] = (3 - m[i][j] + get(i-1,j,M+1))%MOD;\n            }\n        }\n\t\tfor(int i=0; i<M; i++){\n            for(int j=0; j<M; j++)\n                a[i][j] = f[N][i+1][j+1];\n            a[i][M] = (3-f[N][i+1][M+1])%MOD;\n\t\t}\n        gauss(M,M);\n        int ans = 0;\n        for(int i=1; i<=M; i++)\n            p[1][i] = x[i-1],ans += p[1][i];\n        for(int i=2; i<=N; i++)\n            for(int j=1; j<=M; j++)\n                p[i][j] = getans(i-1,j),ans += p[i][j];\n        printf(\"%d\\n\",ans);\n        for(int i=1; i<=N; i++)\n            for(int j=1; j<=M; j++)\n                for(int k=0; k<p[i][j]; k++)\n                    printf(\"%d %d\\n\",i,j);\n\t}\n}\n```\n","tags":["高斯消元"],"categories":["ACM"]},{"title":"求最小割最少边数","url":"/2017/09/18/acm/求最小割最少边数/","content":"给有向图，求一个最小割，它的边数也最小  \n搜了原题题解，发现一堆假算法==  \n假算法说什么将满流边置为1 其它边置为INF 感觉不科学\n因为考虑有不同种最大流情况的图，不同的最大流情况会导致算出来的结果不一样。\n\nAC的解法是对于每条边的容量乘上一个大于边数的数+1,最后再模上这个数。\n\n```c++\n#include <cstdio>\n#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <utility>\n#include <queue>\n#define MAXN 5000\n#define sc(x) scanf(\"%d\",&(x))\n\nusing namespace std;\nconst int INF = 0x3f3f3f3f;\n\nstruct edge{\n\tint t,cap,next;\n};\nedge e[MAXN];\nint cnt;\nint head[MAXN];\nint n,m,s,t;\nint iter[MAXN],level[MAXN];\n\nvoid add_edge(int f,int t,int cap){\n\te[cnt].t = t;\te[cnt].cap = cap;\te[cnt].next = head[f];\n\thead[f] = cnt++;\n\te[cnt].t = f;\te[cnt].cap = 0;\te[cnt].next = head[t];\n\thead[t] = cnt++;\n}\n\nvoid bfs(int s,int t)\n{\n\tmemset(level,-1,sizeof(level));\n\tlevel[s] = 0;\n\tqueue<int> q;\n\tq.push(s);\n\twhile(!q.empty()){\n\t\tint cur = q.front(); q.pop();\n\t\tif(cur==t) break;\n\t\tfor(int i=head[cur]; i!=-1; i=e[i].next){\n\t\t\tint v = e[i].t;\n\t\t\tif(level[v]<0 && e[i].cap>0){\n\t\t\t\tlevel[v] = level[cur] + 1;\n\t\t\t\tq.push(v);\n\t\t\t}\t\n\t\t}\n\t}\n}\n\nint dfs(int u,int t,int flow)\n{\n\tif(u==t) return flow;\n\tfor(int &i=iter[u]; i!=-1; i=e[i].next){\n\t\tint v = e[i].t;\n\t\tif(level[v]>level[u] && e[i].cap>0){\n\t\t\tint val = dfs(v,t,min(flow,e[i].cap));\n\t\t\tif(val>0){\n\t\t\t\te[i].cap -= val;\n\t\t\t\te[i^1].cap +=val;\n\t\t\t\treturn val;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n\nint Dinic()\n{\n\tint ans = 0;\n\twhile(1){\n\t\tbfs(s,t);\n\t//\tfor(int i=1; i<=n; i++)\n\t//\t\tcout<<\"level \"<<i<<\": \"<<level[i]<<endl;\n\t\tif(level[t]<0) break;\n\t\tfor(int i=1; i<=n; i++)\n\t\t\titer[i] = head[i];\n\t\tint val;\n\t\twhile(val=dfs(s,t,INF)){\n\t\t\t//cout<<\"val: \"<<val<<endl;\n\t\t\tans += val;\n\t\t}\n\t}\n\treturn ans;\n}\n\nint main()\n{\n\tint T;\n\tsc(T);\n\twhile(T--){\n\t\tsc(n); sc(m);\n\t\tsc(s); sc(t);\n\t\tcnt = 0;\n\t\tmemset(head,-1,sizeof(head));\n\t\tfor(int i=0; i<m; i++){\n\t\t\tint u,v,w;\n\t\t\tsc(u); sc(v); sc(w);\n\t\t\tadd_edge(u,v,w*1000+1);\n\t\t}\n\t\tint ans = Dinic();\n\t\tcout<<ans%1000<<endl;\n\t}\n}\n\n\n```\n\n","tags":["网络流"],"categories":["ACM"]},{"title":"沈阳网络赛2017","url":"/2017/09/14/acm/沈阳网络赛2017/","content":"\nhdu 6199 dp\n```c++\nll dp[2][350][220];\nll sum[40020];\nll v[40020];\n\nint main()\n{\n    int t,n;\n    sc(t);\n    while(t--){\n        sc(n);\n        sum[0] = 0;\n        for(int i=1; i<=n; i++){\n            scanf(\"%lld\",v+i);\n            sum[i] = sum[i-1]+v[i];\n        }\n        memset(dp,0,sizeof(dp));\n        for(int i=n; i>=1; i--){\n            for(int j=1; j*j<=2*i; j++){\n                if(i+j==n+1){\n                    dp[0][i&mod][j] = sum[n]-sum[i-1];\n                    dp[1][i&mod][j] = sum[i-1] - sum[n];\n                    break;\n                }\n                if(i+j>n+1) continue;\n                dp[0][i&mod][j] = max(dp[1][(i+j)&mod][j], dp[1][(i+j+1)&mod][j+1]+v[i+j]) + sum[i+j-1] - sum[i-1];\n                dp[1][i&mod][j] = min(dp[0][(i+j)&mod][j], dp[0][(i+j+1)&mod][j+1]-v[i+j]) - sum[i+j-1] + sum[i-1];\n            }\n        }\n        cout<<dp[0][1][1]<<endl;\n    }\n}\n```\n\n\nhdu 6201 树上DP\n```c++\nstruct node{\n    int to,cost,next;\n}e[MAXN];\nint head[MAXN];\nint val[MAXN];\nint dp[2][MAXN];\nint cnt = 0;\n\nvoid add_edge(int f,int t,int c)\n{\n    e[cnt].to = t;\n    e[cnt].cost = c;\n    e[cnt].next = head[f];\n    head[f] = cnt;\n    cnt++;\n}\n\nvoid dfs(int u,int pre)\n{\n    dp[0][u] = -val[u];\n    dp[1][u] = val[u];\n    for(int i=head[u]; i!=-1; i=e[i].next){\n        int v = e[i].to;\n        int cost = e[i].cost;\n        if(pre==v) continue;\n        dfs(v,u);\n        dp[0][u] = max(dp[0][u],dp[0][v]-cost);\n        dp[1][u] = max(dp[1][u],dp[1][v]-cost);\n    }\n}\n\nint main()\n{\n    int t,n;\n    sc(t);\n    while(t--){\n        sc(n);\n        for(int i=1; i<=n; i++) sc(val[i]);\n        memset(head,-1,sizeof(head));\n        memset(dp,0,sizeof(dp));\n        cnt = 0;\n        for(int i=1; i<n; i++){\n            int f,t,c;\n            sc(f);  sc(t); sc(c);\n            add_edge(f,t,c);\n            add_edge(t,f,c);\n        }\n        dfs(1,-1);\n        int ans = 0;\n        for(int i=1; i<=n; i++){\n            ans = max(ans,dp[0][i]+dp[1][i]);\n        }\n        printf(\"%d\\n\",ans);\n    }\n}\n```","tags":["题解"],"categories":["ACM"]},{"title":"UVAlive3211-2SAT模板题","url":"/2017/09/03/acm/UVAlive3211-2SAT模板题/","content":"## UVAlive-3211\n题意大概是求n架飞机每个飞机两个降落时间取一个使相邻降落的飞机时间差最大  \n要最优化差值，二分转化为在某一时间下能否满足，按照相邻时间是否大于当前二分的时间构建2-SAT\n模板题模板题  \n\n```c++\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\n\n//struct time{\n//    int time,id;\n//}t[MAXN];\nint t[MAXN];\n\nstruct SAT2{\n    int vis[MAXN*2],cnt;\n    vector<int> G[MAXN*2];\n    int n;\n    bool mark[MAXN*2];\n    bool dfs(int x){\n        if(mark[x^1]) return false;\n        else if(mark[x]) return true;\n        mark[x] = true;\n        vis[cnt++] = x;\n        for(int i=0; i<G[x].size(); i++){\n            if(!dfs(G[x][i])) return false;\n        }\n        return true;\n    }\n\n    void init(int n){\n        this->n = n;\n        for(int i=0; i<=2*n; i++){\n            vis[i] = false;\n            G[i].clear();\n        }\n        memset(mark,false,sizeof(mark));\n    }\n\n    // 当 x!=xval or y != yval(val=0/1)\n    // 则由于拆点每个x或者y变成两个点\n    // x==xval=>y!=yval     y==yval=>x!=xval\n    void add_clause(int x,int xval,int y,int yval){\n        x = x*2+xval;\n        y = y*2+yval;\n        G[x].pb(y^1);\n        G[y].pb(x^1);\n    }\n\n    bool solve(){\n        for(int i=0; i<2*n; i+=2)\n        if(!mark[i] && !mark[i^1]){\n            cnt = 0;\n            if(!dfs(i)){\n                while(cnt>0) mark[vis[--cnt]] = false;\n                if(!dfs(i^1)) return false;\n            }\n        }\n        return true;\n    }\n}st;\nint n;\n\nbool solve(int T)\n{\n    st.init(n);\n    for(int i=0; i<2*n; i++){\n        int j;\n        if(i%2) j = i+1;\n        else    j = i+2;\n        for(;j<2*n;j++){\n            if(abs(t[i]-t[j])<T){\n                st.add_clause(i/2,i&1,j/2,j&1);\n            }\n        }\n    }\n    return st.solve();\n}\n\nint main()\n{\n    while(sc(n)==1&&n){\n        for(int i=0; i<n; i++){\n            int e,l;\n            sc(e);  sc(l);\n            t[i*2] = e;    //t[i*2].id = i*2;\n            t[i*2+1] = l;  //t[i*2+1].id=i*2+1;\n        }\n        int lt = 0,rt = 1e7;\n        while(lt<rt){\n            //cout<<lt<<\" \"<<rt<<endl;\n            int mt = (lt+rt+1)/2;\n            if(solve(mt))\n                lt = mt;\n            else\n                rt = mt-1;\n        }\n        cout<<lt<<endl;\n    }\n}\n\n```\n","tags":["2SAT"],"categories":["ACM"]},{"title":"简单的LCA==","url":"/2017/09/03/acm/简单的LCA/","content":"题源： NAIPC 2016 The University Of Chicago\n校内赛一道LCA==，写掉了一个等号调了一下午== \ndfs爆栈然后手写栈模拟了一发\n\n```c++\nint depth[MAXN*2];\nstruct ST{\n    int mm[2*MAXN];\n    int dp[2*MAXN][25];\n    void init(int n){\n        mm[0] = -1;\n        for(int i=1;i<=n; i++){\n            mm[i] = ((i&(i-1))==0)?mm[i-1]+1:mm[i-1];\n            dp[i][0] = i;\n        }\n        for(int j=1 ;j<=mm[n] ;j++)\n            for(int i=1; i+(1<<j)-1<=n; i++)\n                dp[i][j] = (depth[dp[i][j-1]] < depth[dp[i+(1<<(j-1))][j-1]])? dp[i][j-1]:dp[i+(1<<(j-1))][j-1];\n    }\n    int query(int a,int b){\n        if(a>b)swap(a,b);\n        int k = mm[b-a+1];\n        return depth[dp[a][k]]<=depth[dp[b-(1<<k)+1][k]]?dp[a][k]:dp[b-(1<<k)+1][k];\n    }\n}st;\n\nvector<vector<int> >G(MAXN);\nint vs[MAXN*2];\nint pos[MAXN];\n\n\n//void dfs(int v,int pre,int d,int &k){\n//    pos[v] = k;\n//    vs[k] = v;\n//    depth[k++] = d;\n//    for(int i=0; i<G[v].size(); i++){\n//        if(G[v][i]!=pre){\n//            dfs(G[v][i],v,d+1,k);\n//            vs[k] = v;\n//            depth[k++]=d;\n//        }\n//    }\n//}\n\nstruct dfs{\n    int v,pre,d,i;\n    dfs(int vv,int pp,int dd,int ii):v(vv),pre(pp),d(dd),i(ii){}\n};\nstack<dfs> s;\n\nvoid solve(int &k){\n    s.push(dfs(1,0,0,0));\n    int v,pre,d,i;\n    while(!s.empty()){\n        dfs cur = s.top();\n        s.pop();\n        //cout<<s.size()<<endl;\n        v = cur.v;  pre = cur.pre; d = cur.d; i = cur.i;\n        if(i==0){\n            pos[v] = k;\n            vs[k] = v;\n            depth[k++] = d;\n        }\n        else{\n            vs[k] = v;\n            depth[k++]=d;\n        }\n        //cout<<v<<\" \"<<G[v].size()<<endl;\n        if(i<G[v].size() && G[v][i]==pre) i++;\n        if(i<G[v].size()){\n            //cout<<\"from:\"<<v<<\" to:\"<<G[v][i]<<endl;\n            cur.i = i+1;\n            s.push(cur);\n            s.push(dfs(G[v][i],v,d+1,0));\n        }\n    }\n}\n\nint lca_query(int v,int u)\n{\n    int s = min(pos[v],pos[u]);\n    int e = max(pos[v],pos[u]);\n    return 1+depth[s]+depth[e]-2*depth[st.query(s,e)];\n}\n\nint main()\n{\n    frein;\n    int n;\n    scanf(\"%d\",&n);\n    for(int i=0; i<n-1; i++){\n        int f,t;\n        scanf(\"%d%d\",&f,&t);\n        G[f].pb(t);\n        G[t].pb(f);\n    }\n//    for(int i=1;i<n; i++){\n//        cout<<i<<\":  \"<<endl;\n//        for(int j=0; j<G[i].size(); j++)\n//            cout<<G[i][j]<<\" \";\n//        cout<<endl;\n//    }\n    int cnt=1;\n    solve(cnt);\n//    for(int i=0; i<cnt;i++)\n//        cout<<vs[i]<<\" depth: \"<<depth[i]<<endl;\n//    for(int i=1; i<cnt; i++){\n//        cout<<\"node:\"<<vs[i]<<\" depth:\"<<depth[i]<<endl;\n//    }\n//    for(int i=1; i<=n; i++)\n//        cout<<\"vis\"<<i<<\" is \"<<pos[i]<<endl;\n    st.init(2*n-1);\n    ll ans = 0;\n    for(int i=1; i<=n/2; i++)\n        for(int j=2; i*j<=n; j++){\n            ans += lca_query(i,i*j);\n        }\n    cout<<ans<<endl;\n    return 0;\n}\n```\n","tags":["LCA"],"categories":["ACM"]},{"title":"简单的几何学...","url":"/2017/09/02/acm/简单的几何学/","content":"题源：Central Europe Contest 2015 Zagreb H   \n其实是道很无聊的题目了，就求交点判情况有点麻烦..  \n用向量判交点然后手撕一下\n```c++\nstruct Cvector{\n    double x,y;\n    Cvector(){}\n    Cvector(double xx,double yy):x(xx),y(yy){}\n}node[4];\n\nstruct Cline{\n    Cvector a,b;\n};\n\nCvector operator-(const Cvector &a,const Cvector &b){return Cvector(a.x-b.x,a.y-b.y);}\nCvector operator*(double k, const Cvector &a)       {return Cvector(k*a.x,k*a.y);}\nCvector operator+(const Cvector &a,const Cvector &b){return Cvector(a.x+b.x,a.y+b.y);}\ndouble operator*(const Cvector &a,const Cvector &b) {return a.x*b.x+a.y*b.y;}\ndouble operator^(const Cvector &a,const Cvector &b) {return a.x*b.y-a.y*b.x;}\ndouble area(Cvector a,Cvector b){\n    return (a^b)/2;\n}\n\nCvector intersect(Cline l,Cline m,int &msg){\n    double x = area(m.a-l.a, l.b-l.a);\n    double y = area(l.b-l.a, m.b-l.a);\n    if(x+y==0){\n        msg = 1;//平行或者重合\n        return Cvector(NaN,NaN);\n    }\n    return m.a+((x/(x+y))*(m.b-m.a));\n}\n\nCline l[4];\ndouble caly(Cline cl,double X)\n{\n    Cvector cross[4];\n    Cvector point[2];\n    int pcnt = 0,msg;\n    for(int i=0; i<4; i++)\n        cross[i] = intersect(cl,l[i],msg);\n    for(int i=0; i<4; i++){\n        if(cross[i].x >= l[i].a.x && cross[i].x <= l[i].b.x)\n            point[pcnt++] = cross[i];\n        else if(cross[i].x <= l[i].a.x && cross[i].x >= l[i].b.x)\n            point[pcnt++] = cross[i];\n    }\n    int nodecnt = 0;\n    double ans = 0;\n    for(int i=0; i<4; i++)\n        if(node[i].x<X)\n            nodecnt++;\n    if(nodecnt==3){\n        for(int i=0; i<4; i++)\n            if(node[i].x>=X)\n                ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n        ans = 5.0*5.0-ans;\n    }\n    else for(int i=0; i<4; i++){\n        if(node[i].x<X)\n            ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n    }\n    cout<<ans<<endl;\n    return ans;\n}\n\ndouble calx(Cline cl,double Y)\n{\n    Cvector cross[4];\n    Cvector point[2];\n    int pcnt = 0,msg;\n    for(int i=0; i<4; i++)\n        cross[i] = intersect(cl,l[i],msg);\n    for(int i=0; i<4; i++){\n        if(cross[i].x >= l[i].a.x && cross[i].x <= l[i].b.x)\n            point[pcnt++] = cross[i];\n        else if(cross[i].x <= l[i].a.x && cross[i].x >= l[i].b.x)\n            point[pcnt++] = cross[i];\n    }\n    double ans = 0;\n    int nodecnt = 0;\n    for(int i=0; i<4; i++)\n        if(node[i].y<Y)\n            nodecnt++;\n    if(nodecnt==3){\n        for(int i=0; i<4; i++)\n            if(node[i].y>=Y)\n                ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n        ans = 5.0*5.0-ans;\n    }\n    else for(int i=0; i<4; i++){\n        if(node[i].y<Y)\n            ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n    }\n    cout<<ans<<endl;\n    return ans;\n}\n\n\nint main()\n{\n    for(int i=0; i<4; i++){\n        double x,y;\n        scanf(\"%lf%lf\",&x,&y);\n        node[i].x =x;   node[i].y  = y;\n    }\n    for(int i=0; i<3; i++){\n        l[i].a = node[i];   l[i].b = node[i+1];\n    }\n    l[3].a = node[3];   l[3].b = node[0];\n\n    double ans = 0;\n    Cline cl;\n    cl.a = Cvector(0.5,0.5);    cl.b = Cvector(0.5,-0.5);\n    ans += 3.0*(25.0-caly(cl,0.5));\n    cl.a = Cvector(0.5,-0.5);    cl.b = Cvector(-0.5,-0.5);\n    ans += 1.0*(calx(cl,-0.5));\n    cl.a = Cvector(-0.5,-0.5);    cl.b = Cvector(-0.5,0.5);\n    ans += 4.0*caly(cl,-0.5);\n    cl.a = Cvector(-0.5,0.5);    cl.b = Cvector(0.5,0.5);\n    ans += 6.0*(25.0-calx(cl,0.5));\n    ans *= 5;\n    ans += 5.0*5.0*5.0*4;\n    ans /= (5.0*5.0*5.0-1.0);\n    printf(\"%.6f\\n\",ans);\n}\n\n```\n","tags":["计算几何"],"categories":["ACM"]},{"title":"Uva-14149 二分图匹配求最小点覆盖","url":"/2017/08/28/acm/题解/图论/二分图/Uva-14149 二分图匹配求最小点覆盖/","content":"\n# Uva-14149\n## 题意：   \n给一个R*C的矩形网格，每一个小格子内可能有点，求最小选多少行多少列可以覆盖所有的点，并输出这些行和列\n\n\n## 题解：\n由于类似一个覆盖问题，可以想办法根据矩阵的二维性质构造一个二分图求最小覆盖 。  \n那么使每一行为一个点集每一列为一个点集，(x,y)有点则在x和y之间连一条线。那么最后只需要选点覆盖所有线就行。  \n二分匹配->最小点覆盖  \n要具体求出哪些点参考以下结论\n### 一个结论\n**从二分最大匹配找到最小点覆盖**    \n需要借助匈牙利树： 设二分图两个集合为X Y  \n从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖\n\n```c++\nint R,C,N;\nint uN,vN;\nint G[MAXN][MAXN];\nint Left[MAXN];\nint Right[MAXN];\nbool S[MAXN],T[MAXN];\n\nbool dfs(int u)\n{\n    S[u] = true;\n    for(int v=1; v<=vN;v++)\n    if(G[u][v] && !T[v]){\n        T[v] = true;\n        if(Left[v] == -1 || dfs(Left[v])){\n            Right[u] = v;\n            Left[v] = u;\n            return true;\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(Left,-1,sizeof(Left));\n    memset(Right,-1,sizeof(Right));\n    for(int u=1; u<=uN; u++){\n        memset(T,0,sizeof(T));\n        if(dfs(u)) res++;\n    }\n    return res;\n}\n\nint min_cover(vector<int> &X,vector<int> &Y)\n{\n    int ans = hungary();\n    X.clear();  Y.clear();\n    memset(S,0,sizeof(S));\n    memset(T,0,sizeof(T));\n    for(int i=1;i<=uN;i++)\n        if(Right[i]==-1) dfs(i);\n    for(int i=1;i<=uN;i++)\n        if(!S[i]) X.pb(i);\n    for(int j=1;j<=vN;j++)\n        if(T[j]) Y.pb(j);\n    return ans;\n}\n\nint main()\n{\n    vector<int> x,y;\n    while(scanf(\"%d%d%d\",&R,&C,&N)){\n        if(R==0 && C==0 && N==0)\n            break;\n        uN = R; vN = C;\n        memset(G,0,sizeof(G));\n        for(int i=0; i<N; i++){\n            int y,x;\n            sc(y); sc(x);\n            G[y][x] = 1;\n        }\n        int ans = min_cover(x,y);\n        printf(\"%d\",ans);\n        for(int i=0; i<x.size(); i++)\n            printf(\" r%d\",x[i]);\n        for(int i=0; i<y.size(); i++)\n            printf(\" c%d\",y[i]);\n        printf(\"\\n\");\n    }\n}\n```","tags":["二分图","最小点覆盖"],"categories":["ACM"]},{"title":"2017-广西邀请赛","url":"/2017/08/27/acm/match/2017-广西邀请赛/","content":"算是我队第一次打正式赛了吧..全场贡献了几题思路..打表大法是真的强..  \n终榜5题银..还行..\n\n### 记录几个要补的题：   \n1. C: 怎么求三元环\n2. G: 平面图转对偶图\n3. K： 暴力哈希KMP\n\n### C\n```c++\n#include <iostream>\n#include <cstdio>\n#include <cctype>\n#include <algorithm>\n#include <cstring>\n#include <string>\n#include <cmath>\n#include <vector>\n#include <set>\n#include <stack>\n#include <sstream>\n#include <queue>\n#include <map>\n#include <functional>\n#include <bitset>\n\nusing namespace std;\n#define pb push_back\n#define mk make_pair\n#define ll long long\n#define ull unsigned long long\n#define pii pair<int, int>\n#define mkp make_pair\n#define fst first\n#define scd second\n#define ALL(A) A.begin(), A.end()\n#define REP(i,n) for(int (i)=0;(i)<(int)(n);(i)++)\n#define REP1(i, n) for(int (i)=1;(i)<=(int)(n);(i)++)\n#define fastio ios::sync_with_stdio(0), cin.tie(0)\n#define frein freopen(\"in.txt\", \"r\", stdin)\n#define freout freopen(\"out.txt\", \"w\", stdout)\n#define freout1 freopen(\"out1.txt\", \"w\", stdout)\n#define PI M_PI\n#define MAXN 100000\n#define xork(a,b) ((b&1)?(a):(0))\n#define sc(n) scanf(\"%d\",&(n))\n\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\nstruct edge{\n    int from,to,nxt;\n}E[MAXN*2];\nmap<pii,int> mp;\nint head[MAXN];\nint cnt;\nint edgecnt[MAXN];\nint d[MAXN];\nint node[MAXN];\nint ncnt;\n\nvoid add_edge(int f,int t){\n    E[cnt].to = t; E[cnt].nxt = head[f];\n    head[f] = cnt;\n    mp[mkp(f,t)] = cnt/2;\n    mp[mkp(t,f)] = cnt/2;\n    cnt++;\n    E[cnt].to = f; E[cnt].nxt = head[t];\n    head[t] = cnt;\n    cnt++;\n}\n\nint main()\n{\n    //freout;\n    int n,m;\n    while(~scanf(\"%d%d\",&n,&m)){\n        cnt = 0;\n        memset(head,-1,sizeof(head));\n        memset(d,0,sizeof(d));\n        memset(edgecnt,0,sizeof(edgecnt));\n        mp.clear();\n        for(int i=0; i<m; i++){\n            int u,v;\n            sc(u); sc(v);\n            add_edge(u,v);\n            d[u]++,d[v]++;\n        }\n        int x = (int)sqrt(m);\n        ncnt = 0;\n        for(int i=1; i<=n; i++){\n            if(d[i]<=x){\n                for(int j=head[i]; j!=-1; j=E[j].nxt){\n                    int u = E[j].to;\n                    for(int k=E[j].nxt; k!=-1; k=E[k].nxt){\n                        int v = E[k].to;\n                        if(mp.count(mkp(u,v))){\n                            edgecnt[mp[mkp(u,v)]]++;\n                        }\n                    }\n                }\n            }\n            else{\n                node[ncnt++] = i;\n            }\n        }\n        for(int i=0; i<ncnt; i++){\n            int u = node[i];\n            for(int j=i+1; j<ncnt; j++){\n                int v = node[j];\n                if(mp.count(mkp(u,v)))\n                for(int k=j+1; k<ncnt; k++){\n                    int z = node[k];\n                    if(mp.count(mkp(v,z)) && mp.count(mkp(u,z))){\n                        edgecnt[mp[mkp(v,z)]]++;\n                        edgecnt[mp[mkp(u,z)]]++;\n                        edgecnt[mp[mkp(u,v)]]++;\n                    }\n                }\n            }\n        }\n        ll ans = 0;\n        for(int i=0;i<m; i++){\n            ll c = edgecnt[i];\n            ans += c*(c-1)/2;\n        }\n        cout<<ans<<endl;\n    }\n}\n\n```","tags":["题解","比赛","三元环"],"categories":["ACM"]},{"title":"Uva-11354 最小瓶颈树+LCA倍增法维护最大值","url":"/2017/08/27/acm/题解/图论/Uva-11354 最小瓶颈树+LCA倍增法维护最大值/","content":"\n# Uva-11354\n题意：  \n给你一个无向图，N个节点M条边，边权为d，对Q组询问a b,问能取到的从a到b路径上的最小值。\n\n题解：  \n首先总是要取最小的值，则可以先用kruskal求最小生成树（也就是最小瓶颈树），即在树上求任意两点之间路径边权值的最小值。可以用倍增求解LCA的方法，**在保存p[i][j]（节点i的向上2^i个祖先） 的同时维护mlen[i][j]（节点i向上2^i条边的最大值）**\n\n```c++\n#include <iostream>\n#include <cstdio>\n#include <cctype>\n#include <algorithm>\n#include <cstring>\n#include <string>\n#include <cmath>\n#include <vector>\n#include <set>\n#include <stack>\n#include <sstream>\n#include <queue>\n#include <map>\n#include <functional>\n#include <bitset>\n\nusing namespace std;\n#define pb push_back\n#define mk make_pair\n#define ll long long\n#define ull unsigned long long\n#define pii pair<int, int>\n#define mkp make_pair\n#define fst first\n#define scd second\n#define ALL(A) A.begin(), A.end()\n#define REP(i,n) for(int (i)=0;(i)<(int)(n);(i)++)\n#define REP1(i, n) for(int (i)=1;(i)<=(int)(n);(i)++)\n#define fastio ios::sync_with_stdio(0), cin.tie(0)\n#define frein freopen(\"in.txt\", \"r\", stdin)\n#define freout freopen(\"out.txt\", \"w\", stdout)\n#define freout1 freopen(\"out1.txt\", \"w\", stdout)\n#define PI M_PI\n#define MAXN 100000\n#define xork(a,b) ((b&1)?(a):(0))\n#define sc(n) scanf(\"%d\",&(n))\n\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\nstruct edge{\n    int from,to;\n    int v;\n    bool operator<(const edge &a)const{\n        return v<a.v;\n    }\n};\n\nvector<edge> E;\nvector<vector<pii> >G(MAXN);\nint d[MAXN],len[MAXN];\nint p[MAXN][20],mlen[MAXN][20];\nint f[MAXN];\nint N,M;\n\nint getf(int v){\n    if(f[v]==v) return v;\n    else return f[v] = getf(f[v]);\n}\n\nbool Merge(int v1,int v2){\n    int f1 = getf(v1);\n    int f2 = getf(v2);\n    if(f1 == f2){\n        return false;\n    }\n    f[f1] = f2;\n    return true;\n}\n\nvoid kruskal()\n{\n    for(int i=0; i<=N; i++)\n        f[i] = i;\n    int cnt = 0;\n    for(int i=0; i<E.size(); i++){\n        if(cnt>=N-1)    break;\n        int f = E[i].from;\n        int t = E[i].to;\n        if(Merge(f,t)){\n            cnt++;\n            G[f].pb(mkp(t,E[i].v));\n            G[t].pb(mkp(f,E[i].v));\n//            cout<<f<<\" \"<<t<<\" \"<<E[i].v<<endl;\n        }\n    }\n}\n\nvoid dfs(int v,int pre,int depth)\n{\n    d[v] = depth;\n    for(int i=0; i<G[v].size(); i++){\n        int t = G[v][i].first;\n        int val = G[v][i].second;\n        if(t==pre)  continue;\n        dfs(t,v,depth+1);\n        //len[t] = val;\n        p[t][0] = v;\n        mlen[t][0] = val;\n    }\n}\n\nvoid lca_init(int n)\n{\n//    for(int i=1; i<=n; i++)\n//        printf(\"mlen[%d][0] = %d\\n\",i,mlen[i][0]);\n    for(int j=1; (1<<j)<=n; j++){\n        for(int i=1; i<=n; i++){\n            p[i][j] = p[p[i][j-1]][j-1];\n            mlen[i][j] = max(mlen[i][j-1],mlen[p[i][j-1]][j-1]);\n            //printf(\"mlen[%d][%d] = %d\\n\",i,j,mlen[i][j]);\n        }\n    }\n}\n\nint query(int a,int b)\n{\n    //printf(\"Query a:%d b%d\\n\",a,b);\n    if(d[a]>d[b])  swap(a,b);\n    int f = d[b] - d[a];\n    int maxe = -1;\n    for(int i=0; (1<<i)<=f; i++)\n        if(f&(1<<i)){\n            maxe = max(maxe,mlen[b][i]);\n            b = p[b][i];\n        }\n    //printf(\"maxe = %d\\n\",maxe);\n    if(a!=b){\n        for(int i=(int)log2(N);i>=0; i--){\n            if(p[a][i]!=p[b][i]){\n                maxe = max(maxe,max(mlen[b][i],mlen[a][i]));\n                a = p[a][i];    b = p[b][i];\n            }\n            //printf(\"maxe = %d\\n\",maxe);\n        }\n        maxe = max(maxe,mlen[a][0]);    //和求LCA不同，这里要同时对两个节点更新最大值\n        maxe = max(maxe,mlen[b][0]);\n        //printf(\"a = %d  maxe = %d\\n\",a,maxe);\n    }\n    return maxe;\n}\n\nint main()\n{\n    //freout;\n    bool flag = false;\n    while(~scanf(\"%d%d\",&N,&M)){\n        if(flag) puts(\"\");\n        flag = true;\n        E.clear();\n        for(int i=1; i<=N; i++)\n            G[i].clear();\n        for(int i=0; i<M; i++){\n            edge t;\n            scanf(\"%d%d%d\",&t.from,&t.to,&t.v);\n            E.pb(t);\n        }\n        sort(E.begin(),E.end());\n        kruskal();\n        dfs(1,-1,0);\n        lca_init(N);\n        int Q;\n        sc(Q);\n        for(int i=0; i<Q; i++){\n            int a,b;\n            sc(a); sc(b);\n            printf(\"%d\\n\",query(a,b));\n        }\n    }\n}\n\n```","tags":["LCA","最小瓶颈树","kruskal","倍增法"],"categories":["ACM"]},{"title":"素数线性筛法","url":"/2017/08/20/acm/markdown/math/素数线性筛法/","content":"\n时间复杂度O（N）\n```c++\nbool isprime[10000005];\nint prime[1000004];\nint cnt = 0;\n\nvoid sift(int n)\n{\n    memset(isprime,true,sizeof(isprime));\n    for(int i=2; i<=n; i++){\n\n        if(isprime[i])\n            prime[cnt++] = i;\n        for(int j=0; j<cnt&&prime[j]*i<=n; j++){\n            isprime[prime[j]*i] = false;\n            if(i%prime[j]==0) break;\n        }\n    }\n}\n```","tags":["数论","线性筛法"],"categories":["ACM"]},{"title":"稀疏表","url":"/2017/08/20/acm/markdown/数据结构/稀疏表/","content":"\n## Spared Table （用于解决多种RMQ问题）\n模板：\n（解决区间极小值）\n```c++\n/*\nST用来O（nlogn）时间预处理，O（1）时间查询最大最小值\n*/\n#include <iostream>  \n#include <math.h>  \nusing namespace std;  \n  \n/*方程 \nF[i,j]:区间[i,i + 2^j - 1]的最小值，此时区间长度为2^j \nF[i,j] = min(F[i,j - 1],F[i + 2^(j - 1),j - 1]) \nF[i,0] = nArr[i];*/  \n  \nconst int MAXN = 10010;\nint rmq[2*MAXN];//rmq数组,就是欧拉序列对应的深度序列\n  \nstruct ST\n{\n    int mm[2*MAXN];//意思是向下取log2(k)\n    int dp[2*MAXN][20];//最小值对应的下标\n    void init(int n)\n    {\n        mm[0] = -1;\n        for(int i = 1;i <= n;i++)\n        {\n            mm[i] = ((i&(i-1)) == 0)?mm[i-1]+1:mm[i-1];\n            dp[i][0] = i;\n        }\n        for(int j = 1; j <= mm[n];j++)\n            for(int i = 1; i + (1<<j) - 1 <= n; i++)\n                dp[i][j] = rmq[dp[i][j-1]] <\n                rmq[dp[i+(1<<(j-1))][j-1]]?dp[i][j-1]:dp[i+(1<<(j-1))][j-1];\n    }\n    int query(int a,int b)//查询[a,b]之间最小值的下标\n    {\n        if(a > b)swap(a,b);\n        int k = mm[b-a+1];\n        return rmq[dp[a][k]] <= \n        rmq[dp[b-(1<<k)+1][k]]?dp[a][k]:dp[b-(1<<k)+1][k];\n    }\n};\n```\n\n例：hdu-5726 解决区间最小公倍数\n","tags":["RMQ","稀疏表"],"categories":["ACM"]},{"title":"欧拉函数及一些性质","url":"/2017/08/20/acm/markdown/math/欧拉函数/","content":"\n\n## 唯一分解定理\n\n## 欧拉函数的一些性质\n\n\n**一些公式**  \n1. 若p q互质则有  \n```math\n    phi(N)=phi(p)*phi(q)  \n    \n    (N=p*q)\n```\n2. 当b是质数，a%b=0 则\n```math\n    phi(ab) = phi(a)*b\n```\n\n\n**递推式**   \n对于质数p满足p|x\n1. 若p^2|x不成立,因x/p互质故有：\n```math\n    phi(x)=phi(x/p)*(p-1)\n```\n2. 若p^2|x成立,p|(x/p)且p为质数\n```math\n    phi(x)=phi(x/p)*p\n```\n\n**公式求欧拉函数：**\n    \n```math\nphi(N) = n*(1+1/p1)(1+1/p2)...(1+1/pk)\n```\n其中\n\n```math\nN = p1^a*p2^b*...pk^x\n```\n\n因而可以写出如下的代码用公式求欧拉函数值\n```c++\n    for(int i=1; i<=MAXN; i++)\n        phi[i] = i;\n    for(int i=2; i<=MAXN; i++)\n        if(phi[i]==i){\n            for(int j=i; j<=MAXN; j+=i)\n                phi[j] = phi[j]/i*(i-1);\n        }\n```\n\n\n**lightoj-1370:** \n \n    结论： phi(x)~x之间一定存在一个质数\n    \n\n","tags":["数论","欧拉函数"],"categories":["ACM"]},{"title":"二分图最大匹配的匈牙利算法和性质","url":"/2017/08/20/acm/markdown/图论/二分图/","content":"\n# 二分图最大匹配\n\n## 最大匹配的匈牙利算法\n### 最大匹配：\n在G的一个子图M中，M的边集中的任意两条边都不依附于 同一个顶点，则称M是一个匹配。选择这样的边数最大的子集称为图的最大匹配问题,最大匹配的边数称为最大匹配数.如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备匹配。如果在左右两边加上源汇点后，图G等价于一个网络流，最大匹配问题可以转为最大流的问题。解决此问的匈牙利算法的本质就是寻找最大流的增广路径。  \n\n模板如下\n```c++\n/*\n    匈牙利算法\n    解决最大匹配问题\n    临接表版本\n*/\nstruct edge{\n    int to,next;\n}edge[MAXN];\nint head[MAXN],tot;\nvoid init()\n{\n    tot = 0;\n    memset(head,-1,sizeof(head));\n}\n\nvoid addedge(int u,int v)\n{\n    edge[tot].to = v;   edge[tot].next = head[u];\n    head[u] = tot++;\n}\nint linker[MAXN];\nint used[MAXN];\nint uN;         //点的编号0~uN-1\n\nbool dfs(int u)\n{\n    for(int i=head[u]; i!=-1; i=edge[i].next)\n    {\n        int v = edge[i].to;\n        if(!used[v])\n        {\n            used[v] = true;\n            if(linker[v]==-1 || dfs(linker[v])){\n                linker[v] = u;\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(linker,-1,sizeof(linker));\n    for(itn u=0; u<uN; u++){\n        memset(used,false,sizeof(used));\n        if(dfs(u))  res++;\n    }\n    return res;\n}\n\n/*\n邻接矩阵的匈牙利算法\n最小点覆盖等价于最大匹配，对每一个X集合未覆盖点出发进行一次匈牙利树扩展（dfs（））最后X内未标记和Y内已标记的集合组成最小覆盖\nmin_cover用来通过扩展匈牙利树寻找最小点覆盖\n*/\nint R,C,N;\nint uN,vN;\nint G[MAXN][MAXN];\nint Left[MAXN];\nint Right[MAXN];\nbool S[MAXN],T[MAXN];\n\nbool dfs(int u)\n{\n    S[u] = true;\n    for(int v=1; v<=vN;v++)\n    if(G[u][v] && !T[v]){\n        T[v] = true;\n        if(Left[v] == -1 || dfs(Left[v])){\n            Right[u] = v;\n            Left[v] = u;\n            return true;\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(Left,-1,sizeof(Left));\n    memset(Right,-1,sizeof(Right));\n    for(int u=1; u<=uN; u++){\n        memset(T,0,sizeof(T));\n        if(dfs(u)) res++;\n    }\n    return res;\n}\n\nint min_cover(vector<int> &X,vector<int> &Y)\n{\n    int ans = hungary();\n    X.clear();  Y.clear();\n    memset(S,0,sizeof(S));\n    memset(T,0,sizeof(T));\n    for(int i=1;i<=uN;i++)\n        if(Right[i]==-1) dfs(i);\n    for(int i=1;i<=uN;i++)\n        if(!S[i]) X.pb(i);\n    for(int j=1;j<=vN;j++)\n        if(T[j]) Y.pb(j);\n    return ans;\n}\n```\n\n\n## 二分图的一些特有性质\n### 最小覆盖\n1. **最小定点覆盖**:  \n    最小顶点覆盖是指最少的顶点数使得二分图G中的每条边都至少与其中一个点相关联，二分图的最小顶点覆盖数=二分图的最大匹配数。  \n**最小定点覆盖的证明**：  \n首先，最小点集覆盖一定>=最大匹配，因为假设最大匹配为n，那么我们就得到了n条互不相邻的边，光覆盖这些边就要用到n个点。现在我们来思考为什么最小点击覆盖一定<=最大匹配。任何一种n个点的最小点击覆盖，一定可以转化成一个n的最大匹配。因为最小点集覆盖中的每个点都能找到至少一条只有一个端点在点集中的边（如果找不到则说明该点所有的边的另外一个端点都被覆盖，所以该点则没必要被覆盖，和它在最小点集覆盖中相矛盾），只要每个端点都选择一个这样的边，就必然能转化为一个匹配数与点集覆盖的点数相等的匹配方案。所以最大匹配至少为最小点集覆盖数，即最小点击覆盖一定<=最大匹配。综上，二者相等。\n\n2. **最小边覆盖**：  \n    最小路径覆盖也称为最小边覆盖，是指用尽量少的不相交简单路径覆盖二分图中的所有顶点。二分图的最小路径覆盖数=|V|-二分图的最大匹配数。  \n    **最小边覆盖的证明**：  \n不妨设最小定点覆盖为X一共V个点，那么，最小边覆盖一定》=V-X。原因在于，首先根据最小点覆盖覆盖所有边的性质，最小点覆盖没取到的V-X个点两两无边相连，**也就是说他们是一个独立子集**，那么最小边覆盖要取到所有点的话就需要这V-X个点每个点取一条边。同时V-X又是取得到的，由于原图最小顶点覆盖就是最大二分匹配，每次取边的是后总是遵循是匹配边的话取匹配边，否则任取。那么结果一定取到了所有定点 \n\n\n\n**从二分最大匹配找到最小点覆盖**    \n需要借助匈牙利树： 设二分图两个集合为X Y  \n从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖\n\n### 最大独立集\n**最大独立集=V-最小覆盖集=V-最大匹配**  \n\n![](/images/二分图.png)    \n上图，我们用两个红色的点覆盖了所有边。我们证明的前提条件是已经达到最小覆盖。\n即条件1.已经覆盖所有边，条件2.所用的点数最小  \n**首先我们来证明蓝色点组成的是一个独立集：**   \n如果有两个蓝色点间有边相连，那么这条边则没有被覆盖，则与条件1矛盾。因此是独立集。  \n**再来证明这个独立集最大：**  \n如果我们要再增加这个独立集中的点，则需要把某个红点变成蓝点。而由最小覆盖数=最大匹配数的证明我们知道，每一个红点是最大匹配中的一个匹配点，也就是说每个红点至少连接了一条边。因此当我们将某个红点变成蓝点时，我们需要牺牲的蓝点的个数是大于等于1的。也就是说，我们最多只能找到数量相等的其他独立集，而无法找到数量更大的。因此蓝色点集必定为最大独立集。 蓝色点数 =总点数 - 红色点数，即最大独立集=总数-最小覆盖集。\n\n    ","tags":["二分图"],"categories":["ACM"]},{"title":"异或运算的一个性质","url":"/2017/08/13/acm/markdown/math/有关异或运算/","content":"\n## 一个结论\n1 ^ 2 ^ 3 ^ 4.....^ n是可以在O（1）时间内计算出来的\n参考如下代码\n```c++\nll xor_n(ll n)\n{\n ll t = n & 3;\n if (t & 1) return t / 2LL ^ 1;\n return t / 2LL ^ n;\n}\n```","tags":["数论","异或"],"categories":["ACM"]},{"title":"DP-最长上升子序列","url":"/2017/04/12/acm/题解/DP-最长上升子序列/","content":"## 解析\n这个问题是DP问题中的一个经典模型，可以参考《挑战程序设计竞赛》P64  \n做了几道题由这个模型可以引申解决一些经典DP问题  \n\n## 例子\n\n## 总结\n最长上升子序列为模型的问题有的特点总结为：  \n1. 存在一个有序序列，或是，序列需要至少按照某种规则使之有序\n2. 状态转移由当前元素前面的元素决定，这是有序序列的特殊性质  \n  \n其状态转移方程大致格式为： DP[i] = max{DP[i],dp[j]+k[i]}  \n对于最长上升子序列问题 k[i]\t== 1","tags":["动态规划"],"categories":["ACM"]},{"title":"poj-2348","url":"/2017/04/03/acm/题解/poj-2348/","content":"\n### 题意分析\n题目给出了两个正数a.b  \n每次操作，大的数减掉小的数的整数倍。一个数变为0 的时候结束。  \n谁先先把其中一个数减为0的获胜。问谁可以赢。Stan是先手。  \n假设两个数为a,b（a>=b)  \n如果a==b.那么肯定是先手获胜。一步就可以减为0,b  \n如果a%b==0.就是a是b的倍数，那么也是先手获胜。  \n如果a>=2*b.  那么   那个人肯定知道a%b,b是必胜态还是必败态。如果是必败态，先手将a,b变成a%b,b,那么先手肯定赢。如果是必胜态，先手将a,b变成a%b+b,b.那么对手只有将这两个数变成a%b,b,先手获胜。  \n如果是b<a<2*b  那么只有一条路：变成a-b,b  (这个时候0<a-b<b).这样一直下去看谁先面对上面的必胜状态。  \n所以假如面对b < a <2*b的状态，就先一步一步走下去。直到面对一个a%b==0 || a >=2*b的状态。  \n\n``` c++\n#include <iostream>\n#include <cstdio>\n#include <cstring>\n#include <algorithm>\n#define LL long long \n\nusing namespace std;\n\nint main()\n{\n\tint N,M;\n\twhile(~scanf(\"%d%d\",&N,&M))\n\t{\n\t\tif(M==0 && N==0)\tbreak;\n\t\tint a = max(N,M);\n\t\tint b = min(N,M);\n\t\tint nflag = 0;\n\t\tif(a%b==0||a/b>=2)\n\t\t\tnflag = 0;\n\t\telse{\n\t\t\twhile(b){\n\t\t\t\tif(a%b==0||a/b>=2)\tbreak;\n\t\t\t\ta = a-b;\n\t\t\t\tswap(a,b);\n\t\t\t\tnflag ^=1;\n\t\t\t}\n\t\t}\n\t\tif(!nflag)\n\t\t\tputs(\"Stan wins\");\n\t\telse\n\t\t\tputs(\"Ollie wins\");\n\t\t\t\n\t}\n}\n\n```","tags":["题解","博弈论"],"categories":["ACM"]},{"title":"组合博弈与SG函数","url":"/2017/04/03/acm/题解/组合博弈与SG函数/","content":"\n## 组合博弈\n\n### 组合博弈的规则（Imaprtial Combinatorial Games）\n 1. 有两名选手  \n 2. 两名选手交替对游戏进行移动(move)，每次一步，选手可以在（一般而言）有限的合法移动集合中任选一种进行移动\n 3. 对于游戏的任何一种可能的局面，合法的移动集合只取决于这个局面本身，不取决于轮到哪名选手操作、以前的任何操作、骰子的点数或者其它什么因素； \n 4. 如果轮到某名选手移动，且这个局面的合法的移动集合为空（也就是说此时无法进行移动），则这名选手负。\n\n### 对NP状态的定义\n1. 无法进行任何移动的局面（也就是terminal position）是P-position；\n2. 可以移动到P-position的局面是N-position；\n3. 所有移动都导致N-position的局面是P-position。\n\n## SG函数\n\n### mex运算\n首先定义mex(minimal excludant)运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如mex{0,1,2,4}=3、mex{2,3,5}=0、mex{}=0。\n\n### SG 函数的定义\n对于一个给定的有向无环图，定义关于图的每个顶点的Sprague-Garundy函数g如下：g(x)=mex{ g(y) | y是x的后继 }。\n\n\n### 分析\n来看一下SG函数的性质。首先，所有的terminal position所对应的顶点，也就是没有出边的顶点，其SG值为0，因为它的后继集合是空集。然后对于一个g(x)=0的顶点x，它的所有后继y都满足g(y)!=0。对于一个g(x)!=0的顶点，必定存在一个后继y满足g(y)=0。  \n\n以上这三句话表明，顶点x所代表的postion是P-position当且仅当g(x)=0（跟P-positioin/N-position的定义的那三句话是完全对应的）。我们通过计算有向无环图的每个顶点的SG值，就可以对每种局面找到必胜策略了\n\n我们可以定义有向图游戏的和(Sum of Graph Games)：设G1、G2、……、Gn是n个有向图游戏，定义游戏G是G1、G2、……、Gn的和(Sum)，游戏G的移动规则是：任选一个子游戏Gi并移动上面的棋子。Sprague-Grundy Theorem就是：g(G)=g(G1)^g(G2)^...^g(Gn)。也就是说，游戏的和的SG函数值是它的所有子游戏的SG函数值的异或。\n\n### 证明\n\n根据上述定义只需要证明SG值为0和不为0时满足P态和N态的性质即可  \n1. 集合为空的时候不存在后继集合，SG值为0\n2. 当g(G)=g(G1)^g(G2)^...^g(Gn)=k 时，必存在g(Gk)，有g(Gk)^k < g(Gk)从而存在对第k个子游戏的一种操作，使g(Gk)'=g(Gk)^k 从而g(G)' = 0\n3. 当g(G)=g(G1)^g(G2)^...^g(Gn)=0时对任意一个子游戏进行操作必得到g(Gk)'<g(Gk)，从而g(G)'!=0 为N态，故g(G)=0时为P态\n\n![](/images/还有这种操作.jpg)\n\n### SG函数的应用\n一个组合博弈分为N个子博弈，组合博弈的SG函数值就是子博弈SG函数值的异或。\n在前面的Nim游戏当中，N个堆的分别的SG值就是当前堆的石子数（可以一次性全部取完）\n\n#### 关于怎么去求SG函数的值   \n根据定义我们知道求SG函数的值有几个关键的点：\n1. 求当前状态的所有后缀状态的SG值\n2. 对所有后缀的SG值进行Mes操作\n\n因此，我们需要从终态状态开始，逐个求SG值，这就要求把局面转化为一个现态到终态递减的值或者在求SG值的时候注意安排现态在所有次态求出后  \n对于Mes操作，先记录每一个后缀状态SG值的出现状况，然后找出第一个未出现的值即可  \n可以用以下代码表示\n```c++\n//f[N]:可改变当前状态的方式，N为方式的种类，f[N]要在getSG之前先预处理  \n//SG[]:0~n的SG函数值  \n//S[]:为x后继状态的集合  \nint f[N],SG[MAXN],S[MAXN];  \nvoid  getSG(int n){  \n    int i,j;  \n    memset(SG,0,sizeof(SG));  \n    //因为SG[0]始终等于0，所以i从1开始  \n    for(i = 1; i <= n; i++){  \n        //每一次都要将上一状态 的 后继集合 重置  \n        memset(S,0,sizeof(S));  \n        for(j = 0; f[j] <= i && j <= N; j++)  \n            S[SG[i-f[j]]] = 1;  //将后继状态的SG函数值进行标记  \n        for(j = 0;; j++) if(!S[j]){   //查询当前后继状态SG值中最小的非零值  \n            SG[i] = j;  \n            break;  \n        }  \n    }  \n}  \n```\n\n对于有一类题SG函数值是存在规律的，对于输入量明显较大的题，可以先打个表找出SG函数的规律，对于另外一种\n就需要把整个SG函数表保存起来\n\n参考资料：\nhttp://www.wutianqi.com/?p=1081","tags":["博弈论"],"categories":["ACM"]},{"title":"博弈论入门","url":"/2017/03/30/acm/markdown/博弈论入门/","content":"## 几种博弈：\n### 巴什博奕（Bash Game）\n*只有一堆n个物品，两个人轮流从这堆物品中取物，规定每次至少取一个，最多取m个。最后取光者得胜*\n\n### 威佐夫博奕（Wythoff Game） \n*有两堆各若干个物品，两个人轮流从某一堆或同时从两堆中取同样多的物品，规定每次至少取一个，多者不限，最后取光者得胜。*\n\n那么任给一个局势（a，b），怎样判断它是不是奇异局势呢？我们有如下公式：\n\n    ak =[k（1+√5）/2]，bk= ak + k  （k=0，1，2，…,n 方括号表示取整函数) \n\n可以这样进行判断：\n``` c++\n\tint a = max(M,N);\t//M,N分别为一开始两堆物品个数\n\tint b = min(M,N);\n\tint k = a-b;\n\ta = int(k*(1+sqrt(5))/2.0);\n\tif(a==b)\n\t\tflag = false;\t//先手必败 P态\n\telse\n\t\tflag = true;\t//先手必胜 N态\n```\n\n**威佐夫游戏的一种变形：** 见 POJ2348\n\n\n### Nim游戏\n有n堆各若干个物品，两个人轮流从某一堆取任意多的物品，规定每次至少取一个，多者不限，最后取光者得胜。\n\nNim 游戏是组合游戏的一种\n当每堆物品分别为a1 a2 a3...an时  \n若a1^a2^a3^...an == 0时则为必败态，反之必胜\n\n","tags":["博弈论"],"categories":["ACM"]},{"title":"HDU-5667 矩阵快速幂&费马小定理","url":"/2017/03/22/acm/题解/HDU-5667/","content":"做题新遇到的知识点，暂时未ac 先markdown\n\n## 快速幂\n\n见算法概论p22  \n### 大致思想\n求 a^b mod N 时，从a mod N 开始不断对结果进行平方后迭代。然后把N对应二进制位为1的地方相乘，实际上是借助了：  \n**a^b = a^(2^k1+2^k2+....)**  \n的思想\n\n\n## 费马小定理\n\n当gcd(a,p)=1 且P为质数的时候有： \n\n**(p-1)mod p=1**\n\n\n\n## HDU-5667\n### 题解\n这一题实际上就是对递推式log然后转化为矩阵快速幂求f(n)时a的幂\n\n### 要点\n1. 从递推式到矩阵要注意，仔细观察递推式，矩阵的维数要恰当\n2. 注意在快速幂的时候模（p-1）\n","tags":["数论","快速幂"],"categories":["ACM"]},{"title":"asm_learning_note","url":"/2017/03/16/asm-learning-note/"},{"title":"三葉のテーマ","url":"/2017/03/15/三葉/","content":"   会困扰吗，会尴尬吗，还是...会有些许的高兴呢..  \n\n\n   回忆中，三叶一个人踏上去东京的电车时候，到底是怎样一种心情呢  \n\n\n   最喜欢的一首 \n\n   \n","tags":["随想"],"categories":["说说"]},{"title":"poj-1061 扩展欧几里得","url":"/2017/03/13/acm/题解/poj-1061/","content":"\n## 扩展欧几里得\n第一次写扩展欧几里得，感觉最重要的还是最开始就搞懂定理的推导过程，不然会遇到一些坑，在这里简单的mark一下我的理解。 \n\n### 原理\n扩展欧几里得德递归形式和gcd类似，关键在于中途对x,y的处理，重点在理解一下方程的推导：   \n**ax1+by1=gcd(a,b)**  ....1  \n**bx2+ay2=gcd(b,a%b)**  ....2  \n**gcd(a,b)=gcd(b,a%b)**  ....3  \n\n化简可以得到：x1=y2 y1=x2-a/b*y2  之后便不难理解边界条件设为b=0时，最终可以推出来方程1的一组解x0,y0  \n  \n### 推论\n重点在于其得到的推论：**ax+by=c 仅当cMODgcd(a,b)=0 时有解**  \n设 c = k*gcd(a,b)  \n上式可以化简为 a/gcd(a,b)*x + b/gcd(a,b)*y = k   =>  Ax+By=k  \n显然AB互质，因而满足方程的解系为(x0-nB,x0+nA) n为任意整数  \n\n## 题解\n就这道题目来说，我觉得对新手来说坑还是有几个：  \n1. 将追逐问题转化为ax+by=c 的不定方程组的解的问题，即确定a和b.\n2. 将exgcd求得的解转化为原方程的解（判断是否有解），并最小化\n\n### 代码\n```c++\n#include <iostream>\n\n#define ABS(x) (((x)>0)?(x):(-(x)))\n#define LL long long\nusing namespace std;\n\n//ax+by = gcd(a,b)\nvoid exgcd(LL a,LL b,LL &x,LL &y,LL &d)\n{\n\tif(b==0){\n\t\tx = 1; y = 0; d =a;\n\t\treturn;\n\t}\n\texgcd(b,a%b,x,y,d);\n\tLL t=x;\n\tx = y;\n\ty = t - (a/b)*y;\n\treturn;\n}\n\n\nint main()\n{\n\tLL x,y,m,n,l;\n\tcin>>x>>y>>m>>n>>l;\n\tLL v,dis,d,x0,y0;\n\tv  = ABS(m-n);\n\tif(m>n)\n\t\tdis = (y-x+l)%l;\n\telse\n\t\tdis = (x-y+l)%l;\n\t\t\n\texgcd(v,l,x0,y0,d);\n\t\n\tif(d&&dis%d==0){\n\t\tx0 = x0*dis/d;\n\t\tLL t = l/d;\n\t\tx0 = (x0%t+t)%t;\n\t\tcout<<x0<<endl;\n\t}\n\telse{\n\t\tcout<<\"Impossible\"<<endl;\n\t}\n}\n\n```\n","tags":["题解","数论"],"categories":["ACM"]},{"title":"图网络分析方法","url":"/2017/03/09/algorithms/图网络分析方法/","content":"\n## 前言\n不是什么事情都要给别人一个交代，但总是要给自己一个交代的，因此遍有了这一篇总结。   \n\n 这是一篇来自于课程设计的markdown，由于自己给自己开的坑，花费了大量时间。\n还有一个目的主要是记录下自己学到的知识，以方便以这段经历为跳板，在后面对数据挖掘领域进行更深层次的学习\n\n## 图网络分析方法的主要任务\n\n### 引出\n\n对于一般的图结构的数据来说，抛开节点和边所带的附加数据域来看，图的主要性质，就体现在节点 边的属性和图本身的拓扑结构上了  比如说节点的度 边的权 都是表征图结构基本而又重要的性质.   \n不过对于这些性质来说，还是从微观在描述图的最小成员：节点和边在图拓扑中的性质，因此要描述整个图结构的性质，就需要有另外一些衡量标准与方法  \n\n### 网络性质 NetworkOverview\n这里取图可视化软件**Gephi**的所选取的几个指标：  \n1. Network Diameter 网络直径 \n2. Graph Density 图紧密度\n3. Modularity 模块度\n4. Centrarity 中心度 \n5. Connected subgraph 联通子图 \n\n\n## 网络分析的主要算法\n\n 这里只列举几个我实际学习并实现的 \n\n### PageRank（Centrarity ）-2002\n PageRank 是很为我们熟知的google发家的算法，网络拓扑其实也就是一个很大型的图结构。关于PageRank 的介绍网上已经有较为详细的解读了，[这篇blog写得挺好](http://blog.jobbole.com/71431/)。\n\nPageRank 其实从算法原理上非常简单，就是一个矩阵的迭代，实际应用中真正的问题在于大型网络拓扑的分布式计算 因而有了PageRank的mapreduce实现\n\n\n### 顶点度（Centrarity ）\n ..大家什么都没看到\n\n### Gravian-Newman 社区发现算法（Modularity） -2004\n 社区发现的入门级算法...折腾了我好久  \n 这个我感觉网上现有的一些资料中并没有很好的..我会自己写一篇详细介绍的   \n 附上链接 **[Newman教授的个人主页](http://www-personal.umich.edu/~mejn/)**\n\n\n### FastUnfolding 算法 （Modularity）-2008\n 同样会另起一篇blog介绍这个..但感觉自己对这个算法理解的还不是那么透彻..特别是在模块度的计算上还有些问题..在这里mark住，以便以后继续学习\n\n\n","tags":["数据挖掘","图"],"categories":["算法"]}]