{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/cat.jpg","path":"images/cat.jpg","modified":1,"renderable":0},{"_id":"source/images/二分图.png","path":"images/二分图.png","modified":1,"renderable":0},{"_id":"source/images/养生.jpg","path":"images/养生.jpg","modified":1,"renderable":0},{"_id":"source/images/扑通.jpg","path":"images/扑通.jpg","modified":1,"renderable":0},{"_id":"source/images/等待鸽多.jpg","path":"images/等待鸽多.jpg","modified":1,"renderable":0},{"_id":"source/images/还有这种操作.jpg","path":"images/还有这种操作.jpg","modified":1,"renderable":0},{"_id":"source/images/tf/tensor_data_flow_graph.png","path":"images/tf/tensor_data_flow_graph.png","modified":1,"renderable":0},{"_id":"source/images/tf/tf_api.png","path":"images/tf/tf_api.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/images/tf/simple_neural_net.jpeg","path":"images/tf/simple_neural_net.jpeg","modified":1,"renderable":0},{"_id":"source/images/tf/convolution.png","path":"images/tf/convolution.png","modified":1,"renderable":0},{"_id":"source/images/tf/VGGNet.png","path":"images/tf/VGGNet.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"source/images/西湖暴雨.jpg","path":"images/西湖暴雨.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"source/images/未名麻雀.jpg","path":"images/未名麻雀.jpg","modified":1,"renderable":0}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1489292456000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1489292456000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1489292456000},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1489292456000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1489292456000},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1489292456000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1489292456000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1489292456000},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1489292456000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1489292456000},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1489292456000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1489292456000},{"_id":"themes/next/_config.yml","hash":"0aee077852aec638238542268b0638c66b73ad46","modified":1523857297078},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1489292456000},{"_id":"themes/next/gulpfile.coffee","hash":"933e6d29eb82522cff0df209d52b935e91b1111c","modified":1489292456000},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1489292456000},{"_id":"source/_posts/UVAlive3211-2SAT模板题.md","hash":"614974f4c38a4e3e92ce0fe0ed92d25d9ef9d635","modified":1504435170511},{"_id":"source/_posts/asm-learning-note.md","hash":"d13ec6de614e4a20d9f72ad6190da1b0ffb97d59","modified":1489630234000},{"_id":"source/_posts/三葉.md","hash":"d5d1a29de36dcba59d637b0e0e9e9b1e0eccd3a3","modified":1490377694000},{"_id":"source/_posts/开关反转问题.md","hash":"3a762da1226ad9c4eb9ffce55f3d0e9489838e35","modified":1522335752579},{"_id":"source/_posts/求最小割最少边数.md","hash":"5668207e7ced0417b29d0d4b7c922110c4d2f6b6","modified":1505749161089},{"_id":"source/_posts/沈阳网络赛2017.md","hash":"835fada5cb1eb215e2991f0d55e00572ad8faf64","modified":1505400820915},{"_id":"source/_posts/简单的LCA.md","hash":"ac024ebd3e9d050205a2c781b9360797325e7a51","modified":1504456862274},{"_id":"source/_posts/简单的几何学.md","hash":"d23473616d99363dd045d10e68985f67943db71b","modified":1504322932118},{"_id":"source/_posts/高斯消元求解带模方程组.md","hash":"828d6536f76441556a3ca36cf3d6cd72651d46a5","modified":1522335752592},{"_id":"source/backup/日常12.11.md","hash":"82560ead30331cccf9151cf28a307f9c01fd17cd","modified":1513527938565},{"_id":"source/backup/日常12.18.md","hash":"3183f644573fc5ca161067fc419642cfe3b717b9","modified":1513875991271},{"_id":"source/backup/最终还是来了.md","hash":"3e801a6fcff069fee45b7941adb1b2440aa17d55","modified":1505754016141},{"_id":"source/categories/index.md","hash":"7df1224b40bd393538d461e23f0ddd853cf703d8","modified":1490377694000},{"_id":"source/images/cat.jpg","hash":"f176643ddfdf4a88010ab4032ba8ac447ef6a337","modified":1490377694000},{"_id":"source/images/二分图.png","hash":"a9fc547c4a7811a9f0a48c2d3ae14e2909e85511","modified":1503411250315},{"_id":"source/images/养生.jpg","hash":"556874479f37499d9f73b5bd5c2f5c70007a3731","modified":1505750062358},{"_id":"source/images/扑通.jpg","hash":"64b20054c682babc4e8085510884d9f3b9aaed78","modified":1505751487238},{"_id":"source/images/等待鸽多.jpg","hash":"58d254aaefac70c05cec9c13ef2075731d125d80","modified":1505751563524},{"_id":"source/images/还有这种操作.jpg","hash":"1520f5032d98d2896b081a6e47547b6f9a45c4b7","modified":1491202126000},{"_id":"source/tags/index.md","hash":"84362fc5d5b93b26b808ddfca97d0e2d039548c2","modified":1490377694000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1489292456000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1489292456000},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1489292456000},{"_id":"themes/next/languages/default.yml","hash":"95ec5cdfb563854f231b76162a3494f6ecc5bf61","modified":1489292456000},{"_id":"themes/next/languages/en.yml","hash":"95ec5cdfb563854f231b76162a3494f6ecc5bf61","modified":1489292456000},{"_id":"themes/next/languages/fr-FR.yml","hash":"e98f1558347752a20019b71f0b1f9c8be1b34f42","modified":1489292456000},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1489292456000},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1489292456000},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1489292456000},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1489292456000},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1489292456000},{"_id":"themes/next/languages/ru.yml","hash":"5022885d8955e1b91d8841048db272bf99c59a76","modified":1489292456000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"40d01dc46d57f71c2ef635c45b295d4355456e90","modified":1489292456000},{"_id":"themes/next/languages/zh-hk.yml","hash":"19c23d21f262e24c06ee6ddfd51d2a6585304f88","modified":1489292456000},{"_id":"themes/next/languages/zh-tw.yml","hash":"68407799271c78ecc07f03d238257dd8c65ad42d","modified":1489292456000},{"_id":"themes/next/layout/_layout.swig","hash":"2c0c3547a5b470024326a33ae2779d5ee0252266","modified":1489292456000},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1489292456000},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1489292456000},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1489292456000},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1489292456000},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1489292456000},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1489292456000},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1489292456000},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1489292456000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1489292456000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1489292458000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1489292458000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1489292458000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"source/_posts/algorithms/图网络分析方法.md","hash":"53d71e46aef5039b9aefece046200d517e5d66d7","modified":1490377694000},{"_id":"source/images/tf/tensor_data_flow_graph.png","hash":"fb954d5a02f93fb817c0c25d131a5977b56328ab","modified":1522299991895},{"_id":"source/images/tf/tf_api.png","hash":"d3b01678997069ef4108f95d6335a9ff4f3812fa","modified":1522493604266},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1489292456000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1489292456000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1489292456000},{"_id":"themes/next/layout/_macro/post.swig","hash":"4a191a612383bb04a4705b4044c033f765060207","modified":1489292456000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"911b99ba0445b2c07373128d87a4ef2eb7de341a","modified":1489292456000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1489292456000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1489292456000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"970aa668680896262b1056bb5787fc9ec8754495","modified":1489292456000},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1489292456000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1489292456000},{"_id":"themes/next/layout/_partials/head.swig","hash":"a0eafe24d1dae30c790ae35612154b3ffbbd5cce","modified":1489292456000},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1489292456000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1489292456000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1489292456000},{"_id":"themes/next/layout/_partials/search.swig","hash":"7b61e96508df70152b809ea5354236ab7f0d54f4","modified":1489292456000},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1489292456000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1489292456000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1489292456000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"4512867d80d9eddfc3a0f5fea3c456f33aa9d522","modified":1489292456000},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1489292456000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1489292456000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"79378f3a1cd90518b07808ed09156a3ab55ffa31","modified":1489292456000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1489292456000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1489292456000},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1489292456000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1489292456000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1489292456000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1489292456000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1489292456000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1489292456000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1489292456000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1489292456000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1489292456000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1489292456000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1489292456000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1489292456000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1489292456000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1489292456000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1489292456000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1489292456000},{"_id":"source/images/tf/simple_neural_net.jpeg","hash":"e0ff3bfb200bfb8445e5ba03d1c808f0d0ca4475","modified":1523547091835},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1489292456000},{"_id":"source/_posts/acm/markdown/博弈论入门.md","hash":"436738bb1d6b8c9b4c2a52fc50a97f6e506939bc","modified":1491201954000},{"_id":"source/_posts/acm/题解/DP-最长上升子序列.md","hash":"3231caced020ca82344bccdedfc2400cf26a03a6","modified":1491934128000},{"_id":"source/_posts/acm/match/2017-广西邀请赛.md","hash":"03963cde2e01dfb701277e07dae1ba8d3bdb0464","modified":1504005257755},{"_id":"source/_posts/acm/题解/HDU-5667.md","hash":"d7c21e46a1fc564c1670fd3fbe6e35e085ca25b1","modified":1490353282000},{"_id":"source/_posts/acm/题解/poj-1061.md","hash":"b8dc345953d253ccdfa08fee3402a74c2b9da9c7","modified":1490377694000},{"_id":"source/_posts/acm/题解/poj-2348.md","hash":"3152a2028bd07876e8f28bc287641636d70e8fec","modified":1491306164000},{"_id":"source/_posts/acm/题解/组合博弈与SG函数.md","hash":"c38f70d0a53c087ec963cb6e0eb62d608ed7657d","modified":1491204602000},{"_id":"source/_posts/machinelearning/tensorflow_notes/note1.md","hash":"3e6db6286bafbfad2ad520e0ea5af3ce7c7dbee3","modified":1523860128033},{"_id":"source/_posts/machinelearning/tensorflow_notes/note2.md","hash":"bdce494b6fa50b0d095c1f6ba42584a8c13c470c","modified":1522402015451},{"_id":"source/_posts/machinelearning/tensorflow_notes/note3.md","hash":"74459bdf0821ff6aa04c460d231ae0ae1f8e8b0e","modified":1523801450391},{"_id":"source/_posts/machinelearning/tensorflow_notes/note_CNN.md","hash":"e87f4d5d6c85060929a30d1527359aa5cf132774","modified":1523855232896},{"_id":"source/_posts/machinelearning/tensorflow_notes/style_transfer.md","hash":"08e93fe14646deab8fb5b4820d87efd7fd3badca","modified":1523860137477},{"_id":"source/_posts/machinelearning/tensorflow_notes/tf_minist.md","hash":"cf5c59d731a4c4f770bd4073cc7ef9d26871b3dc","modified":1523855228666},{"_id":"source/images/tf/convolution.png","hash":"f4f35f9f9328300b7be209d8e1f522385472b9ca","modified":1523546032371},{"_id":"source/images/tf/VGGNet.png","hash":"efbdb9c0cffadc335e8696779f8299e9d07e986b","modified":1523804002804},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1489292456000},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1489292456000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1489292456000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1489292456000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"2d1075f4cabcb3956b7b84a8e210f5a66f0a5562","modified":1489292456000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1489292456000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1489292456000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1489292456000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1489292456000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1489292456000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1489292456000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1489292456000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"e46900412e28f529c26e25e6bada342006435a32","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"a279e1881208aff2f669fe235e9661ab825bc540","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"f4dbd4c896e6510ded8ebe05394c28f8a86e71bf","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1489292456000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1489292456000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1489292456000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1489292456000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1489292456000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1489292456000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"e7c76d93605e2b685274400afe51c55cc651486e","modified":1489292456000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1489292458000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1489292456000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1489292458000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1489292458000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1489292458000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1489292458000},{"_id":"themes/next/source/js/src/post-details.js","hash":"3b2d64c2e6ae072ba2a9ebf7f09908a1543abd58","modified":1489292458000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1489292458000},{"_id":"themes/next/source/js/src/utils.js","hash":"e13c9ccf70d593bdf3b8cc1d768f595abd610e6e","modified":1489292458000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1489292458000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1489292458000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1489292458000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1489292458000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1489292458000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1489292458000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1489292458000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1489292458000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1489292458000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1489292458000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1489292458000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1489292458000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1489292458000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1489292458000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1489292458000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1489292458000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1489292458000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1489292458000},{"_id":"source/images/西湖暴雨.jpg","hash":"e83153c25b81b736c6951741c0b5404929378721","modified":1505748989035},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1489292458000},{"_id":"source/_posts/acm/markdown/math/有关异或运算.md","hash":"5cd6be5462e123cd085fb4fb3c2ab40cbb5183f3","modified":1503834233003},{"_id":"source/_posts/acm/markdown/math/欧拉函数.md","hash":"c2d63763bd24e391a74f54ca432c23769d13e122","modified":1503834147120},{"_id":"source/_posts/acm/markdown/math/素数线性筛法.md","hash":"e387d2f0b728c1ae2d91d1957aff46673a972631","modified":1503834191635},{"_id":"source/_posts/acm/markdown/图论/二分图.md","hash":"6b50714fa8895c3a37b9fdbb1fd4904fed0e585c","modified":1505369075976},{"_id":"source/_posts/acm/markdown/数据结构/稀疏表.md","hash":"c21cf348e86cdf4c56671e83358e4f84a8b85ac9","modified":1503834269254},{"_id":"source/_posts/acm/题解/图论/Uva-11354 最小瓶颈树+LCA倍增法维护最大值.md","hash":"73acdda16f458bf90a038bc6cff270878e9e4399","modified":1503835200258},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-mta.swig","hash":"a652f202bd5b30c648c228ab8f0e997eb4928e44","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments/livere.swig","hash":"7240f2e5ec7115f8abbbc4c9ef73d4bed180fdc7","modified":1489292456000},{"_id":"themes/next/layout/_scripts/third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1489292456000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1489292456000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1489292456000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1489292456000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1489292456000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1489292456000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"f15537cee1a9ef4fa1e72a1670ebce4097db8115","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1489292456000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1489292458000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1489292458000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1489292458000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1489292458000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1489292458000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1489292458000},{"_id":"source/_posts/acm/题解/图论/二分图/Uva-14149 二分图匹配求最小点覆盖.md","hash":"4a04b0a3984ccd2f5690bd3b6acb22fe7fd28243","modified":1503834640335},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"755b04edbbfbdd981a783edb09c9cc34cb79cea7","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"b9a2e76f019a5941191f1263b54aef7b69c48789","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"bfd806d0a9f21446a22df82ac02e37d0075cc3b5","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"8fe1e55bc290e6aaf07cc644fe27b62107a272a8","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"173490e21bece35a34858e8e534cf86e34561350","modified":1489292456000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1489292456000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1489292456000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1489292458000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1489292458000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1489292458000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1489292458000},{"_id":"source/images/未名麻雀.jpg","hash":"2dd407331ed1395ced0d075b858960fabd69fa0f","modified":1505748990691}],"Category":[{"name":"ACM","_id":"cjg1v55bf0003acwoeb9usd1m"},{"name":"说说","_id":"cjg1v55cq0008acwoytyu75my"},{"name":"算法","_id":"cjg1v56720012acwoybwigjn7"}],"Data":[],"Page":[{"title":"该来的还是来==","date":"2017-12-11T15:50:11.000Z","tags":null,"categories":"说说","_content":"\n## day1:  \n\tdp暴艹贪心大失败，高精度怎么这么难写，我好菜啊  \n\t算导全解计划咕咕咕...争取明天先把算法实验都肝完... \n\t总之开始日常总结了，并不想让太多人看到，有时间会改版，做个访问控制以及留言啥的...寒假再说..\n\t总之当个记事本之类的东西  \n\t啊.说起来这周是不是还有6级来着..\n\n## day2:  \n\t状压dp写的慢，结果猛然回头发现写的高精度乘WA了，GG，去你的动态分配内存   \n\t和张子昂在咖啡馆碰到了，聊了一下团队的现状，唔..感觉也很不容易  \n\t啊 焦糖玛奇朵好好喝啊  \n\t是不是又忘了复习英语来着\n\t明日计划开始肝NS2的报告吧..复习英语，计组实验..唔..  \n\t妈耶我第二天竟然记得写了= = \n\n## day3:\n\t有点咸鱼的一天..也只做完了计组实验，cpu还没开始动  \n\t然后...明天除了要写完socket实验报告之外真的要复习一下英语了\n\t咸睡！\n\t\n## day4\n\t惊了 竟然还记得写..\n\t早上直接咸鱼到12点，吃个饭1:30\n\t下午从2：00 - 6：30 晚上 8：00 - 12：30 唔 这样一看大概写了9小时报告..其实也浪费了很多时间了..\n\t然而今天依然没看英语= =..........\n\t等一个GG\n\t\n## day5\n\tday7回忆day5咸鱼实况\n\t好像咸鱼半天是把socket收了个尾\n\t然后半夜开始打l4d2(#`O′)...\n\n## day6\n\t乱写完报告，然后lay了\n\n## day7\n\t睡到中午，lay了\n\temmm...\n\t这样就写了一周了！有进步！然而周末两天有点咸鱼了..看来还是不能呆在寝室啊= =。。","source":"backup/日常12.11.md","raw":"---\ntitle: 该来的还是来==\ndate: 2017-12-11 23:50:11\ntags:\ncategories: 说说\n---\n\n## day1:  \n\tdp暴艹贪心大失败，高精度怎么这么难写，我好菜啊  \n\t算导全解计划咕咕咕...争取明天先把算法实验都肝完... \n\t总之开始日常总结了，并不想让太多人看到，有时间会改版，做个访问控制以及留言啥的...寒假再说..\n\t总之当个记事本之类的东西  \n\t啊.说起来这周是不是还有6级来着..\n\n## day2:  \n\t状压dp写的慢，结果猛然回头发现写的高精度乘WA了，GG，去你的动态分配内存   \n\t和张子昂在咖啡馆碰到了，聊了一下团队的现状，唔..感觉也很不容易  \n\t啊 焦糖玛奇朵好好喝啊  \n\t是不是又忘了复习英语来着\n\t明日计划开始肝NS2的报告吧..复习英语，计组实验..唔..  \n\t妈耶我第二天竟然记得写了= = \n\n## day3:\n\t有点咸鱼的一天..也只做完了计组实验，cpu还没开始动  \n\t然后...明天除了要写完socket实验报告之外真的要复习一下英语了\n\t咸睡！\n\t\n## day4\n\t惊了 竟然还记得写..\n\t早上直接咸鱼到12点，吃个饭1:30\n\t下午从2：00 - 6：30 晚上 8：00 - 12：30 唔 这样一看大概写了9小时报告..其实也浪费了很多时间了..\n\t然而今天依然没看英语= =..........\n\t等一个GG\n\t\n## day5\n\tday7回忆day5咸鱼实况\n\t好像咸鱼半天是把socket收了个尾\n\t然后半夜开始打l4d2(#`O′)...\n\n## day6\n\t乱写完报告，然后lay了\n\n## day7\n\t睡到中午，lay了\n\temmm...\n\t这样就写了一周了！有进步！然而周末两天有点咸鱼了..看来还是不能呆在寝室啊= =。。","updated":"2017-12-17T16:25:38.565Z","path":"backup/日常12.11.html","comments":1,"layout":"page","_id":"cjg1v55y5000pacwo58llhekx","content":"<h2 id=\"day1\"><a href=\"#day1\" class=\"headerlink\" title=\"day1:\"></a>day1:</h2><pre><code>dp暴艹贪心大失败，高精度怎么这么难写，我好菜啊  \n算导全解计划咕咕咕...争取明天先把算法实验都肝完... \n总之开始日常总结了，并不想让太多人看到，有时间会改版，做个访问控制以及留言啥的...寒假再说..\n总之当个记事本之类的东西  \n啊.说起来这周是不是还有6级来着..\n</code></pre><h2 id=\"day2\"><a href=\"#day2\" class=\"headerlink\" title=\"day2:\"></a>day2:</h2><pre><code>状压dp写的慢，结果猛然回头发现写的高精度乘WA了，GG，去你的动态分配内存   \n和张子昂在咖啡馆碰到了，聊了一下团队的现状，唔..感觉也很不容易  \n啊 焦糖玛奇朵好好喝啊  \n是不是又忘了复习英语来着\n明日计划开始肝NS2的报告吧..复习英语，计组实验..唔..  \n妈耶我第二天竟然记得写了= = \n</code></pre><h2 id=\"day3\"><a href=\"#day3\" class=\"headerlink\" title=\"day3:\"></a>day3:</h2><pre><code>有点咸鱼的一天..也只做完了计组实验，cpu还没开始动  \n然后...明天除了要写完socket实验报告之外真的要复习一下英语了\n咸睡！\n</code></pre><h2 id=\"day4\"><a href=\"#day4\" class=\"headerlink\" title=\"day4\"></a>day4</h2><pre><code>惊了 竟然还记得写..\n早上直接咸鱼到12点，吃个饭1:30\n下午从2：00 - 6：30 晚上 8：00 - 12：30 唔 这样一看大概写了9小时报告..其实也浪费了很多时间了..\n然而今天依然没看英语= =..........\n等一个GG\n</code></pre><h2 id=\"day5\"><a href=\"#day5\" class=\"headerlink\" title=\"day5\"></a>day5</h2><pre><code>day7回忆day5咸鱼实况\n好像咸鱼半天是把socket收了个尾\n然后半夜开始打l4d2(#`O′)...\n</code></pre><h2 id=\"day6\"><a href=\"#day6\" class=\"headerlink\" title=\"day6\"></a>day6</h2><pre><code>乱写完报告，然后lay了\n</code></pre><h2 id=\"day7\"><a href=\"#day7\" class=\"headerlink\" title=\"day7\"></a>day7</h2><pre><code>睡到中午，lay了\nemmm...\n这样就写了一周了！有进步！然而周末两天有点咸鱼了..看来还是不能呆在寝室啊= =。。\n</code></pre>","excerpt":"","more":"<h2 id=\"day1\"><a href=\"#day1\" class=\"headerlink\" title=\"day1:\"></a>day1:</h2><pre><code>dp暴艹贪心大失败，高精度怎么这么难写，我好菜啊  \n算导全解计划咕咕咕...争取明天先把算法实验都肝完... \n总之开始日常总结了，并不想让太多人看到，有时间会改版，做个访问控制以及留言啥的...寒假再说..\n总之当个记事本之类的东西  \n啊.说起来这周是不是还有6级来着..\n</code></pre><h2 id=\"day2\"><a href=\"#day2\" class=\"headerlink\" title=\"day2:\"></a>day2:</h2><pre><code>状压dp写的慢，结果猛然回头发现写的高精度乘WA了，GG，去你的动态分配内存   \n和张子昂在咖啡馆碰到了，聊了一下团队的现状，唔..感觉也很不容易  \n啊 焦糖玛奇朵好好喝啊  \n是不是又忘了复习英语来着\n明日计划开始肝NS2的报告吧..复习英语，计组实验..唔..  \n妈耶我第二天竟然记得写了= = \n</code></pre><h2 id=\"day3\"><a href=\"#day3\" class=\"headerlink\" title=\"day3:\"></a>day3:</h2><pre><code>有点咸鱼的一天..也只做完了计组实验，cpu还没开始动  \n然后...明天除了要写完socket实验报告之外真的要复习一下英语了\n咸睡！\n</code></pre><h2 id=\"day4\"><a href=\"#day4\" class=\"headerlink\" title=\"day4\"></a>day4</h2><pre><code>惊了 竟然还记得写..\n早上直接咸鱼到12点，吃个饭1:30\n下午从2：00 - 6：30 晚上 8：00 - 12：30 唔 这样一看大概写了9小时报告..其实也浪费了很多时间了..\n然而今天依然没看英语= =..........\n等一个GG\n</code></pre><h2 id=\"day5\"><a href=\"#day5\" class=\"headerlink\" title=\"day5\"></a>day5</h2><pre><code>day7回忆day5咸鱼实况\n好像咸鱼半天是把socket收了个尾\n然后半夜开始打l4d2(#`O′)...\n</code></pre><h2 id=\"day6\"><a href=\"#day6\" class=\"headerlink\" title=\"day6\"></a>day6</h2><pre><code>乱写完报告，然后lay了\n</code></pre><h2 id=\"day7\"><a href=\"#day7\" class=\"headerlink\" title=\"day7\"></a>day7</h2><pre><code>睡到中午，lay了\nemmm...\n这样就写了一周了！有进步！然而周末两天有点咸鱼了..看来还是不能呆在寝室啊= =。。\n</code></pre>"},{"title":"该来的还是来==","date":"2017-12-18T15:50:11.000Z","tags":null,"categories":"说说","_content":"\n## day1:  \n\t竟然开始写第二周了，惊了。\n\t周一直接咸鱼过去了？哦对，写了一晚上算法作业来着\n\t\n## day2：\n\temmmm怎么说，我觉得情商不够主要让人不爽的地方，就是你明明也是在帮别人做事，对方却一副自己都不想理的样子\nwhat ever 无所谓了。\n\n## day3\n\t总算是搞定了cpu之后，可以稍微喘口气了，不过争取这周吧算法报告和操作系统报告都搞得差不多\n\t明天周四早上课之后直接去图书馆？\n\t努力一把，明天预计能写完操作系统实验报告。\n\t最好情况下，后天补完大数之后开始写算法报告，大概周六能写完。\n\t然后还有组原报告orz  \n\t总之，算导刷题计划要再启动了= =，每天5题！早起是关键！\n\t晚安晚安\n\t等一个香水到货\n\t\n## day4 \n\t睡了一个下午，稍微有些咸鱼了  \n\t少吃外卖！   \n\t早起啊啊啊啊  \n\t希望明天完成系统实验报告和大数！","source":"backup/日常12.18.md","raw":"---\ntitle: 该来的还是来==\ndate: 2017-12-18 23:50:11\ntags:\ncategories: 说说\n---\n\n## day1:  \n\t竟然开始写第二周了，惊了。\n\t周一直接咸鱼过去了？哦对，写了一晚上算法作业来着\n\t\n## day2：\n\temmmm怎么说，我觉得情商不够主要让人不爽的地方，就是你明明也是在帮别人做事，对方却一副自己都不想理的样子\nwhat ever 无所谓了。\n\n## day3\n\t总算是搞定了cpu之后，可以稍微喘口气了，不过争取这周吧算法报告和操作系统报告都搞得差不多\n\t明天周四早上课之后直接去图书馆？\n\t努力一把，明天预计能写完操作系统实验报告。\n\t最好情况下，后天补完大数之后开始写算法报告，大概周六能写完。\n\t然后还有组原报告orz  \n\t总之，算导刷题计划要再启动了= =，每天5题！早起是关键！\n\t晚安晚安\n\t等一个香水到货\n\t\n## day4 \n\t睡了一个下午，稍微有些咸鱼了  \n\t少吃外卖！   \n\t早起啊啊啊啊  \n\t希望明天完成系统实验报告和大数！","updated":"2017-12-21T17:06:31.271Z","path":"backup/日常12.18.html","comments":1,"layout":"page","_id":"cjg1v55yk000racwoby3o99hs","content":"<h2 id=\"day1\"><a href=\"#day1\" class=\"headerlink\" title=\"day1:\"></a>day1:</h2><pre><code>竟然开始写第二周了，惊了。\n周一直接咸鱼过去了？哦对，写了一晚上算法作业来着\n</code></pre><h2 id=\"day2：\"><a href=\"#day2：\" class=\"headerlink\" title=\"day2：\"></a>day2：</h2><pre><code>emmmm怎么说，我觉得情商不够主要让人不爽的地方，就是你明明也是在帮别人做事，对方却一副自己都不想理的样子\n</code></pre><p>what ever 无所谓了。</p>\n<h2 id=\"day3\"><a href=\"#day3\" class=\"headerlink\" title=\"day3\"></a>day3</h2><pre><code>总算是搞定了cpu之后，可以稍微喘口气了，不过争取这周吧算法报告和操作系统报告都搞得差不多\n明天周四早上课之后直接去图书馆？\n努力一把，明天预计能写完操作系统实验报告。\n最好情况下，后天补完大数之后开始写算法报告，大概周六能写完。\n然后还有组原报告orz  \n总之，算导刷题计划要再启动了= =，每天5题！早起是关键！\n晚安晚安\n等一个香水到货\n</code></pre><h2 id=\"day4\"><a href=\"#day4\" class=\"headerlink\" title=\"day4\"></a>day4</h2><pre><code>睡了一个下午，稍微有些咸鱼了  \n少吃外卖！   \n早起啊啊啊啊  \n希望明天完成系统实验报告和大数！\n</code></pre>","excerpt":"","more":"<h2 id=\"day1\"><a href=\"#day1\" class=\"headerlink\" title=\"day1:\"></a>day1:</h2><pre><code>竟然开始写第二周了，惊了。\n周一直接咸鱼过去了？哦对，写了一晚上算法作业来着\n</code></pre><h2 id=\"day2：\"><a href=\"#day2：\" class=\"headerlink\" title=\"day2：\"></a>day2：</h2><pre><code>emmmm怎么说，我觉得情商不够主要让人不爽的地方，就是你明明也是在帮别人做事，对方却一副自己都不想理的样子\n</code></pre><p>what ever 无所谓了。</p>\n<h2 id=\"day3\"><a href=\"#day3\" class=\"headerlink\" title=\"day3\"></a>day3</h2><pre><code>总算是搞定了cpu之后，可以稍微喘口气了，不过争取这周吧算法报告和操作系统报告都搞得差不多\n明天周四早上课之后直接去图书馆？\n努力一把，明天预计能写完操作系统实验报告。\n最好情况下，后天补完大数之后开始写算法报告，大概周六能写完。\n然后还有组原报告orz  \n总之，算导刷题计划要再启动了= =，每天5题！早起是关键！\n晚安晚安\n等一个香水到货\n</code></pre><h2 id=\"day4\"><a href=\"#day4\" class=\"headerlink\" title=\"day4\"></a>day4</h2><pre><code>睡了一个下午，稍微有些咸鱼了  \n少吃外卖！   \n早起啊啊啊啊  \n希望明天完成系统实验报告和大数！\n</code></pre>"},{"title":"该来的还是来==","date":"2017-09-18T00:10:33.000Z","tags":null,"categories":"说说","_content":"![](/images/等待鸽多.jpg)  \n\n该来的还是来吧，在咕咕咕两年后，随便乱扯一些东西  \n大概年龄只是一个数字，过生剩下的理由主要是提供过聚的动机和吃一些特定食物的理由（停一停，停一停朋友们，面都吃了三年了。  \n哦，不过从另外一个角度，现在大家可以说  \n你看，他都二十岁了，依旧这么精神。  \n\n上一次写长篇的时候，浑身上下还充满着迷之忧郁青年气氛（反正现在感觉就像个老年人一样，什么都写不动。  \n鬼知道我经历了什么。\n\n~~鬼说：嗯，我知道。 \n。。。。。。。。  \n行吧，那写个鬼~~\n\n总结起来可能就是：  \n头发越留越长，智商是越剩越少 \n\n一下开始没话找话，无总体架构叙述\n\n高中末期建立起来的四人小分队，虽然说好像有些时候有些迷，但据说我一直在睡觉。就我记得的事情来说，\n我觉得我们一直以来关于谁比较quen，以及谁是个什么这两个问题的讨论还是妙趣横生的。  \n我觉得不管怎样，总之过得开心就Ok  \n\n大一去了霓虹，逛了秋叶原、秋叶原和秋叶原（不是，札幌一家咖喱店的服务员小姐姐真好看啊我还记得。\n大一暑假万达瑞华真好啊\n大二：子怡、单总、大小为，在移动组划水划水划，学习了一个，获得了人生的经验。学长们都很努力，加油加油  \n\n暑假之前在~~zpzpz~~远走他乡之前搭了最后一班导游车，就是打车出门，下车暴雨，在暴雨下看西湖，然后出门的第一件事就是回家，但是好看啊。\n![](/images/西湖暴雨.jpg)  \n吃不到湖边外婆家，吃到了知味观，啊。。。爆鳝面  \n叕叒双又去了海南站，大概熟练掌握了五个全家的地理位置。  \n（这里的猫真肥啊\n\n去北京学习了一波..深刻感受到物价贵的地方不适合生存..\n戴笠妙啊..北大很漂亮\n清华很大，别人家的食堂都很不错\n![](/images/未名麻雀.jpg)\n\n\n因为身边有人喝酒的原因自己也也变的能喝一点，我在周围都是水牛的情况下，啤的还是饶了我吧...  \n喝酒目的不同结果也会不同，我不会去买醉啥的，还是喝到有些发晕才比较妙啊，喝到吐就没什么意思了。 \n比如说\n~~emmmmm...老师今天喝了一点酒~~  \n\n啊，可以说是非常的流水帐了  \n\n我有时候悲哀的觉得时间促不及防地快，高中的结点一过，在想清楚之前被催促着走向未来。 \n我觉得我渐渐能听到那种声音，就而今再聚之时，地毯上对坐深夜饮酒，杯子碰到一起，现实无奈的成为了\n话题中心。那大概就是那种声音。 \n也许是只能叹息不能惋惜吧。   \n大体上好像这两年，没什么收获，没什么失去，高中时代的追求没什么结果，大学的努力似乎还不足够，\n我经常想着，或许先放着努力就好了吧，然而有时候却又允许自己只做普通人，大概是问题所在。\n不喜欢平凡又喜欢平凡中的灵动，喜欢独特又无法理解一些小极端。可能是好人又到了一个程度= =，我总是看到别人互怼觉得~~不要打架不要打架~~,说不定有些事情只能互刀呢\nemmmm 想了想打住\n\n反正，作为一个撞南墙选手，做过的事情做出的选择 ，我不后悔\n   \n谢谢谢谢~~王林王林王~~的轮船~~和小火箭~~，早就是自带梗和表情包的优秀交流，emmmm？什 什么？？  \n和硬泉走爆上海滩，以及关于喵了个咪的烤鱼很ok、一点点没问题，和导致深夜睡不着，夜谈愉快。  \n室友去年的时候半夜突然的惊喜妙啊，还好他们没端一盆火锅进寝室  \n感谢何雨笙同学的心意，我觉得你接下来写文章接下来写下去就是知乎大v之路啦\n和队友做题吼啊，一个人做题还是做不起来。。~~专心打辅助~~\n~~智商就很着急，朝哥教我FFT~~\n还有一起玩过的魔兽世界冬拥湖ZP、麦霸君君、想法李狗、洋次郎ym、不需要形容词的游游、拯救单排老年人的颠和周帅\n![](/images/扑通.jpg)\n\n因为为了不咕咕咕，写的混乱，大家凑合看    \n因为人傻，表达不清，我猜还有别字（书写-3没救了，没救了\n\n大概总结起来还是：  \n\n![](/images/养生.jpg)\n\n生快生快快","source":"backup/最终还是来了.md","raw":"---\ntitle: 该来的还是来==\ndate: 2017-09-18 08:10:33\ntags:\ncategories: 说说\n---\n![](/images/等待鸽多.jpg)  \n\n该来的还是来吧，在咕咕咕两年后，随便乱扯一些东西  \n大概年龄只是一个数字，过生剩下的理由主要是提供过聚的动机和吃一些特定食物的理由（停一停，停一停朋友们，面都吃了三年了。  \n哦，不过从另外一个角度，现在大家可以说  \n你看，他都二十岁了，依旧这么精神。  \n\n上一次写长篇的时候，浑身上下还充满着迷之忧郁青年气氛（反正现在感觉就像个老年人一样，什么都写不动。  \n鬼知道我经历了什么。\n\n~~鬼说：嗯，我知道。 \n。。。。。。。。  \n行吧，那写个鬼~~\n\n总结起来可能就是：  \n头发越留越长，智商是越剩越少 \n\n一下开始没话找话，无总体架构叙述\n\n高中末期建立起来的四人小分队，虽然说好像有些时候有些迷，但据说我一直在睡觉。就我记得的事情来说，\n我觉得我们一直以来关于谁比较quen，以及谁是个什么这两个问题的讨论还是妙趣横生的。  \n我觉得不管怎样，总之过得开心就Ok  \n\n大一去了霓虹，逛了秋叶原、秋叶原和秋叶原（不是，札幌一家咖喱店的服务员小姐姐真好看啊我还记得。\n大一暑假万达瑞华真好啊\n大二：子怡、单总、大小为，在移动组划水划水划，学习了一个，获得了人生的经验。学长们都很努力，加油加油  \n\n暑假之前在~~zpzpz~~远走他乡之前搭了最后一班导游车，就是打车出门，下车暴雨，在暴雨下看西湖，然后出门的第一件事就是回家，但是好看啊。\n![](/images/西湖暴雨.jpg)  \n吃不到湖边外婆家，吃到了知味观，啊。。。爆鳝面  \n叕叒双又去了海南站，大概熟练掌握了五个全家的地理位置。  \n（这里的猫真肥啊\n\n去北京学习了一波..深刻感受到物价贵的地方不适合生存..\n戴笠妙啊..北大很漂亮\n清华很大，别人家的食堂都很不错\n![](/images/未名麻雀.jpg)\n\n\n因为身边有人喝酒的原因自己也也变的能喝一点，我在周围都是水牛的情况下，啤的还是饶了我吧...  \n喝酒目的不同结果也会不同，我不会去买醉啥的，还是喝到有些发晕才比较妙啊，喝到吐就没什么意思了。 \n比如说\n~~emmmmm...老师今天喝了一点酒~~  \n\n啊，可以说是非常的流水帐了  \n\n我有时候悲哀的觉得时间促不及防地快，高中的结点一过，在想清楚之前被催促着走向未来。 \n我觉得我渐渐能听到那种声音，就而今再聚之时，地毯上对坐深夜饮酒，杯子碰到一起，现实无奈的成为了\n话题中心。那大概就是那种声音。 \n也许是只能叹息不能惋惜吧。   \n大体上好像这两年，没什么收获，没什么失去，高中时代的追求没什么结果，大学的努力似乎还不足够，\n我经常想着，或许先放着努力就好了吧，然而有时候却又允许自己只做普通人，大概是问题所在。\n不喜欢平凡又喜欢平凡中的灵动，喜欢独特又无法理解一些小极端。可能是好人又到了一个程度= =，我总是看到别人互怼觉得~~不要打架不要打架~~,说不定有些事情只能互刀呢\nemmmm 想了想打住\n\n反正，作为一个撞南墙选手，做过的事情做出的选择 ，我不后悔\n   \n谢谢谢谢~~王林王林王~~的轮船~~和小火箭~~，早就是自带梗和表情包的优秀交流，emmmm？什 什么？？  \n和硬泉走爆上海滩，以及关于喵了个咪的烤鱼很ok、一点点没问题，和导致深夜睡不着，夜谈愉快。  \n室友去年的时候半夜突然的惊喜妙啊，还好他们没端一盆火锅进寝室  \n感谢何雨笙同学的心意，我觉得你接下来写文章接下来写下去就是知乎大v之路啦\n和队友做题吼啊，一个人做题还是做不起来。。~~专心打辅助~~\n~~智商就很着急，朝哥教我FFT~~\n还有一起玩过的魔兽世界冬拥湖ZP、麦霸君君、想法李狗、洋次郎ym、不需要形容词的游游、拯救单排老年人的颠和周帅\n![](/images/扑通.jpg)\n\n因为为了不咕咕咕，写的混乱，大家凑合看    \n因为人傻，表达不清，我猜还有别字（书写-3没救了，没救了\n\n大概总结起来还是：  \n\n![](/images/养生.jpg)\n\n生快生快快","updated":"2017-09-18T17:00:16.141Z","path":"backup/最终还是来了.html","comments":1,"layout":"page","_id":"cjg1v55z0000tacwokym3d3jp","content":"<p><img src=\"/images/等待鸽多.jpg\" alt=\"\">  </p>\n<p>该来的还是来吧，在咕咕咕两年后，随便乱扯一些东西<br>大概年龄只是一个数字，过生剩下的理由主要是提供过聚的动机和吃一些特定食物的理由（停一停，停一停朋友们，面都吃了三年了。<br>哦，不过从另外一个角度，现在大家可以说<br>你看，他都二十岁了，依旧这么精神。  </p>\n<p>上一次写长篇的时候，浑身上下还充满着迷之忧郁青年气氛（反正现在感觉就像个老年人一样，什么都写不动。<br>鬼知道我经历了什么。</p>\n<p><del>鬼说：嗯，我知道。<br>。。。。。。。。<br>行吧，那写个鬼</del></p>\n<p>总结起来可能就是：<br>头发越留越长，智商是越剩越少 </p>\n<p>一下开始没话找话，无总体架构叙述</p>\n<p>高中末期建立起来的四人小分队，虽然说好像有些时候有些迷，但据说我一直在睡觉。就我记得的事情来说，<br>我觉得我们一直以来关于谁比较quen，以及谁是个什么这两个问题的讨论还是妙趣横生的。<br>我觉得不管怎样，总之过得开心就Ok  </p>\n<p>大一去了霓虹，逛了秋叶原、秋叶原和秋叶原（不是，札幌一家咖喱店的服务员小姐姐真好看啊我还记得。<br>大一暑假万达瑞华真好啊<br>大二：子怡、单总、大小为，在移动组划水划水划，学习了一个，获得了人生的经验。学长们都很努力，加油加油  </p>\n<p>暑假之前在<del>zpzpz</del>远走他乡之前搭了最后一班导游车，就是打车出门，下车暴雨，在暴雨下看西湖，然后出门的第一件事就是回家，但是好看啊。<br><img src=\"/images/西湖暴雨.jpg\" alt=\"\"><br>吃不到湖边外婆家，吃到了知味观，啊。。。爆鳝面<br>叕叒双又去了海南站，大概熟练掌握了五个全家的地理位置。<br>（这里的猫真肥啊</p>\n<p>去北京学习了一波..深刻感受到物价贵的地方不适合生存..<br>戴笠妙啊..北大很漂亮<br>清华很大，别人家的食堂都很不错<br><img src=\"/images/未名麻雀.jpg\" alt=\"\"></p>\n<p>因为身边有人喝酒的原因自己也也变的能喝一点，我在周围都是水牛的情况下，啤的还是饶了我吧…<br>喝酒目的不同结果也会不同，我不会去买醉啥的，还是喝到有些发晕才比较妙啊，喝到吐就没什么意思了。<br>比如说<br><del>emmmmm…老师今天喝了一点酒</del>  </p>\n<p>啊，可以说是非常的流水帐了  </p>\n<p>我有时候悲哀的觉得时间促不及防地快，高中的结点一过，在想清楚之前被催促着走向未来。<br>我觉得我渐渐能听到那种声音，就而今再聚之时，地毯上对坐深夜饮酒，杯子碰到一起，现实无奈的成为了<br>话题中心。那大概就是那种声音。<br>也许是只能叹息不能惋惜吧。<br>大体上好像这两年，没什么收获，没什么失去，高中时代的追求没什么结果，大学的努力似乎还不足够，<br>我经常想着，或许先放着努力就好了吧，然而有时候却又允许自己只做普通人，大概是问题所在。<br>不喜欢平凡又喜欢平凡中的灵动，喜欢独特又无法理解一些小极端。可能是好人又到了一个程度= =，我总是看到别人互怼觉得<del>不要打架不要打架</del>,说不定有些事情只能互刀呢<br>emmmm 想了想打住</p>\n<p>反正，作为一个撞南墙选手，做过的事情做出的选择 ，我不后悔</p>\n<p>谢谢谢谢<del>王林王林王</del>的轮船<del>和小火箭</del>，早就是自带梗和表情包的优秀交流，emmmm？什 什么？？<br>和硬泉走爆上海滩，以及关于喵了个咪的烤鱼很ok、一点点没问题，和导致深夜睡不着，夜谈愉快。<br>室友去年的时候半夜突然的惊喜妙啊，还好他们没端一盆火锅进寝室<br>感谢何雨笙同学的心意，我觉得你接下来写文章接下来写下去就是知乎大v之路啦<br>和队友做题吼啊，一个人做题还是做不起来。。<del>专心打辅助</del><br><del>智商就很着急，朝哥教我FFT</del><br>还有一起玩过的魔兽世界冬拥湖ZP、麦霸君君、想法李狗、洋次郎ym、不需要形容词的游游、拯救单排老年人的颠和周帅<br><img src=\"/images/扑通.jpg\" alt=\"\"></p>\n<p>因为为了不咕咕咕，写的混乱，大家凑合看<br>因为人傻，表达不清，我猜还有别字（书写-3没救了，没救了</p>\n<p>大概总结起来还是：  </p>\n<p><img src=\"/images/养生.jpg\" alt=\"\"></p>\n<p>生快生快快</p>\n","excerpt":"","more":"<p><img src=\"/images/等待鸽多.jpg\" alt=\"\">  </p>\n<p>该来的还是来吧，在咕咕咕两年后，随便乱扯一些东西<br>大概年龄只是一个数字，过生剩下的理由主要是提供过聚的动机和吃一些特定食物的理由（停一停，停一停朋友们，面都吃了三年了。<br>哦，不过从另外一个角度，现在大家可以说<br>你看，他都二十岁了，依旧这么精神。  </p>\n<p>上一次写长篇的时候，浑身上下还充满着迷之忧郁青年气氛（反正现在感觉就像个老年人一样，什么都写不动。<br>鬼知道我经历了什么。</p>\n<p><del>鬼说：嗯，我知道。<br>。。。。。。。。<br>行吧，那写个鬼</del></p>\n<p>总结起来可能就是：<br>头发越留越长，智商是越剩越少 </p>\n<p>一下开始没话找话，无总体架构叙述</p>\n<p>高中末期建立起来的四人小分队，虽然说好像有些时候有些迷，但据说我一直在睡觉。就我记得的事情来说，<br>我觉得我们一直以来关于谁比较quen，以及谁是个什么这两个问题的讨论还是妙趣横生的。<br>我觉得不管怎样，总之过得开心就Ok  </p>\n<p>大一去了霓虹，逛了秋叶原、秋叶原和秋叶原（不是，札幌一家咖喱店的服务员小姐姐真好看啊我还记得。<br>大一暑假万达瑞华真好啊<br>大二：子怡、单总、大小为，在移动组划水划水划，学习了一个，获得了人生的经验。学长们都很努力，加油加油  </p>\n<p>暑假之前在<del>zpzpz</del>远走他乡之前搭了最后一班导游车，就是打车出门，下车暴雨，在暴雨下看西湖，然后出门的第一件事就是回家，但是好看啊。<br><img src=\"/images/西湖暴雨.jpg\" alt=\"\"><br>吃不到湖边外婆家，吃到了知味观，啊。。。爆鳝面<br>叕叒双又去了海南站，大概熟练掌握了五个全家的地理位置。<br>（这里的猫真肥啊</p>\n<p>去北京学习了一波..深刻感受到物价贵的地方不适合生存..<br>戴笠妙啊..北大很漂亮<br>清华很大，别人家的食堂都很不错<br><img src=\"/images/未名麻雀.jpg\" alt=\"\"></p>\n<p>因为身边有人喝酒的原因自己也也变的能喝一点，我在周围都是水牛的情况下，啤的还是饶了我吧…<br>喝酒目的不同结果也会不同，我不会去买醉啥的，还是喝到有些发晕才比较妙啊，喝到吐就没什么意思了。<br>比如说<br><del>emmmmm…老师今天喝了一点酒</del>  </p>\n<p>啊，可以说是非常的流水帐了  </p>\n<p>我有时候悲哀的觉得时间促不及防地快，高中的结点一过，在想清楚之前被催促着走向未来。<br>我觉得我渐渐能听到那种声音，就而今再聚之时，地毯上对坐深夜饮酒，杯子碰到一起，现实无奈的成为了<br>话题中心。那大概就是那种声音。<br>也许是只能叹息不能惋惜吧。<br>大体上好像这两年，没什么收获，没什么失去，高中时代的追求没什么结果，大学的努力似乎还不足够，<br>我经常想着，或许先放着努力就好了吧，然而有时候却又允许自己只做普通人，大概是问题所在。<br>不喜欢平凡又喜欢平凡中的灵动，喜欢独特又无法理解一些小极端。可能是好人又到了一个程度= =，我总是看到别人互怼觉得<del>不要打架不要打架</del>,说不定有些事情只能互刀呢<br>emmmm 想了想打住</p>\n<p>反正，作为一个撞南墙选手，做过的事情做出的选择 ，我不后悔</p>\n<p>谢谢谢谢<del>王林王林王</del>的轮船<del>和小火箭</del>，早就是自带梗和表情包的优秀交流，emmmm？什 什么？？<br>和硬泉走爆上海滩，以及关于喵了个咪的烤鱼很ok、一点点没问题，和导致深夜睡不着，夜谈愉快。<br>室友去年的时候半夜突然的惊喜妙啊，还好他们没端一盆火锅进寝室<br>感谢何雨笙同学的心意，我觉得你接下来写文章接下来写下去就是知乎大v之路啦<br>和队友做题吼啊，一个人做题还是做不起来。。<del>专心打辅助</del><br><del>智商就很着急，朝哥教我FFT</del><br>还有一起玩过的魔兽世界冬拥湖ZP、麦霸君君、想法李狗、洋次郎ym、不需要形容词的游游、拯救单排老年人的颠和周帅<br><img src=\"/images/扑通.jpg\" alt=\"\"></p>\n<p>因为为了不咕咕咕，写的混乱，大家凑合看<br>因为人傻，表达不清，我猜还有别字（书写-3没救了，没救了</p>\n<p>大概总结起来还是：  </p>\n<p><img src=\"/images/养生.jpg\" alt=\"\"></p>\n<p>生快生快快</p>\n"},{"title":"categories","date":"2017-03-12T04:54:02.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-03-12 12:54:02\ntype: \"categories\"\n---\n","updated":"2017-03-24T17:48:14.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjg1v55z0000vacwozvxfclko","content":"","excerpt":"","more":""},{"title":"tags","date":"2017-03-12T04:47:58.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-03-12 12:47:58\ntype: \"tags\"\n---\n","updated":"2017-03-24T17:48:14.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjg1v55z0000yacwohq76344w","content":"","excerpt":"","more":""}],"Post":[{"title":"asm_learning_note","date":"2017-03-16T02:10:32.000Z","_content":"","source":"_posts/asm-learning-note.md","raw":"---\ntitle: asm_learning_note\ndate: 2017-03-16 10:10:32\ntags:\n---\n","slug":"asm-learning-note","published":1,"updated":"2017-03-16T02:10:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55a40000acwobre9fyv4","content":"","excerpt":"","more":""},{"title":"UVAlive3211-2SAT模板题","date":"2017-09-03T10:32:08.000Z","_content":"## UVAlive-3211\n题意大概是求n架飞机每个飞机两个降落时间取一个使相邻降落的飞机时间差最大  \n要最优化差值，二分转化为在某一时间下能否满足，按照相邻时间是否大于当前二分的时间构建2-SAT\n模板题模板题  \n\n```c++\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\n\n//struct time{\n//    int time,id;\n//}t[MAXN];\nint t[MAXN];\n\nstruct SAT2{\n    int vis[MAXN*2],cnt;\n    vector<int> G[MAXN*2];\n    int n;\n    bool mark[MAXN*2];\n    bool dfs(int x){\n        if(mark[x^1]) return false;\n        else if(mark[x]) return true;\n        mark[x] = true;\n        vis[cnt++] = x;\n        for(int i=0; i<G[x].size(); i++){\n            if(!dfs(G[x][i])) return false;\n        }\n        return true;\n    }\n\n    void init(int n){\n        this->n = n;\n        for(int i=0; i<=2*n; i++){\n            vis[i] = false;\n            G[i].clear();\n        }\n        memset(mark,false,sizeof(mark));\n    }\n\n    // 当 x!=xval or y != yval(val=0/1)\n    // 则由于拆点每个x或者y变成两个点\n    // x==xval=>y!=yval     y==yval=>x!=xval\n    void add_clause(int x,int xval,int y,int yval){\n        x = x*2+xval;\n        y = y*2+yval;\n        G[x].pb(y^1);\n        G[y].pb(x^1);\n    }\n\n    bool solve(){\n        for(int i=0; i<2*n; i+=2)\n        if(!mark[i] && !mark[i^1]){\n            cnt = 0;\n            if(!dfs(i)){\n                while(cnt>0) mark[vis[--cnt]] = false;\n                if(!dfs(i^1)) return false;\n            }\n        }\n        return true;\n    }\n}st;\nint n;\n\nbool solve(int T)\n{\n    st.init(n);\n    for(int i=0; i<2*n; i++){\n        int j;\n        if(i%2) j = i+1;\n        else    j = i+2;\n        for(;j<2*n;j++){\n            if(abs(t[i]-t[j])<T){\n                st.add_clause(i/2,i&1,j/2,j&1);\n            }\n        }\n    }\n    return st.solve();\n}\n\nint main()\n{\n    while(sc(n)==1&&n){\n        for(int i=0; i<n; i++){\n            int e,l;\n            sc(e);  sc(l);\n            t[i*2] = e;    //t[i*2].id = i*2;\n            t[i*2+1] = l;  //t[i*2+1].id=i*2+1;\n        }\n        int lt = 0,rt = 1e7;\n        while(lt<rt){\n            //cout<<lt<<\" \"<<rt<<endl;\n            int mt = (lt+rt+1)/2;\n            if(solve(mt))\n                lt = mt;\n            else\n                rt = mt-1;\n        }\n        cout<<lt<<endl;\n    }\n}\n\n```\n","source":"_posts/UVAlive3211-2SAT模板题.md","raw":"---\ntitle: UVAlive3211-2SAT模板题\ndate: 2017-09-03 18:32:08\ntags: [2SAT]\ncategories: ACM\n---\n## UVAlive-3211\n题意大概是求n架飞机每个飞机两个降落时间取一个使相邻降落的飞机时间差最大  \n要最优化差值，二分转化为在某一时间下能否满足，按照相邻时间是否大于当前二分的时间构建2-SAT\n模板题模板题  \n\n```c++\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\n\n//struct time{\n//    int time,id;\n//}t[MAXN];\nint t[MAXN];\n\nstruct SAT2{\n    int vis[MAXN*2],cnt;\n    vector<int> G[MAXN*2];\n    int n;\n    bool mark[MAXN*2];\n    bool dfs(int x){\n        if(mark[x^1]) return false;\n        else if(mark[x]) return true;\n        mark[x] = true;\n        vis[cnt++] = x;\n        for(int i=0; i<G[x].size(); i++){\n            if(!dfs(G[x][i])) return false;\n        }\n        return true;\n    }\n\n    void init(int n){\n        this->n = n;\n        for(int i=0; i<=2*n; i++){\n            vis[i] = false;\n            G[i].clear();\n        }\n        memset(mark,false,sizeof(mark));\n    }\n\n    // 当 x!=xval or y != yval(val=0/1)\n    // 则由于拆点每个x或者y变成两个点\n    // x==xval=>y!=yval     y==yval=>x!=xval\n    void add_clause(int x,int xval,int y,int yval){\n        x = x*2+xval;\n        y = y*2+yval;\n        G[x].pb(y^1);\n        G[y].pb(x^1);\n    }\n\n    bool solve(){\n        for(int i=0; i<2*n; i+=2)\n        if(!mark[i] && !mark[i^1]){\n            cnt = 0;\n            if(!dfs(i)){\n                while(cnt>0) mark[vis[--cnt]] = false;\n                if(!dfs(i^1)) return false;\n            }\n        }\n        return true;\n    }\n}st;\nint n;\n\nbool solve(int T)\n{\n    st.init(n);\n    for(int i=0; i<2*n; i++){\n        int j;\n        if(i%2) j = i+1;\n        else    j = i+2;\n        for(;j<2*n;j++){\n            if(abs(t[i]-t[j])<T){\n                st.add_clause(i/2,i&1,j/2,j&1);\n            }\n        }\n    }\n    return st.solve();\n}\n\nint main()\n{\n    while(sc(n)==1&&n){\n        for(int i=0; i<n; i++){\n            int e,l;\n            sc(e);  sc(l);\n            t[i*2] = e;    //t[i*2].id = i*2;\n            t[i*2+1] = l;  //t[i*2+1].id=i*2+1;\n        }\n        int lt = 0,rt = 1e7;\n        while(lt<rt){\n            //cout<<lt<<\" \"<<rt<<endl;\n            int mt = (lt+rt+1)/2;\n            if(solve(mt))\n                lt = mt;\n            else\n                rt = mt-1;\n        }\n        cout<<lt<<endl;\n    }\n}\n\n```\n","slug":"UVAlive3211-2SAT模板题","published":1,"updated":"2017-09-03T10:39:30.511Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55az0001acwommwk1pbl","content":"<h2 id=\"UVAlive-3211\"><a href=\"#UVAlive-3211\" class=\"headerlink\" title=\"UVAlive-3211\"></a>UVAlive-3211</h2><p>题意大概是求n架飞机每个飞机两个降落时间取一个使相邻降落的飞机时间差最大<br>要最优化差值，二分转化为在某一时间下能否满足，按照相邻时间是否大于当前二分的时间构建2-SAT<br>模板题模板题  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div></pre></td><td class=\"code\"><pre><div class=\"line\">ll mod = <span class=\"number\">10000</span>;</div><div class=\"line\">ll INF = <span class=\"number\">1L</span>L&lt;&lt;<span class=\"number\">60L</span>L;</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> eps = <span class=\"number\">1e-8</span>;</div><div class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt; <span class=\"function\">T <span class=\"title\">gcd</span><span class=\"params\">(T a,T b)</span></span></div><div class=\"line\">&#123;<span class=\"keyword\">if</span>(!b)<span class=\"keyword\">return</span> a;<span class=\"keyword\">return</span> gcd(b,a%b);&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//struct time&#123;</span></div><div class=\"line\"><span class=\"comment\">//    int time,id;</span></div><div class=\"line\"><span class=\"comment\">//&#125;t[MAXN];</span></div><div class=\"line\"><span class=\"keyword\">int</span> t[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> SAT2&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> vis[MAXN*<span class=\"number\">2</span>],cnt;</div><div class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; G[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"keyword\">int</span> n;</div><div class=\"line\">    <span class=\"keyword\">bool</span> mark[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(mark[x^<span class=\"number\">1</span>]) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(mark[x]) <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">        mark[x] = <span class=\"literal\">true</span>;</div><div class=\"line\">        vis[cnt++] = x;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;G[x].size(); i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span>(!dfs(G[x][i])) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;n = n;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;=<span class=\"number\">2</span>*n; i++)&#123;</div><div class=\"line\">            vis[i] = <span class=\"literal\">false</span>;</div><div class=\"line\">            G[i].clear();</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(mark,<span class=\"literal\">false</span>,<span class=\"keyword\">sizeof</span>(mark));</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// 当 x!=xval or y != yval(val=0/1)</span></div><div class=\"line\">    <span class=\"comment\">// 则由于拆点每个x或者y变成两个点</span></div><div class=\"line\">    <span class=\"comment\">// x==xval=&gt;y!=yval     y==yval=&gt;x!=xval</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add_clause</span><span class=\"params\">(<span class=\"keyword\">int</span> x,<span class=\"keyword\">int</span> xval,<span class=\"keyword\">int</span> y,<span class=\"keyword\">int</span> yval)</span></span>&#123;</div><div class=\"line\">        x = x*<span class=\"number\">2</span>+xval;</div><div class=\"line\">        y = y*<span class=\"number\">2</span>+yval;</div><div class=\"line\">        G[x].pb(y^<span class=\"number\">1</span>);</div><div class=\"line\">        G[y].pb(x^<span class=\"number\">1</span>);</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">solve</span><span class=\"params\">()</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">2</span>*n; i+=<span class=\"number\">2</span>)</div><div class=\"line\">        <span class=\"keyword\">if</span>(!mark[i] &amp;&amp; !mark[i^<span class=\"number\">1</span>])&#123;</div><div class=\"line\">            cnt = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(!dfs(i))&#123;</div><div class=\"line\">                <span class=\"keyword\">while</span>(cnt&gt;<span class=\"number\">0</span>) mark[vis[--cnt]] = <span class=\"literal\">false</span>;</div><div class=\"line\">                <span class=\"keyword\">if</span>(!dfs(i^<span class=\"number\">1</span>)) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;st;</div><div class=\"line\"><span class=\"keyword\">int</span> n;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">solve</span><span class=\"params\">(<span class=\"keyword\">int</span> T)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    st.init(n);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">2</span>*n; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> j;</div><div class=\"line\">        <span class=\"keyword\">if</span>(i%<span class=\"number\">2</span>) j = i+<span class=\"number\">1</span>;</div><div class=\"line\">        <span class=\"keyword\">else</span>    j = i+<span class=\"number\">2</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(;j&lt;<span class=\"number\">2</span>*n;j++)&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"built_in\">abs</span>(t[i]-t[j])&lt;T)&#123;</div><div class=\"line\">                st.add_clause(i/<span class=\"number\">2</span>,i&amp;<span class=\"number\">1</span>,j/<span class=\"number\">2</span>,j&amp;<span class=\"number\">1</span>);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> st.solve();</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">while</span>(sc(n)==<span class=\"number\">1</span>&amp;&amp;n)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> e,l;</div><div class=\"line\">            sc(e);  sc(l);</div><div class=\"line\">            t[i*<span class=\"number\">2</span>] = e;    <span class=\"comment\">//t[i*2].id = i*2;</span></div><div class=\"line\">            t[i*<span class=\"number\">2</span>+<span class=\"number\">1</span>] = l;  <span class=\"comment\">//t[i*2+1].id=i*2+1;</span></div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">int</span> lt = <span class=\"number\">0</span>,rt = <span class=\"number\">1e7</span>;</div><div class=\"line\">        <span class=\"keyword\">while</span>(lt&lt;rt)&#123;</div><div class=\"line\">            <span class=\"comment\">//cout&lt;&lt;lt&lt;&lt;\" \"&lt;&lt;rt&lt;&lt;endl;</span></div><div class=\"line\">            <span class=\"keyword\">int</span> mt = (lt+rt+<span class=\"number\">1</span>)/<span class=\"number\">2</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(solve(mt))</div><div class=\"line\">                lt = mt;</div><div class=\"line\">            <span class=\"keyword\">else</span></div><div class=\"line\">                rt = mt<span class=\"number\">-1</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">cout</span>&lt;&lt;lt&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h2 id=\"UVAlive-3211\"><a href=\"#UVAlive-3211\" class=\"headerlink\" title=\"UVAlive-3211\"></a>UVAlive-3211</h2><p>题意大概是求n架飞机每个飞机两个降落时间取一个使相邻降落的飞机时间差最大<br>要最优化差值，二分转化为在某一时间下能否满足，按照相邻时间是否大于当前二分的时间构建2-SAT<br>模板题模板题  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div></pre></td><td class=\"code\"><pre><div class=\"line\">ll mod = <span class=\"number\">10000</span>;</div><div class=\"line\">ll INF = <span class=\"number\">1L</span>L&lt;&lt;<span class=\"number\">60L</span>L;</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> eps = <span class=\"number\">1e-8</span>;</div><div class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt; <span class=\"function\">T <span class=\"title\">gcd</span><span class=\"params\">(T a,T b)</span></div><div class=\"line\"></span>&#123;<span class=\"keyword\">if</span>(!b)<span class=\"keyword\">return</span> a;<span class=\"keyword\">return</span> gcd(b,a%b);&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//struct time&#123;</span></div><div class=\"line\"><span class=\"comment\">//    int time,id;</span></div><div class=\"line\"><span class=\"comment\">//&#125;t[MAXN];</span></div><div class=\"line\"><span class=\"keyword\">int</span> t[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> SAT2&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> vis[MAXN*<span class=\"number\">2</span>],cnt;</div><div class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; G[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"keyword\">int</span> n;</div><div class=\"line\">    <span class=\"keyword\">bool</span> mark[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(mark[x^<span class=\"number\">1</span>]) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(mark[x]) <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">        mark[x] = <span class=\"literal\">true</span>;</div><div class=\"line\">        vis[cnt++] = x;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;G[x].size(); i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span>(!dfs(G[x][i])) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;n = n;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;=<span class=\"number\">2</span>*n; i++)&#123;</div><div class=\"line\">            vis[i] = <span class=\"literal\">false</span>;</div><div class=\"line\">            G[i].clear();</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(mark,<span class=\"literal\">false</span>,<span class=\"keyword\">sizeof</span>(mark));</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// 当 x!=xval or y != yval(val=0/1)</span></div><div class=\"line\">    <span class=\"comment\">// 则由于拆点每个x或者y变成两个点</span></div><div class=\"line\">    <span class=\"comment\">// x==xval=&gt;y!=yval     y==yval=&gt;x!=xval</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add_clause</span><span class=\"params\">(<span class=\"keyword\">int</span> x,<span class=\"keyword\">int</span> xval,<span class=\"keyword\">int</span> y,<span class=\"keyword\">int</span> yval)</span></span>&#123;</div><div class=\"line\">        x = x*<span class=\"number\">2</span>+xval;</div><div class=\"line\">        y = y*<span class=\"number\">2</span>+yval;</div><div class=\"line\">        G[x].pb(y^<span class=\"number\">1</span>);</div><div class=\"line\">        G[y].pb(x^<span class=\"number\">1</span>);</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">solve</span><span class=\"params\">()</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">2</span>*n; i+=<span class=\"number\">2</span>)</div><div class=\"line\">        <span class=\"keyword\">if</span>(!mark[i] &amp;&amp; !mark[i^<span class=\"number\">1</span>])&#123;</div><div class=\"line\">            cnt = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(!dfs(i))&#123;</div><div class=\"line\">                <span class=\"keyword\">while</span>(cnt&gt;<span class=\"number\">0</span>) mark[vis[--cnt]] = <span class=\"literal\">false</span>;</div><div class=\"line\">                <span class=\"keyword\">if</span>(!dfs(i^<span class=\"number\">1</span>)) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;st;</div><div class=\"line\"><span class=\"keyword\">int</span> n;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">solve</span><span class=\"params\">(<span class=\"keyword\">int</span> T)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    st.init(n);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">2</span>*n; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> j;</div><div class=\"line\">        <span class=\"keyword\">if</span>(i%<span class=\"number\">2</span>) j = i+<span class=\"number\">1</span>;</div><div class=\"line\">        <span class=\"keyword\">else</span>    j = i+<span class=\"number\">2</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(;j&lt;<span class=\"number\">2</span>*n;j++)&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"built_in\">abs</span>(t[i]-t[j])&lt;T)&#123;</div><div class=\"line\">                st.add_clause(i/<span class=\"number\">2</span>,i&amp;<span class=\"number\">1</span>,j/<span class=\"number\">2</span>,j&amp;<span class=\"number\">1</span>);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> st.solve();</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">while</span>(sc(n)==<span class=\"number\">1</span>&amp;&amp;n)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> e,l;</div><div class=\"line\">            sc(e);  sc(l);</div><div class=\"line\">            t[i*<span class=\"number\">2</span>] = e;    <span class=\"comment\">//t[i*2].id = i*2;</span></div><div class=\"line\">            t[i*<span class=\"number\">2</span>+<span class=\"number\">1</span>] = l;  <span class=\"comment\">//t[i*2+1].id=i*2+1;</span></div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">int</span> lt = <span class=\"number\">0</span>,rt = <span class=\"number\">1e7</span>;</div><div class=\"line\">        <span class=\"keyword\">while</span>(lt&lt;rt)&#123;</div><div class=\"line\">            <span class=\"comment\">//cout&lt;&lt;lt&lt;&lt;\" \"&lt;&lt;rt&lt;&lt;endl;</span></div><div class=\"line\">            <span class=\"keyword\">int</span> mt = (lt+rt+<span class=\"number\">1</span>)/<span class=\"number\">2</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(solve(mt))</div><div class=\"line\">                lt = mt;</div><div class=\"line\">            <span class=\"keyword\">else</span></div><div class=\"line\">                rt = mt<span class=\"number\">-1</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">cout</span>&lt;&lt;lt&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"三葉のテーマ","date":"2017-03-15T15:53:53.000Z","_content":"   会困扰吗，会尴尬吗，还是...会有些许的高兴呢..  \n\n\n   回忆中，三叶一个人踏上去东京的电车时候，到底是怎样一种心情呢  \n\n\n   最喜欢的一首 \n\n   \n","source":"_posts/三葉.md","raw":"---\ntitle: 三葉のテーマ\ndate: 2017-03-15 23:53:53\ncategories: 说说\ntags: 随想\n---\n   会困扰吗，会尴尬吗，还是...会有些许的高兴呢..  \n\n\n   回忆中，三叶一个人踏上去东京的电车时候，到底是怎样一种心情呢  \n\n\n   最喜欢的一首 \n\n   \n","slug":"三葉","published":1,"updated":"2017-03-24T17:48:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55bf0002acwo2mqflq27","content":"<p>   会困扰吗，会尴尬吗，还是…会有些许的高兴呢..  </p>\n<p>   回忆中，三叶一个人踏上去东京的电车时候，到底是怎样一种心情呢  </p>\n<p>   最喜欢的一首 </p>\n","excerpt":"","more":"<p>   会困扰吗，会尴尬吗，还是…会有些许的高兴呢..  </p>\n<p>   回忆中，三叶一个人踏上去东京的电车时候，到底是怎样一种心情呢  </p>\n<p>   最喜欢的一首 </p>\n"},{"title":"开关反转问题","date":"2017-09-21T20:19:25.000Z","_content":"```c++\n#include <cstdio>\n#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <utility>\n#include <queue>\n#define MAXN 50\n#define sc(x) scanf(\"%d\",&(x))\n\nusing namespace std;\n\nconst int INF = 0x3f3f3f3f;\nint a[MAXN][MAXN];\nint p[MAXN][MAXN];\nint f[MAXN][MAXN][MAXN];\nint x[MAXN];\nint mark[MAXN];\nint M,N;\n\nint gauss(int equ,int vars)\n{\n\tint i=0,j=0;\n\tmemset(mark,0,sizeof(mark));\n\tfor(i=0,j=0; i<equ && j<vars; i++,j++){\n\t\tint max_r = i;\n\t\tfor(int k=i+1; k<equ; k++)\n\t\t\tif(a[k][j]>a[max_r][j])\n\t\t\t\tmax_r = k;\n        if(max_r!=i)\n            for(int k=0; k<=vars; k++)\n                swap(a[i][k],a[max_r][k]);\n        if(a[i][j]==0){\n            mark[j] = 1;\n            i--;\tcontinue;\n        }\n        for(int k=i+1; k<equ; k++){\n            if(a[k][j])\n                for(int m=j; m<=vars; m++)\n                    a[k][m] = a[k][m]^a[i][m];\n        }\n\t}\n\ti--;\n\tfor(int k=vars-1; k>=0; k--){\n\t\tif(mark[k]){\n\t\t\tx[k] = 1;\tcontinue;\n\t\t}\n\t\tif(i<0) break;\n\t\tint res = 0;\n\t\tfor(int m=k+1; m<vars; m++)\n\t\t\tres ^= a[i][m]&x[m];\n\t\tx[i--] = res;\n\t}\n\treturn 0;\n}\n\nint get(int i,int j,int k)\n{\n\tint ans = f[i][j][k] + f[i-1][j][k] + f[i][j-1][k] + f[i][j+1][k];\n\treturn ans%2;\n}\n\nint getans(int i,int j)\n{\n\tint ans = p[i][j] + p[i-1][j] + p[i][j-1] + p[i][j+1];\n\treturn ans%2;\n}\n\n\nint main()\n{\n\tint t;\n\tsc(t);\n\twhile(t--){\n\t\tsc(N),sc(M);\n\t\tmemset(a,0,sizeof(a));\n\t\tmemset(p,0,sizeof(p));\n\t\tmemset(f,0,sizeof(f));\n\t\tfor(int k=1; k<=M; k++)\n\t\t{\n\t\t\tf[1][k][k] = 1;\n\t\t}\n\t\tfor(int i=2; i<=N+1; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n                for(int k=1; k<=M; k++)\n                    f[i][j][k] = get(i-1,j,k);\n\n\t\tfor(int i=0; i<M; i++)\n\t\t\tfor(int j=0; j<M; j++)\n\t\t\t\ta[i][j] = f[N+1][i+1][j+1];\n\t\tgauss(M,M);\n\t\tfor(int i=1; i<=M; i++)\n\t\t\tp[1][i] = x[i-1];\n\t\tfor(int i=2; i<=N; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n\t\t\t\tp[i][j] = getans(i-1,j);\n\t\tfor(int i=1; i<=N; i++){\n\t\t\tprintf(\"%d\",p[i][1]);\n\t\t\tfor(int j=2; j<=M; j++)\n\t\t\t\tprintf(\" %d\",p[i][j]);\n\t\t\tprintf(\"\\n\");\n \t    }\n\t}\n\treturn 0;\n}\n\n```","source":"_posts/开关反转问题.md","raw":"---\ntitle: 开关反转问题\ndate: 2017-09-22 04:19:25\ntags:\ncategories:\n---\n```c++\n#include <cstdio>\n#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <utility>\n#include <queue>\n#define MAXN 50\n#define sc(x) scanf(\"%d\",&(x))\n\nusing namespace std;\n\nconst int INF = 0x3f3f3f3f;\nint a[MAXN][MAXN];\nint p[MAXN][MAXN];\nint f[MAXN][MAXN][MAXN];\nint x[MAXN];\nint mark[MAXN];\nint M,N;\n\nint gauss(int equ,int vars)\n{\n\tint i=0,j=0;\n\tmemset(mark,0,sizeof(mark));\n\tfor(i=0,j=0; i<equ && j<vars; i++,j++){\n\t\tint max_r = i;\n\t\tfor(int k=i+1; k<equ; k++)\n\t\t\tif(a[k][j]>a[max_r][j])\n\t\t\t\tmax_r = k;\n        if(max_r!=i)\n            for(int k=0; k<=vars; k++)\n                swap(a[i][k],a[max_r][k]);\n        if(a[i][j]==0){\n            mark[j] = 1;\n            i--;\tcontinue;\n        }\n        for(int k=i+1; k<equ; k++){\n            if(a[k][j])\n                for(int m=j; m<=vars; m++)\n                    a[k][m] = a[k][m]^a[i][m];\n        }\n\t}\n\ti--;\n\tfor(int k=vars-1; k>=0; k--){\n\t\tif(mark[k]){\n\t\t\tx[k] = 1;\tcontinue;\n\t\t}\n\t\tif(i<0) break;\n\t\tint res = 0;\n\t\tfor(int m=k+1; m<vars; m++)\n\t\t\tres ^= a[i][m]&x[m];\n\t\tx[i--] = res;\n\t}\n\treturn 0;\n}\n\nint get(int i,int j,int k)\n{\n\tint ans = f[i][j][k] + f[i-1][j][k] + f[i][j-1][k] + f[i][j+1][k];\n\treturn ans%2;\n}\n\nint getans(int i,int j)\n{\n\tint ans = p[i][j] + p[i-1][j] + p[i][j-1] + p[i][j+1];\n\treturn ans%2;\n}\n\n\nint main()\n{\n\tint t;\n\tsc(t);\n\twhile(t--){\n\t\tsc(N),sc(M);\n\t\tmemset(a,0,sizeof(a));\n\t\tmemset(p,0,sizeof(p));\n\t\tmemset(f,0,sizeof(f));\n\t\tfor(int k=1; k<=M; k++)\n\t\t{\n\t\t\tf[1][k][k] = 1;\n\t\t}\n\t\tfor(int i=2; i<=N+1; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n                for(int k=1; k<=M; k++)\n                    f[i][j][k] = get(i-1,j,k);\n\n\t\tfor(int i=0; i<M; i++)\n\t\t\tfor(int j=0; j<M; j++)\n\t\t\t\ta[i][j] = f[N+1][i+1][j+1];\n\t\tgauss(M,M);\n\t\tfor(int i=1; i<=M; i++)\n\t\t\tp[1][i] = x[i-1];\n\t\tfor(int i=2; i<=N; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n\t\t\t\tp[i][j] = getans(i-1,j);\n\t\tfor(int i=1; i<=N; i++){\n\t\t\tprintf(\"%d\",p[i][1]);\n\t\t\tfor(int j=2; j<=M; j++)\n\t\t\t\tprintf(\" %d\",p[i][j]);\n\t\t\tprintf(\"\\n\");\n \t    }\n\t}\n\treturn 0;\n}\n\n```","slug":"开关反转问题","published":1,"updated":"2018-03-29T15:02:32.579Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55bu0005acwocpfb5xep","content":"<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;utility&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;queue&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MAXN 50</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> sc(x) scanf(<span class=\"meta-string\">\"%d\"</span>,&amp;(x))</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> INF = <span class=\"number\">0x3f3f3f3f</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> a[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> p[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> f[MAXN][MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> x[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> mark[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> M,N;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">gauss</span><span class=\"params\">(<span class=\"keyword\">int</span> equ,<span class=\"keyword\">int</span> vars)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>,j=<span class=\"number\">0</span>;</div><div class=\"line\">\t<span class=\"built_in\">memset</span>(mark,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(mark));</div><div class=\"line\">\t<span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>,j=<span class=\"number\">0</span>; i&lt;equ &amp;&amp; j&lt;vars; i++,j++)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> max_r = i;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=i+<span class=\"number\">1</span>; k&lt;equ; k++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[k][j]&gt;a[max_r][j])</div><div class=\"line\">\t\t\t\tmax_r = k;</div><div class=\"line\">        <span class=\"keyword\">if</span>(max_r!=i)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">0</span>; k&lt;=vars; k++)</div><div class=\"line\">                swap(a[i][k],a[max_r][k]);</div><div class=\"line\">        <span class=\"keyword\">if</span>(a[i][j]==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">            mark[j] = <span class=\"number\">1</span>;</div><div class=\"line\">            i--;\t<span class=\"keyword\">continue</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=i+<span class=\"number\">1</span>; k&lt;equ; k++)&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span>(a[k][j])</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> m=j; m&lt;=vars; m++)</div><div class=\"line\">                    a[k][m] = a[k][m]^a[i][m];</div><div class=\"line\">        &#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\ti--;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=vars<span class=\"number\">-1</span>; k&gt;=<span class=\"number\">0</span>; k--)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(mark[k])&#123;</div><div class=\"line\">\t\t\tx[k] = <span class=\"number\">1</span>;\t<span class=\"keyword\">continue</span>;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(i&lt;<span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> m=k+<span class=\"number\">1</span>; m&lt;vars; m++)</div><div class=\"line\">\t\t\tres ^= a[i][m]&amp;x[m];</div><div class=\"line\">\t\tx[i--] = res;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j,<span class=\"keyword\">int</span> k)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> ans = f[i][j][k] + f[i<span class=\"number\">-1</span>][j][k] + f[i][j<span class=\"number\">-1</span>][k] + f[i][j+<span class=\"number\">1</span>][k];</div><div class=\"line\">\t<span class=\"keyword\">return</span> ans%<span class=\"number\">2</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getans</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> ans = p[i][j] + p[i<span class=\"number\">-1</span>][j] + p[i][j<span class=\"number\">-1</span>] + p[i][j+<span class=\"number\">1</span>];</div><div class=\"line\">\t<span class=\"keyword\">return</span> ans%<span class=\"number\">2</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> t;</div><div class=\"line\">\tsc(t);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(t--)&#123;</div><div class=\"line\">\t\tsc(N),sc(M);</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(a,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(a));</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(p,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(p));</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(f,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(f));</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">1</span>; k&lt;=M; k++)</div><div class=\"line\">\t\t&#123;</div><div class=\"line\">\t\t\tf[<span class=\"number\">1</span>][k][k] = <span class=\"number\">1</span>;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=N+<span class=\"number\">1</span>; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">1</span>; k&lt;=M; k++)</div><div class=\"line\">                    f[i][j][k] = get(i<span class=\"number\">-1</span>,j,k);</div><div class=\"line\"></div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;M; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; j&lt;M; j++)</div><div class=\"line\">\t\t\t\ta[i][j] = f[N+<span class=\"number\">1</span>][i+<span class=\"number\">1</span>][j+<span class=\"number\">1</span>];</div><div class=\"line\">\t\tgauss(M,M);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=M; i++)</div><div class=\"line\">\t\t\tp[<span class=\"number\">1</span>][i] = x[i<span class=\"number\">-1</span>];</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=N; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">\t\t\t\tp[i][j] = getans(i<span class=\"number\">-1</span>,j);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)&#123;</div><div class=\"line\">\t\t\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,p[i][<span class=\"number\">1</span>]);</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">2</span>; j&lt;=M; j++)</div><div class=\"line\">\t\t\t\t<span class=\"built_in\">printf</span>(<span class=\"string\">\" %d\"</span>,p[i][j]);</div><div class=\"line\">\t\t\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</div><div class=\"line\"> \t    &#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","excerpt":"","more":"<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;utility&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;queue&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MAXN 50</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> sc(x) scanf(<span class=\"meta-string\">\"%d\"</span>,&amp;(x))</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> INF = <span class=\"number\">0x3f3f3f3f</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> a[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> p[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> f[MAXN][MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> x[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> mark[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> M,N;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">gauss</span><span class=\"params\">(<span class=\"keyword\">int</span> equ,<span class=\"keyword\">int</span> vars)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>,j=<span class=\"number\">0</span>;</div><div class=\"line\">\t<span class=\"built_in\">memset</span>(mark,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(mark));</div><div class=\"line\">\t<span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>,j=<span class=\"number\">0</span>; i&lt;equ &amp;&amp; j&lt;vars; i++,j++)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> max_r = i;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=i+<span class=\"number\">1</span>; k&lt;equ; k++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[k][j]&gt;a[max_r][j])</div><div class=\"line\">\t\t\t\tmax_r = k;</div><div class=\"line\">        <span class=\"keyword\">if</span>(max_r!=i)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">0</span>; k&lt;=vars; k++)</div><div class=\"line\">                swap(a[i][k],a[max_r][k]);</div><div class=\"line\">        <span class=\"keyword\">if</span>(a[i][j]==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">            mark[j] = <span class=\"number\">1</span>;</div><div class=\"line\">            i--;\t<span class=\"keyword\">continue</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=i+<span class=\"number\">1</span>; k&lt;equ; k++)&#123;</div><div class=\"line\">            <span class=\"keyword\">if</span>(a[k][j])</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> m=j; m&lt;=vars; m++)</div><div class=\"line\">                    a[k][m] = a[k][m]^a[i][m];</div><div class=\"line\">        &#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\ti--;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=vars<span class=\"number\">-1</span>; k&gt;=<span class=\"number\">0</span>; k--)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(mark[k])&#123;</div><div class=\"line\">\t\t\tx[k] = <span class=\"number\">1</span>;\t<span class=\"keyword\">continue</span>;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(i&lt;<span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> m=k+<span class=\"number\">1</span>; m&lt;vars; m++)</div><div class=\"line\">\t\t\tres ^= a[i][m]&amp;x[m];</div><div class=\"line\">\t\tx[i--] = res;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j,<span class=\"keyword\">int</span> k)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> ans = f[i][j][k] + f[i<span class=\"number\">-1</span>][j][k] + f[i][j<span class=\"number\">-1</span>][k] + f[i][j+<span class=\"number\">1</span>][k];</div><div class=\"line\">\t<span class=\"keyword\">return</span> ans%<span class=\"number\">2</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getans</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> ans = p[i][j] + p[i<span class=\"number\">-1</span>][j] + p[i][j<span class=\"number\">-1</span>] + p[i][j+<span class=\"number\">1</span>];</div><div class=\"line\">\t<span class=\"keyword\">return</span> ans%<span class=\"number\">2</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> t;</div><div class=\"line\">\tsc(t);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(t--)&#123;</div><div class=\"line\">\t\tsc(N),sc(M);</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(a,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(a));</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(p,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(p));</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(f,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(f));</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">1</span>; k&lt;=M; k++)</div><div class=\"line\">\t\t&#123;</div><div class=\"line\">\t\t\tf[<span class=\"number\">1</span>][k][k] = <span class=\"number\">1</span>;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=N+<span class=\"number\">1</span>; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">1</span>; k&lt;=M; k++)</div><div class=\"line\">                    f[i][j][k] = get(i<span class=\"number\">-1</span>,j,k);</div><div class=\"line\"></div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;M; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; j&lt;M; j++)</div><div class=\"line\">\t\t\t\ta[i][j] = f[N+<span class=\"number\">1</span>][i+<span class=\"number\">1</span>][j+<span class=\"number\">1</span>];</div><div class=\"line\">\t\tgauss(M,M);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=M; i++)</div><div class=\"line\">\t\t\tp[<span class=\"number\">1</span>][i] = x[i<span class=\"number\">-1</span>];</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=N; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">\t\t\t\tp[i][j] = getans(i<span class=\"number\">-1</span>,j);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)&#123;</div><div class=\"line\">\t\t\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,p[i][<span class=\"number\">1</span>]);</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">2</span>; j&lt;=M; j++)</div><div class=\"line\">\t\t\t\t<span class=\"built_in\">printf</span>(<span class=\"string\">\" %d\"</span>,p[i][j]);</div><div class=\"line\">\t\t\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</div><div class=\"line\"> \t    &#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>"},{"title":"求最小割最少边数","date":"2017-09-18T14:01:39.000Z","_content":"给有向图，求一个最小割，它的边数也最小  \n搜了原题题解，发现一堆假算法==  \n假算法说什么将满流边置为1 其它边置为INF 感觉不科学\n因为考虑有不同种最大流情况的图，不同的最大流情况会导致算出来的结果不一样。\n\nAC的解法是对于每条边的容量乘上一个大于边数的数+1,最后再模上这个数。\n\n```c++\n#include <cstdio>\n#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <utility>\n#include <queue>\n#define MAXN 5000\n#define sc(x) scanf(\"%d\",&(x))\n\nusing namespace std;\nconst int INF = 0x3f3f3f3f;\n\nstruct edge{\n\tint t,cap,next;\n};\nedge e[MAXN];\nint cnt;\nint head[MAXN];\nint n,m,s,t;\nint iter[MAXN],level[MAXN];\n\nvoid add_edge(int f,int t,int cap){\n\te[cnt].t = t;\te[cnt].cap = cap;\te[cnt].next = head[f];\n\thead[f] = cnt++;\n\te[cnt].t = f;\te[cnt].cap = 0;\te[cnt].next = head[t];\n\thead[t] = cnt++;\n}\n\nvoid bfs(int s,int t)\n{\n\tmemset(level,-1,sizeof(level));\n\tlevel[s] = 0;\n\tqueue<int> q;\n\tq.push(s);\n\twhile(!q.empty()){\n\t\tint cur = q.front(); q.pop();\n\t\tif(cur==t) break;\n\t\tfor(int i=head[cur]; i!=-1; i=e[i].next){\n\t\t\tint v = e[i].t;\n\t\t\tif(level[v]<0 && e[i].cap>0){\n\t\t\t\tlevel[v] = level[cur] + 1;\n\t\t\t\tq.push(v);\n\t\t\t}\t\n\t\t}\n\t}\n}\n\nint dfs(int u,int t,int flow)\n{\n\tif(u==t) return flow;\n\tfor(int &i=iter[u]; i!=-1; i=e[i].next){\n\t\tint v = e[i].t;\n\t\tif(level[v]>level[u] && e[i].cap>0){\n\t\t\tint val = dfs(v,t,min(flow,e[i].cap));\n\t\t\tif(val>0){\n\t\t\t\te[i].cap -= val;\n\t\t\t\te[i^1].cap +=val;\n\t\t\t\treturn val;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n\nint Dinic()\n{\n\tint ans = 0;\n\twhile(1){\n\t\tbfs(s,t);\n\t//\tfor(int i=1; i<=n; i++)\n\t//\t\tcout<<\"level \"<<i<<\": \"<<level[i]<<endl;\n\t\tif(level[t]<0) break;\n\t\tfor(int i=1; i<=n; i++)\n\t\t\titer[i] = head[i];\n\t\tint val;\n\t\twhile(val=dfs(s,t,INF)){\n\t\t\t//cout<<\"val: \"<<val<<endl;\n\t\t\tans += val;\n\t\t}\n\t}\n\treturn ans;\n}\n\nint main()\n{\n\tint T;\n\tsc(T);\n\twhile(T--){\n\t\tsc(n); sc(m);\n\t\tsc(s); sc(t);\n\t\tcnt = 0;\n\t\tmemset(head,-1,sizeof(head));\n\t\tfor(int i=0; i<m; i++){\n\t\t\tint u,v,w;\n\t\t\tsc(u); sc(v); sc(w);\n\t\t\tadd_edge(u,v,w*1000+1);\n\t\t}\n\t\tint ans = Dinic();\n\t\tcout<<ans%1000<<endl;\n\t}\n}\n\n\n```\n\n","source":"_posts/求最小割最少边数.md","raw":"---\ntitle: 求最小割最少边数\ndate: 2017-09-18 22:01:39\ntags: [网络流]\ncategories: ACM\n---\n给有向图，求一个最小割，它的边数也最小  \n搜了原题题解，发现一堆假算法==  \n假算法说什么将满流边置为1 其它边置为INF 感觉不科学\n因为考虑有不同种最大流情况的图，不同的最大流情况会导致算出来的结果不一样。\n\nAC的解法是对于每条边的容量乘上一个大于边数的数+1,最后再模上这个数。\n\n```c++\n#include <cstdio>\n#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <utility>\n#include <queue>\n#define MAXN 5000\n#define sc(x) scanf(\"%d\",&(x))\n\nusing namespace std;\nconst int INF = 0x3f3f3f3f;\n\nstruct edge{\n\tint t,cap,next;\n};\nedge e[MAXN];\nint cnt;\nint head[MAXN];\nint n,m,s,t;\nint iter[MAXN],level[MAXN];\n\nvoid add_edge(int f,int t,int cap){\n\te[cnt].t = t;\te[cnt].cap = cap;\te[cnt].next = head[f];\n\thead[f] = cnt++;\n\te[cnt].t = f;\te[cnt].cap = 0;\te[cnt].next = head[t];\n\thead[t] = cnt++;\n}\n\nvoid bfs(int s,int t)\n{\n\tmemset(level,-1,sizeof(level));\n\tlevel[s] = 0;\n\tqueue<int> q;\n\tq.push(s);\n\twhile(!q.empty()){\n\t\tint cur = q.front(); q.pop();\n\t\tif(cur==t) break;\n\t\tfor(int i=head[cur]; i!=-1; i=e[i].next){\n\t\t\tint v = e[i].t;\n\t\t\tif(level[v]<0 && e[i].cap>0){\n\t\t\t\tlevel[v] = level[cur] + 1;\n\t\t\t\tq.push(v);\n\t\t\t}\t\n\t\t}\n\t}\n}\n\nint dfs(int u,int t,int flow)\n{\n\tif(u==t) return flow;\n\tfor(int &i=iter[u]; i!=-1; i=e[i].next){\n\t\tint v = e[i].t;\n\t\tif(level[v]>level[u] && e[i].cap>0){\n\t\t\tint val = dfs(v,t,min(flow,e[i].cap));\n\t\t\tif(val>0){\n\t\t\t\te[i].cap -= val;\n\t\t\t\te[i^1].cap +=val;\n\t\t\t\treturn val;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n\nint Dinic()\n{\n\tint ans = 0;\n\twhile(1){\n\t\tbfs(s,t);\n\t//\tfor(int i=1; i<=n; i++)\n\t//\t\tcout<<\"level \"<<i<<\": \"<<level[i]<<endl;\n\t\tif(level[t]<0) break;\n\t\tfor(int i=1; i<=n; i++)\n\t\t\titer[i] = head[i];\n\t\tint val;\n\t\twhile(val=dfs(s,t,INF)){\n\t\t\t//cout<<\"val: \"<<val<<endl;\n\t\t\tans += val;\n\t\t}\n\t}\n\treturn ans;\n}\n\nint main()\n{\n\tint T;\n\tsc(T);\n\twhile(T--){\n\t\tsc(n); sc(m);\n\t\tsc(s); sc(t);\n\t\tcnt = 0;\n\t\tmemset(head,-1,sizeof(head));\n\t\tfor(int i=0; i<m; i++){\n\t\t\tint u,v,w;\n\t\t\tsc(u); sc(v); sc(w);\n\t\t\tadd_edge(u,v,w*1000+1);\n\t\t}\n\t\tint ans = Dinic();\n\t\tcout<<ans%1000<<endl;\n\t}\n}\n\n\n```\n\n","slug":"求最小割最少边数","published":1,"updated":"2017-09-18T15:39:21.089Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55ca0006acwort35j5hh","content":"<p>给有向图，求一个最小割，它的边数也最小<br>搜了原题题解，发现一堆假算法==<br>假算法说什么将满流边置为1 其它边置为INF 感觉不科学<br>因为考虑有不同种最大流情况的图，不同的最大流情况会导致算出来的结果不一样。</p>\n<p>AC的解法是对于每条边的容量乘上一个大于边数的数+1,最后再模上这个数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;utility&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;queue&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MAXN 5000</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> sc(x) scanf(<span class=\"meta-string\">\"%d\"</span>,&amp;(x))</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> INF = <span class=\"number\">0x3f3f3f3f</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> edge&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> t,cap,next;</div><div class=\"line\">&#125;;</div><div class=\"line\">edge e[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> cnt;</div><div class=\"line\"><span class=\"keyword\">int</span> head[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> n,m,s,t;</div><div class=\"line\"><span class=\"keyword\">int</span> iter[MAXN],level[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add_edge</span><span class=\"params\">(<span class=\"keyword\">int</span> f,<span class=\"keyword\">int</span> t,<span class=\"keyword\">int</span> cap)</span></span>&#123;</div><div class=\"line\">\te[cnt].t = t;\te[cnt].cap = cap;\te[cnt].next = head[f];</div><div class=\"line\">\thead[f] = cnt++;</div><div class=\"line\">\te[cnt].t = f;\te[cnt].cap = <span class=\"number\">0</span>;\te[cnt].next = head[t];</div><div class=\"line\">\thead[t] = cnt++;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bfs</span><span class=\"params\">(<span class=\"keyword\">int</span> s,<span class=\"keyword\">int</span> t)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"built_in\">memset</span>(level,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(level));</div><div class=\"line\">\tlevel[s] = <span class=\"number\">0</span>;</div><div class=\"line\">\t<span class=\"built_in\">queue</span>&lt;<span class=\"keyword\">int</span>&gt; q;</div><div class=\"line\">\tq.push(s);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(!q.empty())&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> cur = q.front(); q.pop();</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(cur==t) <span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=head[cur]; i!=<span class=\"number\">-1</span>; i=e[i].next)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">int</span> v = e[i].t;</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(level[v]&lt;<span class=\"number\">0</span> &amp;&amp; e[i].cap&gt;<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\tlevel[v] = level[cur] + <span class=\"number\">1</span>;</div><div class=\"line\">\t\t\t\tq.push(v);</div><div class=\"line\">\t\t\t&#125;\t</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u,<span class=\"keyword\">int</span> t,<span class=\"keyword\">int</span> flow)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">if</span>(u==t) <span class=\"keyword\">return</span> flow;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> &amp;i=iter[u]; i!=<span class=\"number\">-1</span>; i=e[i].next)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> v = e[i].t;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(level[v]&gt;level[u] &amp;&amp; e[i].cap&gt;<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">int</span> val = dfs(v,t,min(flow,e[i].cap));</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(val&gt;<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\te[i].cap -= val;</div><div class=\"line\">\t\t\t\te[i^<span class=\"number\">1</span>].cap +=val;</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> val;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">Dinic</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">\t<span class=\"keyword\">while</span>(<span class=\"number\">1</span>)&#123;</div><div class=\"line\">\t\tbfs(s,t);</div><div class=\"line\">\t<span class=\"comment\">//\tfor(int i=1; i&lt;=n; i++)</span></div><div class=\"line\">\t<span class=\"comment\">//\t\tcout&lt;&lt;\"level \"&lt;&lt;i&lt;&lt;\": \"&lt;&lt;level[i]&lt;&lt;endl;</span></div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(level[t]&lt;<span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++)</div><div class=\"line\">\t\t\titer[i] = head[i];</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> val;</div><div class=\"line\">\t\t<span class=\"keyword\">while</span>(val=dfs(s,t,INF))&#123;</div><div class=\"line\">\t\t\t<span class=\"comment\">//cout&lt;&lt;\"val: \"&lt;&lt;val&lt;&lt;endl;</span></div><div class=\"line\">\t\t\tans += val;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> T;</div><div class=\"line\">\tsc(T);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(T--)&#123;</div><div class=\"line\">\t\tsc(n); sc(m);</div><div class=\"line\">\t\tsc(s); sc(t);</div><div class=\"line\">\t\tcnt = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(head,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(head));</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;m; i++)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">int</span> u,v,w;</div><div class=\"line\">\t\t\tsc(u); sc(v); sc(w);</div><div class=\"line\">\t\t\tadd_edge(u,v,w*<span class=\"number\">1000</span>+<span class=\"number\">1</span>);</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> ans = Dinic();</div><div class=\"line\">\t\t<span class=\"built_in\">cout</span>&lt;&lt;ans%<span class=\"number\">1000</span>&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>给有向图，求一个最小割，它的边数也最小<br>搜了原题题解，发现一堆假算法==<br>假算法说什么将满流边置为1 其它边置为INF 感觉不科学<br>因为考虑有不同种最大流情况的图，不同的最大流情况会导致算出来的结果不一样。</p>\n<p>AC的解法是对于每条边的容量乘上一个大于边数的数+1,最后再模上这个数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;utility&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;queue&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MAXN 5000</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> sc(x) scanf(<span class=\"meta-string\">\"%d\"</span>,&amp;(x))</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> INF = <span class=\"number\">0x3f3f3f3f</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> edge&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> t,cap,next;</div><div class=\"line\">&#125;;</div><div class=\"line\">edge e[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> cnt;</div><div class=\"line\"><span class=\"keyword\">int</span> head[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> n,m,s,t;</div><div class=\"line\"><span class=\"keyword\">int</span> iter[MAXN],level[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add_edge</span><span class=\"params\">(<span class=\"keyword\">int</span> f,<span class=\"keyword\">int</span> t,<span class=\"keyword\">int</span> cap)</span></span>&#123;</div><div class=\"line\">\te[cnt].t = t;\te[cnt].cap = cap;\te[cnt].next = head[f];</div><div class=\"line\">\thead[f] = cnt++;</div><div class=\"line\">\te[cnt].t = f;\te[cnt].cap = <span class=\"number\">0</span>;\te[cnt].next = head[t];</div><div class=\"line\">\thead[t] = cnt++;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bfs</span><span class=\"params\">(<span class=\"keyword\">int</span> s,<span class=\"keyword\">int</span> t)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"built_in\">memset</span>(level,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(level));</div><div class=\"line\">\tlevel[s] = <span class=\"number\">0</span>;</div><div class=\"line\">\t<span class=\"built_in\">queue</span>&lt;<span class=\"keyword\">int</span>&gt; q;</div><div class=\"line\">\tq.push(s);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(!q.empty())&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> cur = q.front(); q.pop();</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(cur==t) <span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=head[cur]; i!=<span class=\"number\">-1</span>; i=e[i].next)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">int</span> v = e[i].t;</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(level[v]&lt;<span class=\"number\">0</span> &amp;&amp; e[i].cap&gt;<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\tlevel[v] = level[cur] + <span class=\"number\">1</span>;</div><div class=\"line\">\t\t\t\tq.push(v);</div><div class=\"line\">\t\t\t&#125;\t</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u,<span class=\"keyword\">int</span> t,<span class=\"keyword\">int</span> flow)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">if</span>(u==t) <span class=\"keyword\">return</span> flow;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> &amp;i=iter[u]; i!=<span class=\"number\">-1</span>; i=e[i].next)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> v = e[i].t;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(level[v]&gt;level[u] &amp;&amp; e[i].cap&gt;<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">int</span> val = dfs(v,t,min(flow,e[i].cap));</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(val&gt;<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\te[i].cap -= val;</div><div class=\"line\">\t\t\t\te[i^<span class=\"number\">1</span>].cap +=val;</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">return</span> val;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">Dinic</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">\t<span class=\"keyword\">while</span>(<span class=\"number\">1</span>)&#123;</div><div class=\"line\">\t\tbfs(s,t);</div><div class=\"line\">\t<span class=\"comment\">//\tfor(int i=1; i&lt;=n; i++)</span></div><div class=\"line\">\t<span class=\"comment\">//\t\tcout&lt;&lt;\"level \"&lt;&lt;i&lt;&lt;\": \"&lt;&lt;level[i]&lt;&lt;endl;</span></div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(level[t]&lt;<span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++)</div><div class=\"line\">\t\t\titer[i] = head[i];</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> val;</div><div class=\"line\">\t\t<span class=\"keyword\">while</span>(val=dfs(s,t,INF))&#123;</div><div class=\"line\">\t\t\t<span class=\"comment\">//cout&lt;&lt;\"val: \"&lt;&lt;val&lt;&lt;endl;</span></div><div class=\"line\">\t\t\tans += val;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> T;</div><div class=\"line\">\tsc(T);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(T--)&#123;</div><div class=\"line\">\t\tsc(n); sc(m);</div><div class=\"line\">\t\tsc(s); sc(t);</div><div class=\"line\">\t\tcnt = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(head,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(head));</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;m; i++)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">int</span> u,v,w;</div><div class=\"line\">\t\t\tsc(u); sc(v); sc(w);</div><div class=\"line\">\t\t\tadd_edge(u,v,w*<span class=\"number\">1000</span>+<span class=\"number\">1</span>);</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> ans = Dinic();</div><div class=\"line\">\t\t<span class=\"built_in\">cout</span>&lt;&lt;ans%<span class=\"number\">1000</span>&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"沈阳网络赛2017","date":"2017-09-14T08:11:20.000Z","_content":"\nhdu 6199 dp\n```c++\nll dp[2][350][220];\nll sum[40020];\nll v[40020];\n\nint main()\n{\n    int t,n;\n    sc(t);\n    while(t--){\n        sc(n);\n        sum[0] = 0;\n        for(int i=1; i<=n; i++){\n            scanf(\"%lld\",v+i);\n            sum[i] = sum[i-1]+v[i];\n        }\n        memset(dp,0,sizeof(dp));\n        for(int i=n; i>=1; i--){\n            for(int j=1; j*j<=2*i; j++){\n                if(i+j==n+1){\n                    dp[0][i&mod][j] = sum[n]-sum[i-1];\n                    dp[1][i&mod][j] = sum[i-1] - sum[n];\n                    break;\n                }\n                if(i+j>n+1) continue;\n                dp[0][i&mod][j] = max(dp[1][(i+j)&mod][j], dp[1][(i+j+1)&mod][j+1]+v[i+j]) + sum[i+j-1] - sum[i-1];\n                dp[1][i&mod][j] = min(dp[0][(i+j)&mod][j], dp[0][(i+j+1)&mod][j+1]-v[i+j]) - sum[i+j-1] + sum[i-1];\n            }\n        }\n        cout<<dp[0][1][1]<<endl;\n    }\n}\n```\n\n\nhdu 6201 树上DP\n```c++\nstruct node{\n    int to,cost,next;\n}e[MAXN];\nint head[MAXN];\nint val[MAXN];\nint dp[2][MAXN];\nint cnt = 0;\n\nvoid add_edge(int f,int t,int c)\n{\n    e[cnt].to = t;\n    e[cnt].cost = c;\n    e[cnt].next = head[f];\n    head[f] = cnt;\n    cnt++;\n}\n\nvoid dfs(int u,int pre)\n{\n    dp[0][u] = -val[u];\n    dp[1][u] = val[u];\n    for(int i=head[u]; i!=-1; i=e[i].next){\n        int v = e[i].to;\n        int cost = e[i].cost;\n        if(pre==v) continue;\n        dfs(v,u);\n        dp[0][u] = max(dp[0][u],dp[0][v]-cost);\n        dp[1][u] = max(dp[1][u],dp[1][v]-cost);\n    }\n}\n\nint main()\n{\n    int t,n;\n    sc(t);\n    while(t--){\n        sc(n);\n        for(int i=1; i<=n; i++) sc(val[i]);\n        memset(head,-1,sizeof(head));\n        memset(dp,0,sizeof(dp));\n        cnt = 0;\n        for(int i=1; i<n; i++){\n            int f,t,c;\n            sc(f);  sc(t); sc(c);\n            add_edge(f,t,c);\n            add_edge(t,f,c);\n        }\n        dfs(1,-1);\n        int ans = 0;\n        for(int i=1; i<=n; i++){\n            ans = max(ans,dp[0][i]+dp[1][i]);\n        }\n        printf(\"%d\\n\",ans);\n    }\n}\n```","source":"_posts/沈阳网络赛2017.md","raw":"---\ntitle: 沈阳网络赛2017\ndate: 2017-09-14 16:11:20\ntags: [题解]\ncategories: ACM\n---\n\nhdu 6199 dp\n```c++\nll dp[2][350][220];\nll sum[40020];\nll v[40020];\n\nint main()\n{\n    int t,n;\n    sc(t);\n    while(t--){\n        sc(n);\n        sum[0] = 0;\n        for(int i=1; i<=n; i++){\n            scanf(\"%lld\",v+i);\n            sum[i] = sum[i-1]+v[i];\n        }\n        memset(dp,0,sizeof(dp));\n        for(int i=n; i>=1; i--){\n            for(int j=1; j*j<=2*i; j++){\n                if(i+j==n+1){\n                    dp[0][i&mod][j] = sum[n]-sum[i-1];\n                    dp[1][i&mod][j] = sum[i-1] - sum[n];\n                    break;\n                }\n                if(i+j>n+1) continue;\n                dp[0][i&mod][j] = max(dp[1][(i+j)&mod][j], dp[1][(i+j+1)&mod][j+1]+v[i+j]) + sum[i+j-1] - sum[i-1];\n                dp[1][i&mod][j] = min(dp[0][(i+j)&mod][j], dp[0][(i+j+1)&mod][j+1]-v[i+j]) - sum[i+j-1] + sum[i-1];\n            }\n        }\n        cout<<dp[0][1][1]<<endl;\n    }\n}\n```\n\n\nhdu 6201 树上DP\n```c++\nstruct node{\n    int to,cost,next;\n}e[MAXN];\nint head[MAXN];\nint val[MAXN];\nint dp[2][MAXN];\nint cnt = 0;\n\nvoid add_edge(int f,int t,int c)\n{\n    e[cnt].to = t;\n    e[cnt].cost = c;\n    e[cnt].next = head[f];\n    head[f] = cnt;\n    cnt++;\n}\n\nvoid dfs(int u,int pre)\n{\n    dp[0][u] = -val[u];\n    dp[1][u] = val[u];\n    for(int i=head[u]; i!=-1; i=e[i].next){\n        int v = e[i].to;\n        int cost = e[i].cost;\n        if(pre==v) continue;\n        dfs(v,u);\n        dp[0][u] = max(dp[0][u],dp[0][v]-cost);\n        dp[1][u] = max(dp[1][u],dp[1][v]-cost);\n    }\n}\n\nint main()\n{\n    int t,n;\n    sc(t);\n    while(t--){\n        sc(n);\n        for(int i=1; i<=n; i++) sc(val[i]);\n        memset(head,-1,sizeof(head));\n        memset(dp,0,sizeof(dp));\n        cnt = 0;\n        for(int i=1; i<n; i++){\n            int f,t,c;\n            sc(f);  sc(t); sc(c);\n            add_edge(f,t,c);\n            add_edge(t,f,c);\n        }\n        dfs(1,-1);\n        int ans = 0;\n        for(int i=1; i<=n; i++){\n            ans = max(ans,dp[0][i]+dp[1][i]);\n        }\n        printf(\"%d\\n\",ans);\n    }\n}\n```","slug":"沈阳网络赛2017","published":1,"updated":"2017-09-14T14:53:40.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55ca0007acwo5ca4jabo","content":"<p>hdu 6199 dp<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\">ll dp[<span class=\"number\">2</span>][<span class=\"number\">350</span>][<span class=\"number\">220</span>];</div><div class=\"line\">ll sum[<span class=\"number\">40020</span>];</div><div class=\"line\">ll v[<span class=\"number\">40020</span>];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> t,n;</div><div class=\"line\">    sc(t);</div><div class=\"line\">    <span class=\"keyword\">while</span>(t--)&#123;</div><div class=\"line\">        sc(n);</div><div class=\"line\">        sum[<span class=\"number\">0</span>] = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++)&#123;</div><div class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lld\"</span>,v+i);</div><div class=\"line\">            sum[i] = sum[i<span class=\"number\">-1</span>]+v[i];</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(dp,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(dp));</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=n; i&gt;=<span class=\"number\">1</span>; i--)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j*j&lt;=<span class=\"number\">2</span>*i; j++)&#123;</div><div class=\"line\">                <span class=\"keyword\">if</span>(i+j==n+<span class=\"number\">1</span>)&#123;</div><div class=\"line\">                    dp[<span class=\"number\">0</span>][i&amp;mod][j] = sum[n]-sum[i<span class=\"number\">-1</span>];</div><div class=\"line\">                    dp[<span class=\"number\">1</span>][i&amp;mod][j] = sum[i<span class=\"number\">-1</span>] - sum[n];</div><div class=\"line\">                    <span class=\"keyword\">break</span>;</div><div class=\"line\">                &#125;</div><div class=\"line\">                <span class=\"keyword\">if</span>(i+j&gt;n+<span class=\"number\">1</span>) <span class=\"keyword\">continue</span>;</div><div class=\"line\">                dp[<span class=\"number\">0</span>][i&amp;mod][j] = max(dp[<span class=\"number\">1</span>][(i+j)&amp;mod][j], dp[<span class=\"number\">1</span>][(i+j+<span class=\"number\">1</span>)&amp;mod][j+<span class=\"number\">1</span>]+v[i+j]) + sum[i+j<span class=\"number\">-1</span>] - sum[i<span class=\"number\">-1</span>];</div><div class=\"line\">                dp[<span class=\"number\">1</span>][i&amp;mod][j] = min(dp[<span class=\"number\">0</span>][(i+j)&amp;mod][j], dp[<span class=\"number\">0</span>][(i+j+<span class=\"number\">1</span>)&amp;mod][j+<span class=\"number\">1</span>]-v[i+j]) - sum[i+j<span class=\"number\">-1</span>] + sum[i<span class=\"number\">-1</span>];</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">cout</span>&lt;&lt;dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>][<span class=\"number\">1</span>]&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>hdu 6201 树上DP<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">struct</span> node&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> to,cost,next;</div><div class=\"line\">&#125;e[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> head[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> val[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> dp[<span class=\"number\">2</span>][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> cnt = <span class=\"number\">0</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add_edge</span><span class=\"params\">(<span class=\"keyword\">int</span> f,<span class=\"keyword\">int</span> t,<span class=\"keyword\">int</span> c)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    e[cnt].to = t;</div><div class=\"line\">    e[cnt].cost = c;</div><div class=\"line\">    e[cnt].next = head[f];</div><div class=\"line\">    head[f] = cnt;</div><div class=\"line\">    cnt++;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u,<span class=\"keyword\">int</span> pre)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    dp[<span class=\"number\">0</span>][u] = -val[u];</div><div class=\"line\">    dp[<span class=\"number\">1</span>][u] = val[u];</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=head[u]; i!=<span class=\"number\">-1</span>; i=e[i].next)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> v = e[i].to;</div><div class=\"line\">        <span class=\"keyword\">int</span> cost = e[i].cost;</div><div class=\"line\">        <span class=\"keyword\">if</span>(pre==v) <span class=\"keyword\">continue</span>;</div><div class=\"line\">        dfs(v,u);</div><div class=\"line\">        dp[<span class=\"number\">0</span>][u] = max(dp[<span class=\"number\">0</span>][u],dp[<span class=\"number\">0</span>][v]-cost);</div><div class=\"line\">        dp[<span class=\"number\">1</span>][u] = max(dp[<span class=\"number\">1</span>][u],dp[<span class=\"number\">1</span>][v]-cost);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> t,n;</div><div class=\"line\">    sc(t);</div><div class=\"line\">    <span class=\"keyword\">while</span>(t--)&#123;</div><div class=\"line\">        sc(n);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++) sc(val[i]);</div><div class=\"line\">        <span class=\"built_in\">memset</span>(head,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(head));</div><div class=\"line\">        <span class=\"built_in\">memset</span>(dp,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(dp));</div><div class=\"line\">        cnt = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;n; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> f,t,c;</div><div class=\"line\">            sc(f);  sc(t); sc(c);</div><div class=\"line\">            add_edge(f,t,c);</div><div class=\"line\">            add_edge(t,f,c);</div><div class=\"line\">        &#125;</div><div class=\"line\">        dfs(<span class=\"number\">1</span>,<span class=\"number\">-1</span>);</div><div class=\"line\">        <span class=\"keyword\">int</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++)&#123;</div><div class=\"line\">            ans = max(ans,dp[<span class=\"number\">0</span>][i]+dp[<span class=\"number\">1</span>][i]);</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>,ans);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","excerpt":"","more":"<p>hdu 6199 dp<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\">ll dp[<span class=\"number\">2</span>][<span class=\"number\">350</span>][<span class=\"number\">220</span>];</div><div class=\"line\">ll sum[<span class=\"number\">40020</span>];</div><div class=\"line\">ll v[<span class=\"number\">40020</span>];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> t,n;</div><div class=\"line\">    sc(t);</div><div class=\"line\">    <span class=\"keyword\">while</span>(t--)&#123;</div><div class=\"line\">        sc(n);</div><div class=\"line\">        sum[<span class=\"number\">0</span>] = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++)&#123;</div><div class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lld\"</span>,v+i);</div><div class=\"line\">            sum[i] = sum[i<span class=\"number\">-1</span>]+v[i];</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(dp,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(dp));</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=n; i&gt;=<span class=\"number\">1</span>; i--)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j*j&lt;=<span class=\"number\">2</span>*i; j++)&#123;</div><div class=\"line\">                <span class=\"keyword\">if</span>(i+j==n+<span class=\"number\">1</span>)&#123;</div><div class=\"line\">                    dp[<span class=\"number\">0</span>][i&amp;mod][j] = sum[n]-sum[i<span class=\"number\">-1</span>];</div><div class=\"line\">                    dp[<span class=\"number\">1</span>][i&amp;mod][j] = sum[i<span class=\"number\">-1</span>] - sum[n];</div><div class=\"line\">                    <span class=\"keyword\">break</span>;</div><div class=\"line\">                &#125;</div><div class=\"line\">                <span class=\"keyword\">if</span>(i+j&gt;n+<span class=\"number\">1</span>) <span class=\"keyword\">continue</span>;</div><div class=\"line\">                dp[<span class=\"number\">0</span>][i&amp;mod][j] = max(dp[<span class=\"number\">1</span>][(i+j)&amp;mod][j], dp[<span class=\"number\">1</span>][(i+j+<span class=\"number\">1</span>)&amp;mod][j+<span class=\"number\">1</span>]+v[i+j]) + sum[i+j<span class=\"number\">-1</span>] - sum[i<span class=\"number\">-1</span>];</div><div class=\"line\">                dp[<span class=\"number\">1</span>][i&amp;mod][j] = min(dp[<span class=\"number\">0</span>][(i+j)&amp;mod][j], dp[<span class=\"number\">0</span>][(i+j+<span class=\"number\">1</span>)&amp;mod][j+<span class=\"number\">1</span>]-v[i+j]) - sum[i+j<span class=\"number\">-1</span>] + sum[i<span class=\"number\">-1</span>];</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">cout</span>&lt;&lt;dp[<span class=\"number\">0</span>][<span class=\"number\">1</span>][<span class=\"number\">1</span>]&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>hdu 6201 树上DP<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">struct</span> node&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> to,cost,next;</div><div class=\"line\">&#125;e[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> head[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> val[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> dp[<span class=\"number\">2</span>][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> cnt = <span class=\"number\">0</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">add_edge</span><span class=\"params\">(<span class=\"keyword\">int</span> f,<span class=\"keyword\">int</span> t,<span class=\"keyword\">int</span> c)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    e[cnt].to = t;</div><div class=\"line\">    e[cnt].cost = c;</div><div class=\"line\">    e[cnt].next = head[f];</div><div class=\"line\">    head[f] = cnt;</div><div class=\"line\">    cnt++;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u,<span class=\"keyword\">int</span> pre)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    dp[<span class=\"number\">0</span>][u] = -val[u];</div><div class=\"line\">    dp[<span class=\"number\">1</span>][u] = val[u];</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=head[u]; i!=<span class=\"number\">-1</span>; i=e[i].next)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> v = e[i].to;</div><div class=\"line\">        <span class=\"keyword\">int</span> cost = e[i].cost;</div><div class=\"line\">        <span class=\"keyword\">if</span>(pre==v) <span class=\"keyword\">continue</span>;</div><div class=\"line\">        dfs(v,u);</div><div class=\"line\">        dp[<span class=\"number\">0</span>][u] = max(dp[<span class=\"number\">0</span>][u],dp[<span class=\"number\">0</span>][v]-cost);</div><div class=\"line\">        dp[<span class=\"number\">1</span>][u] = max(dp[<span class=\"number\">1</span>][u],dp[<span class=\"number\">1</span>][v]-cost);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> t,n;</div><div class=\"line\">    sc(t);</div><div class=\"line\">    <span class=\"keyword\">while</span>(t--)&#123;</div><div class=\"line\">        sc(n);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++) sc(val[i]);</div><div class=\"line\">        <span class=\"built_in\">memset</span>(head,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(head));</div><div class=\"line\">        <span class=\"built_in\">memset</span>(dp,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(dp));</div><div class=\"line\">        cnt = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;n; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> f,t,c;</div><div class=\"line\">            sc(f);  sc(t); sc(c);</div><div class=\"line\">            add_edge(f,t,c);</div><div class=\"line\">            add_edge(t,f,c);</div><div class=\"line\">        &#125;</div><div class=\"line\">        dfs(<span class=\"number\">1</span>,<span class=\"number\">-1</span>);</div><div class=\"line\">        <span class=\"keyword\">int</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n; i++)&#123;</div><div class=\"line\">            ans = max(ans,dp[<span class=\"number\">0</span>][i]+dp[<span class=\"number\">1</span>][i]);</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>,ans);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n"},{"title":"简单的LCA==","date":"2017-09-03T05:49:50.000Z","_content":"题源： NAIPC 2016 The University Of Chicago\n校内赛一道LCA==，写掉了一个等号调了一下午== \ndfs爆栈然后手写栈模拟了一发\n\n```c++\nint depth[MAXN*2];\nstruct ST{\n    int mm[2*MAXN];\n    int dp[2*MAXN][25];\n    void init(int n){\n        mm[0] = -1;\n        for(int i=1;i<=n; i++){\n            mm[i] = ((i&(i-1))==0)?mm[i-1]+1:mm[i-1];\n            dp[i][0] = i;\n        }\n        for(int j=1 ;j<=mm[n] ;j++)\n            for(int i=1; i+(1<<j)-1<=n; i++)\n                dp[i][j] = (depth[dp[i][j-1]] < depth[dp[i+(1<<(j-1))][j-1]])? dp[i][j-1]:dp[i+(1<<(j-1))][j-1];\n    }\n    int query(int a,int b){\n        if(a>b)swap(a,b);\n        int k = mm[b-a+1];\n        return depth[dp[a][k]]<=depth[dp[b-(1<<k)+1][k]]?dp[a][k]:dp[b-(1<<k)+1][k];\n    }\n}st;\n\nvector<vector<int> >G(MAXN);\nint vs[MAXN*2];\nint pos[MAXN];\n\n\n//void dfs(int v,int pre,int d,int &k){\n//    pos[v] = k;\n//    vs[k] = v;\n//    depth[k++] = d;\n//    for(int i=0; i<G[v].size(); i++){\n//        if(G[v][i]!=pre){\n//            dfs(G[v][i],v,d+1,k);\n//            vs[k] = v;\n//            depth[k++]=d;\n//        }\n//    }\n//}\n\nstruct dfs{\n    int v,pre,d,i;\n    dfs(int vv,int pp,int dd,int ii):v(vv),pre(pp),d(dd),i(ii){}\n};\nstack<dfs> s;\n\nvoid solve(int &k){\n    s.push(dfs(1,0,0,0));\n    int v,pre,d,i;\n    while(!s.empty()){\n        dfs cur = s.top();\n        s.pop();\n        //cout<<s.size()<<endl;\n        v = cur.v;  pre = cur.pre; d = cur.d; i = cur.i;\n        if(i==0){\n            pos[v] = k;\n            vs[k] = v;\n            depth[k++] = d;\n        }\n        else{\n            vs[k] = v;\n            depth[k++]=d;\n        }\n        //cout<<v<<\" \"<<G[v].size()<<endl;\n        if(i<G[v].size() && G[v][i]==pre) i++;\n        if(i<G[v].size()){\n            //cout<<\"from:\"<<v<<\" to:\"<<G[v][i]<<endl;\n            cur.i = i+1;\n            s.push(cur);\n            s.push(dfs(G[v][i],v,d+1,0));\n        }\n    }\n}\n\nint lca_query(int v,int u)\n{\n    int s = min(pos[v],pos[u]);\n    int e = max(pos[v],pos[u]);\n    return 1+depth[s]+depth[e]-2*depth[st.query(s,e)];\n}\n\nint main()\n{\n    frein;\n    int n;\n    scanf(\"%d\",&n);\n    for(int i=0; i<n-1; i++){\n        int f,t;\n        scanf(\"%d%d\",&f,&t);\n        G[f].pb(t);\n        G[t].pb(f);\n    }\n//    for(int i=1;i<n; i++){\n//        cout<<i<<\":  \"<<endl;\n//        for(int j=0; j<G[i].size(); j++)\n//            cout<<G[i][j]<<\" \";\n//        cout<<endl;\n//    }\n    int cnt=1;\n    solve(cnt);\n//    for(int i=0; i<cnt;i++)\n//        cout<<vs[i]<<\" depth: \"<<depth[i]<<endl;\n//    for(int i=1; i<cnt; i++){\n//        cout<<\"node:\"<<vs[i]<<\" depth:\"<<depth[i]<<endl;\n//    }\n//    for(int i=1; i<=n; i++)\n//        cout<<\"vis\"<<i<<\" is \"<<pos[i]<<endl;\n    st.init(2*n-1);\n    ll ans = 0;\n    for(int i=1; i<=n/2; i++)\n        for(int j=2; i*j<=n; j++){\n            ans += lca_query(i,i*j);\n        }\n    cout<<ans<<endl;\n    return 0;\n}\n```\n","source":"_posts/简单的LCA.md","raw":"---\ntitle: 简单的LCA==\ndate: 2017-09-03 13:49:50\ntags: [LCA]\ncategories: ACM\n---\n题源： NAIPC 2016 The University Of Chicago\n校内赛一道LCA==，写掉了一个等号调了一下午== \ndfs爆栈然后手写栈模拟了一发\n\n```c++\nint depth[MAXN*2];\nstruct ST{\n    int mm[2*MAXN];\n    int dp[2*MAXN][25];\n    void init(int n){\n        mm[0] = -1;\n        for(int i=1;i<=n; i++){\n            mm[i] = ((i&(i-1))==0)?mm[i-1]+1:mm[i-1];\n            dp[i][0] = i;\n        }\n        for(int j=1 ;j<=mm[n] ;j++)\n            for(int i=1; i+(1<<j)-1<=n; i++)\n                dp[i][j] = (depth[dp[i][j-1]] < depth[dp[i+(1<<(j-1))][j-1]])? dp[i][j-1]:dp[i+(1<<(j-1))][j-1];\n    }\n    int query(int a,int b){\n        if(a>b)swap(a,b);\n        int k = mm[b-a+1];\n        return depth[dp[a][k]]<=depth[dp[b-(1<<k)+1][k]]?dp[a][k]:dp[b-(1<<k)+1][k];\n    }\n}st;\n\nvector<vector<int> >G(MAXN);\nint vs[MAXN*2];\nint pos[MAXN];\n\n\n//void dfs(int v,int pre,int d,int &k){\n//    pos[v] = k;\n//    vs[k] = v;\n//    depth[k++] = d;\n//    for(int i=0; i<G[v].size(); i++){\n//        if(G[v][i]!=pre){\n//            dfs(G[v][i],v,d+1,k);\n//            vs[k] = v;\n//            depth[k++]=d;\n//        }\n//    }\n//}\n\nstruct dfs{\n    int v,pre,d,i;\n    dfs(int vv,int pp,int dd,int ii):v(vv),pre(pp),d(dd),i(ii){}\n};\nstack<dfs> s;\n\nvoid solve(int &k){\n    s.push(dfs(1,0,0,0));\n    int v,pre,d,i;\n    while(!s.empty()){\n        dfs cur = s.top();\n        s.pop();\n        //cout<<s.size()<<endl;\n        v = cur.v;  pre = cur.pre; d = cur.d; i = cur.i;\n        if(i==0){\n            pos[v] = k;\n            vs[k] = v;\n            depth[k++] = d;\n        }\n        else{\n            vs[k] = v;\n            depth[k++]=d;\n        }\n        //cout<<v<<\" \"<<G[v].size()<<endl;\n        if(i<G[v].size() && G[v][i]==pre) i++;\n        if(i<G[v].size()){\n            //cout<<\"from:\"<<v<<\" to:\"<<G[v][i]<<endl;\n            cur.i = i+1;\n            s.push(cur);\n            s.push(dfs(G[v][i],v,d+1,0));\n        }\n    }\n}\n\nint lca_query(int v,int u)\n{\n    int s = min(pos[v],pos[u]);\n    int e = max(pos[v],pos[u]);\n    return 1+depth[s]+depth[e]-2*depth[st.query(s,e)];\n}\n\nint main()\n{\n    frein;\n    int n;\n    scanf(\"%d\",&n);\n    for(int i=0; i<n-1; i++){\n        int f,t;\n        scanf(\"%d%d\",&f,&t);\n        G[f].pb(t);\n        G[t].pb(f);\n    }\n//    for(int i=1;i<n; i++){\n//        cout<<i<<\":  \"<<endl;\n//        for(int j=0; j<G[i].size(); j++)\n//            cout<<G[i][j]<<\" \";\n//        cout<<endl;\n//    }\n    int cnt=1;\n    solve(cnt);\n//    for(int i=0; i<cnt;i++)\n//        cout<<vs[i]<<\" depth: \"<<depth[i]<<endl;\n//    for(int i=1; i<cnt; i++){\n//        cout<<\"node:\"<<vs[i]<<\" depth:\"<<depth[i]<<endl;\n//    }\n//    for(int i=1; i<=n; i++)\n//        cout<<\"vis\"<<i<<\" is \"<<pos[i]<<endl;\n    st.init(2*n-1);\n    ll ans = 0;\n    for(int i=1; i<=n/2; i++)\n        for(int j=2; i*j<=n; j++){\n            ans += lca_query(i,i*j);\n        }\n    cout<<ans<<endl;\n    return 0;\n}\n```\n","slug":"简单的LCA","published":1,"updated":"2017-09-03T16:41:02.274Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55d5000bacwooxophwa1","content":"<p>题源： NAIPC 2016 The University Of Chicago<br>校内赛一道LCA==，写掉了一个等号调了一下午==<br>dfs爆栈然后手写栈模拟了一发</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> depth[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\"><span class=\"keyword\">struct</span> ST&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> mm[<span class=\"number\">2</span>*MAXN];</div><div class=\"line\">    <span class=\"keyword\">int</span> dp[<span class=\"number\">2</span>*MAXN][<span class=\"number\">25</span>];</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span>&#123;</div><div class=\"line\">        mm[<span class=\"number\">0</span>] = <span class=\"number\">-1</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=n; i++)&#123;</div><div class=\"line\">            mm[i] = ((i&amp;(i<span class=\"number\">-1</span>))==<span class=\"number\">0</span>)?mm[i<span class=\"number\">-1</span>]+<span class=\"number\">1</span>:mm[i<span class=\"number\">-1</span>];</div><div class=\"line\">            dp[i][<span class=\"number\">0</span>] = i;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span> ;j&lt;=mm[n] ;j++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i+(<span class=\"number\">1</span>&lt;&lt;j)<span class=\"number\">-1</span>&lt;=n; i++)</div><div class=\"line\">                dp[i][j] = (depth[dp[i][j<span class=\"number\">-1</span>]] &lt; depth[dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>]])? dp[i][j<span class=\"number\">-1</span>]:dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">query</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(a&gt;b)swap(a,b);</div><div class=\"line\">        <span class=\"keyword\">int</span> k = mm[b-a+<span class=\"number\">1</span>];</div><div class=\"line\">        <span class=\"keyword\">return</span> depth[dp[a][k]]&lt;=depth[dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k]]?dp[a][k]:dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k];</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;st;</div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &gt;G(MAXN);</div><div class=\"line\"><span class=\"keyword\">int</span> vs[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> pos[MAXN];</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//void dfs(int v,int pre,int d,int &amp;k)&#123;</span></div><div class=\"line\"><span class=\"comment\">//    pos[v] = k;</span></div><div class=\"line\"><span class=\"comment\">//    vs[k] = v;</span></div><div class=\"line\"><span class=\"comment\">//    depth[k++] = d;</span></div><div class=\"line\"><span class=\"comment\">//    for(int i=0; i&lt;G[v].size(); i++)&#123;</span></div><div class=\"line\"><span class=\"comment\">//        if(G[v][i]!=pre)&#123;</span></div><div class=\"line\"><span class=\"comment\">//            dfs(G[v][i],v,d+1,k);</span></div><div class=\"line\"><span class=\"comment\">//            vs[k] = v;</span></div><div class=\"line\"><span class=\"comment\">//            depth[k++]=d;</span></div><div class=\"line\"><span class=\"comment\">//        &#125;</span></div><div class=\"line\"><span class=\"comment\">//    &#125;</span></div><div class=\"line\"><span class=\"comment\">//&#125;</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> dfs&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> v,pre,d,i;</div><div class=\"line\">    dfs(<span class=\"keyword\">int</span> vv,<span class=\"keyword\">int</span> pp,<span class=\"keyword\">int</span> dd,<span class=\"keyword\">int</span> ii):v(vv),pre(pp),d(dd),i(ii)&#123;&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"built_in\">stack</span>&lt;dfs&gt; s;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">solve</span><span class=\"params\">(<span class=\"keyword\">int</span> &amp;k)</span></span>&#123;</div><div class=\"line\">    s.push(dfs(<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>));</div><div class=\"line\">    <span class=\"keyword\">int</span> v,pre,d,i;</div><div class=\"line\">    <span class=\"keyword\">while</span>(!s.empty())&#123;</div><div class=\"line\">        dfs cur = s.top();</div><div class=\"line\">        s.pop();</div><div class=\"line\">        <span class=\"comment\">//cout&lt;&lt;s.size()&lt;&lt;endl;</span></div><div class=\"line\">        v = cur.v;  pre = cur.pre; d = cur.d; i = cur.i;</div><div class=\"line\">        <span class=\"keyword\">if</span>(i==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">            pos[v] = k;</div><div class=\"line\">            vs[k] = v;</div><div class=\"line\">            depth[k++] = d;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">else</span>&#123;</div><div class=\"line\">            vs[k] = v;</div><div class=\"line\">            depth[k++]=d;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"comment\">//cout&lt;&lt;v&lt;&lt;\" \"&lt;&lt;G[v].size()&lt;&lt;endl;</span></div><div class=\"line\">        <span class=\"keyword\">if</span>(i&lt;G[v].size() &amp;&amp; G[v][i]==pre) i++;</div><div class=\"line\">        <span class=\"keyword\">if</span>(i&lt;G[v].size())&#123;</div><div class=\"line\">            <span class=\"comment\">//cout&lt;&lt;\"from:\"&lt;&lt;v&lt;&lt;\" to:\"&lt;&lt;G[v][i]&lt;&lt;endl;</span></div><div class=\"line\">            cur.i = i+<span class=\"number\">1</span>;</div><div class=\"line\">            s.push(cur);</div><div class=\"line\">            s.push(dfs(G[v][i],v,d+<span class=\"number\">1</span>,<span class=\"number\">0</span>));</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">lca_query</span><span class=\"params\">(<span class=\"keyword\">int</span> v,<span class=\"keyword\">int</span> u)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> s = min(pos[v],pos[u]);</div><div class=\"line\">    <span class=\"keyword\">int</span> e = max(pos[v],pos[u]);</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>+depth[s]+depth[e]<span class=\"number\">-2</span>*depth[st.query(s,e)];</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    frein;</div><div class=\"line\">    <span class=\"keyword\">int</span> n;</div><div class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>,&amp;n);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n<span class=\"number\">-1</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> f,t;</div><div class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d%d\"</span>,&amp;f,&amp;t);</div><div class=\"line\">        G[f].pb(t);</div><div class=\"line\">        G[t].pb(f);</div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"comment\">//    for(int i=1;i&lt;n; i++)&#123;</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;i&lt;&lt;\":  \"&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//        for(int j=0; j&lt;G[i].size(); j++)</span></div><div class=\"line\"><span class=\"comment\">//            cout&lt;&lt;G[i][j]&lt;&lt;\" \";</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//    &#125;</span></div><div class=\"line\">    <span class=\"keyword\">int</span> cnt=<span class=\"number\">1</span>;</div><div class=\"line\">    solve(cnt);</div><div class=\"line\"><span class=\"comment\">//    for(int i=0; i&lt;cnt;i++)</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;vs[i]&lt;&lt;\" depth: \"&lt;&lt;depth[i]&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//    for(int i=1; i&lt;cnt; i++)&#123;</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;\"node:\"&lt;&lt;vs[i]&lt;&lt;\" depth:\"&lt;&lt;depth[i]&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//    &#125;</span></div><div class=\"line\"><span class=\"comment\">//    for(int i=1; i&lt;=n; i++)</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;\"vis\"&lt;&lt;i&lt;&lt;\" is \"&lt;&lt;pos[i]&lt;&lt;endl;</span></div><div class=\"line\">    st.init(<span class=\"number\">2</span>*n<span class=\"number\">-1</span>);</div><div class=\"line\">    ll ans = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n/<span class=\"number\">2</span>; i++)</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">2</span>; i*j&lt;=n; j++)&#123;</div><div class=\"line\">            ans += lca_query(i,i*j);</div><div class=\"line\">        &#125;</div><div class=\"line\">    <span class=\"built_in\">cout</span>&lt;&lt;ans&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>题源： NAIPC 2016 The University Of Chicago<br>校内赛一道LCA==，写掉了一个等号调了一下午==<br>dfs爆栈然后手写栈模拟了一发</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> depth[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\"><span class=\"keyword\">struct</span> ST&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> mm[<span class=\"number\">2</span>*MAXN];</div><div class=\"line\">    <span class=\"keyword\">int</span> dp[<span class=\"number\">2</span>*MAXN][<span class=\"number\">25</span>];</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span>&#123;</div><div class=\"line\">        mm[<span class=\"number\">0</span>] = <span class=\"number\">-1</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=n; i++)&#123;</div><div class=\"line\">            mm[i] = ((i&amp;(i<span class=\"number\">-1</span>))==<span class=\"number\">0</span>)?mm[i<span class=\"number\">-1</span>]+<span class=\"number\">1</span>:mm[i<span class=\"number\">-1</span>];</div><div class=\"line\">            dp[i][<span class=\"number\">0</span>] = i;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span> ;j&lt;=mm[n] ;j++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i+(<span class=\"number\">1</span>&lt;&lt;j)<span class=\"number\">-1</span>&lt;=n; i++)</div><div class=\"line\">                dp[i][j] = (depth[dp[i][j<span class=\"number\">-1</span>]] &lt; depth[dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>]])? dp[i][j<span class=\"number\">-1</span>]:dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">query</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span></span>&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(a&gt;b)swap(a,b);</div><div class=\"line\">        <span class=\"keyword\">int</span> k = mm[b-a+<span class=\"number\">1</span>];</div><div class=\"line\">        <span class=\"keyword\">return</span> depth[dp[a][k]]&lt;=depth[dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k]]?dp[a][k]:dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k];</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;st;</div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &gt;G(MAXN);</div><div class=\"line\"><span class=\"keyword\">int</span> vs[MAXN*<span class=\"number\">2</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> pos[MAXN];</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//void dfs(int v,int pre,int d,int &amp;k)&#123;</span></div><div class=\"line\"><span class=\"comment\">//    pos[v] = k;</span></div><div class=\"line\"><span class=\"comment\">//    vs[k] = v;</span></div><div class=\"line\"><span class=\"comment\">//    depth[k++] = d;</span></div><div class=\"line\"><span class=\"comment\">//    for(int i=0; i&lt;G[v].size(); i++)&#123;</span></div><div class=\"line\"><span class=\"comment\">//        if(G[v][i]!=pre)&#123;</span></div><div class=\"line\"><span class=\"comment\">//            dfs(G[v][i],v,d+1,k);</span></div><div class=\"line\"><span class=\"comment\">//            vs[k] = v;</span></div><div class=\"line\"><span class=\"comment\">//            depth[k++]=d;</span></div><div class=\"line\"><span class=\"comment\">//        &#125;</span></div><div class=\"line\"><span class=\"comment\">//    &#125;</span></div><div class=\"line\"><span class=\"comment\">//&#125;</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> dfs&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> v,pre,d,i;</div><div class=\"line\">    dfs(<span class=\"keyword\">int</span> vv,<span class=\"keyword\">int</span> pp,<span class=\"keyword\">int</span> dd,<span class=\"keyword\">int</span> ii):v(vv),pre(pp),d(dd),i(ii)&#123;&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"built_in\">stack</span>&lt;dfs&gt; s;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">solve</span><span class=\"params\">(<span class=\"keyword\">int</span> &amp;k)</span></span>&#123;</div><div class=\"line\">    s.push(dfs(<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>));</div><div class=\"line\">    <span class=\"keyword\">int</span> v,pre,d,i;</div><div class=\"line\">    <span class=\"keyword\">while</span>(!s.empty())&#123;</div><div class=\"line\">        dfs cur = s.top();</div><div class=\"line\">        s.pop();</div><div class=\"line\">        <span class=\"comment\">//cout&lt;&lt;s.size()&lt;&lt;endl;</span></div><div class=\"line\">        v = cur.v;  pre = cur.pre; d = cur.d; i = cur.i;</div><div class=\"line\">        <span class=\"keyword\">if</span>(i==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">            pos[v] = k;</div><div class=\"line\">            vs[k] = v;</div><div class=\"line\">            depth[k++] = d;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">else</span>&#123;</div><div class=\"line\">            vs[k] = v;</div><div class=\"line\">            depth[k++]=d;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"comment\">//cout&lt;&lt;v&lt;&lt;\" \"&lt;&lt;G[v].size()&lt;&lt;endl;</span></div><div class=\"line\">        <span class=\"keyword\">if</span>(i&lt;G[v].size() &amp;&amp; G[v][i]==pre) i++;</div><div class=\"line\">        <span class=\"keyword\">if</span>(i&lt;G[v].size())&#123;</div><div class=\"line\">            <span class=\"comment\">//cout&lt;&lt;\"from:\"&lt;&lt;v&lt;&lt;\" to:\"&lt;&lt;G[v][i]&lt;&lt;endl;</span></div><div class=\"line\">            cur.i = i+<span class=\"number\">1</span>;</div><div class=\"line\">            s.push(cur);</div><div class=\"line\">            s.push(dfs(G[v][i],v,d+<span class=\"number\">1</span>,<span class=\"number\">0</span>));</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">lca_query</span><span class=\"params\">(<span class=\"keyword\">int</span> v,<span class=\"keyword\">int</span> u)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> s = min(pos[v],pos[u]);</div><div class=\"line\">    <span class=\"keyword\">int</span> e = max(pos[v],pos[u]);</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>+depth[s]+depth[e]<span class=\"number\">-2</span>*depth[st.query(s,e)];</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    frein;</div><div class=\"line\">    <span class=\"keyword\">int</span> n;</div><div class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>,&amp;n);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n<span class=\"number\">-1</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> f,t;</div><div class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d%d\"</span>,&amp;f,&amp;t);</div><div class=\"line\">        G[f].pb(t);</div><div class=\"line\">        G[t].pb(f);</div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"comment\">//    for(int i=1;i&lt;n; i++)&#123;</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;i&lt;&lt;\":  \"&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//        for(int j=0; j&lt;G[i].size(); j++)</span></div><div class=\"line\"><span class=\"comment\">//            cout&lt;&lt;G[i][j]&lt;&lt;\" \";</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//    &#125;</span></div><div class=\"line\">    <span class=\"keyword\">int</span> cnt=<span class=\"number\">1</span>;</div><div class=\"line\">    solve(cnt);</div><div class=\"line\"><span class=\"comment\">//    for(int i=0; i&lt;cnt;i++)</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;vs[i]&lt;&lt;\" depth: \"&lt;&lt;depth[i]&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//    for(int i=1; i&lt;cnt; i++)&#123;</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;\"node:\"&lt;&lt;vs[i]&lt;&lt;\" depth:\"&lt;&lt;depth[i]&lt;&lt;endl;</span></div><div class=\"line\"><span class=\"comment\">//    &#125;</span></div><div class=\"line\"><span class=\"comment\">//    for(int i=1; i&lt;=n; i++)</span></div><div class=\"line\"><span class=\"comment\">//        cout&lt;&lt;\"vis\"&lt;&lt;i&lt;&lt;\" is \"&lt;&lt;pos[i]&lt;&lt;endl;</span></div><div class=\"line\">    st.init(<span class=\"number\">2</span>*n<span class=\"number\">-1</span>);</div><div class=\"line\">    ll ans = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=n/<span class=\"number\">2</span>; i++)</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">2</span>; i*j&lt;=n; j++)&#123;</div><div class=\"line\">            ans += lca_query(i,i*j);</div><div class=\"line\">        &#125;</div><div class=\"line\">    <span class=\"built_in\">cout</span>&lt;&lt;ans&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"简单的几何学...","date":"2017-09-02T03:24:55.000Z","_content":"题源：Central Europe Contest 2015 Zagreb H   \n其实是道很无聊的题目了，就求交点判情况有点麻烦..  \n用向量判交点然后手撕一下\n```c++\nstruct Cvector{\n    double x,y;\n    Cvector(){}\n    Cvector(double xx,double yy):x(xx),y(yy){}\n}node[4];\n\nstruct Cline{\n    Cvector a,b;\n};\n\nCvector operator-(const Cvector &a,const Cvector &b){return Cvector(a.x-b.x,a.y-b.y);}\nCvector operator*(double k, const Cvector &a)       {return Cvector(k*a.x,k*a.y);}\nCvector operator+(const Cvector &a,const Cvector &b){return Cvector(a.x+b.x,a.y+b.y);}\ndouble operator*(const Cvector &a,const Cvector &b) {return a.x*b.x+a.y*b.y;}\ndouble operator^(const Cvector &a,const Cvector &b) {return a.x*b.y-a.y*b.x;}\ndouble area(Cvector a,Cvector b){\n    return (a^b)/2;\n}\n\nCvector intersect(Cline l,Cline m,int &msg){\n    double x = area(m.a-l.a, l.b-l.a);\n    double y = area(l.b-l.a, m.b-l.a);\n    if(x+y==0){\n        msg = 1;//平行或者重合\n        return Cvector(NaN,NaN);\n    }\n    return m.a+((x/(x+y))*(m.b-m.a));\n}\n\nCline l[4];\ndouble caly(Cline cl,double X)\n{\n    Cvector cross[4];\n    Cvector point[2];\n    int pcnt = 0,msg;\n    for(int i=0; i<4; i++)\n        cross[i] = intersect(cl,l[i],msg);\n    for(int i=0; i<4; i++){\n        if(cross[i].x >= l[i].a.x && cross[i].x <= l[i].b.x)\n            point[pcnt++] = cross[i];\n        else if(cross[i].x <= l[i].a.x && cross[i].x >= l[i].b.x)\n            point[pcnt++] = cross[i];\n    }\n    int nodecnt = 0;\n    double ans = 0;\n    for(int i=0; i<4; i++)\n        if(node[i].x<X)\n            nodecnt++;\n    if(nodecnt==3){\n        for(int i=0; i<4; i++)\n            if(node[i].x>=X)\n                ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n        ans = 5.0*5.0-ans;\n    }\n    else for(int i=0; i<4; i++){\n        if(node[i].x<X)\n            ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n    }\n    cout<<ans<<endl;\n    return ans;\n}\n\ndouble calx(Cline cl,double Y)\n{\n    Cvector cross[4];\n    Cvector point[2];\n    int pcnt = 0,msg;\n    for(int i=0; i<4; i++)\n        cross[i] = intersect(cl,l[i],msg);\n    for(int i=0; i<4; i++){\n        if(cross[i].x >= l[i].a.x && cross[i].x <= l[i].b.x)\n            point[pcnt++] = cross[i];\n        else if(cross[i].x <= l[i].a.x && cross[i].x >= l[i].b.x)\n            point[pcnt++] = cross[i];\n    }\n    double ans = 0;\n    int nodecnt = 0;\n    for(int i=0; i<4; i++)\n        if(node[i].y<Y)\n            nodecnt++;\n    if(nodecnt==3){\n        for(int i=0; i<4; i++)\n            if(node[i].y>=Y)\n                ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n        ans = 5.0*5.0-ans;\n    }\n    else for(int i=0; i<4; i++){\n        if(node[i].y<Y)\n            ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n    }\n    cout<<ans<<endl;\n    return ans;\n}\n\n\nint main()\n{\n    for(int i=0; i<4; i++){\n        double x,y;\n        scanf(\"%lf%lf\",&x,&y);\n        node[i].x =x;   node[i].y  = y;\n    }\n    for(int i=0; i<3; i++){\n        l[i].a = node[i];   l[i].b = node[i+1];\n    }\n    l[3].a = node[3];   l[3].b = node[0];\n\n    double ans = 0;\n    Cline cl;\n    cl.a = Cvector(0.5,0.5);    cl.b = Cvector(0.5,-0.5);\n    ans += 3.0*(25.0-caly(cl,0.5));\n    cl.a = Cvector(0.5,-0.5);    cl.b = Cvector(-0.5,-0.5);\n    ans += 1.0*(calx(cl,-0.5));\n    cl.a = Cvector(-0.5,-0.5);    cl.b = Cvector(-0.5,0.5);\n    ans += 4.0*caly(cl,-0.5);\n    cl.a = Cvector(-0.5,0.5);    cl.b = Cvector(0.5,0.5);\n    ans += 6.0*(25.0-calx(cl,0.5));\n    ans *= 5;\n    ans += 5.0*5.0*5.0*4;\n    ans /= (5.0*5.0*5.0-1.0);\n    printf(\"%.6f\\n\",ans);\n}\n\n```\n","source":"_posts/简单的几何学.md","raw":"---\ntitle: 简单的几何学...\ndate: 2017-09-02 11:24:55\ntags: [计算几何]\ncategories: ACM\n---\n题源：Central Europe Contest 2015 Zagreb H   \n其实是道很无聊的题目了，就求交点判情况有点麻烦..  \n用向量判交点然后手撕一下\n```c++\nstruct Cvector{\n    double x,y;\n    Cvector(){}\n    Cvector(double xx,double yy):x(xx),y(yy){}\n}node[4];\n\nstruct Cline{\n    Cvector a,b;\n};\n\nCvector operator-(const Cvector &a,const Cvector &b){return Cvector(a.x-b.x,a.y-b.y);}\nCvector operator*(double k, const Cvector &a)       {return Cvector(k*a.x,k*a.y);}\nCvector operator+(const Cvector &a,const Cvector &b){return Cvector(a.x+b.x,a.y+b.y);}\ndouble operator*(const Cvector &a,const Cvector &b) {return a.x*b.x+a.y*b.y;}\ndouble operator^(const Cvector &a,const Cvector &b) {return a.x*b.y-a.y*b.x;}\ndouble area(Cvector a,Cvector b){\n    return (a^b)/2;\n}\n\nCvector intersect(Cline l,Cline m,int &msg){\n    double x = area(m.a-l.a, l.b-l.a);\n    double y = area(l.b-l.a, m.b-l.a);\n    if(x+y==0){\n        msg = 1;//平行或者重合\n        return Cvector(NaN,NaN);\n    }\n    return m.a+((x/(x+y))*(m.b-m.a));\n}\n\nCline l[4];\ndouble caly(Cline cl,double X)\n{\n    Cvector cross[4];\n    Cvector point[2];\n    int pcnt = 0,msg;\n    for(int i=0; i<4; i++)\n        cross[i] = intersect(cl,l[i],msg);\n    for(int i=0; i<4; i++){\n        if(cross[i].x >= l[i].a.x && cross[i].x <= l[i].b.x)\n            point[pcnt++] = cross[i];\n        else if(cross[i].x <= l[i].a.x && cross[i].x >= l[i].b.x)\n            point[pcnt++] = cross[i];\n    }\n    int nodecnt = 0;\n    double ans = 0;\n    for(int i=0; i<4; i++)\n        if(node[i].x<X)\n            nodecnt++;\n    if(nodecnt==3){\n        for(int i=0; i<4; i++)\n            if(node[i].x>=X)\n                ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n        ans = 5.0*5.0-ans;\n    }\n    else for(int i=0; i<4; i++){\n        if(node[i].x<X)\n            ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n    }\n    cout<<ans<<endl;\n    return ans;\n}\n\ndouble calx(Cline cl,double Y)\n{\n    Cvector cross[4];\n    Cvector point[2];\n    int pcnt = 0,msg;\n    for(int i=0; i<4; i++)\n        cross[i] = intersect(cl,l[i],msg);\n    for(int i=0; i<4; i++){\n        if(cross[i].x >= l[i].a.x && cross[i].x <= l[i].b.x)\n            point[pcnt++] = cross[i];\n        else if(cross[i].x <= l[i].a.x && cross[i].x >= l[i].b.x)\n            point[pcnt++] = cross[i];\n    }\n    double ans = 0;\n    int nodecnt = 0;\n    for(int i=0; i<4; i++)\n        if(node[i].y<Y)\n            nodecnt++;\n    if(nodecnt==3){\n        for(int i=0; i<4; i++)\n            if(node[i].y>=Y)\n                ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n        ans = 5.0*5.0-ans;\n    }\n    else for(int i=0; i<4; i++){\n        if(node[i].y<Y)\n            ans += abs((point[1]-node[i])^(point[0]-node[i]))/2;\n    }\n    cout<<ans<<endl;\n    return ans;\n}\n\n\nint main()\n{\n    for(int i=0; i<4; i++){\n        double x,y;\n        scanf(\"%lf%lf\",&x,&y);\n        node[i].x =x;   node[i].y  = y;\n    }\n    for(int i=0; i<3; i++){\n        l[i].a = node[i];   l[i].b = node[i+1];\n    }\n    l[3].a = node[3];   l[3].b = node[0];\n\n    double ans = 0;\n    Cline cl;\n    cl.a = Cvector(0.5,0.5);    cl.b = Cvector(0.5,-0.5);\n    ans += 3.0*(25.0-caly(cl,0.5));\n    cl.a = Cvector(0.5,-0.5);    cl.b = Cvector(-0.5,-0.5);\n    ans += 1.0*(calx(cl,-0.5));\n    cl.a = Cvector(-0.5,-0.5);    cl.b = Cvector(-0.5,0.5);\n    ans += 4.0*caly(cl,-0.5);\n    cl.a = Cvector(-0.5,0.5);    cl.b = Cvector(0.5,0.5);\n    ans += 6.0*(25.0-calx(cl,0.5));\n    ans *= 5;\n    ans += 5.0*5.0*5.0*4;\n    ans /= (5.0*5.0*5.0-1.0);\n    printf(\"%.6f\\n\",ans);\n}\n\n```\n","slug":"简单的几何学","published":1,"updated":"2017-09-02T03:28:52.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55y5000oacwo4lv4yerh","content":"<p>题源：Central Europe Contest 2015 Zagreb H<br>其实是道很无聊的题目了，就求交点判情况有点麻烦..<br>用向量判交点然后手撕一下<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">struct</span> Cvector&#123;</div><div class=\"line\">    <span class=\"keyword\">double</span> x,y;</div><div class=\"line\">    Cvector()&#123;&#125;</div><div class=\"line\">    Cvector(<span class=\"keyword\">double</span> xx,<span class=\"keyword\">double</span> yy):x(xx),y(yy)&#123;&#125;</div><div class=\"line\">&#125;node[<span class=\"number\">4</span>];</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> Cline&#123;</div><div class=\"line\">    Cvector a,b;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">Cvector <span class=\"keyword\">operator</span>-(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b)&#123;<span class=\"keyword\">return</span> Cvector(a.x-b.x,a.y-b.y);&#125;</div><div class=\"line\">Cvector <span class=\"keyword\">operator</span>*(<span class=\"keyword\">double</span> k, <span class=\"keyword\">const</span> Cvector &amp;a)       &#123;<span class=\"keyword\">return</span> Cvector(k*a.x,k*a.y);&#125;</div><div class=\"line\">Cvector <span class=\"keyword\">operator</span>+(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b)&#123;<span class=\"keyword\">return</span> Cvector(a.x+b.x,a.y+b.y);&#125;</div><div class=\"line\"><span class=\"keyword\">double</span> <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b) &#123;<span class=\"keyword\">return</span> a.x*b.x+a.y*b.y;&#125;</div><div class=\"line\"><span class=\"keyword\">double</span> <span class=\"keyword\">operator</span>^(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b) &#123;<span class=\"keyword\">return</span> a.x*b.y-a.y*b.x;&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">area</span><span class=\"params\">(Cvector a,Cvector b)</span></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">return</span> (a^b)/<span class=\"number\">2</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\">Cvector <span class=\"title\">intersect</span><span class=\"params\">(Cline l,Cline m,<span class=\"keyword\">int</span> &amp;msg)</span></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">double</span> x = area(m.a-l.a, l.b-l.a);</div><div class=\"line\">    <span class=\"keyword\">double</span> y = area(l.b-l.a, m.b-l.a);</div><div class=\"line\">    <span class=\"keyword\">if</span>(x+y==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">        msg = <span class=\"number\">1</span>;<span class=\"comment\">//平行或者重合</span></div><div class=\"line\">        <span class=\"keyword\">return</span> Cvector(NaN,NaN);</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> m.a+((x/(x+y))*(m.b-m.a));</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">Cline l[<span class=\"number\">4</span>];</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">caly</span><span class=\"params\">(Cline cl,<span class=\"keyword\">double</span> X)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    Cvector cross[<span class=\"number\">4</span>];</div><div class=\"line\">    Cvector point[<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"keyword\">int</span> pcnt = <span class=\"number\">0</span>,msg;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        cross[i] = intersect(cl,l[i],msg);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(cross[i].x &gt;= l[i].a.x &amp;&amp; cross[i].x &lt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(cross[i].x &lt;= l[i].a.x &amp;&amp; cross[i].x &gt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">int</span> nodecnt = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">double</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].x&lt;X)</div><div class=\"line\">            nodecnt++;</div><div class=\"line\">    <span class=\"keyword\">if</span>(nodecnt==<span class=\"number\">3</span>)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">            <span class=\"keyword\">if</span>(node[i].x&gt;=X)</div><div class=\"line\">                ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">        ans = <span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>-ans;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].x&lt;X)</div><div class=\"line\">            ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"built_in\">cout</span>&lt;&lt;ans&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">calx</span><span class=\"params\">(Cline cl,<span class=\"keyword\">double</span> Y)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    Cvector cross[<span class=\"number\">4</span>];</div><div class=\"line\">    Cvector point[<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"keyword\">int</span> pcnt = <span class=\"number\">0</span>,msg;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        cross[i] = intersect(cl,l[i],msg);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(cross[i].x &gt;= l[i].a.x &amp;&amp; cross[i].x &lt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(cross[i].x &lt;= l[i].a.x &amp;&amp; cross[i].x &gt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">double</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> nodecnt = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].y&lt;Y)</div><div class=\"line\">            nodecnt++;</div><div class=\"line\">    <span class=\"keyword\">if</span>(nodecnt==<span class=\"number\">3</span>)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">            <span class=\"keyword\">if</span>(node[i].y&gt;=Y)</div><div class=\"line\">                ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">        ans = <span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>-ans;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].y&lt;Y)</div><div class=\"line\">            ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"built_in\">cout</span>&lt;&lt;ans&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">double</span> x,y;</div><div class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lf%lf\"</span>,&amp;x,&amp;y);</div><div class=\"line\">        node[i].x =x;   node[i].y  = y;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">3</span>; i++)&#123;</div><div class=\"line\">        l[i].a = node[i];   l[i].b = node[i+<span class=\"number\">1</span>];</div><div class=\"line\">    &#125;</div><div class=\"line\">    l[<span class=\"number\">3</span>].a = node[<span class=\"number\">3</span>];   l[<span class=\"number\">3</span>].b = node[<span class=\"number\">0</span>];</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">double</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">    Cline cl;</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>);    cl.b = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">-0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">3.0</span>*(<span class=\"number\">25.0</span>-caly(cl,<span class=\"number\">0.5</span>));</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">-0.5</span>);    cl.b = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">-0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">1.0</span>*(calx(cl,<span class=\"number\">-0.5</span>));</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">-0.5</span>);    cl.b = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">4.0</span>*caly(cl,<span class=\"number\">-0.5</span>);</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">0.5</span>);    cl.b = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">6.0</span>*(<span class=\"number\">25.0</span>-calx(cl,<span class=\"number\">0.5</span>));</div><div class=\"line\">    ans *= <span class=\"number\">5</span>;</div><div class=\"line\">    ans += <span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>*<span class=\"number\">4</span>;</div><div class=\"line\">    ans /= (<span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>*<span class=\"number\">5.0</span><span class=\"number\">-1.0</span>);</div><div class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%.6f\\n\"</span>,ans);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","excerpt":"","more":"<p>题源：Central Europe Contest 2015 Zagreb H<br>其实是道很无聊的题目了，就求交点判情况有点麻烦..<br>用向量判交点然后手撕一下<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">struct</span> Cvector&#123;</div><div class=\"line\">    <span class=\"keyword\">double</span> x,y;</div><div class=\"line\">    Cvector()&#123;&#125;</div><div class=\"line\">    Cvector(<span class=\"keyword\">double</span> xx,<span class=\"keyword\">double</span> yy):x(xx),y(yy)&#123;&#125;</div><div class=\"line\">&#125;node[<span class=\"number\">4</span>];</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> Cline&#123;</div><div class=\"line\">    Cvector a,b;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">Cvector <span class=\"keyword\">operator</span>-(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b)&#123;<span class=\"keyword\">return</span> Cvector(a.x-b.x,a.y-b.y);&#125;</div><div class=\"line\">Cvector <span class=\"keyword\">operator</span>*(<span class=\"keyword\">double</span> k, <span class=\"keyword\">const</span> Cvector &amp;a)       &#123;<span class=\"keyword\">return</span> Cvector(k*a.x,k*a.y);&#125;</div><div class=\"line\">Cvector <span class=\"keyword\">operator</span>+(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b)&#123;<span class=\"keyword\">return</span> Cvector(a.x+b.x,a.y+b.y);&#125;</div><div class=\"line\"><span class=\"keyword\">double</span> <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b) &#123;<span class=\"keyword\">return</span> a.x*b.x+a.y*b.y;&#125;</div><div class=\"line\"><span class=\"keyword\">double</span> <span class=\"keyword\">operator</span>^(<span class=\"keyword\">const</span> Cvector &amp;a,<span class=\"keyword\">const</span> Cvector &amp;b) &#123;<span class=\"keyword\">return</span> a.x*b.y-a.y*b.x;&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">area</span><span class=\"params\">(Cvector a,Cvector b)</span></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">return</span> (a^b)/<span class=\"number\">2</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\">Cvector <span class=\"title\">intersect</span><span class=\"params\">(Cline l,Cline m,<span class=\"keyword\">int</span> &amp;msg)</span></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">double</span> x = area(m.a-l.a, l.b-l.a);</div><div class=\"line\">    <span class=\"keyword\">double</span> y = area(l.b-l.a, m.b-l.a);</div><div class=\"line\">    <span class=\"keyword\">if</span>(x+y==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">        msg = <span class=\"number\">1</span>;<span class=\"comment\">//平行或者重合</span></div><div class=\"line\">        <span class=\"keyword\">return</span> Cvector(NaN,NaN);</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> m.a+((x/(x+y))*(m.b-m.a));</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">Cline l[<span class=\"number\">4</span>];</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">caly</span><span class=\"params\">(Cline cl,<span class=\"keyword\">double</span> X)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    Cvector cross[<span class=\"number\">4</span>];</div><div class=\"line\">    Cvector point[<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"keyword\">int</span> pcnt = <span class=\"number\">0</span>,msg;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        cross[i] = intersect(cl,l[i],msg);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(cross[i].x &gt;= l[i].a.x &amp;&amp; cross[i].x &lt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(cross[i].x &lt;= l[i].a.x &amp;&amp; cross[i].x &gt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">int</span> nodecnt = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">double</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].x&lt;X)</div><div class=\"line\">            nodecnt++;</div><div class=\"line\">    <span class=\"keyword\">if</span>(nodecnt==<span class=\"number\">3</span>)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">            <span class=\"keyword\">if</span>(node[i].x&gt;=X)</div><div class=\"line\">                ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">        ans = <span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>-ans;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].x&lt;X)</div><div class=\"line\">            ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"built_in\">cout</span>&lt;&lt;ans&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">calx</span><span class=\"params\">(Cline cl,<span class=\"keyword\">double</span> Y)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    Cvector cross[<span class=\"number\">4</span>];</div><div class=\"line\">    Cvector point[<span class=\"number\">2</span>];</div><div class=\"line\">    <span class=\"keyword\">int</span> pcnt = <span class=\"number\">0</span>,msg;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        cross[i] = intersect(cl,l[i],msg);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(cross[i].x &gt;= l[i].a.x &amp;&amp; cross[i].x &lt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(cross[i].x &lt;= l[i].a.x &amp;&amp; cross[i].x &gt;= l[i].b.x)</div><div class=\"line\">            point[pcnt++] = cross[i];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">double</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> nodecnt = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].y&lt;Y)</div><div class=\"line\">            nodecnt++;</div><div class=\"line\">    <span class=\"keyword\">if</span>(nodecnt==<span class=\"number\">3</span>)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)</div><div class=\"line\">            <span class=\"keyword\">if</span>(node[i].y&gt;=Y)</div><div class=\"line\">                ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">        ans = <span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>-ans;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(node[i].y&lt;Y)</div><div class=\"line\">            ans += <span class=\"built_in\">abs</span>((point[<span class=\"number\">1</span>]-node[i])^(point[<span class=\"number\">0</span>]-node[i]))/<span class=\"number\">2</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"built_in\">cout</span>&lt;&lt;ans&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">4</span>; i++)&#123;</div><div class=\"line\">        <span class=\"keyword\">double</span> x,y;</div><div class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lf%lf\"</span>,&amp;x,&amp;y);</div><div class=\"line\">        node[i].x =x;   node[i].y  = y;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;<span class=\"number\">3</span>; i++)&#123;</div><div class=\"line\">        l[i].a = node[i];   l[i].b = node[i+<span class=\"number\">1</span>];</div><div class=\"line\">    &#125;</div><div class=\"line\">    l[<span class=\"number\">3</span>].a = node[<span class=\"number\">3</span>];   l[<span class=\"number\">3</span>].b = node[<span class=\"number\">0</span>];</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">double</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">    Cline cl;</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>);    cl.b = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">-0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">3.0</span>*(<span class=\"number\">25.0</span>-caly(cl,<span class=\"number\">0.5</span>));</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">-0.5</span>);    cl.b = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">-0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">1.0</span>*(calx(cl,<span class=\"number\">-0.5</span>));</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">-0.5</span>);    cl.b = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">4.0</span>*caly(cl,<span class=\"number\">-0.5</span>);</div><div class=\"line\">    cl.a = Cvector(<span class=\"number\">-0.5</span>,<span class=\"number\">0.5</span>);    cl.b = Cvector(<span class=\"number\">0.5</span>,<span class=\"number\">0.5</span>);</div><div class=\"line\">    ans += <span class=\"number\">6.0</span>*(<span class=\"number\">25.0</span>-calx(cl,<span class=\"number\">0.5</span>));</div><div class=\"line\">    ans *= <span class=\"number\">5</span>;</div><div class=\"line\">    ans += <span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>*<span class=\"number\">4</span>;</div><div class=\"line\">    ans /= (<span class=\"number\">5.0</span>*<span class=\"number\">5.0</span>*<span class=\"number\">5.0</span><span class=\"number\">-1.0</span>);</div><div class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%.6f\\n\"</span>,ans);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n"},{"title":"高斯消元求解带模方程组","date":"2017-09-20T18:26:04.000Z","_content":"\nHDU-5755  \n一类开关问题  \n做法是设第一行各个位置操作为x1~xn次那么就可以最后一直推下去  \n推出第n+1行所需要的操作个数一定都为0,这样就得到了一个n个变量的方程组  \n用高斯消元求出解都推出来就行\n\n\n```c++\nconst int MOD = 3;\nconst int INF = 0x3f3f3f3f;\nint a[MAXN][MAXN];\nint x[MAXN];\n\ninline int gcd(int a,int b)\n{\n\tint t;\n\twhile(b != 0){\n\t\tt = b;\n\t\tb = a%b;\n\t\ta = t;\n\t}\n\treturn a;\n}\n\ninline void exgcd(int a,int b,int &x,int &y,int &d)\n{\n\tif(b==0){\n\t\tx = 1; y=0; d = a;\treturn;\n\t}\n\texgcd(b,a%b,x,y,d);\n\tint t = x;\n\tx = y;\n\ty = t - (a/b)*y;\n\treturn;\n}\n\nint lcm(int a,int b){\n\treturn a*b/gcd(a,b);\n}\n\nint inv(int a,int mod)\n{\n\tint x,y,d;\n\texgcd(a,mod,x,y,d);\n\treturn (x+mod)%mod;\n}\n\nint gauss(int rows,int var)\n{\n\tint col,k,max_r;\n\tfor(col=0,k=0; col<var && k<rows; col++,k++){\n\t\tmax_r = k;\n\t\tfor(int i=k+1; i<rows; i++)\n\t\t\tif(abs(a[i][col])>abs(a[k][col]))\n\t\t\t\tmax_r = i;\n\t\tif(a[max_r][col]==0){\n\t\t\tk--; continue;\t//Jump to next variable\n\t\t}\n\t\tif(max_r!=k)\n\t\t\tfor(int i=0; i<var+1; i++)\n\t\t\t\tswap(a[k][i],a[max_r][i]);\n\t\tfor(int i=k+1; i<rows; i++){\n\t\t\tif(a[i][col]!=0){\n\t\t\t\tint LCM = lcm(a[k][col],a[i][col]);\n\t\t\t\tint tk = LCM/a[k][col];\n\t\t\t\tint ti = LCM/a[i][col];\n\t\t\t\tfor(int j=col; j<var+1; j++)\n\t\t\t\t\ta[i][j] = ((a[i][j]*ti - a[k][j]*tk)%MOD+MOD)%MOD;\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i=k; i<rows; i++)\n\t\tif(a[i][col]!=0)\n\t\t\treturn -1;\t\t\t\t//\n\tif(rows<var) return rows-var;\t//\n\n\tfor(int i=var-1; i>=0; i--){\n\t\tint temp = a[i][var];\n\t\tfor(int j=i+1; j<var; j++)\n\t\t{\n\t\t\tif(a[i][j]!=0){\n\t\t\t\ttemp -= a[i][j]*x[j];\n\t\t\t\ttemp = (temp%MOD+MOD)%MOD;\n\t\t\t}\n\t\t}\n\t\tx[i] = (temp*inv(a[i][i],MOD))%MOD;\n\t}\n\treturn 0;\n}\n\nint T,N,M;\nint m[50][50];\nint f[50][50][50];\nint p[50][50];\n\nint get(int i,int j,int k)\n{\n    int ans = (f[i][j-1][k]+2*f[i][j][k]+f[i][j+1][k]+f[i-1][j][k])%MOD;\n    return ((3-ans)%MOD+MOD)%MOD;\n}\n\nint getans(int i,int j)\n{\n    int ans = (p[i][j-1]+2*p[i][j]+p[i][j+1]+p[i-1][j]+m[i][j])%MOD;\n    return ((3-ans)%MOD+MOD)%MOD;\n}\n\nint main()\n{\n\tsc(T);\n\twhile(T--){\n\t\tsc(N);\tsc(M);\n\t\tfor(int i=1; i<=N; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n\t\t\t\tsc(m[i][j]);\n\t\tmemset(a,0,sizeof(a));\n        memset(f,0,sizeof(f));\n        memset(p,0,sizeof(p));\n\t\tfor(int i=1; i<=M; i++)\n\t\t\tf[0][i][i] = 1;\n\t\tint cur = 0;\n        for(int i=1; i<=N; i++){\n            for(int j=1; j<=M; j++){\n                for(int k=1; k<=M; k++)\n                    f[i][j][k] = get(i-1,j,k);\n                f[i][j][M+1] = (3 - m[i][j] + get(i-1,j,M+1))%MOD;\n            }\n        }\n\t\tfor(int i=0; i<M; i++){\n            for(int j=0; j<M; j++)\n                a[i][j] = f[N][i+1][j+1];\n            a[i][M] = (3-f[N][i+1][M+1])%MOD;\n\t\t}\n        gauss(M,M);\n        int ans = 0;\n        for(int i=1; i<=M; i++)\n            p[1][i] = x[i-1],ans += p[1][i];\n        for(int i=2; i<=N; i++)\n            for(int j=1; j<=M; j++)\n                p[i][j] = getans(i-1,j),ans += p[i][j];\n        printf(\"%d\\n\",ans);\n        for(int i=1; i<=N; i++)\n            for(int j=1; j<=M; j++)\n                for(int k=0; k<p[i][j]; k++)\n                    printf(\"%d %d\\n\",i,j);\n\t}\n}\n```\n","source":"_posts/高斯消元求解带模方程组.md","raw":"---\ntitle: 高斯消元求解带模方程组\ndate: 2017-09-21 02:26:04\ntags: [高斯消元]\ncategories: ACM\n---\n\nHDU-5755  \n一类开关问题  \n做法是设第一行各个位置操作为x1~xn次那么就可以最后一直推下去  \n推出第n+1行所需要的操作个数一定都为0,这样就得到了一个n个变量的方程组  \n用高斯消元求出解都推出来就行\n\n\n```c++\nconst int MOD = 3;\nconst int INF = 0x3f3f3f3f;\nint a[MAXN][MAXN];\nint x[MAXN];\n\ninline int gcd(int a,int b)\n{\n\tint t;\n\twhile(b != 0){\n\t\tt = b;\n\t\tb = a%b;\n\t\ta = t;\n\t}\n\treturn a;\n}\n\ninline void exgcd(int a,int b,int &x,int &y,int &d)\n{\n\tif(b==0){\n\t\tx = 1; y=0; d = a;\treturn;\n\t}\n\texgcd(b,a%b,x,y,d);\n\tint t = x;\n\tx = y;\n\ty = t - (a/b)*y;\n\treturn;\n}\n\nint lcm(int a,int b){\n\treturn a*b/gcd(a,b);\n}\n\nint inv(int a,int mod)\n{\n\tint x,y,d;\n\texgcd(a,mod,x,y,d);\n\treturn (x+mod)%mod;\n}\n\nint gauss(int rows,int var)\n{\n\tint col,k,max_r;\n\tfor(col=0,k=0; col<var && k<rows; col++,k++){\n\t\tmax_r = k;\n\t\tfor(int i=k+1; i<rows; i++)\n\t\t\tif(abs(a[i][col])>abs(a[k][col]))\n\t\t\t\tmax_r = i;\n\t\tif(a[max_r][col]==0){\n\t\t\tk--; continue;\t//Jump to next variable\n\t\t}\n\t\tif(max_r!=k)\n\t\t\tfor(int i=0; i<var+1; i++)\n\t\t\t\tswap(a[k][i],a[max_r][i]);\n\t\tfor(int i=k+1; i<rows; i++){\n\t\t\tif(a[i][col]!=0){\n\t\t\t\tint LCM = lcm(a[k][col],a[i][col]);\n\t\t\t\tint tk = LCM/a[k][col];\n\t\t\t\tint ti = LCM/a[i][col];\n\t\t\t\tfor(int j=col; j<var+1; j++)\n\t\t\t\t\ta[i][j] = ((a[i][j]*ti - a[k][j]*tk)%MOD+MOD)%MOD;\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i=k; i<rows; i++)\n\t\tif(a[i][col]!=0)\n\t\t\treturn -1;\t\t\t\t//\n\tif(rows<var) return rows-var;\t//\n\n\tfor(int i=var-1; i>=0; i--){\n\t\tint temp = a[i][var];\n\t\tfor(int j=i+1; j<var; j++)\n\t\t{\n\t\t\tif(a[i][j]!=0){\n\t\t\t\ttemp -= a[i][j]*x[j];\n\t\t\t\ttemp = (temp%MOD+MOD)%MOD;\n\t\t\t}\n\t\t}\n\t\tx[i] = (temp*inv(a[i][i],MOD))%MOD;\n\t}\n\treturn 0;\n}\n\nint T,N,M;\nint m[50][50];\nint f[50][50][50];\nint p[50][50];\n\nint get(int i,int j,int k)\n{\n    int ans = (f[i][j-1][k]+2*f[i][j][k]+f[i][j+1][k]+f[i-1][j][k])%MOD;\n    return ((3-ans)%MOD+MOD)%MOD;\n}\n\nint getans(int i,int j)\n{\n    int ans = (p[i][j-1]+2*p[i][j]+p[i][j+1]+p[i-1][j]+m[i][j])%MOD;\n    return ((3-ans)%MOD+MOD)%MOD;\n}\n\nint main()\n{\n\tsc(T);\n\twhile(T--){\n\t\tsc(N);\tsc(M);\n\t\tfor(int i=1; i<=N; i++)\n\t\t\tfor(int j=1; j<=M; j++)\n\t\t\t\tsc(m[i][j]);\n\t\tmemset(a,0,sizeof(a));\n        memset(f,0,sizeof(f));\n        memset(p,0,sizeof(p));\n\t\tfor(int i=1; i<=M; i++)\n\t\t\tf[0][i][i] = 1;\n\t\tint cur = 0;\n        for(int i=1; i<=N; i++){\n            for(int j=1; j<=M; j++){\n                for(int k=1; k<=M; k++)\n                    f[i][j][k] = get(i-1,j,k);\n                f[i][j][M+1] = (3 - m[i][j] + get(i-1,j,M+1))%MOD;\n            }\n        }\n\t\tfor(int i=0; i<M; i++){\n            for(int j=0; j<M; j++)\n                a[i][j] = f[N][i+1][j+1];\n            a[i][M] = (3-f[N][i+1][M+1])%MOD;\n\t\t}\n        gauss(M,M);\n        int ans = 0;\n        for(int i=1; i<=M; i++)\n            p[1][i] = x[i-1],ans += p[1][i];\n        for(int i=2; i<=N; i++)\n            for(int j=1; j<=M; j++)\n                p[i][j] = getans(i-1,j),ans += p[i][j];\n        printf(\"%d\\n\",ans);\n        for(int i=1; i<=N; i++)\n            for(int j=1; j<=M; j++)\n                for(int k=0; k<p[i][j]; k++)\n                    printf(\"%d %d\\n\",i,j);\n\t}\n}\n```\n","slug":"高斯消元求解带模方程组","published":1,"updated":"2018-03-29T15:02:32.592Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v55yk000qacworptfc5f2","content":"<p>HDU-5755<br>一类开关问题<br>做法是设第一行各个位置操作为x1~xn次那么就可以最后一直推下去<br>推出第n+1行所需要的操作个数一定都为0,这样就得到了一个n个变量的方程组<br>用高斯消元求出解都推出来就行</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> MOD = <span class=\"number\">3</span>;</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> INF = <span class=\"number\">0x3f3f3f3f</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> a[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> x[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> <span class=\"keyword\">int</span> <span class=\"title\">gcd</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> t;</div><div class=\"line\">\t<span class=\"keyword\">while</span>(b != <span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tt = b;</div><div class=\"line\">\t\tb = a%b;</div><div class=\"line\">\t\ta = t;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> a;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> <span class=\"title\">exgcd</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b,<span class=\"keyword\">int</span> &amp;x,<span class=\"keyword\">int</span> &amp;y,<span class=\"keyword\">int</span> &amp;d)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">if</span>(b==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tx = <span class=\"number\">1</span>; y=<span class=\"number\">0</span>; d = a;\t<span class=\"keyword\">return</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\texgcd(b,a%b,x,y,d);</div><div class=\"line\">\t<span class=\"keyword\">int</span> t = x;</div><div class=\"line\">\tx = y;</div><div class=\"line\">\ty = t - (a/b)*y;</div><div class=\"line\">\t<span class=\"keyword\">return</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">lcm</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">return</span> a*b/gcd(a,b);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">inv</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> mod)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> x,y,d;</div><div class=\"line\">\texgcd(a,mod,x,y,d);</div><div class=\"line\">\t<span class=\"keyword\">return</span> (x+mod)%mod;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">gauss</span><span class=\"params\">(<span class=\"keyword\">int</span> rows,<span class=\"keyword\">int</span> var)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> col,k,max_r;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(col=<span class=\"number\">0</span>,k=<span class=\"number\">0</span>; col&lt;var &amp;&amp; k&lt;rows; col++,k++)&#123;</div><div class=\"line\">\t\tmax_r = k;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=k+<span class=\"number\">1</span>; i&lt;rows; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(<span class=\"built_in\">abs</span>(a[i][col])&gt;<span class=\"built_in\">abs</span>(a[k][col]))</div><div class=\"line\">\t\t\t\tmax_r = i;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(a[max_r][col]==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\tk--; <span class=\"keyword\">continue</span>;\t<span class=\"comment\">//Jump to next variable</span></div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(max_r!=k)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;var+<span class=\"number\">1</span>; i++)</div><div class=\"line\">\t\t\t\tswap(a[k][i],a[max_r][i]);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=k+<span class=\"number\">1</span>; i&lt;rows; i++)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[i][col]!=<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">int</span> LCM = lcm(a[k][col],a[i][col]);</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">int</span> tk = LCM/a[k][col];</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">int</span> ti = LCM/a[i][col];</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=col; j&lt;var+<span class=\"number\">1</span>; j++)</div><div class=\"line\">\t\t\t\t\ta[i][j] = ((a[i][j]*ti - a[k][j]*tk)%MOD+MOD)%MOD;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=k; i&lt;rows; i++)</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(a[i][col]!=<span class=\"number\">0</span>)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"number\">-1</span>;\t\t\t\t<span class=\"comment\">//</span></div><div class=\"line\">\t<span class=\"keyword\">if</span>(rows&lt;var) <span class=\"keyword\">return</span> rows-var;\t<span class=\"comment\">//</span></div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=var<span class=\"number\">-1</span>; i&gt;=<span class=\"number\">0</span>; i--)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> temp = a[i][var];</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=i+<span class=\"number\">1</span>; j&lt;var; j++)</div><div class=\"line\">\t\t&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[i][j]!=<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\ttemp -= a[i][j]*x[j];</div><div class=\"line\">\t\t\t\ttemp = (temp%MOD+MOD)%MOD;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\tx[i] = (temp*inv(a[i][i],MOD))%MOD;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> T,N,M;</div><div class=\"line\"><span class=\"keyword\">int</span> m[<span class=\"number\">50</span>][<span class=\"number\">50</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> f[<span class=\"number\">50</span>][<span class=\"number\">50</span>][<span class=\"number\">50</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> p[<span class=\"number\">50</span>][<span class=\"number\">50</span>];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j,<span class=\"keyword\">int</span> k)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = (f[i][j<span class=\"number\">-1</span>][k]+<span class=\"number\">2</span>*f[i][j][k]+f[i][j+<span class=\"number\">1</span>][k]+f[i<span class=\"number\">-1</span>][j][k])%MOD;</div><div class=\"line\">    <span class=\"keyword\">return</span> ((<span class=\"number\">3</span>-ans)%MOD+MOD)%MOD;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getans</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = (p[i][j<span class=\"number\">-1</span>]+<span class=\"number\">2</span>*p[i][j]+p[i][j+<span class=\"number\">1</span>]+p[i<span class=\"number\">-1</span>][j]+m[i][j])%MOD;</div><div class=\"line\">    <span class=\"keyword\">return</span> ((<span class=\"number\">3</span>-ans)%MOD+MOD)%MOD;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\tsc(T);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(T--)&#123;</div><div class=\"line\">\t\tsc(N);\tsc(M);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">\t\t\t\tsc(m[i][j]);</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(a,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(a));</div><div class=\"line\">        <span class=\"built_in\">memset</span>(f,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(f));</div><div class=\"line\">        <span class=\"built_in\">memset</span>(p,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(p));</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=M; i++)</div><div class=\"line\">\t\t\tf[<span class=\"number\">0</span>][i][i] = <span class=\"number\">1</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> cur = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)&#123;</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">1</span>; k&lt;=M; k++)</div><div class=\"line\">                    f[i][j][k] = get(i<span class=\"number\">-1</span>,j,k);</div><div class=\"line\">                f[i][j][M+<span class=\"number\">1</span>] = (<span class=\"number\">3</span> - m[i][j] + get(i<span class=\"number\">-1</span>,j,M+<span class=\"number\">1</span>))%MOD;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;M; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; j&lt;M; j++)</div><div class=\"line\">                a[i][j] = f[N][i+<span class=\"number\">1</span>][j+<span class=\"number\">1</span>];</div><div class=\"line\">            a[i][M] = (<span class=\"number\">3</span>-f[N][i+<span class=\"number\">1</span>][M+<span class=\"number\">1</span>])%MOD;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">        gauss(M,M);</div><div class=\"line\">        <span class=\"keyword\">int</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=M; i++)</div><div class=\"line\">            p[<span class=\"number\">1</span>][i] = x[i<span class=\"number\">-1</span>],ans += p[<span class=\"number\">1</span>][i];</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=N; i++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">                p[i][j] = getans(i<span class=\"number\">-1</span>,j),ans += p[i][j];</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>,ans);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">0</span>; k&lt;p[i][j]; k++)</div><div class=\"line\">                    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d %d\\n\"</span>,i,j);</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>HDU-5755<br>一类开关问题<br>做法是设第一行各个位置操作为x1~xn次那么就可以最后一直推下去<br>推出第n+1行所需要的操作个数一定都为0,这样就得到了一个n个变量的方程组<br>用高斯消元求出解都推出来就行</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> MOD = <span class=\"number\">3</span>;</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> INF = <span class=\"number\">0x3f3f3f3f</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> a[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> x[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> <span class=\"keyword\">int</span> <span class=\"title\">gcd</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> t;</div><div class=\"line\">\t<span class=\"keyword\">while</span>(b != <span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tt = b;</div><div class=\"line\">\t\tb = a%b;</div><div class=\"line\">\t\ta = t;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> a;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> <span class=\"title\">exgcd</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b,<span class=\"keyword\">int</span> &amp;x,<span class=\"keyword\">int</span> &amp;y,<span class=\"keyword\">int</span> &amp;d)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">if</span>(b==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tx = <span class=\"number\">1</span>; y=<span class=\"number\">0</span>; d = a;\t<span class=\"keyword\">return</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\texgcd(b,a%b,x,y,d);</div><div class=\"line\">\t<span class=\"keyword\">int</span> t = x;</div><div class=\"line\">\tx = y;</div><div class=\"line\">\ty = t - (a/b)*y;</div><div class=\"line\">\t<span class=\"keyword\">return</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">lcm</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">return</span> a*b/gcd(a,b);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">inv</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> mod)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> x,y,d;</div><div class=\"line\">\texgcd(a,mod,x,y,d);</div><div class=\"line\">\t<span class=\"keyword\">return</span> (x+mod)%mod;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">gauss</span><span class=\"params\">(<span class=\"keyword\">int</span> rows,<span class=\"keyword\">int</span> var)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> col,k,max_r;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(col=<span class=\"number\">0</span>,k=<span class=\"number\">0</span>; col&lt;var &amp;&amp; k&lt;rows; col++,k++)&#123;</div><div class=\"line\">\t\tmax_r = k;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=k+<span class=\"number\">1</span>; i&lt;rows; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(<span class=\"built_in\">abs</span>(a[i][col])&gt;<span class=\"built_in\">abs</span>(a[k][col]))</div><div class=\"line\">\t\t\t\tmax_r = i;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(a[max_r][col]==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\tk--; <span class=\"keyword\">continue</span>;\t<span class=\"comment\">//Jump to next variable</span></div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(max_r!=k)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;var+<span class=\"number\">1</span>; i++)</div><div class=\"line\">\t\t\t\tswap(a[k][i],a[max_r][i]);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=k+<span class=\"number\">1</span>; i&lt;rows; i++)&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[i][col]!=<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">int</span> LCM = lcm(a[k][col],a[i][col]);</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">int</span> tk = LCM/a[k][col];</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">int</span> ti = LCM/a[i][col];</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=col; j&lt;var+<span class=\"number\">1</span>; j++)</div><div class=\"line\">\t\t\t\t\ta[i][j] = ((a[i][j]*ti - a[k][j]*tk)%MOD+MOD)%MOD;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=k; i&lt;rows; i++)</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(a[i][col]!=<span class=\"number\">0</span>)</div><div class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"number\">-1</span>;\t\t\t\t<span class=\"comment\">//</span></div><div class=\"line\">\t<span class=\"keyword\">if</span>(rows&lt;var) <span class=\"keyword\">return</span> rows-var;\t<span class=\"comment\">//</span></div><div class=\"line\"></div><div class=\"line\">\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=var<span class=\"number\">-1</span>; i&gt;=<span class=\"number\">0</span>; i--)&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> temp = a[i][var];</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=i+<span class=\"number\">1</span>; j&lt;var; j++)</div><div class=\"line\">\t\t&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[i][j]!=<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\t\t\ttemp -= a[i][j]*x[j];</div><div class=\"line\">\t\t\t\ttemp = (temp%MOD+MOD)%MOD;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\tx[i] = (temp*inv(a[i][i],MOD))%MOD;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> T,N,M;</div><div class=\"line\"><span class=\"keyword\">int</span> m[<span class=\"number\">50</span>][<span class=\"number\">50</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> f[<span class=\"number\">50</span>][<span class=\"number\">50</span>][<span class=\"number\">50</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> p[<span class=\"number\">50</span>][<span class=\"number\">50</span>];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j,<span class=\"keyword\">int</span> k)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = (f[i][j<span class=\"number\">-1</span>][k]+<span class=\"number\">2</span>*f[i][j][k]+f[i][j+<span class=\"number\">1</span>][k]+f[i<span class=\"number\">-1</span>][j][k])%MOD;</div><div class=\"line\">    <span class=\"keyword\">return</span> ((<span class=\"number\">3</span>-ans)%MOD+MOD)%MOD;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getans</span><span class=\"params\">(<span class=\"keyword\">int</span> i,<span class=\"keyword\">int</span> j)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = (p[i][j<span class=\"number\">-1</span>]+<span class=\"number\">2</span>*p[i][j]+p[i][j+<span class=\"number\">1</span>]+p[i<span class=\"number\">-1</span>][j]+m[i][j])%MOD;</div><div class=\"line\">    <span class=\"keyword\">return</span> ((<span class=\"number\">3</span>-ans)%MOD+MOD)%MOD;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\tsc(T);</div><div class=\"line\">\t<span class=\"keyword\">while</span>(T--)&#123;</div><div class=\"line\">\t\tsc(N);\tsc(M);</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)</div><div class=\"line\">\t\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">\t\t\t\tsc(m[i][j]);</div><div class=\"line\">\t\t<span class=\"built_in\">memset</span>(a,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(a));</div><div class=\"line\">        <span class=\"built_in\">memset</span>(f,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(f));</div><div class=\"line\">        <span class=\"built_in\">memset</span>(p,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(p));</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=M; i++)</div><div class=\"line\">\t\t\tf[<span class=\"number\">0</span>][i][i] = <span class=\"number\">1</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> cur = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)&#123;</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">1</span>; k&lt;=M; k++)</div><div class=\"line\">                    f[i][j][k] = get(i<span class=\"number\">-1</span>,j,k);</div><div class=\"line\">                f[i][j][M+<span class=\"number\">1</span>] = (<span class=\"number\">3</span> - m[i][j] + get(i<span class=\"number\">-1</span>,j,M+<span class=\"number\">1</span>))%MOD;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">\t\t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;M; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; j&lt;M; j++)</div><div class=\"line\">                a[i][j] = f[N][i+<span class=\"number\">1</span>][j+<span class=\"number\">1</span>];</div><div class=\"line\">            a[i][M] = (<span class=\"number\">3</span>-f[N][i+<span class=\"number\">1</span>][M+<span class=\"number\">1</span>])%MOD;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">        gauss(M,M);</div><div class=\"line\">        <span class=\"keyword\">int</span> ans = <span class=\"number\">0</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=M; i++)</div><div class=\"line\">            p[<span class=\"number\">1</span>][i] = x[i<span class=\"number\">-1</span>],ans += p[<span class=\"number\">1</span>][i];</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=N; i++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">                p[i][j] = getans(i<span class=\"number\">-1</span>,j),ans += p[i][j];</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>,ans);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=N; i++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>; j&lt;=M; j++)</div><div class=\"line\">                <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> k=<span class=\"number\">0</span>; k&lt;p[i][j]; k++)</div><div class=\"line\">                    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d %d\\n\"</span>,i,j);</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"图网络分析方法","date":"2017-03-09T13:54:00.000Z","_content":"\n## 前言\n不是什么事情都要给别人一个交代，但总是要给自己一个交代的，因此遍有了这一篇总结。   \n\n 这是一篇来自于课程设计的markdown，由于自己给自己开的坑，花费了大量时间。\n还有一个目的主要是记录下自己学到的知识，以方便以这段经历为跳板，在后面对数据挖掘领域进行更深层次的学习\n\n## 图网络分析方法的主要任务\n\n### 引出\n\n对于一般的图结构的数据来说，抛开节点和边所带的附加数据域来看，图的主要性质，就体现在节点 边的属性和图本身的拓扑结构上了  比如说节点的度 边的权 都是表征图结构基本而又重要的性质.   \n不过对于这些性质来说，还是从微观在描述图的最小成员：节点和边在图拓扑中的性质，因此要描述整个图结构的性质，就需要有另外一些衡量标准与方法  \n\n### 网络性质 NetworkOverview\n这里取图可视化软件**Gephi**的所选取的几个指标：  \n1. Network Diameter 网络直径 \n2. Graph Density 图紧密度\n3. Modularity 模块度\n4. Centrarity 中心度 \n5. Connected subgraph 联通子图 \n\n\n## 网络分析的主要算法\n\n 这里只列举几个我实际学习并实现的 \n\n### PageRank（Centrarity ）-2002\n PageRank 是很为我们熟知的google发家的算法，网络拓扑其实也就是一个很大型的图结构。关于PageRank 的介绍网上已经有较为详细的解读了，[这篇blog写得挺好](http://blog.jobbole.com/71431/)。\n\nPageRank 其实从算法原理上非常简单，就是一个矩阵的迭代，实际应用中真正的问题在于大型网络拓扑的分布式计算 因而有了PageRank的mapreduce实现\n\n\n### 顶点度（Centrarity ）\n ..大家什么都没看到\n\n### Gravian-Newman 社区发现算法（Modularity） -2004\n 社区发现的入门级算法...折腾了我好久  \n 这个我感觉网上现有的一些资料中并没有很好的..我会自己写一篇详细介绍的   \n 附上链接 **[Newman教授的个人主页](http://www-personal.umich.edu/~mejn/)**\n\n\n### FastUnfolding 算法 （Modularity）-2008\n 同样会另起一篇blog介绍这个..但感觉自己对这个算法理解的还不是那么透彻..特别是在模块度的计算上还有些问题..在这里mark住，以便以后继续学习\n\n\n","source":"_posts/algorithms/图网络分析方法.md","raw":"---\ntitle: 图网络分析方法  \ndate: 2017-03-09 21:54:00  \ncategories: 算法\ntags:  [数据挖掘,图] \n---\n\n## 前言\n不是什么事情都要给别人一个交代，但总是要给自己一个交代的，因此遍有了这一篇总结。   \n\n 这是一篇来自于课程设计的markdown，由于自己给自己开的坑，花费了大量时间。\n还有一个目的主要是记录下自己学到的知识，以方便以这段经历为跳板，在后面对数据挖掘领域进行更深层次的学习\n\n## 图网络分析方法的主要任务\n\n### 引出\n\n对于一般的图结构的数据来说，抛开节点和边所带的附加数据域来看，图的主要性质，就体现在节点 边的属性和图本身的拓扑结构上了  比如说节点的度 边的权 都是表征图结构基本而又重要的性质.   \n不过对于这些性质来说，还是从微观在描述图的最小成员：节点和边在图拓扑中的性质，因此要描述整个图结构的性质，就需要有另外一些衡量标准与方法  \n\n### 网络性质 NetworkOverview\n这里取图可视化软件**Gephi**的所选取的几个指标：  \n1. Network Diameter 网络直径 \n2. Graph Density 图紧密度\n3. Modularity 模块度\n4. Centrarity 中心度 \n5. Connected subgraph 联通子图 \n\n\n## 网络分析的主要算法\n\n 这里只列举几个我实际学习并实现的 \n\n### PageRank（Centrarity ）-2002\n PageRank 是很为我们熟知的google发家的算法，网络拓扑其实也就是一个很大型的图结构。关于PageRank 的介绍网上已经有较为详细的解读了，[这篇blog写得挺好](http://blog.jobbole.com/71431/)。\n\nPageRank 其实从算法原理上非常简单，就是一个矩阵的迭代，实际应用中真正的问题在于大型网络拓扑的分布式计算 因而有了PageRank的mapreduce实现\n\n\n### 顶点度（Centrarity ）\n ..大家什么都没看到\n\n### Gravian-Newman 社区发现算法（Modularity） -2004\n 社区发现的入门级算法...折腾了我好久  \n 这个我感觉网上现有的一些资料中并没有很好的..我会自己写一篇详细介绍的   \n 附上链接 **[Newman教授的个人主页](http://www-personal.umich.edu/~mejn/)**\n\n\n### FastUnfolding 算法 （Modularity）-2008\n 同样会另起一篇blog介绍这个..但感觉自己对这个算法理解的还不是那么透彻..特别是在模块度的计算上还有些问题..在这里mark住，以便以后继续学习\n\n\n","slug":"algorithms/图网络分析方法","published":1,"updated":"2017-03-24T17:48:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v566u0011acwos7tp180t","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>不是什么事情都要给别人一个交代，但总是要给自己一个交代的，因此遍有了这一篇总结。   </p>\n<p> 这是一篇来自于课程设计的markdown，由于自己给自己开的坑，花费了大量时间。<br>还有一个目的主要是记录下自己学到的知识，以方便以这段经历为跳板，在后面对数据挖掘领域进行更深层次的学习</p>\n<h2 id=\"图网络分析方法的主要任务\"><a href=\"#图网络分析方法的主要任务\" class=\"headerlink\" title=\"图网络分析方法的主要任务\"></a>图网络分析方法的主要任务</h2><h3 id=\"引出\"><a href=\"#引出\" class=\"headerlink\" title=\"引出\"></a>引出</h3><p>对于一般的图结构的数据来说，抛开节点和边所带的附加数据域来看，图的主要性质，就体现在节点 边的属性和图本身的拓扑结构上了  比如说节点的度 边的权 都是表征图结构基本而又重要的性质.<br>不过对于这些性质来说，还是从微观在描述图的最小成员：节点和边在图拓扑中的性质，因此要描述整个图结构的性质，就需要有另外一些衡量标准与方法  </p>\n<h3 id=\"网络性质-NetworkOverview\"><a href=\"#网络性质-NetworkOverview\" class=\"headerlink\" title=\"网络性质 NetworkOverview\"></a>网络性质 NetworkOverview</h3><p>这里取图可视化软件<strong>Gephi</strong>的所选取的几个指标：  </p>\n<ol>\n<li>Network Diameter 网络直径 </li>\n<li>Graph Density 图紧密度</li>\n<li>Modularity 模块度</li>\n<li>Centrarity 中心度 </li>\n<li>Connected subgraph 联通子图 </li>\n</ol>\n<h2 id=\"网络分析的主要算法\"><a href=\"#网络分析的主要算法\" class=\"headerlink\" title=\"网络分析的主要算法\"></a>网络分析的主要算法</h2><p> 这里只列举几个我实际学习并实现的 </p>\n<h3 id=\"PageRank（Centrarity-）-2002\"><a href=\"#PageRank（Centrarity-）-2002\" class=\"headerlink\" title=\"PageRank（Centrarity ）-2002\"></a>PageRank（Centrarity ）-2002</h3><p> PageRank 是很为我们熟知的google发家的算法，网络拓扑其实也就是一个很大型的图结构。关于PageRank 的介绍网上已经有较为详细的解读了，<a href=\"http://blog.jobbole.com/71431/\" target=\"_blank\" rel=\"external\">这篇blog写得挺好</a>。</p>\n<p>PageRank 其实从算法原理上非常简单，就是一个矩阵的迭代，实际应用中真正的问题在于大型网络拓扑的分布式计算 因而有了PageRank的mapreduce实现</p>\n<h3 id=\"顶点度（Centrarity-）\"><a href=\"#顶点度（Centrarity-）\" class=\"headerlink\" title=\"顶点度（Centrarity ）\"></a>顶点度（Centrarity ）</h3><p> ..大家什么都没看到</p>\n<h3 id=\"Gravian-Newman-社区发现算法（Modularity）-2004\"><a href=\"#Gravian-Newman-社区发现算法（Modularity）-2004\" class=\"headerlink\" title=\"Gravian-Newman 社区发现算法（Modularity） -2004\"></a>Gravian-Newman 社区发现算法（Modularity） -2004</h3><p> 社区发现的入门级算法…折腾了我好久<br> 这个我感觉网上现有的一些资料中并没有很好的..我会自己写一篇详细介绍的<br> 附上链接 <strong><a href=\"http://www-personal.umich.edu/~mejn/\" target=\"_blank\" rel=\"external\">Newman教授的个人主页</a></strong></p>\n<h3 id=\"FastUnfolding-算法-（Modularity）-2008\"><a href=\"#FastUnfolding-算法-（Modularity）-2008\" class=\"headerlink\" title=\"FastUnfolding 算法 （Modularity）-2008\"></a>FastUnfolding 算法 （Modularity）-2008</h3><p> 同样会另起一篇blog介绍这个..但感觉自己对这个算法理解的还不是那么透彻..特别是在模块度的计算上还有些问题..在这里mark住，以便以后继续学习</p>\n","excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>不是什么事情都要给别人一个交代，但总是要给自己一个交代的，因此遍有了这一篇总结。   </p>\n<p> 这是一篇来自于课程设计的markdown，由于自己给自己开的坑，花费了大量时间。<br>还有一个目的主要是记录下自己学到的知识，以方便以这段经历为跳板，在后面对数据挖掘领域进行更深层次的学习</p>\n<h2 id=\"图网络分析方法的主要任务\"><a href=\"#图网络分析方法的主要任务\" class=\"headerlink\" title=\"图网络分析方法的主要任务\"></a>图网络分析方法的主要任务</h2><h3 id=\"引出\"><a href=\"#引出\" class=\"headerlink\" title=\"引出\"></a>引出</h3><p>对于一般的图结构的数据来说，抛开节点和边所带的附加数据域来看，图的主要性质，就体现在节点 边的属性和图本身的拓扑结构上了  比如说节点的度 边的权 都是表征图结构基本而又重要的性质.<br>不过对于这些性质来说，还是从微观在描述图的最小成员：节点和边在图拓扑中的性质，因此要描述整个图结构的性质，就需要有另外一些衡量标准与方法  </p>\n<h3 id=\"网络性质-NetworkOverview\"><a href=\"#网络性质-NetworkOverview\" class=\"headerlink\" title=\"网络性质 NetworkOverview\"></a>网络性质 NetworkOverview</h3><p>这里取图可视化软件<strong>Gephi</strong>的所选取的几个指标：  </p>\n<ol>\n<li>Network Diameter 网络直径 </li>\n<li>Graph Density 图紧密度</li>\n<li>Modularity 模块度</li>\n<li>Centrarity 中心度 </li>\n<li>Connected subgraph 联通子图 </li>\n</ol>\n<h2 id=\"网络分析的主要算法\"><a href=\"#网络分析的主要算法\" class=\"headerlink\" title=\"网络分析的主要算法\"></a>网络分析的主要算法</h2><p> 这里只列举几个我实际学习并实现的 </p>\n<h3 id=\"PageRank（Centrarity-）-2002\"><a href=\"#PageRank（Centrarity-）-2002\" class=\"headerlink\" title=\"PageRank（Centrarity ）-2002\"></a>PageRank（Centrarity ）-2002</h3><p> PageRank 是很为我们熟知的google发家的算法，网络拓扑其实也就是一个很大型的图结构。关于PageRank 的介绍网上已经有较为详细的解读了，<a href=\"http://blog.jobbole.com/71431/\">这篇blog写得挺好</a>。</p>\n<p>PageRank 其实从算法原理上非常简单，就是一个矩阵的迭代，实际应用中真正的问题在于大型网络拓扑的分布式计算 因而有了PageRank的mapreduce实现</p>\n<h3 id=\"顶点度（Centrarity-）\"><a href=\"#顶点度（Centrarity-）\" class=\"headerlink\" title=\"顶点度（Centrarity ）\"></a>顶点度（Centrarity ）</h3><p> ..大家什么都没看到</p>\n<h3 id=\"Gravian-Newman-社区发现算法（Modularity）-2004\"><a href=\"#Gravian-Newman-社区发现算法（Modularity）-2004\" class=\"headerlink\" title=\"Gravian-Newman 社区发现算法（Modularity） -2004\"></a>Gravian-Newman 社区发现算法（Modularity） -2004</h3><p> 社区发现的入门级算法…折腾了我好久<br> 这个我感觉网上现有的一些资料中并没有很好的..我会自己写一篇详细介绍的<br> 附上链接 <strong><a href=\"http://www-personal.umich.edu/~mejn/\">Newman教授的个人主页</a></strong></p>\n<h3 id=\"FastUnfolding-算法-（Modularity）-2008\"><a href=\"#FastUnfolding-算法-（Modularity）-2008\" class=\"headerlink\" title=\"FastUnfolding 算法 （Modularity）-2008\"></a>FastUnfolding 算法 （Modularity）-2008</h3><p> 同样会另起一篇blog介绍这个..但感觉自己对这个算法理解的还不是那么透彻..特别是在模块度的计算上还有些问题..在这里mark住，以便以后继续学习</p>\n"},{"title":"博弈论入门","date":"2017-03-30T09:42:14.000Z","_content":"## 几种博弈：\n### 巴什博奕（Bash Game）\n*只有一堆n个物品，两个人轮流从这堆物品中取物，规定每次至少取一个，最多取m个。最后取光者得胜*\n\n### 威佐夫博奕（Wythoff Game） \n*有两堆各若干个物品，两个人轮流从某一堆或同时从两堆中取同样多的物品，规定每次至少取一个，多者不限，最后取光者得胜。*\n\n那么任给一个局势（a，b），怎样判断它是不是奇异局势呢？我们有如下公式：\n\n    ak =[k（1+√5）/2]，bk= ak + k  （k=0，1，2，…,n 方括号表示取整函数) \n\n可以这样进行判断：\n``` c++\n\tint a = max(M,N);\t//M,N分别为一开始两堆物品个数\n\tint b = min(M,N);\n\tint k = a-b;\n\ta = int(k*(1+sqrt(5))/2.0);\n\tif(a==b)\n\t\tflag = false;\t//先手必败 P态\n\telse\n\t\tflag = true;\t//先手必胜 N态\n```\n\n**威佐夫游戏的一种变形：** 见 POJ2348\n\n\n### Nim游戏\n有n堆各若干个物品，两个人轮流从某一堆取任意多的物品，规定每次至少取一个，多者不限，最后取光者得胜。\n\nNim 游戏是组合游戏的一种\n当每堆物品分别为a1 a2 a3...an时  \n若a1^a2^a3^...an == 0时则为必败态，反之必胜\n\n","source":"_posts/acm/markdown/博弈论入门.md","raw":"---\ntitle: 博弈论入门\ndate: 2017-03-30 17:42:14\ntags: [博弈论]\ncategories: ACM\n---\n## 几种博弈：\n### 巴什博奕（Bash Game）\n*只有一堆n个物品，两个人轮流从这堆物品中取物，规定每次至少取一个，最多取m个。最后取光者得胜*\n\n### 威佐夫博奕（Wythoff Game） \n*有两堆各若干个物品，两个人轮流从某一堆或同时从两堆中取同样多的物品，规定每次至少取一个，多者不限，最后取光者得胜。*\n\n那么任给一个局势（a，b），怎样判断它是不是奇异局势呢？我们有如下公式：\n\n    ak =[k（1+√5）/2]，bk= ak + k  （k=0，1，2，…,n 方括号表示取整函数) \n\n可以这样进行判断：\n``` c++\n\tint a = max(M,N);\t//M,N分别为一开始两堆物品个数\n\tint b = min(M,N);\n\tint k = a-b;\n\ta = int(k*(1+sqrt(5))/2.0);\n\tif(a==b)\n\t\tflag = false;\t//先手必败 P态\n\telse\n\t\tflag = true;\t//先手必胜 N态\n```\n\n**威佐夫游戏的一种变形：** 见 POJ2348\n\n\n### Nim游戏\n有n堆各若干个物品，两个人轮流从某一堆取任意多的物品，规定每次至少取一个，多者不限，最后取光者得胜。\n\nNim 游戏是组合游戏的一种\n当每堆物品分别为a1 a2 a3...an时  \n若a1^a2^a3^...an == 0时则为必败态，反之必胜\n\n","slug":"acm/markdown/博弈论入门","published":1,"updated":"2017-04-03T06:45:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v568m0018acwo4l25tmsd","content":"<h2 id=\"几种博弈：\"><a href=\"#几种博弈：\" class=\"headerlink\" title=\"几种博弈：\"></a>几种博弈：</h2><h3 id=\"巴什博奕（Bash-Game）\"><a href=\"#巴什博奕（Bash-Game）\" class=\"headerlink\" title=\"巴什博奕（Bash Game）\"></a>巴什博奕（Bash Game）</h3><p><em>只有一堆n个物品，两个人轮流从这堆物品中取物，规定每次至少取一个，最多取m个。最后取光者得胜</em></p>\n<h3 id=\"威佐夫博奕（Wythoff-Game）\"><a href=\"#威佐夫博奕（Wythoff-Game）\" class=\"headerlink\" title=\"威佐夫博奕（Wythoff Game）\"></a>威佐夫博奕（Wythoff Game）</h3><p><em>有两堆各若干个物品，两个人轮流从某一堆或同时从两堆中取同样多的物品，规定每次至少取一个，多者不限，最后取光者得胜。</em></p>\n<p>那么任给一个局势（a，b），怎样判断它是不是奇异局势呢？我们有如下公式：</p>\n<pre><code>ak =[k（1+√5）/2]，bk= ak + k  （k=0，1，2，…,n 方括号表示取整函数) \n</code></pre><p>可以这样进行判断：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> a = max(M,N);\t<span class=\"comment\">//M,N分别为一开始两堆物品个数</span></div><div class=\"line\"><span class=\"keyword\">int</span> b = min(M,N);</div><div class=\"line\"><span class=\"keyword\">int</span> k = a-b;</div><div class=\"line\">a = <span class=\"keyword\">int</span>(k*(<span class=\"number\">1</span>+<span class=\"built_in\">sqrt</span>(<span class=\"number\">5</span>))/<span class=\"number\">2.0</span>);</div><div class=\"line\"><span class=\"keyword\">if</span>(a==b)</div><div class=\"line\">\tflag = <span class=\"literal\">false</span>;\t<span class=\"comment\">//先手必败 P态</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">\tflag = <span class=\"literal\">true</span>;\t<span class=\"comment\">//先手必胜 N态</span></div></pre></td></tr></table></figure></p>\n<p><strong>威佐夫游戏的一种变形：</strong> 见 POJ2348</p>\n<h3 id=\"Nim游戏\"><a href=\"#Nim游戏\" class=\"headerlink\" title=\"Nim游戏\"></a>Nim游戏</h3><p>有n堆各若干个物品，两个人轮流从某一堆取任意多的物品，规定每次至少取一个，多者不限，最后取光者得胜。</p>\n<p>Nim 游戏是组合游戏的一种<br>当每堆物品分别为a1 a2 a3…an时<br>若a1^a2^a3^…an == 0时则为必败态，反之必胜</p>\n","excerpt":"","more":"<h2 id=\"几种博弈：\"><a href=\"#几种博弈：\" class=\"headerlink\" title=\"几种博弈：\"></a>几种博弈：</h2><h3 id=\"巴什博奕（Bash-Game）\"><a href=\"#巴什博奕（Bash-Game）\" class=\"headerlink\" title=\"巴什博奕（Bash Game）\"></a>巴什博奕（Bash Game）</h3><p><em>只有一堆n个物品，两个人轮流从这堆物品中取物，规定每次至少取一个，最多取m个。最后取光者得胜</em></p>\n<h3 id=\"威佐夫博奕（Wythoff-Game）\"><a href=\"#威佐夫博奕（Wythoff-Game）\" class=\"headerlink\" title=\"威佐夫博奕（Wythoff Game）\"></a>威佐夫博奕（Wythoff Game）</h3><p><em>有两堆各若干个物品，两个人轮流从某一堆或同时从两堆中取同样多的物品，规定每次至少取一个，多者不限，最后取光者得胜。</em></p>\n<p>那么任给一个局势（a，b），怎样判断它是不是奇异局势呢？我们有如下公式：</p>\n<pre><code>ak =[k（1+√5）/2]，bk= ak + k  （k=0，1，2，…,n 方括号表示取整函数) \n</code></pre><p>可以这样进行判断：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> a = max(M,N);\t<span class=\"comment\">//M,N分别为一开始两堆物品个数</span></div><div class=\"line\"><span class=\"keyword\">int</span> b = min(M,N);</div><div class=\"line\"><span class=\"keyword\">int</span> k = a-b;</div><div class=\"line\">a = <span class=\"keyword\">int</span>(k*(<span class=\"number\">1</span>+<span class=\"built_in\">sqrt</span>(<span class=\"number\">5</span>))/<span class=\"number\">2.0</span>);</div><div class=\"line\"><span class=\"keyword\">if</span>(a==b)</div><div class=\"line\">\tflag = <span class=\"literal\">false</span>;\t<span class=\"comment\">//先手必败 P态</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">\tflag = <span class=\"literal\">true</span>;\t<span class=\"comment\">//先手必胜 N态</span></div></pre></td></tr></table></figure></p>\n<p><strong>威佐夫游戏的一种变形：</strong> 见 POJ2348</p>\n<h3 id=\"Nim游戏\"><a href=\"#Nim游戏\" class=\"headerlink\" title=\"Nim游戏\"></a>Nim游戏</h3><p>有n堆各若干个物品，两个人轮流从某一堆取任意多的物品，规定每次至少取一个，多者不限，最后取光者得胜。</p>\n<p>Nim 游戏是组合游戏的一种<br>当每堆物品分别为a1 a2 a3…an时<br>若a1^a2^a3^…an == 0时则为必败态，反之必胜</p>\n"},{"title":"DP-最长上升子序列","date":"2017-04-11T17:59:43.000Z","_content":"## 解析\n这个问题是DP问题中的一个经典模型，可以参考《挑战程序设计竞赛》P64  \n做了几道题由这个模型可以引申解决一些经典DP问题  \n\n## 例子\n\n## 总结\n最长上升子序列为模型的问题有的特点总结为：  \n1. 存在一个有序序列，或是，序列需要至少按照某种规则使之有序\n2. 状态转移由当前元素前面的元素决定，这是有序序列的特殊性质  \n  \n其状态转移方程大致格式为： DP[i] = max{DP[i],dp[j]+k[i]}  \n对于最长上升子序列问题 k[i]\t== 1","source":"_posts/acm/题解/DP-最长上升子序列.md","raw":"---\ntitle: DP-最长上升子序列\ndate: 2017-04-12 01:59:43\ntags: [动态规划]\ncategories: ACM\n---\n## 解析\n这个问题是DP问题中的一个经典模型，可以参考《挑战程序设计竞赛》P64  \n做了几道题由这个模型可以引申解决一些经典DP问题  \n\n## 例子\n\n## 总结\n最长上升子序列为模型的问题有的特点总结为：  \n1. 存在一个有序序列，或是，序列需要至少按照某种规则使之有序\n2. 状态转移由当前元素前面的元素决定，这是有序序列的特殊性质  \n  \n其状态转移方程大致格式为： DP[i] = max{DP[i],dp[j]+k[i]}  \n对于最长上升子序列问题 k[i]\t== 1","slug":"acm/题解/DP-最长上升子序列","published":1,"updated":"2017-04-11T18:08:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v568m0019acwomj52grt2","content":"<h2 id=\"解析\"><a href=\"#解析\" class=\"headerlink\" title=\"解析\"></a>解析</h2><p>这个问题是DP问题中的一个经典模型，可以参考《挑战程序设计竞赛》P64<br>做了几道题由这个模型可以引申解决一些经典DP问题  </p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>最长上升子序列为模型的问题有的特点总结为：  </p>\n<ol>\n<li>存在一个有序序列，或是，序列需要至少按照某种规则使之有序</li>\n<li>状态转移由当前元素前面的元素决定，这是有序序列的特殊性质  </li>\n</ol>\n<p>其状态转移方程大致格式为： DP[i] = max{DP[i],dp[j]+k[i]}<br>对于最长上升子序列问题 k[i]    == 1</p>\n","excerpt":"","more":"<h2 id=\"解析\"><a href=\"#解析\" class=\"headerlink\" title=\"解析\"></a>解析</h2><p>这个问题是DP问题中的一个经典模型，可以参考《挑战程序设计竞赛》P64<br>做了几道题由这个模型可以引申解决一些经典DP问题  </p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>最长上升子序列为模型的问题有的特点总结为：  </p>\n<ol>\n<li>存在一个有序序列，或是，序列需要至少按照某种规则使之有序</li>\n<li>状态转移由当前元素前面的元素决定，这是有序序列的特殊性质  </li>\n</ol>\n<p>其状态转移方程大致格式为： DP[i] = max{DP[i],dp[j]+k[i]}<br>对于最长上升子序列问题 k[i]    == 1</p>\n"},{"title":"2017-广西邀请赛","date":"2017-08-27T09:25:04.000Z","_content":"算是我队第一次打正式赛了吧..全场贡献了几题思路..打表大法是真的强..  \n终榜5题银..还行..\n\n### 记录几个要补的题：   \n1. C: 怎么求三元环\n2. G: 平面图转对偶图\n3. K： 暴力哈希KMP\n\n### C\n```c++\n#include <iostream>\n#include <cstdio>\n#include <cctype>\n#include <algorithm>\n#include <cstring>\n#include <string>\n#include <cmath>\n#include <vector>\n#include <set>\n#include <stack>\n#include <sstream>\n#include <queue>\n#include <map>\n#include <functional>\n#include <bitset>\n\nusing namespace std;\n#define pb push_back\n#define mk make_pair\n#define ll long long\n#define ull unsigned long long\n#define pii pair<int, int>\n#define mkp make_pair\n#define fst first\n#define scd second\n#define ALL(A) A.begin(), A.end()\n#define REP(i,n) for(int (i)=0;(i)<(int)(n);(i)++)\n#define REP1(i, n) for(int (i)=1;(i)<=(int)(n);(i)++)\n#define fastio ios::sync_with_stdio(0), cin.tie(0)\n#define frein freopen(\"in.txt\", \"r\", stdin)\n#define freout freopen(\"out.txt\", \"w\", stdout)\n#define freout1 freopen(\"out1.txt\", \"w\", stdout)\n#define PI M_PI\n#define MAXN 100000\n#define xork(a,b) ((b&1)?(a):(0))\n#define sc(n) scanf(\"%d\",&(n))\n\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\nstruct edge{\n    int from,to,nxt;\n}E[MAXN*2];\nmap<pii,int> mp;\nint head[MAXN];\nint cnt;\nint edgecnt[MAXN];\nint d[MAXN];\nint node[MAXN];\nint ncnt;\n\nvoid add_edge(int f,int t){\n    E[cnt].to = t; E[cnt].nxt = head[f];\n    head[f] = cnt;\n    mp[mkp(f,t)] = cnt/2;\n    mp[mkp(t,f)] = cnt/2;\n    cnt++;\n    E[cnt].to = f; E[cnt].nxt = head[t];\n    head[t] = cnt;\n    cnt++;\n}\n\nint main()\n{\n    //freout;\n    int n,m;\n    while(~scanf(\"%d%d\",&n,&m)){\n        cnt = 0;\n        memset(head,-1,sizeof(head));\n        memset(d,0,sizeof(d));\n        memset(edgecnt,0,sizeof(edgecnt));\n        mp.clear();\n        for(int i=0; i<m; i++){\n            int u,v;\n            sc(u); sc(v);\n            add_edge(u,v);\n            d[u]++,d[v]++;\n        }\n        int x = (int)sqrt(m);\n        ncnt = 0;\n        for(int i=1; i<=n; i++){\n            if(d[i]<=x){\n                for(int j=head[i]; j!=-1; j=E[j].nxt){\n                    int u = E[j].to;\n                    for(int k=E[j].nxt; k!=-1; k=E[k].nxt){\n                        int v = E[k].to;\n                        if(mp.count(mkp(u,v))){\n                            edgecnt[mp[mkp(u,v)]]++;\n                        }\n                    }\n                }\n            }\n            else{\n                node[ncnt++] = i;\n            }\n        }\n        for(int i=0; i<ncnt; i++){\n            int u = node[i];\n            for(int j=i+1; j<ncnt; j++){\n                int v = node[j];\n                if(mp.count(mkp(u,v)))\n                for(int k=j+1; k<ncnt; k++){\n                    int z = node[k];\n                    if(mp.count(mkp(v,z)) && mp.count(mkp(u,z))){\n                        edgecnt[mp[mkp(v,z)]]++;\n                        edgecnt[mp[mkp(u,z)]]++;\n                        edgecnt[mp[mkp(u,v)]]++;\n                    }\n                }\n            }\n        }\n        ll ans = 0;\n        for(int i=0;i<m; i++){\n            ll c = edgecnt[i];\n            ans += c*(c-1)/2;\n        }\n        cout<<ans<<endl;\n    }\n}\n\n```","source":"_posts/acm/match/2017-广西邀请赛.md","raw":"---\ntitle: 2017-广西邀请赛\ndate: 2017-08-27 17:25:04\ntags: [比赛,题解,三元环]\ncategories: ACM\n---\n算是我队第一次打正式赛了吧..全场贡献了几题思路..打表大法是真的强..  \n终榜5题银..还行..\n\n### 记录几个要补的题：   \n1. C: 怎么求三元环\n2. G: 平面图转对偶图\n3. K： 暴力哈希KMP\n\n### C\n```c++\n#include <iostream>\n#include <cstdio>\n#include <cctype>\n#include <algorithm>\n#include <cstring>\n#include <string>\n#include <cmath>\n#include <vector>\n#include <set>\n#include <stack>\n#include <sstream>\n#include <queue>\n#include <map>\n#include <functional>\n#include <bitset>\n\nusing namespace std;\n#define pb push_back\n#define mk make_pair\n#define ll long long\n#define ull unsigned long long\n#define pii pair<int, int>\n#define mkp make_pair\n#define fst first\n#define scd second\n#define ALL(A) A.begin(), A.end()\n#define REP(i,n) for(int (i)=0;(i)<(int)(n);(i)++)\n#define REP1(i, n) for(int (i)=1;(i)<=(int)(n);(i)++)\n#define fastio ios::sync_with_stdio(0), cin.tie(0)\n#define frein freopen(\"in.txt\", \"r\", stdin)\n#define freout freopen(\"out.txt\", \"w\", stdout)\n#define freout1 freopen(\"out1.txt\", \"w\", stdout)\n#define PI M_PI\n#define MAXN 100000\n#define xork(a,b) ((b&1)?(a):(0))\n#define sc(n) scanf(\"%d\",&(n))\n\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\nstruct edge{\n    int from,to,nxt;\n}E[MAXN*2];\nmap<pii,int> mp;\nint head[MAXN];\nint cnt;\nint edgecnt[MAXN];\nint d[MAXN];\nint node[MAXN];\nint ncnt;\n\nvoid add_edge(int f,int t){\n    E[cnt].to = t; E[cnt].nxt = head[f];\n    head[f] = cnt;\n    mp[mkp(f,t)] = cnt/2;\n    mp[mkp(t,f)] = cnt/2;\n    cnt++;\n    E[cnt].to = f; E[cnt].nxt = head[t];\n    head[t] = cnt;\n    cnt++;\n}\n\nint main()\n{\n    //freout;\n    int n,m;\n    while(~scanf(\"%d%d\",&n,&m)){\n        cnt = 0;\n        memset(head,-1,sizeof(head));\n        memset(d,0,sizeof(d));\n        memset(edgecnt,0,sizeof(edgecnt));\n        mp.clear();\n        for(int i=0; i<m; i++){\n            int u,v;\n            sc(u); sc(v);\n            add_edge(u,v);\n            d[u]++,d[v]++;\n        }\n        int x = (int)sqrt(m);\n        ncnt = 0;\n        for(int i=1; i<=n; i++){\n            if(d[i]<=x){\n                for(int j=head[i]; j!=-1; j=E[j].nxt){\n                    int u = E[j].to;\n                    for(int k=E[j].nxt; k!=-1; k=E[k].nxt){\n                        int v = E[k].to;\n                        if(mp.count(mkp(u,v))){\n                            edgecnt[mp[mkp(u,v)]]++;\n                        }\n                    }\n                }\n            }\n            else{\n                node[ncnt++] = i;\n            }\n        }\n        for(int i=0; i<ncnt; i++){\n            int u = node[i];\n            for(int j=i+1; j<ncnt; j++){\n                int v = node[j];\n                if(mp.count(mkp(u,v)))\n                for(int k=j+1; k<ncnt; k++){\n                    int z = node[k];\n                    if(mp.count(mkp(v,z)) && mp.count(mkp(u,z))){\n                        edgecnt[mp[mkp(v,z)]]++;\n                        edgecnt[mp[mkp(u,z)]]++;\n                        edgecnt[mp[mkp(u,v)]]++;\n                    }\n                }\n            }\n        }\n        ll ans = 0;\n        for(int i=0;i<m; i++){\n            ll c = edgecnt[i];\n            ans += c*(c-1)/2;\n        }\n        cout<<ans<<endl;\n    }\n}\n\n```","slug":"acm/match/2017-广西邀请赛","published":1,"updated":"2017-08-29T11:14:17.755Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v5692001bacwow9kuei5g","content":"<p>算是我队第一次打正式赛了吧..全场贡献了几题思路..打表大法是真的强..<br>终榜5题银..还行..</p>\n<h3 id=\"记录几个要补的题：\"><a href=\"#记录几个要补的题：\" class=\"headerlink\" title=\"记录几个要补的题：\"></a>记录几个要补的题：</h3><ol>\n<li>C: 怎么求三元环</li>\n<li>G: 平面图转对偶图</li>\n<li>K： 暴力哈希KMP</li>\n</ol>\n<h3 id=\"C\"><a href=\"#C\" class=\"headerlink\" title=\"C\"></a>C</h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\">#include &lt;cstdio&gt;</div><div class=\"line\">#include &lt;cctype&gt;</div><div class=\"line\">#include &lt;algorithm&gt;</div><div class=\"line\">#include &lt;cstring&gt;</div><div class=\"line\">#include &lt;string&gt;</div><div class=\"line\">#include &lt;cmath&gt;</div><div class=\"line\">#include &lt;vector&gt;</div><div class=\"line\">#include &lt;set&gt;</div><div class=\"line\">#include &lt;stack&gt;</div><div class=\"line\">#include &lt;sstream&gt;</div><div class=\"line\">#include &lt;queue&gt;</div><div class=\"line\">#include &lt;map&gt;</div><div class=\"line\">#include &lt;functional&gt;</div><div class=\"line\">#include &lt;bitset&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\">#define pb push_back</div><div class=\"line\">#define mk make_pair</div><div class=\"line\">#define ll long long</div><div class=\"line\">#define ull unsigned long long</div><div class=\"line\">#define pii pair&lt;int, int&gt;</div><div class=\"line\">#define mkp make_pair</div><div class=\"line\">#define fst first</div><div class=\"line\">#define scd second</div><div class=\"line\">#define ALL(A) A.begin(), A.end()</div><div class=\"line\">#define REP(i,n) for(int (i)=0;(i)&lt;(int)(n);(i)++)</div><div class=\"line\">#define REP1(i, n) for(int (i)=1;(i)&lt;=(int)(n);(i)++)</div><div class=\"line\">#define fastio ios::sync_with_stdio(0), cin.tie(0)</div><div class=\"line\">#define frein freopen(\"in.txt\", \"r\", stdin)</div><div class=\"line\">#define freout freopen(\"out.txt\", \"w\", stdout)</div><div class=\"line\">#define freout1 freopen(\"out1.txt\", \"w\", stdout)</div><div class=\"line\">#define PI M_PI</div><div class=\"line\">#define MAXN 100000</div><div class=\"line\">#define xork(a,b) ((b&amp;1)?(a):(0))</div><div class=\"line\">#define sc(n) scanf(\"%d\",&amp;(n))</div><div class=\"line\"></div><div class=\"line\">ll mod = 10000;</div><div class=\"line\">ll INF = 1LL&lt;&lt;60LL;</div><div class=\"line\">const double eps = 1e-8;</div><div class=\"line\">template&lt;typename T&gt; T gcd(T a,T b)</div><div class=\"line\">&#123;if(!b)return a;return gcd(b,a%b);&#125;</div><div class=\"line\">struct edge&#123;</div><div class=\"line\">    int from,to,nxt;</div><div class=\"line\">&#125;E[MAXN*2];</div><div class=\"line\">map&lt;pii,int&gt; mp;</div><div class=\"line\">int head[MAXN];</div><div class=\"line\">int cnt;</div><div class=\"line\">int edgecnt[MAXN];</div><div class=\"line\">int d[MAXN];</div><div class=\"line\">int node[MAXN];</div><div class=\"line\">int ncnt;</div><div class=\"line\"></div><div class=\"line\">void add_edge(int f,int t)&#123;</div><div class=\"line\">    E[cnt].to = t; E[cnt].nxt = head[f];</div><div class=\"line\">    head[f] = cnt;</div><div class=\"line\">    mp[mkp(f,t)] = cnt/2;</div><div class=\"line\">    mp[mkp(t,f)] = cnt/2;</div><div class=\"line\">    cnt++;</div><div class=\"line\">    E[cnt].to = f; E[cnt].nxt = head[t];</div><div class=\"line\">    head[t] = cnt;</div><div class=\"line\">    cnt++;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()</div><div class=\"line\">&#123;</div><div class=\"line\">    //freout;</div><div class=\"line\">    int n,m;</div><div class=\"line\">    while(~scanf(\"%d%d\",&amp;n,&amp;m))&#123;</div><div class=\"line\">        cnt = 0;</div><div class=\"line\">        memset(head,-1,sizeof(head));</div><div class=\"line\">        memset(d,0,sizeof(d));</div><div class=\"line\">        memset(edgecnt,0,sizeof(edgecnt));</div><div class=\"line\">        mp.clear();</div><div class=\"line\">        for(int i=0; i&lt;m; i++)&#123;</div><div class=\"line\">            int u,v;</div><div class=\"line\">            sc(u); sc(v);</div><div class=\"line\">            add_edge(u,v);</div><div class=\"line\">            d[u]++,d[v]++;</div><div class=\"line\">        &#125;</div><div class=\"line\">        int x = (int)sqrt(m);</div><div class=\"line\">        ncnt = 0;</div><div class=\"line\">        for(int i=1; i&lt;=n; i++)&#123;</div><div class=\"line\">            if(d[i]&lt;=x)&#123;</div><div class=\"line\">                for(int j=head[i]; j!=-1; j=E[j].nxt)&#123;</div><div class=\"line\">                    int u = E[j].to;</div><div class=\"line\">                    for(int k=E[j].nxt; k!=-1; k=E[k].nxt)&#123;</div><div class=\"line\">                        int v = E[k].to;</div><div class=\"line\">                        if(mp.count(mkp(u,v)))&#123;</div><div class=\"line\">                            edgecnt[mp[mkp(u,v)]]++;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            else&#123;</div><div class=\"line\">                node[ncnt++] = i;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        for(int i=0; i&lt;ncnt; i++)&#123;</div><div class=\"line\">            int u = node[i];</div><div class=\"line\">            for(int j=i+1; j&lt;ncnt; j++)&#123;</div><div class=\"line\">                int v = node[j];</div><div class=\"line\">                if(mp.count(mkp(u,v)))</div><div class=\"line\">                for(int k=j+1; k&lt;ncnt; k++)&#123;</div><div class=\"line\">                    int z = node[k];</div><div class=\"line\">                    if(mp.count(mkp(v,z)) &amp;&amp; mp.count(mkp(u,z)))&#123;</div><div class=\"line\">                        edgecnt[mp[mkp(v,z)]]++;</div><div class=\"line\">                        edgecnt[mp[mkp(u,z)]]++;</div><div class=\"line\">                        edgecnt[mp[mkp(u,v)]]++;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        ll ans = 0;</div><div class=\"line\">        for(int i=0;i&lt;m; i++)&#123;</div><div class=\"line\">            ll c = edgecnt[i];</div><div class=\"line\">            ans += c*(c-1)/2;</div><div class=\"line\">        &#125;</div><div class=\"line\">        cout&lt;&lt;ans&lt;&lt;endl;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","excerpt":"","more":"<p>算是我队第一次打正式赛了吧..全场贡献了几题思路..打表大法是真的强..<br>终榜5题银..还行..</p>\n<h3 id=\"记录几个要补的题：\"><a href=\"#记录几个要补的题：\" class=\"headerlink\" title=\"记录几个要补的题：\"></a>记录几个要补的题：</h3><ol>\n<li>C: 怎么求三元环</li>\n<li>G: 平面图转对偶图</li>\n<li>K： 暴力哈希KMP</li>\n</ol>\n<h3 id=\"C\"><a href=\"#C\" class=\"headerlink\" title=\"C\"></a>C</h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\">#include &lt;cstdio&gt;</div><div class=\"line\">#include &lt;cctype&gt;</div><div class=\"line\">#include &lt;algorithm&gt;</div><div class=\"line\">#include &lt;cstring&gt;</div><div class=\"line\">#include &lt;string&gt;</div><div class=\"line\">#include &lt;cmath&gt;</div><div class=\"line\">#include &lt;vector&gt;</div><div class=\"line\">#include &lt;set&gt;</div><div class=\"line\">#include &lt;stack&gt;</div><div class=\"line\">#include &lt;sstream&gt;</div><div class=\"line\">#include &lt;queue&gt;</div><div class=\"line\">#include &lt;map&gt;</div><div class=\"line\">#include &lt;functional&gt;</div><div class=\"line\">#include &lt;bitset&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\">#define pb push_back</div><div class=\"line\">#define mk make_pair</div><div class=\"line\">#define ll long long</div><div class=\"line\">#define ull unsigned long long</div><div class=\"line\">#define pii pair&lt;int, int&gt;</div><div class=\"line\">#define mkp make_pair</div><div class=\"line\">#define fst first</div><div class=\"line\">#define scd second</div><div class=\"line\">#define ALL(A) A.begin(), A.end()</div><div class=\"line\">#define REP(i,n) for(int (i)=0;(i)&lt;(int)(n);(i)++)</div><div class=\"line\">#define REP1(i, n) for(int (i)=1;(i)&lt;=(int)(n);(i)++)</div><div class=\"line\">#define fastio ios::sync_with_stdio(0), cin.tie(0)</div><div class=\"line\">#define frein freopen(\"in.txt\", \"r\", stdin)</div><div class=\"line\">#define freout freopen(\"out.txt\", \"w\", stdout)</div><div class=\"line\">#define freout1 freopen(\"out1.txt\", \"w\", stdout)</div><div class=\"line\">#define PI M_PI</div><div class=\"line\">#define MAXN 100000</div><div class=\"line\">#define xork(a,b) ((b&amp;1)?(a):(0))</div><div class=\"line\">#define sc(n) scanf(\"%d\",&amp;(n))</div><div class=\"line\"></div><div class=\"line\">ll mod = 10000;</div><div class=\"line\">ll INF = 1LL&lt;&lt;60LL;</div><div class=\"line\">const double eps = 1e-8;</div><div class=\"line\">template&lt;typename T&gt; T gcd(T a,T b)</div><div class=\"line\">&#123;if(!b)return a;return gcd(b,a%b);&#125;</div><div class=\"line\">struct edge&#123;</div><div class=\"line\">    int from,to,nxt;</div><div class=\"line\">&#125;E[MAXN*2];</div><div class=\"line\">map&lt;pii,int&gt; mp;</div><div class=\"line\">int head[MAXN];</div><div class=\"line\">int cnt;</div><div class=\"line\">int edgecnt[MAXN];</div><div class=\"line\">int d[MAXN];</div><div class=\"line\">int node[MAXN];</div><div class=\"line\">int ncnt;</div><div class=\"line\"></div><div class=\"line\">void add_edge(int f,int t)&#123;</div><div class=\"line\">    E[cnt].to = t; E[cnt].nxt = head[f];</div><div class=\"line\">    head[f] = cnt;</div><div class=\"line\">    mp[mkp(f,t)] = cnt/2;</div><div class=\"line\">    mp[mkp(t,f)] = cnt/2;</div><div class=\"line\">    cnt++;</div><div class=\"line\">    E[cnt].to = f; E[cnt].nxt = head[t];</div><div class=\"line\">    head[t] = cnt;</div><div class=\"line\">    cnt++;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()</div><div class=\"line\">&#123;</div><div class=\"line\">    //freout;</div><div class=\"line\">    int n,m;</div><div class=\"line\">    while(~scanf(\"%d%d\",&amp;n,&amp;m))&#123;</div><div class=\"line\">        cnt = 0;</div><div class=\"line\">        memset(head,-1,sizeof(head));</div><div class=\"line\">        memset(d,0,sizeof(d));</div><div class=\"line\">        memset(edgecnt,0,sizeof(edgecnt));</div><div class=\"line\">        mp.clear();</div><div class=\"line\">        for(int i=0; i&lt;m; i++)&#123;</div><div class=\"line\">            int u,v;</div><div class=\"line\">            sc(u); sc(v);</div><div class=\"line\">            add_edge(u,v);</div><div class=\"line\">            d[u]++,d[v]++;</div><div class=\"line\">        &#125;</div><div class=\"line\">        int x = (int)sqrt(m);</div><div class=\"line\">        ncnt = 0;</div><div class=\"line\">        for(int i=1; i&lt;=n; i++)&#123;</div><div class=\"line\">            if(d[i]&lt;=x)&#123;</div><div class=\"line\">                for(int j=head[i]; j!=-1; j=E[j].nxt)&#123;</div><div class=\"line\">                    int u = E[j].to;</div><div class=\"line\">                    for(int k=E[j].nxt; k!=-1; k=E[k].nxt)&#123;</div><div class=\"line\">                        int v = E[k].to;</div><div class=\"line\">                        if(mp.count(mkp(u,v)))&#123;</div><div class=\"line\">                            edgecnt[mp[mkp(u,v)]]++;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            else&#123;</div><div class=\"line\">                node[ncnt++] = i;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        for(int i=0; i&lt;ncnt; i++)&#123;</div><div class=\"line\">            int u = node[i];</div><div class=\"line\">            for(int j=i+1; j&lt;ncnt; j++)&#123;</div><div class=\"line\">                int v = node[j];</div><div class=\"line\">                if(mp.count(mkp(u,v)))</div><div class=\"line\">                for(int k=j+1; k&lt;ncnt; k++)&#123;</div><div class=\"line\">                    int z = node[k];</div><div class=\"line\">                    if(mp.count(mkp(v,z)) &amp;&amp; mp.count(mkp(u,z)))&#123;</div><div class=\"line\">                        edgecnt[mp[mkp(v,z)]]++;</div><div class=\"line\">                        edgecnt[mp[mkp(u,z)]]++;</div><div class=\"line\">                        edgecnt[mp[mkp(u,v)]]++;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        ll ans = 0;</div><div class=\"line\">        for(int i=0;i&lt;m; i++)&#123;</div><div class=\"line\">            ll c = edgecnt[i];</div><div class=\"line\">            ans += c*(c-1)/2;</div><div class=\"line\">        &#125;</div><div class=\"line\">        cout&lt;&lt;ans&lt;&lt;endl;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>"},{"title":"HDU-5667 矩阵快速幂&费马小定理","date":"2017-03-22T04:36:35.000Z","_content":"做题新遇到的知识点，暂时未ac 先markdown\n\n## 快速幂\n\n见算法概论p22  \n### 大致思想\n求 a^b mod N 时，从a mod N 开始不断对结果进行平方后迭代。然后把N对应二进制位为1的地方相乘，实际上是借助了：  \n**a^b = a^(2^k1+2^k2+....)**  \n的思想\n\n\n## 费马小定理\n\n当gcd(a,p)=1 且P为质数的时候有： \n\n**(p-1)mod p=1**\n\n\n\n## HDU-5667\n### 题解\n这一题实际上就是对递推式log然后转化为矩阵快速幂求f(n)时a的幂\n\n### 要点\n1. 从递推式到矩阵要注意，仔细观察递推式，矩阵的维数要恰当\n2. 注意在快速幂的时候模（p-1）\n","source":"_posts/acm/题解/HDU-5667.md","raw":"---\ntitle: HDU-5667 矩阵快速幂&费马小定理 \ndate: 2017-03-22 12:36:35\ntags: [数论,快速幂] \ncategories: ACM\n---\n做题新遇到的知识点，暂时未ac 先markdown\n\n## 快速幂\n\n见算法概论p22  \n### 大致思想\n求 a^b mod N 时，从a mod N 开始不断对结果进行平方后迭代。然后把N对应二进制位为1的地方相乘，实际上是借助了：  \n**a^b = a^(2^k1+2^k2+....)**  \n的思想\n\n\n## 费马小定理\n\n当gcd(a,p)=1 且P为质数的时候有： \n\n**(p-1)mod p=1**\n\n\n\n## HDU-5667\n### 题解\n这一题实际上就是对递推式log然后转化为矩阵快速幂求f(n)时a的幂\n\n### 要点\n1. 从递推式到矩阵要注意，仔细观察递推式，矩阵的维数要恰当\n2. 注意在快速幂的时候模（p-1）\n","slug":"acm/题解/HDU-5667","published":1,"updated":"2017-03-24T11:01:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v5692001dacwoua6b4l2b","content":"<p>做题新遇到的知识点，暂时未ac 先markdown</p>\n<h2 id=\"快速幂\"><a href=\"#快速幂\" class=\"headerlink\" title=\"快速幂\"></a>快速幂</h2><p>见算法概论p22  </p>\n<h3 id=\"大致思想\"><a href=\"#大致思想\" class=\"headerlink\" title=\"大致思想\"></a>大致思想</h3><p>求 a^b mod N 时，从a mod N 开始不断对结果进行平方后迭代。然后把N对应二进制位为1的地方相乘，实际上是借助了：<br><strong>a^b = a^(2^k1+2^k2+….)</strong><br>的思想</p>\n<h2 id=\"费马小定理\"><a href=\"#费马小定理\" class=\"headerlink\" title=\"费马小定理\"></a>费马小定理</h2><p>当gcd(a,p)=1 且P为质数的时候有： </p>\n<p><strong>(p-1)mod p=1</strong></p>\n<h2 id=\"HDU-5667\"><a href=\"#HDU-5667\" class=\"headerlink\" title=\"HDU-5667\"></a>HDU-5667</h2><h3 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h3><p>这一题实际上就是对递推式log然后转化为矩阵快速幂求f(n)时a的幂</p>\n<h3 id=\"要点\"><a href=\"#要点\" class=\"headerlink\" title=\"要点\"></a>要点</h3><ol>\n<li>从递推式到矩阵要注意，仔细观察递推式，矩阵的维数要恰当</li>\n<li>注意在快速幂的时候模（p-1）</li>\n</ol>\n","excerpt":"","more":"<p>做题新遇到的知识点，暂时未ac 先markdown</p>\n<h2 id=\"快速幂\"><a href=\"#快速幂\" class=\"headerlink\" title=\"快速幂\"></a>快速幂</h2><p>见算法概论p22  </p>\n<h3 id=\"大致思想\"><a href=\"#大致思想\" class=\"headerlink\" title=\"大致思想\"></a>大致思想</h3><p>求 a^b mod N 时，从a mod N 开始不断对结果进行平方后迭代。然后把N对应二进制位为1的地方相乘，实际上是借助了：<br><strong>a^b = a^(2^k1+2^k2+….)</strong><br>的思想</p>\n<h2 id=\"费马小定理\"><a href=\"#费马小定理\" class=\"headerlink\" title=\"费马小定理\"></a>费马小定理</h2><p>当gcd(a,p)=1 且P为质数的时候有： </p>\n<p><strong>(p-1)mod p=1</strong></p>\n<h2 id=\"HDU-5667\"><a href=\"#HDU-5667\" class=\"headerlink\" title=\"HDU-5667\"></a>HDU-5667</h2><h3 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h3><p>这一题实际上就是对递推式log然后转化为矩阵快速幂求f(n)时a的幂</p>\n<h3 id=\"要点\"><a href=\"#要点\" class=\"headerlink\" title=\"要点\"></a>要点</h3><ol>\n<li>从递推式到矩阵要注意，仔细观察递推式，矩阵的维数要恰当</li>\n<li>注意在快速幂的时候模（p-1）</li>\n</ol>\n"},{"title":"poj-2348","date":"2017-04-03T08:37:52.000Z","_content":"\n### 题意分析\n题目给出了两个正数a.b  \n每次操作，大的数减掉小的数的整数倍。一个数变为0 的时候结束。  \n谁先先把其中一个数减为0的获胜。问谁可以赢。Stan是先手。  \n假设两个数为a,b（a>=b)  \n如果a==b.那么肯定是先手获胜。一步就可以减为0,b  \n如果a%b==0.就是a是b的倍数，那么也是先手获胜。  \n如果a>=2*b.  那么   那个人肯定知道a%b,b是必胜态还是必败态。如果是必败态，先手将a,b变成a%b,b,那么先手肯定赢。如果是必胜态，先手将a,b变成a%b+b,b.那么对手只有将这两个数变成a%b,b,先手获胜。  \n如果是b<a<2*b  那么只有一条路：变成a-b,b  (这个时候0<a-b<b).这样一直下去看谁先面对上面的必胜状态。  \n所以假如面对b < a <2*b的状态，就先一步一步走下去。直到面对一个a%b==0 || a >=2*b的状态。  \n\n``` c++\n#include <iostream>\n#include <cstdio>\n#include <cstring>\n#include <algorithm>\n#define LL long long \n\nusing namespace std;\n\nint main()\n{\n\tint N,M;\n\twhile(~scanf(\"%d%d\",&N,&M))\n\t{\n\t\tif(M==0 && N==0)\tbreak;\n\t\tint a = max(N,M);\n\t\tint b = min(N,M);\n\t\tint nflag = 0;\n\t\tif(a%b==0||a/b>=2)\n\t\t\tnflag = 0;\n\t\telse{\n\t\t\twhile(b){\n\t\t\t\tif(a%b==0||a/b>=2)\tbreak;\n\t\t\t\ta = a-b;\n\t\t\t\tswap(a,b);\n\t\t\t\tnflag ^=1;\n\t\t\t}\n\t\t}\n\t\tif(!nflag)\n\t\t\tputs(\"Stan wins\");\n\t\telse\n\t\t\tputs(\"Ollie wins\");\n\t\t\t\n\t}\n}\n\n```","source":"_posts/acm/题解/poj-2348.md","raw":"---\ntitle: poj-2348\ndate: 2017-04-03 16:37:52\ntags: [博弈论,题解]\ncategories: ACM\n---\n\n### 题意分析\n题目给出了两个正数a.b  \n每次操作，大的数减掉小的数的整数倍。一个数变为0 的时候结束。  \n谁先先把其中一个数减为0的获胜。问谁可以赢。Stan是先手。  \n假设两个数为a,b（a>=b)  \n如果a==b.那么肯定是先手获胜。一步就可以减为0,b  \n如果a%b==0.就是a是b的倍数，那么也是先手获胜。  \n如果a>=2*b.  那么   那个人肯定知道a%b,b是必胜态还是必败态。如果是必败态，先手将a,b变成a%b,b,那么先手肯定赢。如果是必胜态，先手将a,b变成a%b+b,b.那么对手只有将这两个数变成a%b,b,先手获胜。  \n如果是b<a<2*b  那么只有一条路：变成a-b,b  (这个时候0<a-b<b).这样一直下去看谁先面对上面的必胜状态。  \n所以假如面对b < a <2*b的状态，就先一步一步走下去。直到面对一个a%b==0 || a >=2*b的状态。  \n\n``` c++\n#include <iostream>\n#include <cstdio>\n#include <cstring>\n#include <algorithm>\n#define LL long long \n\nusing namespace std;\n\nint main()\n{\n\tint N,M;\n\twhile(~scanf(\"%d%d\",&N,&M))\n\t{\n\t\tif(M==0 && N==0)\tbreak;\n\t\tint a = max(N,M);\n\t\tint b = min(N,M);\n\t\tint nflag = 0;\n\t\tif(a%b==0||a/b>=2)\n\t\t\tnflag = 0;\n\t\telse{\n\t\t\twhile(b){\n\t\t\t\tif(a%b==0||a/b>=2)\tbreak;\n\t\t\t\ta = a-b;\n\t\t\t\tswap(a,b);\n\t\t\t\tnflag ^=1;\n\t\t\t}\n\t\t}\n\t\tif(!nflag)\n\t\t\tputs(\"Stan wins\");\n\t\telse\n\t\t\tputs(\"Ollie wins\");\n\t\t\t\n\t}\n}\n\n```","slug":"acm/题解/poj-2348","published":1,"updated":"2017-04-04T11:42:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v569i001facwofhcivjrv","content":"<h3 id=\"题意分析\"><a href=\"#题意分析\" class=\"headerlink\" title=\"题意分析\"></a>题意分析</h3><p>题目给出了两个正数a.b<br>每次操作，大的数减掉小的数的整数倍。一个数变为0 的时候结束。<br>谁先先把其中一个数减为0的获胜。问谁可以赢。Stan是先手。<br>假设两个数为a,b（a&gt;=b)<br>如果a==b.那么肯定是先手获胜。一步就可以减为0,b<br>如果a%b==0.就是a是b的倍数，那么也是先手获胜。<br>如果a&gt;=2<em>b.  那么   那个人肯定知道a%b,b是必胜态还是必败态。如果是必败态，先手将a,b变成a%b,b,那么先手肯定赢。如果是必胜态，先手将a,b变成a%b+b,b.那么对手只有将这两个数变成a%b,b,先手获胜。<br>如果是b&lt;a&lt;2</em>b  那么只有一条路：变成a-b,b  (这个时候0<a-b<b).这样一直下去看谁先面对上面的必胜状态。 所以假如面对b=\"\" <=\"\" a=\"\" <2*b的状态，就先一步一步走下去。直到面对一个a%b=\"=0\" ||=\"\">=2*b的状态。  </a-b<b).这样一直下去看谁先面对上面的必胜状态。></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LL long long </span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> N,M;</div><div class=\"line\">\t<span class=\"keyword\">while</span>(~<span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d%d\"</span>,&amp;N,&amp;M))</div><div class=\"line\">\t&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(M==<span class=\"number\">0</span> &amp;&amp; N==<span class=\"number\">0</span>)\t<span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> a = max(N,M);</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> b = min(N,M);</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> nflag = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(a%b==<span class=\"number\">0</span>||a/b&gt;=<span class=\"number\">2</span>)</div><div class=\"line\">\t\t\tnflag = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">while</span>(b)&#123;</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">if</span>(a%b==<span class=\"number\">0</span>||a/b&gt;=<span class=\"number\">2</span>)\t<span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t\t\ta = a-b;</div><div class=\"line\">\t\t\t\tswap(a,b);</div><div class=\"line\">\t\t\t\tnflag ^=<span class=\"number\">1</span>;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(!nflag)</div><div class=\"line\">\t\t\t<span class=\"built_in\">puts</span>(<span class=\"string\">\"Stan wins\"</span>);</div><div class=\"line\">\t\t<span class=\"keyword\">else</span></div><div class=\"line\">\t\t\t<span class=\"built_in\">puts</span>(<span class=\"string\">\"Ollie wins\"</span>);</div><div class=\"line\">\t\t\t</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","excerpt":"","more":"<h3 id=\"题意分析\"><a href=\"#题意分析\" class=\"headerlink\" title=\"题意分析\"></a>题意分析</h3><p>题目给出了两个正数a.b<br>每次操作，大的数减掉小的数的整数倍。一个数变为0 的时候结束。<br>谁先先把其中一个数减为0的获胜。问谁可以赢。Stan是先手。<br>假设两个数为a,b（a&gt;=b)<br>如果a==b.那么肯定是先手获胜。一步就可以减为0,b<br>如果a%b==0.就是a是b的倍数，那么也是先手获胜。<br>如果a&gt;=2<em>b.  那么   那个人肯定知道a%b,b是必胜态还是必败态。如果是必败态，先手将a,b变成a%b,b,那么先手肯定赢。如果是必胜态，先手将a,b变成a%b+b,b.那么对手只有将这两个数变成a%b,b,先手获胜。<br>如果是b&lt;a&lt;2</em>b  那么只有一条路：变成a-b,b  (这个时候0<a-b<b).这样一直下去看谁先面对上面的必胜状态。  \n所以假如面对b < a <2*b的状态，就先一步一步走下去。直到面对一个a%b==0 || a >=2*b的状态。  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LL long long </span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">int</span> N,M;</div><div class=\"line\">\t<span class=\"keyword\">while</span>(~<span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d%d\"</span>,&amp;N,&amp;M))</div><div class=\"line\">\t&#123;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(M==<span class=\"number\">0</span> &amp;&amp; N==<span class=\"number\">0</span>)\t<span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> a = max(N,M);</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> b = min(N,M);</div><div class=\"line\">\t\t<span class=\"keyword\">int</span> nflag = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(a%b==<span class=\"number\">0</span>||a/b&gt;=<span class=\"number\">2</span>)</div><div class=\"line\">\t\t\tnflag = <span class=\"number\">0</span>;</div><div class=\"line\">\t\t<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">\t\t\t<span class=\"keyword\">while</span>(b)&#123;</div><div class=\"line\">\t\t\t\t<span class=\"keyword\">if</span>(a%b==<span class=\"number\">0</span>||a/b&gt;=<span class=\"number\">2</span>)\t<span class=\"keyword\">break</span>;</div><div class=\"line\">\t\t\t\ta = a-b;</div><div class=\"line\">\t\t\t\tswap(a,b);</div><div class=\"line\">\t\t\t\tnflag ^=<span class=\"number\">1</span>;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\t<span class=\"keyword\">if</span>(!nflag)</div><div class=\"line\">\t\t\t<span class=\"built_in\">puts</span>(<span class=\"string\">\"Stan wins\"</span>);</div><div class=\"line\">\t\t<span class=\"keyword\">else</span></div><div class=\"line\">\t\t\t<span class=\"built_in\">puts</span>(<span class=\"string\">\"Ollie wins\"</span>);</div><div class=\"line\">\t\t\t</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>"},{"title":"poj-1061 扩展欧几里得","date":"2017-03-12T16:03:34.000Z","_content":"\n## 扩展欧几里得\n第一次写扩展欧几里得，感觉最重要的还是最开始就搞懂定理的推导过程，不然会遇到一些坑，在这里简单的mark一下我的理解。 \n\n### 原理\n扩展欧几里得德递归形式和gcd类似，关键在于中途对x,y的处理，重点在理解一下方程的推导：   \n**ax1+by1=gcd(a,b)**  ....1  \n**bx2+ay2=gcd(b,a%b)**  ....2  \n**gcd(a,b)=gcd(b,a%b)**  ....3  \n\n化简可以得到：x1=y2 y1=x2-a/b*y2  之后便不难理解边界条件设为b=0时，最终可以推出来方程1的一组解x0,y0  \n  \n### 推论\n重点在于其得到的推论：**ax+by=c 仅当cMODgcd(a,b)=0 时有解**  \n设 c = k*gcd(a,b)  \n上式可以化简为 a/gcd(a,b)*x + b/gcd(a,b)*y = k   =>  Ax+By=k  \n显然AB互质，因而满足方程的解系为(x0-nB,x0+nA) n为任意整数  \n\n## 题解\n就这道题目来说，我觉得对新手来说坑还是有几个：  \n1. 将追逐问题转化为ax+by=c 的不定方程组的解的问题，即确定a和b.\n2. 将exgcd求得的解转化为原方程的解（判断是否有解），并最小化\n\n### 代码\n```c++\n#include <iostream>\n\n#define ABS(x) (((x)>0)?(x):(-(x)))\n#define LL long long\nusing namespace std;\n\n//ax+by = gcd(a,b)\nvoid exgcd(LL a,LL b,LL &x,LL &y,LL &d)\n{\n\tif(b==0){\n\t\tx = 1; y = 0; d =a;\n\t\treturn;\n\t}\n\texgcd(b,a%b,x,y,d);\n\tLL t=x;\n\tx = y;\n\ty = t - (a/b)*y;\n\treturn;\n}\n\n\nint main()\n{\n\tLL x,y,m,n,l;\n\tcin>>x>>y>>m>>n>>l;\n\tLL v,dis,d,x0,y0;\n\tv  = ABS(m-n);\n\tif(m>n)\n\t\tdis = (y-x+l)%l;\n\telse\n\t\tdis = (x-y+l)%l;\n\t\t\n\texgcd(v,l,x0,y0,d);\n\t\n\tif(d&&dis%d==0){\n\t\tx0 = x0*dis/d;\n\t\tLL t = l/d;\n\t\tx0 = (x0%t+t)%t;\n\t\tcout<<x0<<endl;\n\t}\n\telse{\n\t\tcout<<\"Impossible\"<<endl;\n\t}\n}\n\n```\n","source":"_posts/acm/题解/poj-1061.md","raw":"---\ntitle: poj-1061 扩展欧几里得\ndate: 2017-03-13 00:03:34\ncategories: ACM\ntags:  [数论,题解]\n---\n\n## 扩展欧几里得\n第一次写扩展欧几里得，感觉最重要的还是最开始就搞懂定理的推导过程，不然会遇到一些坑，在这里简单的mark一下我的理解。 \n\n### 原理\n扩展欧几里得德递归形式和gcd类似，关键在于中途对x,y的处理，重点在理解一下方程的推导：   \n**ax1+by1=gcd(a,b)**  ....1  \n**bx2+ay2=gcd(b,a%b)**  ....2  \n**gcd(a,b)=gcd(b,a%b)**  ....3  \n\n化简可以得到：x1=y2 y1=x2-a/b*y2  之后便不难理解边界条件设为b=0时，最终可以推出来方程1的一组解x0,y0  \n  \n### 推论\n重点在于其得到的推论：**ax+by=c 仅当cMODgcd(a,b)=0 时有解**  \n设 c = k*gcd(a,b)  \n上式可以化简为 a/gcd(a,b)*x + b/gcd(a,b)*y = k   =>  Ax+By=k  \n显然AB互质，因而满足方程的解系为(x0-nB,x0+nA) n为任意整数  \n\n## 题解\n就这道题目来说，我觉得对新手来说坑还是有几个：  \n1. 将追逐问题转化为ax+by=c 的不定方程组的解的问题，即确定a和b.\n2. 将exgcd求得的解转化为原方程的解（判断是否有解），并最小化\n\n### 代码\n```c++\n#include <iostream>\n\n#define ABS(x) (((x)>0)?(x):(-(x)))\n#define LL long long\nusing namespace std;\n\n//ax+by = gcd(a,b)\nvoid exgcd(LL a,LL b,LL &x,LL &y,LL &d)\n{\n\tif(b==0){\n\t\tx = 1; y = 0; d =a;\n\t\treturn;\n\t}\n\texgcd(b,a%b,x,y,d);\n\tLL t=x;\n\tx = y;\n\ty = t - (a/b)*y;\n\treturn;\n}\n\n\nint main()\n{\n\tLL x,y,m,n,l;\n\tcin>>x>>y>>m>>n>>l;\n\tLL v,dis,d,x0,y0;\n\tv  = ABS(m-n);\n\tif(m>n)\n\t\tdis = (y-x+l)%l;\n\telse\n\t\tdis = (x-y+l)%l;\n\t\t\n\texgcd(v,l,x0,y0,d);\n\t\n\tif(d&&dis%d==0){\n\t\tx0 = x0*dis/d;\n\t\tLL t = l/d;\n\t\tx0 = (x0%t+t)%t;\n\t\tcout<<x0<<endl;\n\t}\n\telse{\n\t\tcout<<\"Impossible\"<<endl;\n\t}\n}\n\n```\n","slug":"acm/题解/poj-1061","published":1,"updated":"2017-03-24T17:48:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v569i001jacwoyhhetdxe","content":"<h2 id=\"扩展欧几里得\"><a href=\"#扩展欧几里得\" class=\"headerlink\" title=\"扩展欧几里得\"></a>扩展欧几里得</h2><p>第一次写扩展欧几里得，感觉最重要的还是最开始就搞懂定理的推导过程，不然会遇到一些坑，在这里简单的mark一下我的理解。 </p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p>扩展欧几里得德递归形式和gcd类似，关键在于中途对x,y的处理，重点在理解一下方程的推导：<br><strong>ax1+by1=gcd(a,b)</strong>  ….1<br><strong>bx2+ay2=gcd(b,a%b)</strong>  ….2<br><strong>gcd(a,b)=gcd(b,a%b)</strong>  ….3  </p>\n<p>化简可以得到：x1=y2 y1=x2-a/b*y2  之后便不难理解边界条件设为b=0时，最终可以推出来方程1的一组解x0,y0  </p>\n<h3 id=\"推论\"><a href=\"#推论\" class=\"headerlink\" title=\"推论\"></a>推论</h3><p>重点在于其得到的推论：<strong>ax+by=c 仅当cMODgcd(a,b)=0 时有解</strong><br>设 c = k<em>gcd(a,b)<br>上式可以化简为 a/gcd(a,b)</em>x + b/gcd(a,b)*y = k   =&gt;  Ax+By=k<br>显然AB互质，因而满足方程的解系为(x0-nB,x0+nA) n为任意整数  </p>\n<h2 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h2><p>就这道题目来说，我觉得对新手来说坑还是有几个：  </p>\n<ol>\n<li>将追逐问题转化为ax+by=c 的不定方程组的解的问题，即确定a和b.</li>\n<li>将exgcd求得的解转化为原方程的解（判断是否有解），并最小化</li>\n</ol>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ABS(x) (((x)&gt;0)?(x):(-(x)))</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LL long long</span></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//ax+by = gcd(a,b)</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">exgcd</span><span class=\"params\">(LL a,LL b,LL &amp;x,LL &amp;y,LL &amp;d)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">if</span>(b==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tx = <span class=\"number\">1</span>; y = <span class=\"number\">0</span>; d =a;</div><div class=\"line\">\t\t<span class=\"keyword\">return</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\texgcd(b,a%b,x,y,d);</div><div class=\"line\">\tLL t=x;</div><div class=\"line\">\tx = y;</div><div class=\"line\">\ty = t - (a/b)*y;</div><div class=\"line\">\t<span class=\"keyword\">return</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\tLL x,y,m,n,l;</div><div class=\"line\">\t<span class=\"built_in\">cin</span>&gt;&gt;x&gt;&gt;y&gt;&gt;m&gt;&gt;n&gt;&gt;l;</div><div class=\"line\">\tLL v,dis,d,x0,y0;</div><div class=\"line\">\tv  = ABS(m-n);</div><div class=\"line\">\t<span class=\"keyword\">if</span>(m&gt;n)</div><div class=\"line\">\t\tdis = (y-x+l)%l;</div><div class=\"line\">\t<span class=\"keyword\">else</span></div><div class=\"line\">\t\tdis = (x-y+l)%l;</div><div class=\"line\">\t\t</div><div class=\"line\">\texgcd(v,l,x0,y0,d);</div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"keyword\">if</span>(d&amp;&amp;dis%d==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tx0 = x0*dis/d;</div><div class=\"line\">\t\tLL t = l/d;</div><div class=\"line\">\t\tx0 = (x0%t+t)%t;</div><div class=\"line\">\t\t<span class=\"built_in\">cout</span>&lt;&lt;x0&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">\t\t<span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"Impossible\"</span>&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h2 id=\"扩展欧几里得\"><a href=\"#扩展欧几里得\" class=\"headerlink\" title=\"扩展欧几里得\"></a>扩展欧几里得</h2><p>第一次写扩展欧几里得，感觉最重要的还是最开始就搞懂定理的推导过程，不然会遇到一些坑，在这里简单的mark一下我的理解。 </p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p>扩展欧几里得德递归形式和gcd类似，关键在于中途对x,y的处理，重点在理解一下方程的推导：<br><strong>ax1+by1=gcd(a,b)</strong>  ….1<br><strong>bx2+ay2=gcd(b,a%b)</strong>  ….2<br><strong>gcd(a,b)=gcd(b,a%b)</strong>  ….3  </p>\n<p>化简可以得到：x1=y2 y1=x2-a/b*y2  之后便不难理解边界条件设为b=0时，最终可以推出来方程1的一组解x0,y0  </p>\n<h3 id=\"推论\"><a href=\"#推论\" class=\"headerlink\" title=\"推论\"></a>推论</h3><p>重点在于其得到的推论：<strong>ax+by=c 仅当cMODgcd(a,b)=0 时有解</strong><br>设 c = k<em>gcd(a,b)<br>上式可以化简为 a/gcd(a,b)</em>x + b/gcd(a,b)*y = k   =&gt;  Ax+By=k<br>显然AB互质，因而满足方程的解系为(x0-nB,x0+nA) n为任意整数  </p>\n<h2 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h2><p>就这道题目来说，我觉得对新手来说坑还是有几个：  </p>\n<ol>\n<li>将追逐问题转化为ax+by=c 的不定方程组的解的问题，即确定a和b.</li>\n<li>将exgcd求得的解转化为原方程的解（判断是否有解），并最小化</li>\n</ol>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ABS(x) (((x)&gt;0)?(x):(-(x)))</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LL long long</span></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">//ax+by = gcd(a,b)</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">exgcd</span><span class=\"params\">(LL a,LL b,LL &amp;x,LL &amp;y,LL &amp;d)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">if</span>(b==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tx = <span class=\"number\">1</span>; y = <span class=\"number\">0</span>; d =a;</div><div class=\"line\">\t\t<span class=\"keyword\">return</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\texgcd(b,a%b,x,y,d);</div><div class=\"line\">\tLL t=x;</div><div class=\"line\">\tx = y;</div><div class=\"line\">\ty = t - (a/b)*y;</div><div class=\"line\">\t<span class=\"keyword\">return</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\tLL x,y,m,n,l;</div><div class=\"line\">\t<span class=\"built_in\">cin</span>&gt;&gt;x&gt;&gt;y&gt;&gt;m&gt;&gt;n&gt;&gt;l;</div><div class=\"line\">\tLL v,dis,d,x0,y0;</div><div class=\"line\">\tv  = ABS(m-n);</div><div class=\"line\">\t<span class=\"keyword\">if</span>(m&gt;n)</div><div class=\"line\">\t\tdis = (y-x+l)%l;</div><div class=\"line\">\t<span class=\"keyword\">else</span></div><div class=\"line\">\t\tdis = (x-y+l)%l;</div><div class=\"line\">\t\t</div><div class=\"line\">\texgcd(v,l,x0,y0,d);</div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"keyword\">if</span>(d&amp;&amp;dis%d==<span class=\"number\">0</span>)&#123;</div><div class=\"line\">\t\tx0 = x0*dis/d;</div><div class=\"line\">\t\tLL t = l/d;</div><div class=\"line\">\t\tx0 = (x0%t+t)%t;</div><div class=\"line\">\t\t<span class=\"built_in\">cout</span>&lt;&lt;x0&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\t<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">\t\t<span class=\"built_in\">cout</span>&lt;&lt;<span class=\"string\">\"Impossible\"</span>&lt;&lt;<span class=\"built_in\">endl</span>;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"组合博弈与SG函数","date":"2017-04-03T06:04:03.000Z","_content":"\n## 组合博弈\n\n### 组合博弈的规则（Imaprtial Combinatorial Games）\n 1. 有两名选手  \n 2. 两名选手交替对游戏进行移动(move)，每次一步，选手可以在（一般而言）有限的合法移动集合中任选一种进行移动\n 3. 对于游戏的任何一种可能的局面，合法的移动集合只取决于这个局面本身，不取决于轮到哪名选手操作、以前的任何操作、骰子的点数或者其它什么因素； \n 4. 如果轮到某名选手移动，且这个局面的合法的移动集合为空（也就是说此时无法进行移动），则这名选手负。\n\n### 对NP状态的定义\n1. 无法进行任何移动的局面（也就是terminal position）是P-position；\n2. 可以移动到P-position的局面是N-position；\n3. 所有移动都导致N-position的局面是P-position。\n\n## SG函数\n\n### mex运算\n首先定义mex(minimal excludant)运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如mex{0,1,2,4}=3、mex{2,3,5}=0、mex{}=0。\n\n### SG 函数的定义\n对于一个给定的有向无环图，定义关于图的每个顶点的Sprague-Garundy函数g如下：g(x)=mex{ g(y) | y是x的后继 }。\n\n\n### 分析\n来看一下SG函数的性质。首先，所有的terminal position所对应的顶点，也就是没有出边的顶点，其SG值为0，因为它的后继集合是空集。然后对于一个g(x)=0的顶点x，它的所有后继y都满足g(y)!=0。对于一个g(x)!=0的顶点，必定存在一个后继y满足g(y)=0。  \n\n以上这三句话表明，顶点x所代表的postion是P-position当且仅当g(x)=0（跟P-positioin/N-position的定义的那三句话是完全对应的）。我们通过计算有向无环图的每个顶点的SG值，就可以对每种局面找到必胜策略了\n\n我们可以定义有向图游戏的和(Sum of Graph Games)：设G1、G2、……、Gn是n个有向图游戏，定义游戏G是G1、G2、……、Gn的和(Sum)，游戏G的移动规则是：任选一个子游戏Gi并移动上面的棋子。Sprague-Grundy Theorem就是：g(G)=g(G1)^g(G2)^...^g(Gn)。也就是说，游戏的和的SG函数值是它的所有子游戏的SG函数值的异或。\n\n### 证明\n\n根据上述定义只需要证明SG值为0和不为0时满足P态和N态的性质即可  \n1. 集合为空的时候不存在后继集合，SG值为0\n2. 当g(G)=g(G1)^g(G2)^...^g(Gn)=k 时，必存在g(Gk)，有g(Gk)^k < g(Gk)从而存在对第k个子游戏的一种操作，使g(Gk)'=g(Gk)^k 从而g(G)' = 0\n3. 当g(G)=g(G1)^g(G2)^...^g(Gn)=0时对任意一个子游戏进行操作必得到g(Gk)'<g(Gk)，从而g(G)'!=0 为N态，故g(G)=0时为P态\n\n![](/images/还有这种操作.jpg)\n\n### SG函数的应用\n一个组合博弈分为N个子博弈，组合博弈的SG函数值就是子博弈SG函数值的异或。\n在前面的Nim游戏当中，N个堆的分别的SG值就是当前堆的石子数（可以一次性全部取完）\n\n#### 关于怎么去求SG函数的值   \n根据定义我们知道求SG函数的值有几个关键的点：\n1. 求当前状态的所有后缀状态的SG值\n2. 对所有后缀的SG值进行Mes操作\n\n因此，我们需要从终态状态开始，逐个求SG值，这就要求把局面转化为一个现态到终态递减的值或者在求SG值的时候注意安排现态在所有次态求出后  \n对于Mes操作，先记录每一个后缀状态SG值的出现状况，然后找出第一个未出现的值即可  \n可以用以下代码表示\n```c++\n//f[N]:可改变当前状态的方式，N为方式的种类，f[N]要在getSG之前先预处理  \n//SG[]:0~n的SG函数值  \n//S[]:为x后继状态的集合  \nint f[N],SG[MAXN],S[MAXN];  \nvoid  getSG(int n){  \n    int i,j;  \n    memset(SG,0,sizeof(SG));  \n    //因为SG[0]始终等于0，所以i从1开始  \n    for(i = 1; i <= n; i++){  \n        //每一次都要将上一状态 的 后继集合 重置  \n        memset(S,0,sizeof(S));  \n        for(j = 0; f[j] <= i && j <= N; j++)  \n            S[SG[i-f[j]]] = 1;  //将后继状态的SG函数值进行标记  \n        for(j = 0;; j++) if(!S[j]){   //查询当前后继状态SG值中最小的非零值  \n            SG[i] = j;  \n            break;  \n        }  \n    }  \n}  \n```\n\n对于有一类题SG函数值是存在规律的，对于输入量明显较大的题，可以先打个表找出SG函数的规律，对于另外一种\n就需要把整个SG函数表保存起来\n\n参考资料：\nhttp://www.wutianqi.com/?p=1081","source":"_posts/acm/题解/组合博弈与SG函数.md","raw":"---\ntitle: 组合博弈与SG函数\ndate: 2017-04-03 14:04:03\ntags: [博弈论]\ncategories: ACM\n---\n\n## 组合博弈\n\n### 组合博弈的规则（Imaprtial Combinatorial Games）\n 1. 有两名选手  \n 2. 两名选手交替对游戏进行移动(move)，每次一步，选手可以在（一般而言）有限的合法移动集合中任选一种进行移动\n 3. 对于游戏的任何一种可能的局面，合法的移动集合只取决于这个局面本身，不取决于轮到哪名选手操作、以前的任何操作、骰子的点数或者其它什么因素； \n 4. 如果轮到某名选手移动，且这个局面的合法的移动集合为空（也就是说此时无法进行移动），则这名选手负。\n\n### 对NP状态的定义\n1. 无法进行任何移动的局面（也就是terminal position）是P-position；\n2. 可以移动到P-position的局面是N-position；\n3. 所有移动都导致N-position的局面是P-position。\n\n## SG函数\n\n### mex运算\n首先定义mex(minimal excludant)运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如mex{0,1,2,4}=3、mex{2,3,5}=0、mex{}=0。\n\n### SG 函数的定义\n对于一个给定的有向无环图，定义关于图的每个顶点的Sprague-Garundy函数g如下：g(x)=mex{ g(y) | y是x的后继 }。\n\n\n### 分析\n来看一下SG函数的性质。首先，所有的terminal position所对应的顶点，也就是没有出边的顶点，其SG值为0，因为它的后继集合是空集。然后对于一个g(x)=0的顶点x，它的所有后继y都满足g(y)!=0。对于一个g(x)!=0的顶点，必定存在一个后继y满足g(y)=0。  \n\n以上这三句话表明，顶点x所代表的postion是P-position当且仅当g(x)=0（跟P-positioin/N-position的定义的那三句话是完全对应的）。我们通过计算有向无环图的每个顶点的SG值，就可以对每种局面找到必胜策略了\n\n我们可以定义有向图游戏的和(Sum of Graph Games)：设G1、G2、……、Gn是n个有向图游戏，定义游戏G是G1、G2、……、Gn的和(Sum)，游戏G的移动规则是：任选一个子游戏Gi并移动上面的棋子。Sprague-Grundy Theorem就是：g(G)=g(G1)^g(G2)^...^g(Gn)。也就是说，游戏的和的SG函数值是它的所有子游戏的SG函数值的异或。\n\n### 证明\n\n根据上述定义只需要证明SG值为0和不为0时满足P态和N态的性质即可  \n1. 集合为空的时候不存在后继集合，SG值为0\n2. 当g(G)=g(G1)^g(G2)^...^g(Gn)=k 时，必存在g(Gk)，有g(Gk)^k < g(Gk)从而存在对第k个子游戏的一种操作，使g(Gk)'=g(Gk)^k 从而g(G)' = 0\n3. 当g(G)=g(G1)^g(G2)^...^g(Gn)=0时对任意一个子游戏进行操作必得到g(Gk)'<g(Gk)，从而g(G)'!=0 为N态，故g(G)=0时为P态\n\n![](/images/还有这种操作.jpg)\n\n### SG函数的应用\n一个组合博弈分为N个子博弈，组合博弈的SG函数值就是子博弈SG函数值的异或。\n在前面的Nim游戏当中，N个堆的分别的SG值就是当前堆的石子数（可以一次性全部取完）\n\n#### 关于怎么去求SG函数的值   \n根据定义我们知道求SG函数的值有几个关键的点：\n1. 求当前状态的所有后缀状态的SG值\n2. 对所有后缀的SG值进行Mes操作\n\n因此，我们需要从终态状态开始，逐个求SG值，这就要求把局面转化为一个现态到终态递减的值或者在求SG值的时候注意安排现态在所有次态求出后  \n对于Mes操作，先记录每一个后缀状态SG值的出现状况，然后找出第一个未出现的值即可  \n可以用以下代码表示\n```c++\n//f[N]:可改变当前状态的方式，N为方式的种类，f[N]要在getSG之前先预处理  \n//SG[]:0~n的SG函数值  \n//S[]:为x后继状态的集合  \nint f[N],SG[MAXN],S[MAXN];  \nvoid  getSG(int n){  \n    int i,j;  \n    memset(SG,0,sizeof(SG));  \n    //因为SG[0]始终等于0，所以i从1开始  \n    for(i = 1; i <= n; i++){  \n        //每一次都要将上一状态 的 后继集合 重置  \n        memset(S,0,sizeof(S));  \n        for(j = 0; f[j] <= i && j <= N; j++)  \n            S[SG[i-f[j]]] = 1;  //将后继状态的SG函数值进行标记  \n        for(j = 0;; j++) if(!S[j]){   //查询当前后继状态SG值中最小的非零值  \n            SG[i] = j;  \n            break;  \n        }  \n    }  \n}  \n```\n\n对于有一类题SG函数值是存在规律的，对于输入量明显较大的题，可以先打个表找出SG函数的规律，对于另外一种\n就需要把整个SG函数表保存起来\n\n参考资料：\nhttp://www.wutianqi.com/?p=1081","slug":"acm/题解/组合博弈与SG函数","published":1,"updated":"2017-04-03T07:30:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v569x001macwor6ld2x8t","content":"<h2 id=\"组合博弈\"><a href=\"#组合博弈\" class=\"headerlink\" title=\"组合博弈\"></a>组合博弈</h2><h3 id=\"组合博弈的规则（Imaprtial-Combinatorial-Games）\"><a href=\"#组合博弈的规则（Imaprtial-Combinatorial-Games）\" class=\"headerlink\" title=\"组合博弈的规则（Imaprtial Combinatorial Games）\"></a>组合博弈的规则（Imaprtial Combinatorial Games）</h3><ol>\n<li>有两名选手  </li>\n<li>两名选手交替对游戏进行移动(move)，每次一步，选手可以在（一般而言）有限的合法移动集合中任选一种进行移动</li>\n<li>对于游戏的任何一种可能的局面，合法的移动集合只取决于这个局面本身，不取决于轮到哪名选手操作、以前的任何操作、骰子的点数或者其它什么因素； </li>\n<li>如果轮到某名选手移动，且这个局面的合法的移动集合为空（也就是说此时无法进行移动），则这名选手负。</li>\n</ol>\n<h3 id=\"对NP状态的定义\"><a href=\"#对NP状态的定义\" class=\"headerlink\" title=\"对NP状态的定义\"></a>对NP状态的定义</h3><ol>\n<li>无法进行任何移动的局面（也就是terminal position）是P-position；</li>\n<li>可以移动到P-position的局面是N-position；</li>\n<li>所有移动都导致N-position的局面是P-position。</li>\n</ol>\n<h2 id=\"SG函数\"><a href=\"#SG函数\" class=\"headerlink\" title=\"SG函数\"></a>SG函数</h2><h3 id=\"mex运算\"><a href=\"#mex运算\" class=\"headerlink\" title=\"mex运算\"></a>mex运算</h3><p>首先定义mex(minimal excludant)运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如mex{0,1,2,4}=3、mex{2,3,5}=0、mex{}=0。</p>\n<h3 id=\"SG-函数的定义\"><a href=\"#SG-函数的定义\" class=\"headerlink\" title=\"SG 函数的定义\"></a>SG 函数的定义</h3><p>对于一个给定的有向无环图，定义关于图的每个顶点的Sprague-Garundy函数g如下：g(x)=mex{ g(y) | y是x的后继 }。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>来看一下SG函数的性质。首先，所有的terminal position所对应的顶点，也就是没有出边的顶点，其SG值为0，因为它的后继集合是空集。然后对于一个g(x)=0的顶点x，它的所有后继y都满足g(y)!=0。对于一个g(x)!=0的顶点，必定存在一个后继y满足g(y)=0。  </p>\n<p>以上这三句话表明，顶点x所代表的postion是P-position当且仅当g(x)=0（跟P-positioin/N-position的定义的那三句话是完全对应的）。我们通过计算有向无环图的每个顶点的SG值，就可以对每种局面找到必胜策略了</p>\n<p>我们可以定义有向图游戏的和(Sum of Graph Games)：设G1、G2、……、Gn是n个有向图游戏，定义游戏G是G1、G2、……、Gn的和(Sum)，游戏G的移动规则是：任选一个子游戏Gi并移动上面的棋子。Sprague-Grundy Theorem就是：g(G)=g(G1)^g(G2)^…^g(Gn)。也就是说，游戏的和的SG函数值是它的所有子游戏的SG函数值的异或。</p>\n<h3 id=\"证明\"><a href=\"#证明\" class=\"headerlink\" title=\"证明\"></a>证明</h3><p>根据上述定义只需要证明SG值为0和不为0时满足P态和N态的性质即可  </p>\n<ol>\n<li>集合为空的时候不存在后继集合，SG值为0</li>\n<li>当g(G)=g(G1)^g(G2)^…^g(Gn)=k 时，必存在g(Gk)，有g(Gk)^k &lt; g(Gk)从而存在对第k个子游戏的一种操作，使g(Gk)’=g(Gk)^k 从而g(G)’ = 0</li>\n<li>当g(G)=g(G1)^g(G2)^…^g(Gn)=0时对任意一个子游戏进行操作必得到g(Gk)’&lt;g(Gk)，从而g(G)’!=0 为N态，故g(G)=0时为P态</li>\n</ol>\n<p><img src=\"/images/还有这种操作.jpg\" alt=\"\"></p>\n<h3 id=\"SG函数的应用\"><a href=\"#SG函数的应用\" class=\"headerlink\" title=\"SG函数的应用\"></a>SG函数的应用</h3><p>一个组合博弈分为N个子博弈，组合博弈的SG函数值就是子博弈SG函数值的异或。<br>在前面的Nim游戏当中，N个堆的分别的SG值就是当前堆的石子数（可以一次性全部取完）</p>\n<h4 id=\"关于怎么去求SG函数的值\"><a href=\"#关于怎么去求SG函数的值\" class=\"headerlink\" title=\"关于怎么去求SG函数的值\"></a>关于怎么去求SG函数的值</h4><p>根据定义我们知道求SG函数的值有几个关键的点：</p>\n<ol>\n<li>求当前状态的所有后缀状态的SG值</li>\n<li>对所有后缀的SG值进行Mes操作</li>\n</ol>\n<p>因此，我们需要从终态状态开始，逐个求SG值，这就要求把局面转化为一个现态到终态递减的值或者在求SG值的时候注意安排现态在所有次态求出后<br>对于Mes操作，先记录每一个后缀状态SG值的出现状况，然后找出第一个未出现的值即可<br>可以用以下代码表示<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//f[N]:可改变当前状态的方式，N为方式的种类，f[N]要在getSG之前先预处理  </span></div><div class=\"line\"><span class=\"comment\">//SG[]:0~n的SG函数值  </span></div><div class=\"line\"><span class=\"comment\">//S[]:为x后继状态的集合  </span></div><div class=\"line\"><span class=\"keyword\">int</span> f[N],SG[MAXN],S[MAXN];  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>  <span class=\"title\">getSG</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span>&#123;  </div><div class=\"line\">    <span class=\"keyword\">int</span> i,j;  </div><div class=\"line\">    <span class=\"built_in\">memset</span>(SG,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(SG));  </div><div class=\"line\">    <span class=\"comment\">//因为SG[0]始终等于0，所以i从1开始  </span></div><div class=\"line\">    <span class=\"keyword\">for</span>(i = <span class=\"number\">1</span>; i &lt;= n; i++)&#123;  </div><div class=\"line\">        <span class=\"comment\">//每一次都要将上一状态 的 后继集合 重置  </span></div><div class=\"line\">        <span class=\"built_in\">memset</span>(S,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(S));  </div><div class=\"line\">        <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>; f[j] &lt;= i &amp;&amp; j &lt;= N; j++)  </div><div class=\"line\">            S[SG[i-f[j]]] = <span class=\"number\">1</span>;  <span class=\"comment\">//将后继状态的SG函数值进行标记  </span></div><div class=\"line\">        <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>;; j++) <span class=\"keyword\">if</span>(!S[j])&#123;   <span class=\"comment\">//查询当前后继状态SG值中最小的非零值  </span></div><div class=\"line\">            SG[i] = j;  </div><div class=\"line\">            <span class=\"keyword\">break</span>;  </div><div class=\"line\">        &#125;  </div><div class=\"line\">    &#125;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>对于有一类题SG函数值是存在规律的，对于输入量明显较大的题，可以先打个表找出SG函数的规律，对于另外一种<br>就需要把整个SG函数表保存起来</p>\n<p>参考资料：<br><a href=\"http://www.wutianqi.com/?p=1081\" target=\"_blank\" rel=\"external\">http://www.wutianqi.com/?p=1081</a></p>\n","excerpt":"","more":"<h2 id=\"组合博弈\"><a href=\"#组合博弈\" class=\"headerlink\" title=\"组合博弈\"></a>组合博弈</h2><h3 id=\"组合博弈的规则（Imaprtial-Combinatorial-Games）\"><a href=\"#组合博弈的规则（Imaprtial-Combinatorial-Games）\" class=\"headerlink\" title=\"组合博弈的规则（Imaprtial Combinatorial Games）\"></a>组合博弈的规则（Imaprtial Combinatorial Games）</h3><ol>\n<li>有两名选手  </li>\n<li>两名选手交替对游戏进行移动(move)，每次一步，选手可以在（一般而言）有限的合法移动集合中任选一种进行移动</li>\n<li>对于游戏的任何一种可能的局面，合法的移动集合只取决于这个局面本身，不取决于轮到哪名选手操作、以前的任何操作、骰子的点数或者其它什么因素； </li>\n<li>如果轮到某名选手移动，且这个局面的合法的移动集合为空（也就是说此时无法进行移动），则这名选手负。</li>\n</ol>\n<h3 id=\"对NP状态的定义\"><a href=\"#对NP状态的定义\" class=\"headerlink\" title=\"对NP状态的定义\"></a>对NP状态的定义</h3><ol>\n<li>无法进行任何移动的局面（也就是terminal position）是P-position；</li>\n<li>可以移动到P-position的局面是N-position；</li>\n<li>所有移动都导致N-position的局面是P-position。</li>\n</ol>\n<h2 id=\"SG函数\"><a href=\"#SG函数\" class=\"headerlink\" title=\"SG函数\"></a>SG函数</h2><h3 id=\"mex运算\"><a href=\"#mex运算\" class=\"headerlink\" title=\"mex运算\"></a>mex运算</h3><p>首先定义mex(minimal excludant)运算，这是施加于一个集合的运算，表示最小的不属于这个集合的非负整数。例如mex{0,1,2,4}=3、mex{2,3,5}=0、mex{}=0。</p>\n<h3 id=\"SG-函数的定义\"><a href=\"#SG-函数的定义\" class=\"headerlink\" title=\"SG 函数的定义\"></a>SG 函数的定义</h3><p>对于一个给定的有向无环图，定义关于图的每个顶点的Sprague-Garundy函数g如下：g(x)=mex{ g(y) | y是x的后继 }。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>来看一下SG函数的性质。首先，所有的terminal position所对应的顶点，也就是没有出边的顶点，其SG值为0，因为它的后继集合是空集。然后对于一个g(x)=0的顶点x，它的所有后继y都满足g(y)!=0。对于一个g(x)!=0的顶点，必定存在一个后继y满足g(y)=0。  </p>\n<p>以上这三句话表明，顶点x所代表的postion是P-position当且仅当g(x)=0（跟P-positioin/N-position的定义的那三句话是完全对应的）。我们通过计算有向无环图的每个顶点的SG值，就可以对每种局面找到必胜策略了</p>\n<p>我们可以定义有向图游戏的和(Sum of Graph Games)：设G1、G2、……、Gn是n个有向图游戏，定义游戏G是G1、G2、……、Gn的和(Sum)，游戏G的移动规则是：任选一个子游戏Gi并移动上面的棋子。Sprague-Grundy Theorem就是：g(G)=g(G1)^g(G2)^…^g(Gn)。也就是说，游戏的和的SG函数值是它的所有子游戏的SG函数值的异或。</p>\n<h3 id=\"证明\"><a href=\"#证明\" class=\"headerlink\" title=\"证明\"></a>证明</h3><p>根据上述定义只需要证明SG值为0和不为0时满足P态和N态的性质即可  </p>\n<ol>\n<li>集合为空的时候不存在后继集合，SG值为0</li>\n<li>当g(G)=g(G1)^g(G2)^…^g(Gn)=k 时，必存在g(Gk)，有g(Gk)^k &lt; g(Gk)从而存在对第k个子游戏的一种操作，使g(Gk)’=g(Gk)^k 从而g(G)’ = 0</li>\n<li>当g(G)=g(G1)^g(G2)^…^g(Gn)=0时对任意一个子游戏进行操作必得到g(Gk)’&lt;g(Gk)，从而g(G)’!=0 为N态，故g(G)=0时为P态</li>\n</ol>\n<p><img src=\"/images/还有这种操作.jpg\" alt=\"\"></p>\n<h3 id=\"SG函数的应用\"><a href=\"#SG函数的应用\" class=\"headerlink\" title=\"SG函数的应用\"></a>SG函数的应用</h3><p>一个组合博弈分为N个子博弈，组合博弈的SG函数值就是子博弈SG函数值的异或。<br>在前面的Nim游戏当中，N个堆的分别的SG值就是当前堆的石子数（可以一次性全部取完）</p>\n<h4 id=\"关于怎么去求SG函数的值\"><a href=\"#关于怎么去求SG函数的值\" class=\"headerlink\" title=\"关于怎么去求SG函数的值\"></a>关于怎么去求SG函数的值</h4><p>根据定义我们知道求SG函数的值有几个关键的点：</p>\n<ol>\n<li>求当前状态的所有后缀状态的SG值</li>\n<li>对所有后缀的SG值进行Mes操作</li>\n</ol>\n<p>因此，我们需要从终态状态开始，逐个求SG值，这就要求把局面转化为一个现态到终态递减的值或者在求SG值的时候注意安排现态在所有次态求出后<br>对于Mes操作，先记录每一个后缀状态SG值的出现状况，然后找出第一个未出现的值即可<br>可以用以下代码表示<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//f[N]:可改变当前状态的方式，N为方式的种类，f[N]要在getSG之前先预处理  </span></div><div class=\"line\"><span class=\"comment\">//SG[]:0~n的SG函数值  </span></div><div class=\"line\"><span class=\"comment\">//S[]:为x后继状态的集合  </span></div><div class=\"line\"><span class=\"keyword\">int</span> f[N],SG[MAXN],S[MAXN];  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>  <span class=\"title\">getSG</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span>&#123;  </div><div class=\"line\">    <span class=\"keyword\">int</span> i,j;  </div><div class=\"line\">    <span class=\"built_in\">memset</span>(SG,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(SG));  </div><div class=\"line\">    <span class=\"comment\">//因为SG[0]始终等于0，所以i从1开始  </span></div><div class=\"line\">    <span class=\"keyword\">for</span>(i = <span class=\"number\">1</span>; i &lt;= n; i++)&#123;  </div><div class=\"line\">        <span class=\"comment\">//每一次都要将上一状态 的 后继集合 重置  </span></div><div class=\"line\">        <span class=\"built_in\">memset</span>(S,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(S));  </div><div class=\"line\">        <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>; f[j] &lt;= i &amp;&amp; j &lt;= N; j++)  </div><div class=\"line\">            S[SG[i-f[j]]] = <span class=\"number\">1</span>;  <span class=\"comment\">//将后继状态的SG函数值进行标记  </span></div><div class=\"line\">        <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>;; j++) <span class=\"keyword\">if</span>(!S[j])&#123;   <span class=\"comment\">//查询当前后继状态SG值中最小的非零值  </span></div><div class=\"line\">            SG[i] = j;  </div><div class=\"line\">            <span class=\"keyword\">break</span>;  </div><div class=\"line\">        &#125;  </div><div class=\"line\">    &#125;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>对于有一类题SG函数值是存在规律的，对于输入量明显较大的题，可以先打个表找出SG函数的规律，对于另外一种<br>就需要把整个SG函数表保存起来</p>\n<p>参考资料：<br><a href=\"http://www.wutianqi.com/?p=1081\">http://www.wutianqi.com/?p=1081</a></p>\n"},{"title":"TensorFlow 学习笔记1","date":"2018-03-26T02:10:32.000Z","mathjax":true,"_content":"# TensorFlow 学习笔记 #1\n## TensorFlow Basics\n### Graphs and Sessions\n首先，需要和普通python程序区别出来的是，tensorflow将计算的定义和具体执行过程分离开来，个人认为这有点像函数式中的求值运算。  \n\n不过tensorflow的特点在于其把所依赖的所有计算转换成一个数据流图（dag）\n\n![数据流图](./images/tf/tensor_data_flow_graph.png)\n\n1. 根据输入构成数据流图\n2. 创建会话，执行操作\n\n用图的优点有如下几个：  \n1. 能够保存计算结果。只会运行你所期望得到值的子图。\n2.  易于分布任务，进行分布式的计算\n3.  Break computation into small, differential pieces to facilitate auto-differentiation\n4.  Many common machine learning models are taught and visualized as directed graphs\n\n**何为TensorFlow?**  \n**Tensor**: An n-dimensional array  \n0-d tensor: scalar (number)   \n1-d tensor: vector  \n2-d tensor: matrix  \n\n## Tensorflow ops\n### TensorBorad\nTensorborad 使用通过将图的节点信息和图中的操作记入event files当中来完成整个流程的可视化，使用如下代码创建event files以及停止记录\n```python\n# use tf.get_default_graph() to get default graph\nwriter = tf.summary.FileWriter([logdir], [graph])\n# ...\nwriter.close()\n```\n之后运行python代码并打开tensorboard\n```bash\n$ python3 [my_program.py] \n$ tensorboard --logdir=\"./graphs\" --port 6006\n```\n但是我们此时看到的图每个节点我们无法对上名字，这就要在定义图的时候给出其的名字\n```python\na = tf.constant(2, name=\"a\")\nb = tf.constant(2, name=\"b\")\nx = tf.add(a, b, name=\"add\")\n```\n\n### Some useful tricks\n#### 查看protobuf\n常数存储在函数的定义当中，通过查看图的protobuf(protocol buffer)来查看图定义当中的内容。\n```python\nimport tensorflow as tf\n\nmy_const = tf.constant([1.0, 2.0], name=\"my_const\")\nprint(tf.get_default_graph().as_graph_def())\n```\nOutput :\n```json\nnode {\n  name: \"my_const\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"\n      }\n    }\n  }\n}\nversions {\n  producer: 24\n}\n```\n\n#### 变量的声明和初始化\n为了变量共享的方便 官方推荐使用tf.get_variable方法\n```python\ns = tf.get_variable(\"scalar\", initializer=tf.constant(2)) \nm = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\nW = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n```\n同时可以较简单的初始化变量\n```python\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n```\n\n#### Assign a variable\n观察如下程序\n```python\nW = tf.Variable(10)\nW.assign(100)\nwith tf.Session() as sess:\n\tsess.run(W.initializer)\n\tprint(W.eval()) # >> 10\n```\n结果输出是10，但为什么不是100呢。注意的是，之前也说过，tensorflow的声明和运行是分离的，W.assign(100)创建了一个assign操作，但是我们并没有运行它，所以应该按照如下写\n```python\nW = tf.Variable(10)\nassign_op = W.assign(100)\nwith tf.Session() as sess:\n\tsess.run(assign_op)\n\tprint(W.eval()) # >> 100\n```\n\n#### Sessions\n会话独自保存值，因而假如有两个不同的会话对同一个变量进行操作，其得到最终的值也有可能不相同。  \n有时候为了方便可以使用interactive session来隐式地run session\n```python\nsess = tf.InteractiveSession()\na = tf.constant(5.0)\nb = tf.constant(6.0)\nc = a * b\nprint(c.eval()) # we can use 'c.eval()' without explicitly stating a session\nsess.close()\n```\ntf.get_default_session()返回当前进程的默认session\n\n#### the trap of lazy loading\n考虑如下代码有什么不好的地方\n```\nx = tf.Variable(10, name='x')\ny = tf.Variable(20, name='y')\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter('graphs/lazy_loading', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(tf.add(x, y))\n\tprint(tf.get_default_graph().as_graph_def()) \n\twriter.close()\n```\nsess.run(tf.add(x, y))这一句会将tf.add(x,y)这个操作创建10次，造成网络的大量冗余\n考虑解决方案：\n1. 总是将操作的定义与执行分离开来\n2. 使用python的@property来保证你的函数只被调用一次","source":"_posts/machinelearning/tensorflow_notes/note1.md","raw":"---\ntitle: TensorFlow 学习笔记1 \ndate: 2018-03-26 10:10:32\ntags: [tensorflow]\nmathjax: true\n---\n# TensorFlow 学习笔记 #1\n## TensorFlow Basics\n### Graphs and Sessions\n首先，需要和普通python程序区别出来的是，tensorflow将计算的定义和具体执行过程分离开来，个人认为这有点像函数式中的求值运算。  \n\n不过tensorflow的特点在于其把所依赖的所有计算转换成一个数据流图（dag）\n\n![数据流图](./images/tf/tensor_data_flow_graph.png)\n\n1. 根据输入构成数据流图\n2. 创建会话，执行操作\n\n用图的优点有如下几个：  \n1. 能够保存计算结果。只会运行你所期望得到值的子图。\n2.  易于分布任务，进行分布式的计算\n3.  Break computation into small, differential pieces to facilitate auto-differentiation\n4.  Many common machine learning models are taught and visualized as directed graphs\n\n**何为TensorFlow?**  \n**Tensor**: An n-dimensional array  \n0-d tensor: scalar (number)   \n1-d tensor: vector  \n2-d tensor: matrix  \n\n## Tensorflow ops\n### TensorBorad\nTensorborad 使用通过将图的节点信息和图中的操作记入event files当中来完成整个流程的可视化，使用如下代码创建event files以及停止记录\n```python\n# use tf.get_default_graph() to get default graph\nwriter = tf.summary.FileWriter([logdir], [graph])\n# ...\nwriter.close()\n```\n之后运行python代码并打开tensorboard\n```bash\n$ python3 [my_program.py] \n$ tensorboard --logdir=\"./graphs\" --port 6006\n```\n但是我们此时看到的图每个节点我们无法对上名字，这就要在定义图的时候给出其的名字\n```python\na = tf.constant(2, name=\"a\")\nb = tf.constant(2, name=\"b\")\nx = tf.add(a, b, name=\"add\")\n```\n\n### Some useful tricks\n#### 查看protobuf\n常数存储在函数的定义当中，通过查看图的protobuf(protocol buffer)来查看图定义当中的内容。\n```python\nimport tensorflow as tf\n\nmy_const = tf.constant([1.0, 2.0], name=\"my_const\")\nprint(tf.get_default_graph().as_graph_def())\n```\nOutput :\n```json\nnode {\n  name: \"my_const\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"\n      }\n    }\n  }\n}\nversions {\n  producer: 24\n}\n```\n\n#### 变量的声明和初始化\n为了变量共享的方便 官方推荐使用tf.get_variable方法\n```python\ns = tf.get_variable(\"scalar\", initializer=tf.constant(2)) \nm = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\nW = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n```\n同时可以较简单的初始化变量\n```python\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n```\n\n#### Assign a variable\n观察如下程序\n```python\nW = tf.Variable(10)\nW.assign(100)\nwith tf.Session() as sess:\n\tsess.run(W.initializer)\n\tprint(W.eval()) # >> 10\n```\n结果输出是10，但为什么不是100呢。注意的是，之前也说过，tensorflow的声明和运行是分离的，W.assign(100)创建了一个assign操作，但是我们并没有运行它，所以应该按照如下写\n```python\nW = tf.Variable(10)\nassign_op = W.assign(100)\nwith tf.Session() as sess:\n\tsess.run(assign_op)\n\tprint(W.eval()) # >> 100\n```\n\n#### Sessions\n会话独自保存值，因而假如有两个不同的会话对同一个变量进行操作，其得到最终的值也有可能不相同。  \n有时候为了方便可以使用interactive session来隐式地run session\n```python\nsess = tf.InteractiveSession()\na = tf.constant(5.0)\nb = tf.constant(6.0)\nc = a * b\nprint(c.eval()) # we can use 'c.eval()' without explicitly stating a session\nsess.close()\n```\ntf.get_default_session()返回当前进程的默认session\n\n#### the trap of lazy loading\n考虑如下代码有什么不好的地方\n```\nx = tf.Variable(10, name='x')\ny = tf.Variable(20, name='y')\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter('graphs/lazy_loading', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(tf.add(x, y))\n\tprint(tf.get_default_graph().as_graph_def()) \n\twriter.close()\n```\nsess.run(tf.add(x, y))这一句会将tf.add(x,y)这个操作创建10次，造成网络的大量冗余\n考虑解决方案：\n1. 总是将操作的定义与执行分离开来\n2. 使用python的@property来保证你的函数只被调用一次","slug":"machinelearning/tensorflow_notes/note1","published":1,"updated":"2018-04-16T06:28:48.033Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v569x001qacwo12qoi16v","content":"<h1 id=\"TensorFlow-学习笔记-1\"><a href=\"#TensorFlow-学习笔记-1\" class=\"headerlink\" title=\"TensorFlow 学习笔记 #1\"></a>TensorFlow 学习笔记 #1</h1><h2 id=\"TensorFlow-Basics\"><a href=\"#TensorFlow-Basics\" class=\"headerlink\" title=\"TensorFlow Basics\"></a>TensorFlow Basics</h2><h3 id=\"Graphs-and-Sessions\"><a href=\"#Graphs-and-Sessions\" class=\"headerlink\" title=\"Graphs and Sessions\"></a>Graphs and Sessions</h3><p>首先，需要和普通python程序区别出来的是，tensorflow将计算的定义和具体执行过程分离开来，个人认为这有点像函数式中的求值运算。  </p>\n<p>不过tensorflow的特点在于其把所依赖的所有计算转换成一个数据流图（dag）</p>\n<p><img src=\"./images/tf/tensor_data_flow_graph.png\" alt=\"数据流图\"></p>\n<ol>\n<li>根据输入构成数据流图</li>\n<li>创建会话，执行操作</li>\n</ol>\n<p>用图的优点有如下几个：  </p>\n<ol>\n<li>能够保存计算结果。只会运行你所期望得到值的子图。</li>\n<li>易于分布任务，进行分布式的计算</li>\n<li>Break computation into small, differential pieces to facilitate auto-differentiation</li>\n<li>Many common machine learning models are taught and visualized as directed graphs</li>\n</ol>\n<p><strong>何为TensorFlow?</strong><br><strong>Tensor</strong>: An n-dimensional array<br>0-d tensor: scalar (number)<br>1-d tensor: vector<br>2-d tensor: matrix  </p>\n<h2 id=\"Tensorflow-ops\"><a href=\"#Tensorflow-ops\" class=\"headerlink\" title=\"Tensorflow ops\"></a>Tensorflow ops</h2><h3 id=\"TensorBorad\"><a href=\"#TensorBorad\" class=\"headerlink\" title=\"TensorBorad\"></a>TensorBorad</h3><p>Tensorborad 使用通过将图的节点信息和图中的操作记入event files当中来完成整个流程的可视化，使用如下代码创建event files以及停止记录<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># use tf.get_default_graph() to get default graph</span></div><div class=\"line\">writer = tf.summary.FileWriter([logdir], [graph])</div><div class=\"line\"><span class=\"comment\"># ...</span></div><div class=\"line\">writer.close()</div></pre></td></tr></table></figure></p>\n<p>之后运行python代码并打开tensorboard<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ python3 [my_program.py] </div><div class=\"line\">$ tensorboard --logdir=<span class=\"string\">\"./graphs\"</span> --port 6006</div></pre></td></tr></table></figure></p>\n<p>但是我们此时看到的图每个节点我们无法对上名字，这就要在定义图的时候给出其的名字<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">a = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"a\"</span>)</div><div class=\"line\">b = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"b\"</span>)</div><div class=\"line\">x = tf.add(a, b, name=<span class=\"string\">\"add\"</span>)</div></pre></td></tr></table></figure></p>\n<h3 id=\"Some-useful-tricks\"><a href=\"#Some-useful-tricks\" class=\"headerlink\" title=\"Some useful tricks\"></a>Some useful tricks</h3><h4 id=\"查看protobuf\"><a href=\"#查看protobuf\" class=\"headerlink\" title=\"查看protobuf\"></a>查看protobuf</h4><p>常数存储在函数的定义当中，通过查看图的protobuf(protocol buffer)来查看图定义当中的内容。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</div><div class=\"line\"></div><div class=\"line\">my_const = tf.constant([<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>], name=<span class=\"string\">\"my_const\"</span>)</div><div class=\"line\">print(tf.get_default_graph().as_graph_def())</div></pre></td></tr></table></figure></p>\n<p>Output :<br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">node &#123;</div><div class=\"line\">  name: \"my_const\"</div><div class=\"line\">  op: \"Const\"</div><div class=\"line\">  attr &#123;</div><div class=\"line\">    key: \"dtype\"</div><div class=\"line\">    value &#123;</div><div class=\"line\">      type: DT_FLOAT</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">  attr &#123;</div><div class=\"line\">    key: \"value\"</div><div class=\"line\">    value &#123;</div><div class=\"line\">      tensor &#123;</div><div class=\"line\">        dtype: DT_FLOAT</div><div class=\"line\">        tensor_shape &#123;</div><div class=\"line\">          dim &#123;</div><div class=\"line\">            size: 2</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">versions &#123;</div><div class=\"line\">  producer: 24</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"变量的声明和初始化\"><a href=\"#变量的声明和初始化\" class=\"headerlink\" title=\"变量的声明和初始化\"></a>变量的声明和初始化</h4><p>为了变量共享的方便 官方推荐使用tf.get_variable方法<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">s = tf.get_variable(<span class=\"string\">\"scalar\"</span>, initializer=tf.constant(<span class=\"number\">2</span>)) </div><div class=\"line\">m = tf.get_variable(<span class=\"string\">\"matrix\"</span>, initializer=tf.constant([[<span class=\"number\">0</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">3</span>]]))</div><div class=\"line\">W = tf.get_variable(<span class=\"string\">\"big_matrix\"</span>, shape=(<span class=\"number\">784</span>, <span class=\"number\">10</span>), initializer=tf.zeros_initializer())</div></pre></td></tr></table></figure></p>\n<p>同时可以较简单的初始化变量<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\tsess.run(tf.global_variables_initializer())</div></pre></td></tr></table></figure></p>\n<h4 id=\"Assign-a-variable\"><a href=\"#Assign-a-variable\" class=\"headerlink\" title=\"Assign a variable\"></a>Assign a variable</h4><p>观察如下程序<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">W = tf.Variable(<span class=\"number\">10</span>)</div><div class=\"line\">W.assign(<span class=\"number\">100</span>)</div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\tsess.run(W.initializer)</div><div class=\"line\">\tprint(W.eval()) <span class=\"comment\"># &gt;&gt; 10</span></div></pre></td></tr></table></figure></p>\n<p>结果输出是10，但为什么不是100呢。注意的是，之前也说过，tensorflow的声明和运行是分离的，W.assign(100)创建了一个assign操作，但是我们并没有运行它，所以应该按照如下写<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">W = tf.Variable(<span class=\"number\">10</span>)</div><div class=\"line\">assign_op = W.assign(<span class=\"number\">100</span>)</div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\tsess.run(assign_op)</div><div class=\"line\">\tprint(W.eval()) <span class=\"comment\"># &gt;&gt; 100</span></div></pre></td></tr></table></figure></p>\n<h4 id=\"Sessions\"><a href=\"#Sessions\" class=\"headerlink\" title=\"Sessions\"></a>Sessions</h4><p>会话独自保存值，因而假如有两个不同的会话对同一个变量进行操作，其得到最终的值也有可能不相同。<br>有时候为了方便可以使用interactive session来隐式地run session<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">sess = tf.InteractiveSession()</div><div class=\"line\">a = tf.constant(<span class=\"number\">5.0</span>)</div><div class=\"line\">b = tf.constant(<span class=\"number\">6.0</span>)</div><div class=\"line\">c = a * b</div><div class=\"line\">print(c.eval()) <span class=\"comment\"># we can use 'c.eval()' without explicitly stating a session</span></div><div class=\"line\">sess.close()</div></pre></td></tr></table></figure></p>\n<p>tf.get_default_session()返回当前进程的默认session</p>\n<h4 id=\"the-trap-of-lazy-loading\"><a href=\"#the-trap-of-lazy-loading\" class=\"headerlink\" title=\"the trap of lazy loading\"></a>the trap of lazy loading</h4><p>考虑如下代码有什么不好的地方<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">x = tf.Variable(10, name=&apos;x&apos;)</div><div class=\"line\">y = tf.Variable(20, name=&apos;y&apos;)</div><div class=\"line\"></div><div class=\"line\">with tf.Session() as sess:</div><div class=\"line\">\tsess.run(tf.global_variables_initializer())</div><div class=\"line\">\twriter = tf.summary.FileWriter(&apos;graphs/lazy_loading&apos;, sess.graph)</div><div class=\"line\">\tfor _ in range(10):</div><div class=\"line\">\t\tsess.run(tf.add(x, y))</div><div class=\"line\">\tprint(tf.get_default_graph().as_graph_def()) </div><div class=\"line\">\twriter.close()</div></pre></td></tr></table></figure></p>\n<p>sess.run(tf.add(x, y))这一句会将tf.add(x,y)这个操作创建10次，造成网络的大量冗余<br>考虑解决方案：</p>\n<ol>\n<li>总是将操作的定义与执行分离开来</li>\n<li>使用python的@property来保证你的函数只被调用一次</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"TensorFlow-学习笔记-1\"><a href=\"#TensorFlow-学习笔记-1\" class=\"headerlink\" title=\"TensorFlow 学习笔记 #1\"></a>TensorFlow 学习笔记 #1</h1><h2 id=\"TensorFlow-Basics\"><a href=\"#TensorFlow-Basics\" class=\"headerlink\" title=\"TensorFlow Basics\"></a>TensorFlow Basics</h2><h3 id=\"Graphs-and-Sessions\"><a href=\"#Graphs-and-Sessions\" class=\"headerlink\" title=\"Graphs and Sessions\"></a>Graphs and Sessions</h3><p>首先，需要和普通python程序区别出来的是，tensorflow将计算的定义和具体执行过程分离开来，个人认为这有点像函数式中的求值运算。  </p>\n<p>不过tensorflow的特点在于其把所依赖的所有计算转换成一个数据流图（dag）</p>\n<p><img src=\"./images/tf/tensor_data_flow_graph.png\" alt=\"数据流图\"></p>\n<ol>\n<li>根据输入构成数据流图</li>\n<li>创建会话，执行操作</li>\n</ol>\n<p>用图的优点有如下几个：  </p>\n<ol>\n<li>能够保存计算结果。只会运行你所期望得到值的子图。</li>\n<li>易于分布任务，进行分布式的计算</li>\n<li>Break computation into small, differential pieces to facilitate auto-differentiation</li>\n<li>Many common machine learning models are taught and visualized as directed graphs</li>\n</ol>\n<p><strong>何为TensorFlow?</strong><br><strong>Tensor</strong>: An n-dimensional array<br>0-d tensor: scalar (number)<br>1-d tensor: vector<br>2-d tensor: matrix  </p>\n<h2 id=\"Tensorflow-ops\"><a href=\"#Tensorflow-ops\" class=\"headerlink\" title=\"Tensorflow ops\"></a>Tensorflow ops</h2><h3 id=\"TensorBorad\"><a href=\"#TensorBorad\" class=\"headerlink\" title=\"TensorBorad\"></a>TensorBorad</h3><p>Tensorborad 使用通过将图的节点信息和图中的操作记入event files当中来完成整个流程的可视化，使用如下代码创建event files以及停止记录<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># use tf.get_default_graph() to get default graph</span></div><div class=\"line\">writer = tf.summary.FileWriter([logdir], [graph])</div><div class=\"line\"><span class=\"comment\"># ...</span></div><div class=\"line\">writer.close()</div></pre></td></tr></table></figure></p>\n<p>之后运行python代码并打开tensorboard<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ python3 [my_program.py] </div><div class=\"line\">$ tensorboard --logdir=<span class=\"string\">\"./graphs\"</span> --port 6006</div></pre></td></tr></table></figure></p>\n<p>但是我们此时看到的图每个节点我们无法对上名字，这就要在定义图的时候给出其的名字<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">a = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"a\"</span>)</div><div class=\"line\">b = tf.constant(<span class=\"number\">2</span>, name=<span class=\"string\">\"b\"</span>)</div><div class=\"line\">x = tf.add(a, b, name=<span class=\"string\">\"add\"</span>)</div></pre></td></tr></table></figure></p>\n<h3 id=\"Some-useful-tricks\"><a href=\"#Some-useful-tricks\" class=\"headerlink\" title=\"Some useful tricks\"></a>Some useful tricks</h3><h4 id=\"查看protobuf\"><a href=\"#查看protobuf\" class=\"headerlink\" title=\"查看protobuf\"></a>查看protobuf</h4><p>常数存储在函数的定义当中，通过查看图的protobuf(protocol buffer)来查看图定义当中的内容。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</div><div class=\"line\"></div><div class=\"line\">my_const = tf.constant([<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>], name=<span class=\"string\">\"my_const\"</span>)</div><div class=\"line\">print(tf.get_default_graph().as_graph_def())</div></pre></td></tr></table></figure></p>\n<p>Output :<br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">node &#123;</div><div class=\"line\">  name: \"my_const\"</div><div class=\"line\">  op: \"Const\"</div><div class=\"line\">  attr &#123;</div><div class=\"line\">    key: \"dtype\"</div><div class=\"line\">    value &#123;</div><div class=\"line\">      type: DT_FLOAT</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">  attr &#123;</div><div class=\"line\">    key: \"value\"</div><div class=\"line\">    value &#123;</div><div class=\"line\">      tensor &#123;</div><div class=\"line\">        dtype: DT_FLOAT</div><div class=\"line\">        tensor_shape &#123;</div><div class=\"line\">          dim &#123;</div><div class=\"line\">            size: 2</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">versions &#123;</div><div class=\"line\">  producer: 24</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"变量的声明和初始化\"><a href=\"#变量的声明和初始化\" class=\"headerlink\" title=\"变量的声明和初始化\"></a>变量的声明和初始化</h4><p>为了变量共享的方便 官方推荐使用tf.get_variable方法<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">s = tf.get_variable(<span class=\"string\">\"scalar\"</span>, initializer=tf.constant(<span class=\"number\">2</span>)) </div><div class=\"line\">m = tf.get_variable(<span class=\"string\">\"matrix\"</span>, initializer=tf.constant([[<span class=\"number\">0</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">3</span>]]))</div><div class=\"line\">W = tf.get_variable(<span class=\"string\">\"big_matrix\"</span>, shape=(<span class=\"number\">784</span>, <span class=\"number\">10</span>), initializer=tf.zeros_initializer())</div></pre></td></tr></table></figure></p>\n<p>同时可以较简单的初始化变量<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\tsess.run(tf.global_variables_initializer())</div></pre></td></tr></table></figure></p>\n<h4 id=\"Assign-a-variable\"><a href=\"#Assign-a-variable\" class=\"headerlink\" title=\"Assign a variable\"></a>Assign a variable</h4><p>观察如下程序<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">W = tf.Variable(<span class=\"number\">10</span>)</div><div class=\"line\">W.assign(<span class=\"number\">100</span>)</div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\tsess.run(W.initializer)</div><div class=\"line\">\tprint(W.eval()) <span class=\"comment\"># &gt;&gt; 10</span></div></pre></td></tr></table></figure></p>\n<p>结果输出是10，但为什么不是100呢。注意的是，之前也说过，tensorflow的声明和运行是分离的，W.assign(100)创建了一个assign操作，但是我们并没有运行它，所以应该按照如下写<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">W = tf.Variable(<span class=\"number\">10</span>)</div><div class=\"line\">assign_op = W.assign(<span class=\"number\">100</span>)</div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\tsess.run(assign_op)</div><div class=\"line\">\tprint(W.eval()) <span class=\"comment\"># &gt;&gt; 100</span></div></pre></td></tr></table></figure></p>\n<h4 id=\"Sessions\"><a href=\"#Sessions\" class=\"headerlink\" title=\"Sessions\"></a>Sessions</h4><p>会话独自保存值，因而假如有两个不同的会话对同一个变量进行操作，其得到最终的值也有可能不相同。<br>有时候为了方便可以使用interactive session来隐式地run session<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">sess = tf.InteractiveSession()</div><div class=\"line\">a = tf.constant(<span class=\"number\">5.0</span>)</div><div class=\"line\">b = tf.constant(<span class=\"number\">6.0</span>)</div><div class=\"line\">c = a * b</div><div class=\"line\">print(c.eval()) <span class=\"comment\"># we can use 'c.eval()' without explicitly stating a session</span></div><div class=\"line\">sess.close()</div></pre></td></tr></table></figure></p>\n<p>tf.get_default_session()返回当前进程的默认session</p>\n<h4 id=\"the-trap-of-lazy-loading\"><a href=\"#the-trap-of-lazy-loading\" class=\"headerlink\" title=\"the trap of lazy loading\"></a>the trap of lazy loading</h4><p>考虑如下代码有什么不好的地方<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">x = tf.Variable(10, name=&apos;x&apos;)</div><div class=\"line\">y = tf.Variable(20, name=&apos;y&apos;)</div><div class=\"line\"></div><div class=\"line\">with tf.Session() as sess:</div><div class=\"line\">\tsess.run(tf.global_variables_initializer())</div><div class=\"line\">\twriter = tf.summary.FileWriter(&apos;graphs/lazy_loading&apos;, sess.graph)</div><div class=\"line\">\tfor _ in range(10):</div><div class=\"line\">\t\tsess.run(tf.add(x, y))</div><div class=\"line\">\tprint(tf.get_default_graph().as_graph_def()) </div><div class=\"line\">\twriter.close()</div></pre></td></tr></table></figure></p>\n<p>sess.run(tf.add(x, y))这一句会将tf.add(x,y)这个操作创建10次，造成网络的大量冗余<br>考虑解决方案：</p>\n<ol>\n<li>总是将操作的定义与执行分离开来</li>\n<li>使用python的@property来保证你的函数只被调用一次</li>\n</ol>\n"},{"title":"TensorFlow 学习笔记3 Manage EXperiments","date":"2018-04-11T12:59:00.000Z","_content":"# Tensorflow 学习笔记 #3\n\n**keywords** :  model base, variable sharing, model sharing\n\n## 构建tensorflow模型的一般步骤\nPhase1: **assenmble graph** \n1. Import Data\n2. Define the weigths\n3. Define the inferece model\n4. Define loss function\n5. Define optimizer\n\n\nPhase2: **execute the computation**\n1. initialize all model variables for the first time\n2. Initialize iterator / feed training data\n3. Excecute the inference model on the training data\n4. compute cost\n5. Adjust model parameters to minimize cost \n\n利用python面向对象的性质为自己的模型简历一个类：\n```python\nclass Model:\n    def __init__(self, params):\n        pass\n\n    def _import_data(self):\n        \"\"\" Step 1: import data \"\"\"\n        pass\n\n    def _create_embedding(self):\n        \"\"\" Step 2: in word2vec, it's actually the weights that we care about \"\"\"\n        pass\n\n    def _create_loss(self):\n        \"\"\" Step 3 + 4: define the inference + the loss function \"\"\"\n        pass\n\n    def _create_optimizer(self):\n        \"\"\" Step 5: define optimizer \"\"\"\n        pass\n```\n\n\n## Variable Sharing\n### Name Scope\n    为了能够在tensor board上较为清晰的辨识出节点之间的关系，引入name_scope可将其分组\n```python\nwith tf.name_scope(name_of_that_scope):\n    # declare op1\n    # declare op2\n    # declare op3\n```\n\n### Variable Scope\n    使用Varibale scope来做到变量共享，在variable_scope中使用get_variable方法来获取之前创建的变量而不是新的一个变量\n```python\nwith tf.variable_scope(\"xxx\") as scope:\n    # a = tf.get_variable(\"x\",.)..\n```\n\n## tensorflow 实验管理\n### 使用checkpoint保存训练中间结果\n对于一个需要较长时间训练的模型来说，断点恢复能力是十分必要的。  \ntensorflow也设置了相应的机制，即为checkpoint，可以用来周期性的保存当前模型的参数等数据。  \n实现这一点的是tf.train.Sacer() 类，它会将图的变量保存在二进制文件当中。 \n```python\ntf.train.Saver.save(\n    sess,\n    save_path,\n    global_step=None,\n    latest_filename=None,\n    meta_graph_suffix='meta',\n    write_meta_graph=True,\n    write_state=True\n)\n```\n常用的保存checkpoint的方法如下所示：\n```python\n# define model\n\n# create a saver object\nsaver = tf.train.Saver()\n\n# launch a session to execute the computation\nwith tf.Session() as sess:\n    # actual training loop\n    for step in range(training_steps): \n\tsess.run([optimizer])\n\tif (step + 1) % 1000 == 0:\n\t   saver.save(sess, 'checkpoint_directory/model_name', global_step=global_step)\n``` \n这里的global_step是一个用来记录图训练了多少步的变量，创建其的时候需要设置其不能被训练。\n（optimizer默认训练所有变量）\n```python\nglobal_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n```\noptimizer一般也接收一个global_step变量的输入，每一次优化更新之后会将global_step的值自增\n```python\noptimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss,global_step=global_step)\n```\n\ntensorflow还支持在一个文件夹里面找checkpoint,如果有合法的，恢复checkpoint,否则继续执行\n```python\nckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\nif ckpt and ckpt.model_checkpoint_path:\n     saver.restore(sess, ckpt.model_checkpoint_path)\n```\n\n### 使用tf.summary可视化训练数据\n\n```python\ndef _create_summaries(self):\n     with tf.name_scope(\"summaries\"):\n            tf.summary.scalar(\"loss\", self.loss)\n            tf.summary.scalar(\"accuracy\", self.accuracy)            \n            tf.summary.histogram(\"histogram loss\", self.loss)\n            # because you have several summaries, we should merge them all\n            # into one op to make it easier to manage\n            self.summary_op = tf.summary.merge_all()\n```\nsummary_op和其它operation一样，需要在sess中运行得到结果。  \n得到结果之后使用add_summary把结果写入writer当中，就可以在tensorbord中看到add_summary的图的各种曲线啦  \n```python\nwriter.add_summary(summary, global_step=step)\n```\nsummary的用法参考[这里](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)\n\n### control randomization\n\n### Auto diff\n","source":"_posts/machinelearning/tensorflow_notes/note3.md","raw":"---\ntitle: TensorFlow 学习笔记3 Manage EXperiments #3\ndate: 2018-04-11 20:59:00\ntags: [tensorflow]\n---\n# Tensorflow 学习笔记 #3\n\n**keywords** :  model base, variable sharing, model sharing\n\n## 构建tensorflow模型的一般步骤\nPhase1: **assenmble graph** \n1. Import Data\n2. Define the weigths\n3. Define the inferece model\n4. Define loss function\n5. Define optimizer\n\n\nPhase2: **execute the computation**\n1. initialize all model variables for the first time\n2. Initialize iterator / feed training data\n3. Excecute the inference model on the training data\n4. compute cost\n5. Adjust model parameters to minimize cost \n\n利用python面向对象的性质为自己的模型简历一个类：\n```python\nclass Model:\n    def __init__(self, params):\n        pass\n\n    def _import_data(self):\n        \"\"\" Step 1: import data \"\"\"\n        pass\n\n    def _create_embedding(self):\n        \"\"\" Step 2: in word2vec, it's actually the weights that we care about \"\"\"\n        pass\n\n    def _create_loss(self):\n        \"\"\" Step 3 + 4: define the inference + the loss function \"\"\"\n        pass\n\n    def _create_optimizer(self):\n        \"\"\" Step 5: define optimizer \"\"\"\n        pass\n```\n\n\n## Variable Sharing\n### Name Scope\n    为了能够在tensor board上较为清晰的辨识出节点之间的关系，引入name_scope可将其分组\n```python\nwith tf.name_scope(name_of_that_scope):\n    # declare op1\n    # declare op2\n    # declare op3\n```\n\n### Variable Scope\n    使用Varibale scope来做到变量共享，在variable_scope中使用get_variable方法来获取之前创建的变量而不是新的一个变量\n```python\nwith tf.variable_scope(\"xxx\") as scope:\n    # a = tf.get_variable(\"x\",.)..\n```\n\n## tensorflow 实验管理\n### 使用checkpoint保存训练中间结果\n对于一个需要较长时间训练的模型来说，断点恢复能力是十分必要的。  \ntensorflow也设置了相应的机制，即为checkpoint，可以用来周期性的保存当前模型的参数等数据。  \n实现这一点的是tf.train.Sacer() 类，它会将图的变量保存在二进制文件当中。 \n```python\ntf.train.Saver.save(\n    sess,\n    save_path,\n    global_step=None,\n    latest_filename=None,\n    meta_graph_suffix='meta',\n    write_meta_graph=True,\n    write_state=True\n)\n```\n常用的保存checkpoint的方法如下所示：\n```python\n# define model\n\n# create a saver object\nsaver = tf.train.Saver()\n\n# launch a session to execute the computation\nwith tf.Session() as sess:\n    # actual training loop\n    for step in range(training_steps): \n\tsess.run([optimizer])\n\tif (step + 1) % 1000 == 0:\n\t   saver.save(sess, 'checkpoint_directory/model_name', global_step=global_step)\n``` \n这里的global_step是一个用来记录图训练了多少步的变量，创建其的时候需要设置其不能被训练。\n（optimizer默认训练所有变量）\n```python\nglobal_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n```\noptimizer一般也接收一个global_step变量的输入，每一次优化更新之后会将global_step的值自增\n```python\noptimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss,global_step=global_step)\n```\n\ntensorflow还支持在一个文件夹里面找checkpoint,如果有合法的，恢复checkpoint,否则继续执行\n```python\nckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\nif ckpt and ckpt.model_checkpoint_path:\n     saver.restore(sess, ckpt.model_checkpoint_path)\n```\n\n### 使用tf.summary可视化训练数据\n\n```python\ndef _create_summaries(self):\n     with tf.name_scope(\"summaries\"):\n            tf.summary.scalar(\"loss\", self.loss)\n            tf.summary.scalar(\"accuracy\", self.accuracy)            \n            tf.summary.histogram(\"histogram loss\", self.loss)\n            # because you have several summaries, we should merge them all\n            # into one op to make it easier to manage\n            self.summary_op = tf.summary.merge_all()\n```\nsummary_op和其它operation一样，需要在sess中运行得到结果。  \n得到结果之后使用add_summary把结果写入writer当中，就可以在tensorbord中看到add_summary的图的各种曲线啦  \n```python\nwriter.add_summary(summary, global_step=step)\n```\nsummary的用法参考[这里](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)\n\n### control randomization\n\n### Auto diff\n","slug":"machinelearning/tensorflow_notes/note3","published":1,"updated":"2018-04-15T14:10:50.391Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56ad001tacwoqr3mfqa4","content":"<h1 id=\"Tensorflow-学习笔记-3\"><a href=\"#Tensorflow-学习笔记-3\" class=\"headerlink\" title=\"Tensorflow 学习笔记 #3\"></a>Tensorflow 学习笔记 #3</h1><p><strong>keywords</strong> :  model base, variable sharing, model sharing</p>\n<h2 id=\"构建tensorflow模型的一般步骤\"><a href=\"#构建tensorflow模型的一般步骤\" class=\"headerlink\" title=\"构建tensorflow模型的一般步骤\"></a>构建tensorflow模型的一般步骤</h2><p>Phase1: <strong>assenmble graph</strong> </p>\n<ol>\n<li>Import Data</li>\n<li>Define the weigths</li>\n<li>Define the inferece model</li>\n<li>Define loss function</li>\n<li>Define optimizer</li>\n</ol>\n<p>Phase2: <strong>execute the computation</strong></p>\n<ol>\n<li>initialize all model variables for the first time</li>\n<li>Initialize iterator / feed training data</li>\n<li>Excecute the inference model on the training data</li>\n<li>compute cost</li>\n<li>Adjust model parameters to minimize cost </li>\n</ol>\n<p>利用python面向对象的性质为自己的模型简历一个类：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Model</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, params)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_import_data</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 1: import data \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_embedding</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 2: in word2vec, it's actually the weights that we care about \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_loss</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 3 + 4: define the inference + the loss function \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_optimizer</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 5: define optimizer \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Variable-Sharing\"><a href=\"#Variable-Sharing\" class=\"headerlink\" title=\"Variable Sharing\"></a>Variable Sharing</h2><h3 id=\"Name-Scope\"><a href=\"#Name-Scope\" class=\"headerlink\" title=\"Name Scope\"></a>Name Scope</h3><pre><code>为了能够在tensor board上较为清晰的辨识出节点之间的关系，引入name_scope可将其分组\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(name_of_that_scope):</div><div class=\"line\">    <span class=\"comment\"># declare op1</span></div><div class=\"line\">    <span class=\"comment\"># declare op2</span></div><div class=\"line\">    <span class=\"comment\"># declare op3</span></div></pre></td></tr></table></figure>\n<h3 id=\"Variable-Scope\"><a href=\"#Variable-Scope\" class=\"headerlink\" title=\"Variable Scope\"></a>Variable Scope</h3><pre><code>使用Varibale scope来做到变量共享，在variable_scope中使用get_variable方法来获取之前创建的变量而不是新的一个变量\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">\"xxx\"</span>) <span class=\"keyword\">as</span> scope:</div><div class=\"line\">    <span class=\"comment\"># a = tf.get_variable(\"x\",.)..</span></div></pre></td></tr></table></figure>\n<h2 id=\"tensorflow-实验管理\"><a href=\"#tensorflow-实验管理\" class=\"headerlink\" title=\"tensorflow 实验管理\"></a>tensorflow 实验管理</h2><h3 id=\"使用checkpoint保存训练中间结果\"><a href=\"#使用checkpoint保存训练中间结果\" class=\"headerlink\" title=\"使用checkpoint保存训练中间结果\"></a>使用checkpoint保存训练中间结果</h3><p>对于一个需要较长时间训练的模型来说，断点恢复能力是十分必要的。<br>tensorflow也设置了相应的机制，即为checkpoint，可以用来周期性的保存当前模型的参数等数据。<br>实现这一点的是tf.train.Sacer() 类，它会将图的变量保存在二进制文件当中。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">tf.train.Saver.save(</div><div class=\"line\">    sess,</div><div class=\"line\">    save_path,</div><div class=\"line\">    global_step=<span class=\"keyword\">None</span>,</div><div class=\"line\">    latest_filename=<span class=\"keyword\">None</span>,</div><div class=\"line\">    meta_graph_suffix=<span class=\"string\">'meta'</span>,</div><div class=\"line\">    write_meta_graph=<span class=\"keyword\">True</span>,</div><div class=\"line\">    write_state=<span class=\"keyword\">True</span></div><div class=\"line\">)</div></pre></td></tr></table></figure></p>\n<p>常用的保存checkpoint的方法如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># define model</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># create a saver object</span></div><div class=\"line\">saver = tf.train.Saver()</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># launch a session to execute the computation</span></div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">    <span class=\"comment\"># actual training loop</span></div><div class=\"line\">    <span class=\"keyword\">for</span> step <span class=\"keyword\">in</span> range(training_steps): </div><div class=\"line\">\tsess.run([optimizer])</div><div class=\"line\">\t<span class=\"keyword\">if</span> (step + <span class=\"number\">1</span>) % <span class=\"number\">1000</span> == <span class=\"number\">0</span>:</div><div class=\"line\">\t   saver.save(sess, <span class=\"string\">'checkpoint_directory/model_name'</span>, global_step=global_step)</div><div class=\"line\">``` </div><div class=\"line\">这里的global_step是一个用来记录图训练了多少步的变量，创建其的时候需要设置其不能被训练。</div><div class=\"line\">（optimizer默认训练所有变量）</div><div class=\"line\">```python</div><div class=\"line\">global_step = tf.Variable(<span class=\"number\">0</span>, dtype=tf.int32, trainable=<span class=\"keyword\">False</span>, name=<span class=\"string\">'global_step'</span>)</div></pre></td></tr></table></figure></p>\n<p>optimizer一般也接收一个global_step变量的输入，每一次优化更新之后会将global_step的值自增<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss,global_step=global_step)</div></pre></td></tr></table></figure></p>\n<p>tensorflow还支持在一个文件夹里面找checkpoint,如果有合法的，恢复checkpoint,否则继续执行<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class=\"string\">'checkpoints/checkpoint'</span>))</div><div class=\"line\"><span class=\"keyword\">if</span> ckpt <span class=\"keyword\">and</span> ckpt.model_checkpoint_path:</div><div class=\"line\">     saver.restore(sess, ckpt.model_checkpoint_path)</div></pre></td></tr></table></figure></p>\n<h3 id=\"使用tf-summary可视化训练数据\"><a href=\"#使用tf-summary可视化训练数据\" class=\"headerlink\" title=\"使用tf.summary可视化训练数据\"></a>使用tf.summary可视化训练数据</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_summaries</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">     <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"summaries\"</span>):</div><div class=\"line\">            tf.summary.scalar(<span class=\"string\">\"loss\"</span>, self.loss)</div><div class=\"line\">            tf.summary.scalar(<span class=\"string\">\"accuracy\"</span>, self.accuracy)            </div><div class=\"line\">            tf.summary.histogram(<span class=\"string\">\"histogram loss\"</span>, self.loss)</div><div class=\"line\">            <span class=\"comment\"># because you have several summaries, we should merge them all</span></div><div class=\"line\">            <span class=\"comment\"># into one op to make it easier to manage</span></div><div class=\"line\">            self.summary_op = tf.summary.merge_all()</div></pre></td></tr></table></figure>\n<p>summary_op和其它operation一样，需要在sess中运行得到结果。<br>得到结果之后使用add_summary把结果写入writer当中，就可以在tensorbord中看到add_summary的图的各种曲线啦<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">writer.add_summary(summary, global_step=step)</div></pre></td></tr></table></figure></p>\n<p>summary的用法参考<a href=\"https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard\" target=\"_blank\" rel=\"external\">这里</a></p>\n<h3 id=\"control-randomization\"><a href=\"#control-randomization\" class=\"headerlink\" title=\"control randomization\"></a>control randomization</h3><h3 id=\"Auto-diff\"><a href=\"#Auto-diff\" class=\"headerlink\" title=\"Auto diff\"></a>Auto diff</h3>","excerpt":"","more":"<h1 id=\"Tensorflow-学习笔记-3\"><a href=\"#Tensorflow-学习笔记-3\" class=\"headerlink\" title=\"Tensorflow 学习笔记 #3\"></a>Tensorflow 学习笔记 #3</h1><p><strong>keywords</strong> :  model base, variable sharing, model sharing</p>\n<h2 id=\"构建tensorflow模型的一般步骤\"><a href=\"#构建tensorflow模型的一般步骤\" class=\"headerlink\" title=\"构建tensorflow模型的一般步骤\"></a>构建tensorflow模型的一般步骤</h2><p>Phase1: <strong>assenmble graph</strong> </p>\n<ol>\n<li>Import Data</li>\n<li>Define the weigths</li>\n<li>Define the inferece model</li>\n<li>Define loss function</li>\n<li>Define optimizer</li>\n</ol>\n<p>Phase2: <strong>execute the computation</strong></p>\n<ol>\n<li>initialize all model variables for the first time</li>\n<li>Initialize iterator / feed training data</li>\n<li>Excecute the inference model on the training data</li>\n<li>compute cost</li>\n<li>Adjust model parameters to minimize cost </li>\n</ol>\n<p>利用python面向对象的性质为自己的模型简历一个类：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Model</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, params)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_import_data</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 1: import data \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_embedding</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 2: in word2vec, it's actually the weights that we care about \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_loss</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 3 + 4: define the inference + the loss function \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_optimizer</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\" Step 5: define optimizer \"\"\"</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Variable-Sharing\"><a href=\"#Variable-Sharing\" class=\"headerlink\" title=\"Variable Sharing\"></a>Variable Sharing</h2><h3 id=\"Name-Scope\"><a href=\"#Name-Scope\" class=\"headerlink\" title=\"Name Scope\"></a>Name Scope</h3><pre><code>为了能够在tensor board上较为清晰的辨识出节点之间的关系，引入name_scope可将其分组\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">with</span> tf.name_scope(name_of_that_scope):</div><div class=\"line\">    <span class=\"comment\"># declare op1</span></div><div class=\"line\">    <span class=\"comment\"># declare op2</span></div><div class=\"line\">    <span class=\"comment\"># declare op3</span></div></pre></td></tr></table></figure>\n<h3 id=\"Variable-Scope\"><a href=\"#Variable-Scope\" class=\"headerlink\" title=\"Variable Scope\"></a>Variable Scope</h3><pre><code>使用Varibale scope来做到变量共享，在variable_scope中使用get_variable方法来获取之前创建的变量而不是新的一个变量\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">\"xxx\"</span>) <span class=\"keyword\">as</span> scope:</div><div class=\"line\">    <span class=\"comment\"># a = tf.get_variable(\"x\",.)..</span></div></pre></td></tr></table></figure>\n<h2 id=\"tensorflow-实验管理\"><a href=\"#tensorflow-实验管理\" class=\"headerlink\" title=\"tensorflow 实验管理\"></a>tensorflow 实验管理</h2><h3 id=\"使用checkpoint保存训练中间结果\"><a href=\"#使用checkpoint保存训练中间结果\" class=\"headerlink\" title=\"使用checkpoint保存训练中间结果\"></a>使用checkpoint保存训练中间结果</h3><p>对于一个需要较长时间训练的模型来说，断点恢复能力是十分必要的。<br>tensorflow也设置了相应的机制，即为checkpoint，可以用来周期性的保存当前模型的参数等数据。<br>实现这一点的是tf.train.Sacer() 类，它会将图的变量保存在二进制文件当中。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">tf.train.Saver.save(</div><div class=\"line\">    sess,</div><div class=\"line\">    save_path,</div><div class=\"line\">    global_step=<span class=\"keyword\">None</span>,</div><div class=\"line\">    latest_filename=<span class=\"keyword\">None</span>,</div><div class=\"line\">    meta_graph_suffix=<span class=\"string\">'meta'</span>,</div><div class=\"line\">    write_meta_graph=<span class=\"keyword\">True</span>,</div><div class=\"line\">    write_state=<span class=\"keyword\">True</span></div><div class=\"line\">)</div></pre></td></tr></table></figure></p>\n<p>常用的保存checkpoint的方法如下所示：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># define model</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># create a saver object</span></div><div class=\"line\">saver = tf.train.Saver()</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># launch a session to execute the computation</span></div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">    <span class=\"comment\"># actual training loop</span></div><div class=\"line\">    <span class=\"keyword\">for</span> step <span class=\"keyword\">in</span> range(training_steps): </div><div class=\"line\">\tsess.run([optimizer])</div><div class=\"line\">\t<span class=\"keyword\">if</span> (step + <span class=\"number\">1</span>) % <span class=\"number\">1000</span> == <span class=\"number\">0</span>:</div><div class=\"line\">\t   saver.save(sess, <span class=\"string\">'checkpoint_directory/model_name'</span>, global_step=global_step)</div><div class=\"line\">``` </div><div class=\"line\">这里的global_step是一个用来记录图训练了多少步的变量，创建其的时候需要设置其不能被训练。</div><div class=\"line\">（optimizer默认训练所有变量）</div><div class=\"line\">```python</div><div class=\"line\">global_step = tf.Variable(<span class=\"number\">0</span>, dtype=tf.int32, trainable=<span class=\"keyword\">False</span>, name=<span class=\"string\">'global_step'</span>)</div></pre></td></tr></table></figure></p>\n<p>optimizer一般也接收一个global_step变量的输入，每一次优化更新之后会将global_step的值自增<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss,global_step=global_step)</div></pre></td></tr></table></figure></p>\n<p>tensorflow还支持在一个文件夹里面找checkpoint,如果有合法的，恢复checkpoint,否则继续执行<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class=\"string\">'checkpoints/checkpoint'</span>))</div><div class=\"line\"><span class=\"keyword\">if</span> ckpt <span class=\"keyword\">and</span> ckpt.model_checkpoint_path:</div><div class=\"line\">     saver.restore(sess, ckpt.model_checkpoint_path)</div></pre></td></tr></table></figure></p>\n<h3 id=\"使用tf-summary可视化训练数据\"><a href=\"#使用tf-summary可视化训练数据\" class=\"headerlink\" title=\"使用tf.summary可视化训练数据\"></a>使用tf.summary可视化训练数据</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_create_summaries</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">     <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">\"summaries\"</span>):</div><div class=\"line\">            tf.summary.scalar(<span class=\"string\">\"loss\"</span>, self.loss)</div><div class=\"line\">            tf.summary.scalar(<span class=\"string\">\"accuracy\"</span>, self.accuracy)            </div><div class=\"line\">            tf.summary.histogram(<span class=\"string\">\"histogram loss\"</span>, self.loss)</div><div class=\"line\">            <span class=\"comment\"># because you have several summaries, we should merge them all</span></div><div class=\"line\">            <span class=\"comment\"># into one op to make it easier to manage</span></div><div class=\"line\">            self.summary_op = tf.summary.merge_all()</div></pre></td></tr></table></figure>\n<p>summary_op和其它operation一样，需要在sess中运行得到结果。<br>得到结果之后使用add_summary把结果写入writer当中，就可以在tensorbord中看到add_summary的图的各种曲线啦<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">writer.add_summary(summary, global_step=step)</div></pre></td></tr></table></figure></p>\n<p>summary的用法参考<a href=\"https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard\">这里</a></p>\n<h3 id=\"control-randomization\"><a href=\"#control-randomization\" class=\"headerlink\" title=\"control randomization\"></a>control randomization</h3><h3 id=\"Auto-diff\"><a href=\"#Auto-diff\" class=\"headerlink\" title=\"Auto diff\"></a>Auto diff</h3>"},{"title":"TensorFlow 学习笔记2","date":"2018-03-30T03:31:00.000Z","_content":"# TensorFlow 学习笔记 #2\n  \n先来看一个简单的线性回归的代码例子，再来看在其基础上可以做出什么改进\n```python\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = \"data/birth_life_2010.txt\"\n\n# Step 1: read in data from the .txt file\n# data is a numpy array of shape (190, 2), each row is a datapoint\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\nX = tf.placeholder(tf.float32, name='X')\nY = tf.placeholder(tf.float32, name='Y')\n\n# Step 3: create weight and bias, initialized to 0\nw = tf.get_variable('weights', initializer=tf.constant(0.0))\nb = tf.get_variable('bias', initializer=tf.constant(0.0))\n\n# Step 4: construct model to predict Y (life expectancy from birth rate)\nY_predicted = w * X + b \n\n# Step 5: use the square error as the loss function\nloss = tf.square(Y - Y_predicted, name='loss')\n\n# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n \nwith tf.Session() as sess:\n\t# Step 7: initialize the necessary variables, in this case, w and b\n\tsess.run(tf.global_variables_initializer()) \n\t\n\t# Step 8: train the model\n\tfor i in range(100): # run 100 epochs\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op to minimize loss\n\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y}) \n\t\n\t# Step 9: output the values of w and b\n\tw_out, b_out = sess.run([w, b])\n```\n\n## tensorflow 控制流\n观察上面线性回归所使用的loss function，是个简单的二次函数  \n分析离群点，假设有一个离样本较远的离群点，那么这个离群点造成的loss fuction上的损失较大，会大大影响整个模型的建模。\n\n**使用[huber loss](https://en.wikipedia.org/wiki/Huber_loss)代替原来简单的loss fuction**  \n其定义如下所示    \n\n$$\nL_\\delta(y,f(x))=\\left\\{\n\\begin{array}{ll}\n\\frac12(y-f(x))^2,&\\textrm{for }|y-f(x)|\\leq\\delta\\\\\n\\delta\\cdot(|y-f(x)|-\\delta/2),& \\textrm{otherwise.}\n\\end{array}\n\\right.\n$$\n\nHuber loss给离群点设置了相对更小的权重,因而提升了拟合的效果。\n\n一个显然的事实是由于tensorflow 定义和执行的分离，我们不能用python的条件分支语句来控制optimizer使用哪一种loss function,tensor flow提供了分支控制的方法\n\nOps | Methods\n:-|:-\nControl Flow Ops | tf.count_up_to, tf.cond, tf.case, tf.while_loop, tf.group ...\nComparison Ops | tf.equal, tf.not_equal, tf.less, tf.greater, tf.where, ...\nLogical Ops | tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor\nDebugging Ops | tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print, ...\n\nhuber_loss：\n```python\ndef huber_loss(labels, predictions, delta=14.0):\n    residual = tf.abs(labels - predictions)\n    def f1(): return 0.5 * tf.square(residual)\n    def f2(): return delta * residual - 0.5 * tf.square(delta)\n    return tf.cond(residual < delta, f1, f2)\n```\n## tensorflow 输入\n### placeholder & feed_dict\nnote1跳过了对tensorflow基本输入方式的叙述。实际上由于graph在定义的时候不需要考虑实际输入数据的特性。一般创建输入变量的时候实际上是为要输入的变量预留位置，使用tf.placeholder定义,如下是一个使用的例子\n```python\na = tf.placeholder(dtype, shape=None, name=None)\n...\nwith tf.Session() as sess:\n   sess.run(something, feed_dict = {a:[1,2,3]})\n```\nshape参数制定了传入的tensor的结构，shape为None意味着任意结构的tensor都能被接收（可能潜在地会引入bug）\n\n### tf.data\nplaceholder让数据的处理和带入图中运算分开，在tensorflow框架之外完成（完全可以用numpy等工具处理），不过这样带来的不好的地方之一在于，数据处理被放在了python的单一线程当中，会让数据处理较慢。（大量数据要从外部一个个装载到place_holder处）  \n\n如上述代码当中看起来就不优雅的一段：\n```python\n\tfor i in range(100): # run 100 epochs\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op to minimize loss\n\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y}) \n```\n将数据分100次载入place_holder当中实际上较大的拖慢了程序的速度。还需要考虑的是在并行计算的时候载入feed_dict可能阻碍了其它操作的执行。\n\ntensorflow提供的解决方案是将数据存储在tf.data.Dataset object当中\n```python\ntf.data.Dataset.from_tensor_slices((features, labels))\n# can use numpy arrays as features and labels \n```\n\n之后使用迭代器来访问dataset当中的每一个数据\n```python\n# we use make_initializable_iterator for multiple epochs\niterator = dataset.make_initializable_iterator()\nX, Y = iterator.get_next() \n···\nfor i in range(100): \n        # reset where iterator point to\n        sess.run(iterator.initializer)\n        total_loss = 0\n        try:\n            while True:\n                sess.run([optimizer]) \n        except tf.errors.OutOfRangeError:\n            pass\n```\n\ndataset 也支持许多原生的对数据集的操作来改变数据集或是生成新的数据集\n```python\ndataset = dataset.shuffle(1000)\ndataset = dataset.repeat(100)\ndataset = dataset.batch(128)\ndataset = dataset.map(lambda x: tf.one_hot(x, 10)) \n# convert each element of dataset to one_hot vector\n```\n## Optimizers\n默认情况下optimizer在每一轮迭代的过程中自动更新loss function所依赖的所有变量，若有不想更新的变量，在定义的时候加上参数trainable=False\n\n(to do: add contont about more detailed control of model trains using tf.gradient)\n\n## Refs\n[03_Lecture note_Linear and Logistic Regression](https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit#)  \n[Huber Loss](https://en.wikipedia.org/wiki/Huber_loss)\n","source":"_posts/machinelearning/tensorflow_notes/note2.md","raw":"---\ntitle: TensorFlow 学习笔记2 #2\ndate: 2018-03-30 11:31:00\ntags: [tensorflow]\n---\n# TensorFlow 学习笔记 #2\n  \n先来看一个简单的线性回归的代码例子，再来看在其基础上可以做出什么改进\n```python\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = \"data/birth_life_2010.txt\"\n\n# Step 1: read in data from the .txt file\n# data is a numpy array of shape (190, 2), each row is a datapoint\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\nX = tf.placeholder(tf.float32, name='X')\nY = tf.placeholder(tf.float32, name='Y')\n\n# Step 3: create weight and bias, initialized to 0\nw = tf.get_variable('weights', initializer=tf.constant(0.0))\nb = tf.get_variable('bias', initializer=tf.constant(0.0))\n\n# Step 4: construct model to predict Y (life expectancy from birth rate)\nY_predicted = w * X + b \n\n# Step 5: use the square error as the loss function\nloss = tf.square(Y - Y_predicted, name='loss')\n\n# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n \nwith tf.Session() as sess:\n\t# Step 7: initialize the necessary variables, in this case, w and b\n\tsess.run(tf.global_variables_initializer()) \n\t\n\t# Step 8: train the model\n\tfor i in range(100): # run 100 epochs\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op to minimize loss\n\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y}) \n\t\n\t# Step 9: output the values of w and b\n\tw_out, b_out = sess.run([w, b])\n```\n\n## tensorflow 控制流\n观察上面线性回归所使用的loss function，是个简单的二次函数  \n分析离群点，假设有一个离样本较远的离群点，那么这个离群点造成的loss fuction上的损失较大，会大大影响整个模型的建模。\n\n**使用[huber loss](https://en.wikipedia.org/wiki/Huber_loss)代替原来简单的loss fuction**  \n其定义如下所示    \n\n$$\nL_\\delta(y,f(x))=\\left\\{\n\\begin{array}{ll}\n\\frac12(y-f(x))^2,&\\textrm{for }|y-f(x)|\\leq\\delta\\\\\n\\delta\\cdot(|y-f(x)|-\\delta/2),& \\textrm{otherwise.}\n\\end{array}\n\\right.\n$$\n\nHuber loss给离群点设置了相对更小的权重,因而提升了拟合的效果。\n\n一个显然的事实是由于tensorflow 定义和执行的分离，我们不能用python的条件分支语句来控制optimizer使用哪一种loss function,tensor flow提供了分支控制的方法\n\nOps | Methods\n:-|:-\nControl Flow Ops | tf.count_up_to, tf.cond, tf.case, tf.while_loop, tf.group ...\nComparison Ops | tf.equal, tf.not_equal, tf.less, tf.greater, tf.where, ...\nLogical Ops | tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor\nDebugging Ops | tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print, ...\n\nhuber_loss：\n```python\ndef huber_loss(labels, predictions, delta=14.0):\n    residual = tf.abs(labels - predictions)\n    def f1(): return 0.5 * tf.square(residual)\n    def f2(): return delta * residual - 0.5 * tf.square(delta)\n    return tf.cond(residual < delta, f1, f2)\n```\n## tensorflow 输入\n### placeholder & feed_dict\nnote1跳过了对tensorflow基本输入方式的叙述。实际上由于graph在定义的时候不需要考虑实际输入数据的特性。一般创建输入变量的时候实际上是为要输入的变量预留位置，使用tf.placeholder定义,如下是一个使用的例子\n```python\na = tf.placeholder(dtype, shape=None, name=None)\n...\nwith tf.Session() as sess:\n   sess.run(something, feed_dict = {a:[1,2,3]})\n```\nshape参数制定了传入的tensor的结构，shape为None意味着任意结构的tensor都能被接收（可能潜在地会引入bug）\n\n### tf.data\nplaceholder让数据的处理和带入图中运算分开，在tensorflow框架之外完成（完全可以用numpy等工具处理），不过这样带来的不好的地方之一在于，数据处理被放在了python的单一线程当中，会让数据处理较慢。（大量数据要从外部一个个装载到place_holder处）  \n\n如上述代码当中看起来就不优雅的一段：\n```python\n\tfor i in range(100): # run 100 epochs\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op to minimize loss\n\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y}) \n```\n将数据分100次载入place_holder当中实际上较大的拖慢了程序的速度。还需要考虑的是在并行计算的时候载入feed_dict可能阻碍了其它操作的执行。\n\ntensorflow提供的解决方案是将数据存储在tf.data.Dataset object当中\n```python\ntf.data.Dataset.from_tensor_slices((features, labels))\n# can use numpy arrays as features and labels \n```\n\n之后使用迭代器来访问dataset当中的每一个数据\n```python\n# we use make_initializable_iterator for multiple epochs\niterator = dataset.make_initializable_iterator()\nX, Y = iterator.get_next() \n···\nfor i in range(100): \n        # reset where iterator point to\n        sess.run(iterator.initializer)\n        total_loss = 0\n        try:\n            while True:\n                sess.run([optimizer]) \n        except tf.errors.OutOfRangeError:\n            pass\n```\n\ndataset 也支持许多原生的对数据集的操作来改变数据集或是生成新的数据集\n```python\ndataset = dataset.shuffle(1000)\ndataset = dataset.repeat(100)\ndataset = dataset.batch(128)\ndataset = dataset.map(lambda x: tf.one_hot(x, 10)) \n# convert each element of dataset to one_hot vector\n```\n## Optimizers\n默认情况下optimizer在每一轮迭代的过程中自动更新loss function所依赖的所有变量，若有不想更新的变量，在定义的时候加上参数trainable=False\n\n(to do: add contont about more detailed control of model trains using tf.gradient)\n\n## Refs\n[03_Lecture note_Linear and Logistic Regression](https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit#)  \n[Huber Loss](https://en.wikipedia.org/wiki/Huber_loss)\n","slug":"machinelearning/tensorflow_notes/note2","published":1,"updated":"2018-03-30T09:26:55.451Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56ad001xacwoc8soe86s","content":"<h1 id=\"TensorFlow-学习笔记-2\"><a href=\"#TensorFlow-学习笔记-2\" class=\"headerlink\" title=\"TensorFlow 学习笔记 #2\"></a>TensorFlow 学习笔记 #2</h1><p>先来看一个简单的线性回归的代码例子，再来看在其基础上可以做出什么改进<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> utils</div><div class=\"line\"></div><div class=\"line\">DATA_FILE = <span class=\"string\">\"data/birth_life_2010.txt\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 1: read in data from the .txt file</span></div><div class=\"line\"><span class=\"comment\"># data is a numpy array of shape (190, 2), each row is a datapoint</span></div><div class=\"line\">data, n_samples = utils.read_birth_life_data(DATA_FILE)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 2: create placeholders for X (birth rate) and Y (life expectancy)</span></div><div class=\"line\">X = tf.placeholder(tf.float32, name=<span class=\"string\">'X'</span>)</div><div class=\"line\">Y = tf.placeholder(tf.float32, name=<span class=\"string\">'Y'</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 3: create weight and bias, initialized to 0</span></div><div class=\"line\">w = tf.get_variable(<span class=\"string\">'weights'</span>, initializer=tf.constant(<span class=\"number\">0.0</span>))</div><div class=\"line\">b = tf.get_variable(<span class=\"string\">'bias'</span>, initializer=tf.constant(<span class=\"number\">0.0</span>))</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 4: construct model to predict Y (life expectancy from birth rate)</span></div><div class=\"line\">Y_predicted = w * X + b </div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 5: use the square error as the loss function</span></div><div class=\"line\">loss = tf.square(Y - Y_predicted, name=<span class=\"string\">'loss'</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 6: using gradient descent with learning rate of 0.01 to minimize loss</span></div><div class=\"line\">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class=\"number\">0.001</span>).minimize(loss)</div><div class=\"line\"> </div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\t<span class=\"comment\"># Step 7: initialize the necessary variables, in this case, w and b</span></div><div class=\"line\">\tsess.run(tf.global_variables_initializer()) </div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"comment\"># Step 8: train the model</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>): <span class=\"comment\"># run 100 epochs</span></div><div class=\"line\">\t\t<span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> data:</div><div class=\"line\">\t\t\t<span class=\"comment\"># Session runs train_op to minimize loss</span></div><div class=\"line\">\t\t\tsess.run(optimizer, feed_dict=&#123;X: x, Y:y&#125;) </div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"comment\"># Step 9: output the values of w and b</span></div><div class=\"line\">\tw_out, b_out = sess.run([w, b])</div></pre></td></tr></table></figure></p>\n<h2 id=\"tensorflow-控制流\"><a href=\"#tensorflow-控制流\" class=\"headerlink\" title=\"tensorflow 控制流\"></a>tensorflow 控制流</h2><p>观察上面线性回归所使用的loss function，是个简单的二次函数<br>分析离群点，假设有一个离样本较远的离群点，那么这个离群点造成的loss fuction上的损失较大，会大大影响整个模型的建模。</p>\n<p><strong>使用<a href=\"https://en.wikipedia.org/wiki/Huber_loss\" target=\"_blank\" rel=\"external\">huber loss</a>代替原来简单的loss fuction</strong><br>其定义如下所示    </p>\n<p>$$<br>L_\\delta(y,f(x))=\\left{<br>\\begin{array}{ll}<br>\\frac12(y-f(x))^2,&amp;\\textrm{for }|y-f(x)|\\leq\\delta\\\\<br>\\delta\\cdot(|y-f(x)|-\\delta/2),&amp; \\textrm{otherwise.}<br>\\end{array}<br>\\right.<br>$$</p>\n<p>Huber loss给离群点设置了相对更小的权重,因而提升了拟合的效果。</p>\n<p>一个显然的事实是由于tensorflow 定义和执行的分离，我们不能用python的条件分支语句来控制optimizer使用哪一种loss function,tensor flow提供了分支控制的方法</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Ops</th>\n<th style=\"text-align:left\">Methods</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Control Flow Ops</td>\n<td style=\"text-align:left\">tf.count_up_to, tf.cond, tf.case, tf.while_loop, tf.group …</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Comparison Ops</td>\n<td style=\"text-align:left\">tf.equal, tf.not_equal, tf.less, tf.greater, tf.where, …</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Logical Ops</td>\n<td style=\"text-align:left\">tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Debugging Ops</td>\n<td style=\"text-align:left\">tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print, …</td>\n</tr>\n</tbody>\n</table>\n<p>huber_loss：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">huber_loss</span><span class=\"params\">(labels, predictions, delta=<span class=\"number\">14.0</span>)</span>:</span></div><div class=\"line\">    residual = tf.abs(labels - predictions)</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">f1</span><span class=\"params\">()</span>:</span> <span class=\"keyword\">return</span> <span class=\"number\">0.5</span> * tf.square(residual)</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">f2</span><span class=\"params\">()</span>:</span> <span class=\"keyword\">return</span> delta * residual - <span class=\"number\">0.5</span> * tf.square(delta)</div><div class=\"line\">    <span class=\"keyword\">return</span> tf.cond(residual &lt; delta, f1, f2)</div></pre></td></tr></table></figure></p>\n<h2 id=\"tensorflow-输入\"><a href=\"#tensorflow-输入\" class=\"headerlink\" title=\"tensorflow 输入\"></a>tensorflow 输入</h2><h3 id=\"placeholder-amp-feed-dict\"><a href=\"#placeholder-amp-feed-dict\" class=\"headerlink\" title=\"placeholder &amp; feed_dict\"></a>placeholder &amp; feed_dict</h3><p>note1跳过了对tensorflow基本输入方式的叙述。实际上由于graph在定义的时候不需要考虑实际输入数据的特性。一般创建输入变量的时候实际上是为要输入的变量预留位置，使用tf.placeholder定义,如下是一个使用的例子<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">a = tf.placeholder(dtype, shape=<span class=\"keyword\">None</span>, name=<span class=\"keyword\">None</span>)</div><div class=\"line\">...</div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">   sess.run(something, feed_dict = &#123;a:[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]&#125;)</div></pre></td></tr></table></figure></p>\n<p>shape参数制定了传入的tensor的结构，shape为None意味着任意结构的tensor都能被接收（可能潜在地会引入bug）</p>\n<h3 id=\"tf-data\"><a href=\"#tf-data\" class=\"headerlink\" title=\"tf.data\"></a>tf.data</h3><p>placeholder让数据的处理和带入图中运算分开，在tensorflow框架之外完成（完全可以用numpy等工具处理），不过这样带来的不好的地方之一在于，数据处理被放在了python的单一线程当中，会让数据处理较慢。（大量数据要从外部一个个装载到place_holder处）  </p>\n<p>如上述代码当中看起来就不优雅的一段：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>): <span class=\"comment\"># run 100 epochs</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> data:</div><div class=\"line\">\t\t<span class=\"comment\"># Session runs train_op to minimize loss</span></div><div class=\"line\">\t\tsess.run(optimizer, feed_dict=&#123;X: x, Y:y&#125;)</div></pre></td></tr></table></figure></p>\n<p>将数据分100次载入place_holder当中实际上较大的拖慢了程序的速度。还需要考虑的是在并行计算的时候载入feed_dict可能阻碍了其它操作的执行。</p>\n<p>tensorflow提供的解决方案是将数据存储在tf.data.Dataset object当中<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">tf.data.Dataset.from_tensor_slices((features, labels))</div><div class=\"line\"><span class=\"comment\"># can use numpy arrays as features and labels</span></div></pre></td></tr></table></figure></p>\n<p>之后使用迭代器来访问dataset当中的每一个数据<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># we use make_initializable_iterator for multiple epochs</span></div><div class=\"line\">iterator = dataset.make_initializable_iterator()</div><div class=\"line\">X, Y = iterator.get_next() </div><div class=\"line\">···</div><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>): </div><div class=\"line\">        <span class=\"comment\"># reset where iterator point to</span></div><div class=\"line\">        sess.run(iterator.initializer)</div><div class=\"line\">        total_loss = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">try</span>:</div><div class=\"line\">            <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">                sess.run([optimizer]) </div><div class=\"line\">        <span class=\"keyword\">except</span> tf.errors.OutOfRangeError:</div><div class=\"line\">            <span class=\"keyword\">pass</span></div></pre></td></tr></table></figure></p>\n<p>dataset 也支持许多原生的对数据集的操作来改变数据集或是生成新的数据集<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">dataset = dataset.shuffle(<span class=\"number\">1000</span>)</div><div class=\"line\">dataset = dataset.repeat(<span class=\"number\">100</span>)</div><div class=\"line\">dataset = dataset.batch(<span class=\"number\">128</span>)</div><div class=\"line\">dataset = dataset.map(<span class=\"keyword\">lambda</span> x: tf.one_hot(x, <span class=\"number\">10</span>)) </div><div class=\"line\"><span class=\"comment\"># convert each element of dataset to one_hot vector</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Optimizers\"><a href=\"#Optimizers\" class=\"headerlink\" title=\"Optimizers\"></a>Optimizers</h2><p>默认情况下optimizer在每一轮迭代的过程中自动更新loss function所依赖的所有变量，若有不想更新的变量，在定义的时候加上参数trainable=False</p>\n<p>(to do: add contont about more detailed control of model trains using tf.gradient)</p>\n<h2 id=\"Refs\"><a href=\"#Refs\" class=\"headerlink\" title=\"Refs\"></a>Refs</h2><p><a href=\"https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit#\" target=\"_blank\" rel=\"external\">03_Lecture note_Linear and Logistic Regression</a><br><a href=\"https://en.wikipedia.org/wiki/Huber_loss\" target=\"_blank\" rel=\"external\">Huber Loss</a></p>\n","excerpt":"","more":"<h1 id=\"TensorFlow-学习笔记-2\"><a href=\"#TensorFlow-学习笔记-2\" class=\"headerlink\" title=\"TensorFlow 学习笔记 #2\"></a>TensorFlow 学习笔记 #2</h1><p>先来看一个简单的线性回归的代码例子，再来看在其基础上可以做出什么改进<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> utils</div><div class=\"line\"></div><div class=\"line\">DATA_FILE = <span class=\"string\">\"data/birth_life_2010.txt\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 1: read in data from the .txt file</span></div><div class=\"line\"><span class=\"comment\"># data is a numpy array of shape (190, 2), each row is a datapoint</span></div><div class=\"line\">data, n_samples = utils.read_birth_life_data(DATA_FILE)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 2: create placeholders for X (birth rate) and Y (life expectancy)</span></div><div class=\"line\">X = tf.placeholder(tf.float32, name=<span class=\"string\">'X'</span>)</div><div class=\"line\">Y = tf.placeholder(tf.float32, name=<span class=\"string\">'Y'</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 3: create weight and bias, initialized to 0</span></div><div class=\"line\">w = tf.get_variable(<span class=\"string\">'weights'</span>, initializer=tf.constant(<span class=\"number\">0.0</span>))</div><div class=\"line\">b = tf.get_variable(<span class=\"string\">'bias'</span>, initializer=tf.constant(<span class=\"number\">0.0</span>))</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 4: construct model to predict Y (life expectancy from birth rate)</span></div><div class=\"line\">Y_predicted = w * X + b </div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 5: use the square error as the loss function</span></div><div class=\"line\">loss = tf.square(Y - Y_predicted, name=<span class=\"string\">'loss'</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Step 6: using gradient descent with learning rate of 0.01 to minimize loss</span></div><div class=\"line\">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class=\"number\">0.001</span>).minimize(loss)</div><div class=\"line\"> </div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">\t<span class=\"comment\"># Step 7: initialize the necessary variables, in this case, w and b</span></div><div class=\"line\">\tsess.run(tf.global_variables_initializer()) </div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"comment\"># Step 8: train the model</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>): <span class=\"comment\"># run 100 epochs</span></div><div class=\"line\">\t\t<span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> data:</div><div class=\"line\">\t\t\t<span class=\"comment\"># Session runs train_op to minimize loss</span></div><div class=\"line\">\t\t\tsess.run(optimizer, feed_dict=&#123;X: x, Y:y&#125;) </div><div class=\"line\">\t</div><div class=\"line\">\t<span class=\"comment\"># Step 9: output the values of w and b</span></div><div class=\"line\">\tw_out, b_out = sess.run([w, b])</div></pre></td></tr></table></figure></p>\n<h2 id=\"tensorflow-控制流\"><a href=\"#tensorflow-控制流\" class=\"headerlink\" title=\"tensorflow 控制流\"></a>tensorflow 控制流</h2><p>观察上面线性回归所使用的loss function，是个简单的二次函数<br>分析离群点，假设有一个离样本较远的离群点，那么这个离群点造成的loss fuction上的损失较大，会大大影响整个模型的建模。</p>\n<p><strong>使用<a href=\"https://en.wikipedia.org/wiki/Huber_loss\">huber loss</a>代替原来简单的loss fuction</strong><br>其定义如下所示    </p>\n<p>$$<br>L_\\delta(y,f(x))=\\left{<br>\\begin{array}{ll}<br>\\frac12(y-f(x))^2,&amp;\\textrm{for }|y-f(x)|\\leq\\delta\\\\<br>\\delta\\cdot(|y-f(x)|-\\delta/2),&amp; \\textrm{otherwise.}<br>\\end{array}<br>\\right.<br>$$</p>\n<p>Huber loss给离群点设置了相对更小的权重,因而提升了拟合的效果。</p>\n<p>一个显然的事实是由于tensorflow 定义和执行的分离，我们不能用python的条件分支语句来控制optimizer使用哪一种loss function,tensor flow提供了分支控制的方法</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Ops</th>\n<th style=\"text-align:left\">Methods</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Control Flow Ops</td>\n<td style=\"text-align:left\">tf.count_up_to, tf.cond, tf.case, tf.while_loop, tf.group …</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Comparison Ops</td>\n<td style=\"text-align:left\">tf.equal, tf.not_equal, tf.less, tf.greater, tf.where, …</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Logical Ops</td>\n<td style=\"text-align:left\">tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Debugging Ops</td>\n<td style=\"text-align:left\">tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print, …</td>\n</tr>\n</tbody>\n</table>\n<p>huber_loss：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">huber_loss</span><span class=\"params\">(labels, predictions, delta=<span class=\"number\">14.0</span>)</span>:</span></div><div class=\"line\">    residual = tf.abs(labels - predictions)</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">f1</span><span class=\"params\">()</span>:</span> <span class=\"keyword\">return</span> <span class=\"number\">0.5</span> * tf.square(residual)</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">f2</span><span class=\"params\">()</span>:</span> <span class=\"keyword\">return</span> delta * residual - <span class=\"number\">0.5</span> * tf.square(delta)</div><div class=\"line\">    <span class=\"keyword\">return</span> tf.cond(residual &lt; delta, f1, f2)</div></pre></td></tr></table></figure></p>\n<h2 id=\"tensorflow-输入\"><a href=\"#tensorflow-输入\" class=\"headerlink\" title=\"tensorflow 输入\"></a>tensorflow 输入</h2><h3 id=\"placeholder-amp-feed-dict\"><a href=\"#placeholder-amp-feed-dict\" class=\"headerlink\" title=\"placeholder &amp; feed_dict\"></a>placeholder &amp; feed_dict</h3><p>note1跳过了对tensorflow基本输入方式的叙述。实际上由于graph在定义的时候不需要考虑实际输入数据的特性。一般创建输入变量的时候实际上是为要输入的变量预留位置，使用tf.placeholder定义,如下是一个使用的例子<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">a = tf.placeholder(dtype, shape=<span class=\"keyword\">None</span>, name=<span class=\"keyword\">None</span>)</div><div class=\"line\">...</div><div class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">   sess.run(something, feed_dict = &#123;a:[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]&#125;)</div></pre></td></tr></table></figure></p>\n<p>shape参数制定了传入的tensor的结构，shape为None意味着任意结构的tensor都能被接收（可能潜在地会引入bug）</p>\n<h3 id=\"tf-data\"><a href=\"#tf-data\" class=\"headerlink\" title=\"tf.data\"></a>tf.data</h3><p>placeholder让数据的处理和带入图中运算分开，在tensorflow框架之外完成（完全可以用numpy等工具处理），不过这样带来的不好的地方之一在于，数据处理被放在了python的单一线程当中，会让数据处理较慢。（大量数据要从外部一个个装载到place_holder处）  </p>\n<p>如上述代码当中看起来就不优雅的一段：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>): <span class=\"comment\"># run 100 epochs</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> data:</div><div class=\"line\">\t\t<span class=\"comment\"># Session runs train_op to minimize loss</span></div><div class=\"line\">\t\tsess.run(optimizer, feed_dict=&#123;X: x, Y:y&#125;)</div></pre></td></tr></table></figure></p>\n<p>将数据分100次载入place_holder当中实际上较大的拖慢了程序的速度。还需要考虑的是在并行计算的时候载入feed_dict可能阻碍了其它操作的执行。</p>\n<p>tensorflow提供的解决方案是将数据存储在tf.data.Dataset object当中<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">tf.data.Dataset.from_tensor_slices((features, labels))</div><div class=\"line\"><span class=\"comment\"># can use numpy arrays as features and labels</span></div></pre></td></tr></table></figure></p>\n<p>之后使用迭代器来访问dataset当中的每一个数据<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># we use make_initializable_iterator for multiple epochs</span></div><div class=\"line\">iterator = dataset.make_initializable_iterator()</div><div class=\"line\">X, Y = iterator.get_next() </div><div class=\"line\">···</div><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>): </div><div class=\"line\">        <span class=\"comment\"># reset where iterator point to</span></div><div class=\"line\">        sess.run(iterator.initializer)</div><div class=\"line\">        total_loss = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">try</span>:</div><div class=\"line\">            <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">                sess.run([optimizer]) </div><div class=\"line\">        <span class=\"keyword\">except</span> tf.errors.OutOfRangeError:</div><div class=\"line\">            <span class=\"keyword\">pass</span></div></pre></td></tr></table></figure></p>\n<p>dataset 也支持许多原生的对数据集的操作来改变数据集或是生成新的数据集<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">dataset = dataset.shuffle(<span class=\"number\">1000</span>)</div><div class=\"line\">dataset = dataset.repeat(<span class=\"number\">100</span>)</div><div class=\"line\">dataset = dataset.batch(<span class=\"number\">128</span>)</div><div class=\"line\">dataset = dataset.map(<span class=\"keyword\">lambda</span> x: tf.one_hot(x, <span class=\"number\">10</span>)) </div><div class=\"line\"><span class=\"comment\"># convert each element of dataset to one_hot vector</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Optimizers\"><a href=\"#Optimizers\" class=\"headerlink\" title=\"Optimizers\"></a>Optimizers</h2><p>默认情况下optimizer在每一轮迭代的过程中自动更新loss function所依赖的所有变量，若有不想更新的变量，在定义的时候加上参数trainable=False</p>\n<p>(to do: add contont about more detailed control of model trains using tf.gradient)</p>\n<h2 id=\"Refs\"><a href=\"#Refs\" class=\"headerlink\" title=\"Refs\"></a>Refs</h2><p><a href=\"https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit#\">03_Lecture note_Linear and Logistic Regression</a><br><a href=\"https://en.wikipedia.org/wiki/Huber_loss\">Huber Loss</a></p>\n"},{"title":"Convolutional Nerual Networks for Visual Recongnition","date":"2018-04-12T14:58:00.000Z","_content":"\n# Convolutional Nerual Networks (CNNs/ConvNets)\n\n## Over view\n### 引入\n首先为啥会有CNN这个东西呢？  \n一个普通的神经网络的示意图如下所示  \n![](./images/tf/simple_neural_net.jpeg)\n可见，这种神经网络层与层之间是全连接的，对于minist这种数据集使用，假设输入图像为32*32*3 = 3072个节点，勉强可以处理。但是对于更大的输入图像，200*200*3 = 120000个神经元节点，这种神经网络处理起来就比较费力。  \n很显然，这种时候全连接就显得比较无用和浪费，大量的参数不仅难以优化，而且会快速的导致网络的过拟合。  \n\n### Architecture\n卷积神经网络同样由许多层构成，其中主要的有三种：\n1. Concoluntional Layer (卷积层)\n2. Polling Layer ()\n3. Full-Connected Layer ()\n\n一个较为典型的架构是：[INPUT-CONV-RELU-POOL-FC]\n* INPUT: 3-d [width * height * color-channels]\n* CONV : 卷积层\n* RELU : Rectified Linear Unit (线性整流函数) 常用的有斜坡函数(max(0,x))\n* POOL : 对输入进行下降抽样（输出向量的前两位小于输入）\n* FC: 全连接的层  \n\n其中只有CONV层和FC层是包含所需要优化的参数的。\n\n## Layers\n### Convolutional Layer (卷积层)\n我们知道在高维度的输入下，全连接不太实际。取而代之的是，可以对每个节点和输入的某个局部的区域连接。而如何选择这个区域，由一组超参数（hyperparameter）决定，这被称为神经元的（receptive field），也就是filter size.\n\n#### 输出维度（spatial-arrangement）\n输出的空间维度由三个超参数决定：\n* Depth: 输出的深度等于用到的filter的个数。可以理解为：不同的filter试图在数据里面找到不同的特征。\n* Stride: Stride可以理解为对filter滑动的间距。当Stride较大的时候，输出的维度较小。（通常情况下1、2）\n* Zero-padding: 有时候在特定Stride值下，不能整除的时候周围输入就要补零。\n\n$W =$ input volume size  \n$P =$ receptive field size of the conv layer nerons  \n$S =$ stride  \n$P =$ amount of zero-padding  \n则有：  \n$(W-F+2P)/S + 1$则为一个filter所对应的CONV Layer的节点数。\n\n#### 参数共享（parameter sharing）\n在Conv Layer Local connectivity的情况下，假设输入向量大小为[a* b * c], 输出[x * y* z], filter [n * m * c]。那么Conv Layer一共有xyz个节点，每一个节点有nmc个参数，一共有xyznmc个参数，取x = 55, y = 55, z = 96,n = 11,m = 11, c = 3。这种数量级仍然是难以接受的。\n\n可以通过一个合理的假设大量减少参数的数量，可以认为如果某个特征在某一点是有效的，那么在其它点其是同样有效的。也就是说，限制Conv layer在每一个filter（depth）下的神经元使用同样的参数和bias，总的参数数量可以快速减少到zmnc。（在back propogation当中，同意深度下使用相同参数的神经元的贡献会被相加）\n\nConv Layer 的计算过程如图所示：  \n![](./images/tf/convolution.png)\n\n#### Two key insights：\n关于CONV Layer的两个关键点  \n1) Features are hierarchical\nComposing high-complexity features out of low-complexity features is more\nefficient than learning high-complexity features directly.\ne.g.: having an “circle” detector is useful for detecting faces… and basketballs\n2) Features are translationally invariant\nIf a feature is useful to compute at (x, y) it is useful to compute that feature at\n(x’, y’) as well\n\nps: 为何叫卷积层呢：因为其与两个信号的卷积类似。  \n\n\n\n### Pooling Layer (不知道咋翻译..)\nPooling Layer常被加在连续的Conv Layer当中，它的主要作用是逐步减少空间大小来减少参数的数量，从而控制过拟合。  \n\nPooling层独立的作用于各个depth slice。\n\n一个常见的例子是使用2*2的filter，stride为2,使用max function，取四激励中最大的，从而忽略掉75%的激励\n\n当然还有一些其它pooling的方法，如average pooling和L2-norm pooling在此mark以后深入研究。\n\n","source":"_posts/machinelearning/tensorflow_notes/note_CNN.md","raw":"---\ntitle: Convolutional Nerual Networks for Visual Recongnition\ndate: 2018-04-12 22:58:00\ntags: [CNN,DeepLearning]\n---\n\n# Convolutional Nerual Networks (CNNs/ConvNets)\n\n## Over view\n### 引入\n首先为啥会有CNN这个东西呢？  \n一个普通的神经网络的示意图如下所示  \n![](./images/tf/simple_neural_net.jpeg)\n可见，这种神经网络层与层之间是全连接的，对于minist这种数据集使用，假设输入图像为32*32*3 = 3072个节点，勉强可以处理。但是对于更大的输入图像，200*200*3 = 120000个神经元节点，这种神经网络处理起来就比较费力。  \n很显然，这种时候全连接就显得比较无用和浪费，大量的参数不仅难以优化，而且会快速的导致网络的过拟合。  \n\n### Architecture\n卷积神经网络同样由许多层构成，其中主要的有三种：\n1. Concoluntional Layer (卷积层)\n2. Polling Layer ()\n3. Full-Connected Layer ()\n\n一个较为典型的架构是：[INPUT-CONV-RELU-POOL-FC]\n* INPUT: 3-d [width * height * color-channels]\n* CONV : 卷积层\n* RELU : Rectified Linear Unit (线性整流函数) 常用的有斜坡函数(max(0,x))\n* POOL : 对输入进行下降抽样（输出向量的前两位小于输入）\n* FC: 全连接的层  \n\n其中只有CONV层和FC层是包含所需要优化的参数的。\n\n## Layers\n### Convolutional Layer (卷积层)\n我们知道在高维度的输入下，全连接不太实际。取而代之的是，可以对每个节点和输入的某个局部的区域连接。而如何选择这个区域，由一组超参数（hyperparameter）决定，这被称为神经元的（receptive field），也就是filter size.\n\n#### 输出维度（spatial-arrangement）\n输出的空间维度由三个超参数决定：\n* Depth: 输出的深度等于用到的filter的个数。可以理解为：不同的filter试图在数据里面找到不同的特征。\n* Stride: Stride可以理解为对filter滑动的间距。当Stride较大的时候，输出的维度较小。（通常情况下1、2）\n* Zero-padding: 有时候在特定Stride值下，不能整除的时候周围输入就要补零。\n\n$W =$ input volume size  \n$P =$ receptive field size of the conv layer nerons  \n$S =$ stride  \n$P =$ amount of zero-padding  \n则有：  \n$(W-F+2P)/S + 1$则为一个filter所对应的CONV Layer的节点数。\n\n#### 参数共享（parameter sharing）\n在Conv Layer Local connectivity的情况下，假设输入向量大小为[a* b * c], 输出[x * y* z], filter [n * m * c]。那么Conv Layer一共有xyz个节点，每一个节点有nmc个参数，一共有xyznmc个参数，取x = 55, y = 55, z = 96,n = 11,m = 11, c = 3。这种数量级仍然是难以接受的。\n\n可以通过一个合理的假设大量减少参数的数量，可以认为如果某个特征在某一点是有效的，那么在其它点其是同样有效的。也就是说，限制Conv layer在每一个filter（depth）下的神经元使用同样的参数和bias，总的参数数量可以快速减少到zmnc。（在back propogation当中，同意深度下使用相同参数的神经元的贡献会被相加）\n\nConv Layer 的计算过程如图所示：  \n![](./images/tf/convolution.png)\n\n#### Two key insights：\n关于CONV Layer的两个关键点  \n1) Features are hierarchical\nComposing high-complexity features out of low-complexity features is more\nefficient than learning high-complexity features directly.\ne.g.: having an “circle” detector is useful for detecting faces… and basketballs\n2) Features are translationally invariant\nIf a feature is useful to compute at (x, y) it is useful to compute that feature at\n(x’, y’) as well\n\nps: 为何叫卷积层呢：因为其与两个信号的卷积类似。  \n\n\n\n### Pooling Layer (不知道咋翻译..)\nPooling Layer常被加在连续的Conv Layer当中，它的主要作用是逐步减少空间大小来减少参数的数量，从而控制过拟合。  \n\nPooling层独立的作用于各个depth slice。\n\n一个常见的例子是使用2*2的filter，stride为2,使用max function，取四激励中最大的，从而忽略掉75%的激励\n\n当然还有一些其它pooling的方法，如average pooling和L2-norm pooling在此mark以后深入研究。\n\n","slug":"machinelearning/tensorflow_notes/note_CNN","published":1,"updated":"2018-04-16T05:07:12.896Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56ad001yacwoe54ryp05","content":"<h1 id=\"Convolutional-Nerual-Networks-CNNs-ConvNets\"><a href=\"#Convolutional-Nerual-Networks-CNNs-ConvNets\" class=\"headerlink\" title=\"Convolutional Nerual Networks (CNNs/ConvNets)\"></a>Convolutional Nerual Networks (CNNs/ConvNets)</h1><h2 id=\"Over-view\"><a href=\"#Over-view\" class=\"headerlink\" title=\"Over view\"></a>Over view</h2><h3 id=\"引入\"><a href=\"#引入\" class=\"headerlink\" title=\"引入\"></a>引入</h3><p>首先为啥会有CNN这个东西呢？<br>一个普通的神经网络的示意图如下所示<br><img src=\"./images/tf/simple_neural_net.jpeg\" alt=\"\"><br>可见，这种神经网络层与层之间是全连接的，对于minist这种数据集使用，假设输入图像为32<em>32</em>3 = 3072个节点，勉强可以处理。但是对于更大的输入图像，200<em>200</em>3 = 120000个神经元节点，这种神经网络处理起来就比较费力。<br>很显然，这种时候全连接就显得比较无用和浪费，大量的参数不仅难以优化，而且会快速的导致网络的过拟合。  </p>\n<h3 id=\"Architecture\"><a href=\"#Architecture\" class=\"headerlink\" title=\"Architecture\"></a>Architecture</h3><p>卷积神经网络同样由许多层构成，其中主要的有三种：</p>\n<ol>\n<li>Concoluntional Layer (卷积层)</li>\n<li>Polling Layer ()</li>\n<li>Full-Connected Layer ()</li>\n</ol>\n<p>一个较为典型的架构是：[INPUT-CONV-RELU-POOL-FC]</p>\n<ul>\n<li>INPUT: 3-d [width <em> height </em> color-channels]</li>\n<li>CONV : 卷积层</li>\n<li>RELU : Rectified Linear Unit (线性整流函数) 常用的有斜坡函数(max(0,x))</li>\n<li>POOL : 对输入进行下降抽样（输出向量的前两位小于输入）</li>\n<li>FC: 全连接的层  </li>\n</ul>\n<p>其中只有CONV层和FC层是包含所需要优化的参数的。</p>\n<h2 id=\"Layers\"><a href=\"#Layers\" class=\"headerlink\" title=\"Layers\"></a>Layers</h2><h3 id=\"Convolutional-Layer-卷积层\"><a href=\"#Convolutional-Layer-卷积层\" class=\"headerlink\" title=\"Convolutional Layer (卷积层)\"></a>Convolutional Layer (卷积层)</h3><p>我们知道在高维度的输入下，全连接不太实际。取而代之的是，可以对每个节点和输入的某个局部的区域连接。而如何选择这个区域，由一组超参数（hyperparameter）决定，这被称为神经元的（receptive field），也就是filter size.</p>\n<h4 id=\"输出维度（spatial-arrangement）\"><a href=\"#输出维度（spatial-arrangement）\" class=\"headerlink\" title=\"输出维度（spatial-arrangement）\"></a>输出维度（spatial-arrangement）</h4><p>输出的空间维度由三个超参数决定：</p>\n<ul>\n<li>Depth: 输出的深度等于用到的filter的个数。可以理解为：不同的filter试图在数据里面找到不同的特征。</li>\n<li>Stride: Stride可以理解为对filter滑动的间距。当Stride较大的时候，输出的维度较小。（通常情况下1、2）</li>\n<li>Zero-padding: 有时候在特定Stride值下，不能整除的时候周围输入就要补零。</li>\n</ul>\n<p>$W =$ input volume size<br>$P =$ receptive field size of the conv layer nerons<br>$S =$ stride<br>$P =$ amount of zero-padding<br>则有：<br>$(W-F+2P)/S + 1$则为一个filter所对应的CONV Layer的节点数。</p>\n<h4 id=\"参数共享（parameter-sharing）\"><a href=\"#参数共享（parameter-sharing）\" class=\"headerlink\" title=\"参数共享（parameter sharing）\"></a>参数共享（parameter sharing）</h4><p>在Conv Layer Local connectivity的情况下，假设输入向量大小为[a<em> b </em> c], 输出[x <em> y</em> z], filter [n <em> m </em> c]。那么Conv Layer一共有xyz个节点，每一个节点有nmc个参数，一共有xyznmc个参数，取x = 55, y = 55, z = 96,n = 11,m = 11, c = 3。这种数量级仍然是难以接受的。</p>\n<p>可以通过一个合理的假设大量减少参数的数量，可以认为如果某个特征在某一点是有效的，那么在其它点其是同样有效的。也就是说，限制Conv layer在每一个filter（depth）下的神经元使用同样的参数和bias，总的参数数量可以快速减少到zmnc。（在back propogation当中，同意深度下使用相同参数的神经元的贡献会被相加）</p>\n<p>Conv Layer 的计算过程如图所示：<br><img src=\"./images/tf/convolution.png\" alt=\"\"></p>\n<h4 id=\"Two-key-insights：\"><a href=\"#Two-key-insights：\" class=\"headerlink\" title=\"Two key insights：\"></a>Two key insights：</h4><p>关于CONV Layer的两个关键点<br>1) Features are hierarchical<br>Composing high-complexity features out of low-complexity features is more<br>efficient than learning high-complexity features directly.<br>e.g.: having an “circle” detector is useful for detecting faces… and basketballs<br>2) Features are translationally invariant<br>If a feature is useful to compute at (x, y) it is useful to compute that feature at<br>(x’, y’) as well</p>\n<p>ps: 为何叫卷积层呢：因为其与两个信号的卷积类似。  </p>\n<h3 id=\"Pooling-Layer-不知道咋翻译\"><a href=\"#Pooling-Layer-不知道咋翻译\" class=\"headerlink\" title=\"Pooling Layer (不知道咋翻译..)\"></a>Pooling Layer (不知道咋翻译..)</h3><p>Pooling Layer常被加在连续的Conv Layer当中，它的主要作用是逐步减少空间大小来减少参数的数量，从而控制过拟合。  </p>\n<p>Pooling层独立的作用于各个depth slice。</p>\n<p>一个常见的例子是使用2*2的filter，stride为2,使用max function，取四激励中最大的，从而忽略掉75%的激励</p>\n<p>当然还有一些其它pooling的方法，如average pooling和L2-norm pooling在此mark以后深入研究。</p>\n","excerpt":"","more":"<h1 id=\"Convolutional-Nerual-Networks-CNNs-ConvNets\"><a href=\"#Convolutional-Nerual-Networks-CNNs-ConvNets\" class=\"headerlink\" title=\"Convolutional Nerual Networks (CNNs/ConvNets)\"></a>Convolutional Nerual Networks (CNNs/ConvNets)</h1><h2 id=\"Over-view\"><a href=\"#Over-view\" class=\"headerlink\" title=\"Over view\"></a>Over view</h2><h3 id=\"引入\"><a href=\"#引入\" class=\"headerlink\" title=\"引入\"></a>引入</h3><p>首先为啥会有CNN这个东西呢？<br>一个普通的神经网络的示意图如下所示<br><img src=\"./images/tf/simple_neural_net.jpeg\" alt=\"\"><br>可见，这种神经网络层与层之间是全连接的，对于minist这种数据集使用，假设输入图像为32<em>32</em>3 = 3072个节点，勉强可以处理。但是对于更大的输入图像，200<em>200</em>3 = 120000个神经元节点，这种神经网络处理起来就比较费力。<br>很显然，这种时候全连接就显得比较无用和浪费，大量的参数不仅难以优化，而且会快速的导致网络的过拟合。  </p>\n<h3 id=\"Architecture\"><a href=\"#Architecture\" class=\"headerlink\" title=\"Architecture\"></a>Architecture</h3><p>卷积神经网络同样由许多层构成，其中主要的有三种：</p>\n<ol>\n<li>Concoluntional Layer (卷积层)</li>\n<li>Polling Layer ()</li>\n<li>Full-Connected Layer ()</li>\n</ol>\n<p>一个较为典型的架构是：[INPUT-CONV-RELU-POOL-FC]</p>\n<ul>\n<li>INPUT: 3-d [width <em> height </em> color-channels]</li>\n<li>CONV : 卷积层</li>\n<li>RELU : Rectified Linear Unit (线性整流函数) 常用的有斜坡函数(max(0,x))</li>\n<li>POOL : 对输入进行下降抽样（输出向量的前两位小于输入）</li>\n<li>FC: 全连接的层  </li>\n</ul>\n<p>其中只有CONV层和FC层是包含所需要优化的参数的。</p>\n<h2 id=\"Layers\"><a href=\"#Layers\" class=\"headerlink\" title=\"Layers\"></a>Layers</h2><h3 id=\"Convolutional-Layer-卷积层\"><a href=\"#Convolutional-Layer-卷积层\" class=\"headerlink\" title=\"Convolutional Layer (卷积层)\"></a>Convolutional Layer (卷积层)</h3><p>我们知道在高维度的输入下，全连接不太实际。取而代之的是，可以对每个节点和输入的某个局部的区域连接。而如何选择这个区域，由一组超参数（hyperparameter）决定，这被称为神经元的（receptive field），也就是filter size.</p>\n<h4 id=\"输出维度（spatial-arrangement）\"><a href=\"#输出维度（spatial-arrangement）\" class=\"headerlink\" title=\"输出维度（spatial-arrangement）\"></a>输出维度（spatial-arrangement）</h4><p>输出的空间维度由三个超参数决定：</p>\n<ul>\n<li>Depth: 输出的深度等于用到的filter的个数。可以理解为：不同的filter试图在数据里面找到不同的特征。</li>\n<li>Stride: Stride可以理解为对filter滑动的间距。当Stride较大的时候，输出的维度较小。（通常情况下1、2）</li>\n<li>Zero-padding: 有时候在特定Stride值下，不能整除的时候周围输入就要补零。</li>\n</ul>\n<p>$W =$ input volume size<br>$P =$ receptive field size of the conv layer nerons<br>$S =$ stride<br>$P =$ amount of zero-padding<br>则有：<br>$(W-F+2P)/S + 1$则为一个filter所对应的CONV Layer的节点数。</p>\n<h4 id=\"参数共享（parameter-sharing）\"><a href=\"#参数共享（parameter-sharing）\" class=\"headerlink\" title=\"参数共享（parameter sharing）\"></a>参数共享（parameter sharing）</h4><p>在Conv Layer Local connectivity的情况下，假设输入向量大小为[a<em> b </em> c], 输出[x <em> y</em> z], filter [n <em> m </em> c]。那么Conv Layer一共有xyz个节点，每一个节点有nmc个参数，一共有xyznmc个参数，取x = 55, y = 55, z = 96,n = 11,m = 11, c = 3。这种数量级仍然是难以接受的。</p>\n<p>可以通过一个合理的假设大量减少参数的数量，可以认为如果某个特征在某一点是有效的，那么在其它点其是同样有效的。也就是说，限制Conv layer在每一个filter（depth）下的神经元使用同样的参数和bias，总的参数数量可以快速减少到zmnc。（在back propogation当中，同意深度下使用相同参数的神经元的贡献会被相加）</p>\n<p>Conv Layer 的计算过程如图所示：<br><img src=\"./images/tf/convolution.png\" alt=\"\"></p>\n<h4 id=\"Two-key-insights：\"><a href=\"#Two-key-insights：\" class=\"headerlink\" title=\"Two key insights：\"></a>Two key insights：</h4><p>关于CONV Layer的两个关键点<br>1) Features are hierarchical<br>Composing high-complexity features out of low-complexity features is more<br>efficient than learning high-complexity features directly.<br>e.g.: having an “circle” detector is useful for detecting faces… and basketballs<br>2) Features are translationally invariant<br>If a feature is useful to compute at (x, y) it is useful to compute that feature at<br>(x’, y’) as well</p>\n<p>ps: 为何叫卷积层呢：因为其与两个信号的卷积类似。  </p>\n<h3 id=\"Pooling-Layer-不知道咋翻译\"><a href=\"#Pooling-Layer-不知道咋翻译\" class=\"headerlink\" title=\"Pooling Layer (不知道咋翻译..)\"></a>Pooling Layer (不知道咋翻译..)</h3><p>Pooling Layer常被加在连续的Conv Layer当中，它的主要作用是逐步减少空间大小来减少参数的数量，从而控制过拟合。  </p>\n<p>Pooling层独立的作用于各个depth slice。</p>\n<p>一个常见的例子是使用2*2的filter，stride为2,使用max function，取四激励中最大的，从而忽略掉75%的激励</p>\n<p>当然还有一些其它pooling的方法，如average pooling和L2-norm pooling在此mark以后深入研究。</p>\n"},{"title":"Using tensorflow on Minist","date":"2018-03-31T03:31:00.000Z","_content":"# 使用卷积神经网络预测minist手写数字\nminist是一个入门的标准cv集。 \n详细注释见minist当中注释  \n直接上代码\n```python\n\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n  # MNIST images are 28x28 pixels, and have one color channel\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  # Computes 32 features using a 5x5 filter with ReLU activation.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 28, 28, 1]\n  # Output Tensor Shape: [batch_size, 28, 28, 32]\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  # First max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 28, 28, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 32]\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2\n  # Computes 64 features using a 5x5 filter.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 14, 14, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 64]\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #2\n  # Second max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 14, 14, 64]\n  # Output Tensor Shape: [batch_size, 7, 7, 64]\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Flatten tensor into a batch of vectors\n  # Input Tensor Shape: [batch_size, 7, 7, 64]\n  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n  # Dense Layer\n  # Densely connected layer with 1024 neurons\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n  # Output Tensor Shape: [batch_size, 1024]\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  # Logits layer\n  # Input Tensor Shape: [batch_size, 1024]\n  # Output Tensor Shape: [batch_size, 10]\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=20000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data},\n      y=eval_labels,\n      num_epochs=1,\n      shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n```\n目前我没弄懂的一点在于，这个框架没用session 也没用eager mode是怎么跑起来的， 如果我想可视化地观察一下这个卷积神经网络的结构又该怎么做呢？\n \n有点明白了，官方的doc当中有这么一句话：  \nEstimators build the graph for you. In other words, you don't have to build the graph.  \n\n其实在一开始应该早就说明白过了，tensorflow的api是分层级的:  \n![](./images/tf/tf_api.png)\n\n如上图estimator 和eager mode是同一层级的，它会自动的帮你构建整个图\n\nTODO: 试着跑一遍代码，用log记录下图的结构，然后在tensorboard里面打开康康。  \n\n\n\n","source":"_posts/machinelearning/tensorflow_notes/tf_minist.md","raw":"---\ntitle: Using tensorflow on Minist\ndate: 2018-03-31 11:31:00\ntags: [tensorflow,CV,ML]\n---\n# 使用卷积神经网络预测minist手写数字\nminist是一个入门的标准cv集。 \n详细注释见minist当中注释  \n直接上代码\n```python\n\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n  # MNIST images are 28x28 pixels, and have one color channel\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  # Computes 32 features using a 5x5 filter with ReLU activation.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 28, 28, 1]\n  # Output Tensor Shape: [batch_size, 28, 28, 32]\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  # First max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 28, 28, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 32]\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2\n  # Computes 64 features using a 5x5 filter.\n  # Padding is added to preserve width and height.\n  # Input Tensor Shape: [batch_size, 14, 14, 32]\n  # Output Tensor Shape: [batch_size, 14, 14, 64]\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #2\n  # Second max pooling layer with a 2x2 filter and stride of 2\n  # Input Tensor Shape: [batch_size, 14, 14, 64]\n  # Output Tensor Shape: [batch_size, 7, 7, 64]\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Flatten tensor into a batch of vectors\n  # Input Tensor Shape: [batch_size, 7, 7, 64]\n  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n  # Dense Layer\n  # Densely connected layer with 1024 neurons\n  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n  # Output Tensor Shape: [batch_size, 1024]\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n\n  # Add dropout operation; 0.6 probability that element will be kept\n  dropout = tf.layers.dropout(\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  # Logits layer\n  # Input Tensor Shape: [batch_size, 1024]\n  # Output Tensor Shape: [batch_size, 10]\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])}\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef main(unused_argv):\n  # Load training and eval data\n  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n  train_data = mnist.train.images  # Returns np.array\n  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n  eval_data = mnist.test.images  # Returns np.array\n  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n\n  # Create the Estimator\n  mnist_classifier = tf.estimator.Estimator(\n      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n\n  # Set up logging for predictions\n  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n  logging_hook = tf.train.LoggingTensorHook(\n      tensors=tensors_to_log, every_n_iter=50)\n\n  # Train the model\n  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": train_data},\n      y=train_labels,\n      batch_size=100,\n      num_epochs=None,\n      shuffle=True)\n  mnist_classifier.train(\n      input_fn=train_input_fn,\n      steps=20000,\n      hooks=[logging_hook])\n\n  # Evaluate the model and print results\n  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x={\"x\": eval_data},\n      y=eval_labels,\n      num_epochs=1,\n      shuffle=False)\n  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n  print(eval_results)\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n```\n目前我没弄懂的一点在于，这个框架没用session 也没用eager mode是怎么跑起来的， 如果我想可视化地观察一下这个卷积神经网络的结构又该怎么做呢？\n \n有点明白了，官方的doc当中有这么一句话：  \nEstimators build the graph for you. In other words, you don't have to build the graph.  \n\n其实在一开始应该早就说明白过了，tensorflow的api是分层级的:  \n![](./images/tf/tf_api.png)\n\n如上图estimator 和eager mode是同一层级的，它会自动的帮你构建整个图\n\nTODO: 试着跑一遍代码，用log记录下图的结构，然后在tensorboard里面打开康康。  \n\n\n\n","slug":"machinelearning/tensorflow_notes/tf_minist","published":1,"updated":"2018-04-16T05:07:08.666Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56as0020acwo0yk8bnep","content":"<h1 id=\"使用卷积神经网络预测minist手写数字\"><a href=\"#使用卷积神经网络预测minist手写数字\" class=\"headerlink\" title=\"使用卷积神经网络预测minist手写数字\"></a>使用卷积神经网络预测minist手写数字</h1><p>minist是一个入门的标准cv集。<br>详细注释见minist当中注释<br>直接上代码<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"string\">\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> absolute_import</div><div class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> division</div><div class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> print_function</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</div><div class=\"line\"></div><div class=\"line\">tf.logging.set_verbosity(tf.logging.INFO)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cnn_model_fn</span><span class=\"params\">(features, labels, mode)</span>:</span></div><div class=\"line\">  <span class=\"string\">\"\"\"Model function for CNN.\"\"\"</span></div><div class=\"line\">  <span class=\"comment\"># Input Layer</span></div><div class=\"line\">  <span class=\"comment\"># Reshape X to 4-D tensor: [batch_size, width, height, channels]</span></div><div class=\"line\">  <span class=\"comment\"># MNIST images are 28x28 pixels, and have one color channel</span></div><div class=\"line\">  input_layer = tf.reshape(features[<span class=\"string\">\"x\"</span>], [<span class=\"number\">-1</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>, <span class=\"number\">1</span>])</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Convolutional Layer #1</span></div><div class=\"line\">  <span class=\"comment\"># Computes 32 features using a 5x5 filter with ReLU activation.</span></div><div class=\"line\">  <span class=\"comment\"># Padding is added to preserve width and height.</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 28, 28, 1]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 28, 28, 32]</span></div><div class=\"line\">  conv1 = tf.layers.conv2d(</div><div class=\"line\">      inputs=input_layer,</div><div class=\"line\">      filters=<span class=\"number\">32</span>,</div><div class=\"line\">      kernel_size=[<span class=\"number\">5</span>, <span class=\"number\">5</span>],</div><div class=\"line\">      padding=<span class=\"string\">\"same\"</span>,</div><div class=\"line\">      activation=tf.nn.relu)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Pooling Layer #1</span></div><div class=\"line\">  <span class=\"comment\"># First max pooling layer with a 2x2 filter and stride of 2</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 28, 28, 32]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 14, 14, 32]</span></div><div class=\"line\">  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[<span class=\"number\">2</span>, <span class=\"number\">2</span>], strides=<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Convolutional Layer #2</span></div><div class=\"line\">  <span class=\"comment\"># Computes 64 features using a 5x5 filter.</span></div><div class=\"line\">  <span class=\"comment\"># Padding is added to preserve width and height.</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 14, 14, 32]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 14, 14, 64]</span></div><div class=\"line\">  conv2 = tf.layers.conv2d(</div><div class=\"line\">      inputs=pool1,</div><div class=\"line\">      filters=<span class=\"number\">64</span>,</div><div class=\"line\">      kernel_size=[<span class=\"number\">5</span>, <span class=\"number\">5</span>],</div><div class=\"line\">      padding=<span class=\"string\">\"same\"</span>,</div><div class=\"line\">      activation=tf.nn.relu)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Pooling Layer #2</span></div><div class=\"line\">  <span class=\"comment\"># Second max pooling layer with a 2x2 filter and stride of 2</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 14, 14, 64]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 7, 7, 64]</span></div><div class=\"line\">  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[<span class=\"number\">2</span>, <span class=\"number\">2</span>], strides=<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Flatten tensor into a batch of vectors</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 7, 7, 64]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 7 * 7 * 64]</span></div><div class=\"line\">  pool2_flat = tf.reshape(pool2, [<span class=\"number\">-1</span>, <span class=\"number\">7</span> * <span class=\"number\">7</span> * <span class=\"number\">64</span>])</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Dense Layer</span></div><div class=\"line\">  <span class=\"comment\"># Densely connected layer with 1024 neurons</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 7 * 7 * 64]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 1024]</span></div><div class=\"line\">  dense = tf.layers.dense(inputs=pool2_flat, units=<span class=\"number\">1024</span>, activation=tf.nn.relu)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Add dropout operation; 0.6 probability that element will be kept</span></div><div class=\"line\">  dropout = tf.layers.dropout(</div><div class=\"line\">      inputs=dense, rate=<span class=\"number\">0.4</span>, training=mode == tf.estimator.ModeKeys.TRAIN)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Logits layer</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 1024]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 10]</span></div><div class=\"line\">  logits = tf.layers.dense(inputs=dropout, units=<span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">  predictions = &#123;</div><div class=\"line\">      <span class=\"comment\"># Generate predictions (for PREDICT and EVAL mode)</span></div><div class=\"line\">      <span class=\"string\">\"classes\"</span>: tf.argmax(input=logits, axis=<span class=\"number\">1</span>),</div><div class=\"line\">      <span class=\"comment\"># Add `softmax_tensor` to the graph. It is used for PREDICT and by the</span></div><div class=\"line\">      <span class=\"comment\"># `logging_hook`.</span></div><div class=\"line\">      <span class=\"string\">\"probabilities\"</span>: tf.nn.softmax(logits, name=<span class=\"string\">\"softmax_tensor\"</span>)</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">if</span> mode == tf.estimator.ModeKeys.PREDICT:</div><div class=\"line\">    <span class=\"keyword\">return</span> tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Calculate Loss (for both TRAIN and EVAL modes)</span></div><div class=\"line\">  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Configure the Training Op (for TRAIN mode)</span></div><div class=\"line\">  <span class=\"keyword\">if</span> mode == tf.estimator.ModeKeys.TRAIN:</div><div class=\"line\">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class=\"number\">0.001</span>)</div><div class=\"line\">    train_op = optimizer.minimize(</div><div class=\"line\">        loss=loss,</div><div class=\"line\">        global_step=tf.train.get_global_step())</div><div class=\"line\">    <span class=\"keyword\">return</span> tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Add evaluation metrics (for EVAL mode)</span></div><div class=\"line\">  eval_metric_ops = &#123;</div><div class=\"line\">      <span class=\"string\">\"accuracy\"</span>: tf.metrics.accuracy(</div><div class=\"line\">          labels=labels, predictions=predictions[<span class=\"string\">\"classes\"</span>])&#125;</div><div class=\"line\">  <span class=\"keyword\">return</span> tf.estimator.EstimatorSpec(</div><div class=\"line\">      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(unused_argv)</span>:</span></div><div class=\"line\">  <span class=\"comment\"># Load training and eval data</span></div><div class=\"line\">  mnist = tf.contrib.learn.datasets.load_dataset(<span class=\"string\">\"mnist\"</span>)</div><div class=\"line\">  train_data = mnist.train.images  <span class=\"comment\"># Returns np.array</span></div><div class=\"line\">  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)</div><div class=\"line\">  eval_data = mnist.test.images  <span class=\"comment\"># Returns np.array</span></div><div class=\"line\">  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Create the Estimator</span></div><div class=\"line\">  mnist_classifier = tf.estimator.Estimator(</div><div class=\"line\">      model_fn=cnn_model_fn, model_dir=<span class=\"string\">\"/tmp/mnist_convnet_model\"</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Set up logging for predictions</span></div><div class=\"line\">  <span class=\"comment\"># Log the values in the \"Softmax\" tensor with label \"probabilities\"</span></div><div class=\"line\">  tensors_to_log = &#123;<span class=\"string\">\"probabilities\"</span>: <span class=\"string\">\"softmax_tensor\"</span>&#125;</div><div class=\"line\">  logging_hook = tf.train.LoggingTensorHook(</div><div class=\"line\">      tensors=tensors_to_log, every_n_iter=<span class=\"number\">50</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Train the model</span></div><div class=\"line\">  train_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class=\"line\">      x=&#123;<span class=\"string\">\"x\"</span>: train_data&#125;,</div><div class=\"line\">      y=train_labels,</div><div class=\"line\">      batch_size=<span class=\"number\">100</span>,</div><div class=\"line\">      num_epochs=<span class=\"keyword\">None</span>,</div><div class=\"line\">      shuffle=<span class=\"keyword\">True</span>)</div><div class=\"line\">  mnist_classifier.train(</div><div class=\"line\">      input_fn=train_input_fn,</div><div class=\"line\">      steps=<span class=\"number\">20000</span>,</div><div class=\"line\">      hooks=[logging_hook])</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Evaluate the model and print results</span></div><div class=\"line\">  eval_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class=\"line\">      x=&#123;<span class=\"string\">\"x\"</span>: eval_data&#125;,</div><div class=\"line\">      y=eval_labels,</div><div class=\"line\">      num_epochs=<span class=\"number\">1</span>,</div><div class=\"line\">      shuffle=<span class=\"keyword\">False</span>)</div><div class=\"line\">  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)</div><div class=\"line\">  print(eval_results)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</div><div class=\"line\">  tf.app.run()</div></pre></td></tr></table></figure></p>\n<p>目前我没弄懂的一点在于，这个框架没用session 也没用eager mode是怎么跑起来的， 如果我想可视化地观察一下这个卷积神经网络的结构又该怎么做呢？</p>\n<p>有点明白了，官方的doc当中有这么一句话：<br>Estimators build the graph for you. In other words, you don’t have to build the graph.  </p>\n<p>其实在一开始应该早就说明白过了，tensorflow的api是分层级的:<br><img src=\"./images/tf/tf_api.png\" alt=\"\"></p>\n<p>如上图estimator 和eager mode是同一层级的，它会自动的帮你构建整个图</p>\n<p>TODO: 试着跑一遍代码，用log记录下图的结构，然后在tensorboard里面打开康康。  </p>\n","excerpt":"","more":"<h1 id=\"使用卷积神经网络预测minist手写数字\"><a href=\"#使用卷积神经网络预测minist手写数字\" class=\"headerlink\" title=\"使用卷积神经网络预测minist手写数字\"></a>使用卷积神经网络预测minist手写数字</h1><p>minist是一个入门的标准cv集。<br>详细注释见minist当中注释<br>直接上代码<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"string\">\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> absolute_import</div><div class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> division</div><div class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> print_function</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</div><div class=\"line\"></div><div class=\"line\">tf.logging.set_verbosity(tf.logging.INFO)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cnn_model_fn</span><span class=\"params\">(features, labels, mode)</span>:</span></div><div class=\"line\">  <span class=\"string\">\"\"\"Model function for CNN.\"\"\"</span></div><div class=\"line\">  <span class=\"comment\"># Input Layer</span></div><div class=\"line\">  <span class=\"comment\"># Reshape X to 4-D tensor: [batch_size, width, height, channels]</span></div><div class=\"line\">  <span class=\"comment\"># MNIST images are 28x28 pixels, and have one color channel</span></div><div class=\"line\">  input_layer = tf.reshape(features[<span class=\"string\">\"x\"</span>], [<span class=\"number\">-1</span>, <span class=\"number\">28</span>, <span class=\"number\">28</span>, <span class=\"number\">1</span>])</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Convolutional Layer #1</span></div><div class=\"line\">  <span class=\"comment\"># Computes 32 features using a 5x5 filter with ReLU activation.</span></div><div class=\"line\">  <span class=\"comment\"># Padding is added to preserve width and height.</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 28, 28, 1]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 28, 28, 32]</span></div><div class=\"line\">  conv1 = tf.layers.conv2d(</div><div class=\"line\">      inputs=input_layer,</div><div class=\"line\">      filters=<span class=\"number\">32</span>,</div><div class=\"line\">      kernel_size=[<span class=\"number\">5</span>, <span class=\"number\">5</span>],</div><div class=\"line\">      padding=<span class=\"string\">\"same\"</span>,</div><div class=\"line\">      activation=tf.nn.relu)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Pooling Layer #1</span></div><div class=\"line\">  <span class=\"comment\"># First max pooling layer with a 2x2 filter and stride of 2</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 28, 28, 32]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 14, 14, 32]</span></div><div class=\"line\">  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[<span class=\"number\">2</span>, <span class=\"number\">2</span>], strides=<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Convolutional Layer #2</span></div><div class=\"line\">  <span class=\"comment\"># Computes 64 features using a 5x5 filter.</span></div><div class=\"line\">  <span class=\"comment\"># Padding is added to preserve width and height.</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 14, 14, 32]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 14, 14, 64]</span></div><div class=\"line\">  conv2 = tf.layers.conv2d(</div><div class=\"line\">      inputs=pool1,</div><div class=\"line\">      filters=<span class=\"number\">64</span>,</div><div class=\"line\">      kernel_size=[<span class=\"number\">5</span>, <span class=\"number\">5</span>],</div><div class=\"line\">      padding=<span class=\"string\">\"same\"</span>,</div><div class=\"line\">      activation=tf.nn.relu)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Pooling Layer #2</span></div><div class=\"line\">  <span class=\"comment\"># Second max pooling layer with a 2x2 filter and stride of 2</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 14, 14, 64]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 7, 7, 64]</span></div><div class=\"line\">  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[<span class=\"number\">2</span>, <span class=\"number\">2</span>], strides=<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Flatten tensor into a batch of vectors</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 7, 7, 64]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 7 * 7 * 64]</span></div><div class=\"line\">  pool2_flat = tf.reshape(pool2, [<span class=\"number\">-1</span>, <span class=\"number\">7</span> * <span class=\"number\">7</span> * <span class=\"number\">64</span>])</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Dense Layer</span></div><div class=\"line\">  <span class=\"comment\"># Densely connected layer with 1024 neurons</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 7 * 7 * 64]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 1024]</span></div><div class=\"line\">  dense = tf.layers.dense(inputs=pool2_flat, units=<span class=\"number\">1024</span>, activation=tf.nn.relu)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Add dropout operation; 0.6 probability that element will be kept</span></div><div class=\"line\">  dropout = tf.layers.dropout(</div><div class=\"line\">      inputs=dense, rate=<span class=\"number\">0.4</span>, training=mode == tf.estimator.ModeKeys.TRAIN)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Logits layer</span></div><div class=\"line\">  <span class=\"comment\"># Input Tensor Shape: [batch_size, 1024]</span></div><div class=\"line\">  <span class=\"comment\"># Output Tensor Shape: [batch_size, 10]</span></div><div class=\"line\">  logits = tf.layers.dense(inputs=dropout, units=<span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">  predictions = &#123;</div><div class=\"line\">      <span class=\"comment\"># Generate predictions (for PREDICT and EVAL mode)</span></div><div class=\"line\">      <span class=\"string\">\"classes\"</span>: tf.argmax(input=logits, axis=<span class=\"number\">1</span>),</div><div class=\"line\">      <span class=\"comment\"># Add `softmax_tensor` to the graph. It is used for PREDICT and by the</span></div><div class=\"line\">      <span class=\"comment\"># `logging_hook`.</span></div><div class=\"line\">      <span class=\"string\">\"probabilities\"</span>: tf.nn.softmax(logits, name=<span class=\"string\">\"softmax_tensor\"</span>)</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">if</span> mode == tf.estimator.ModeKeys.PREDICT:</div><div class=\"line\">    <span class=\"keyword\">return</span> tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Calculate Loss (for both TRAIN and EVAL modes)</span></div><div class=\"line\">  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Configure the Training Op (for TRAIN mode)</span></div><div class=\"line\">  <span class=\"keyword\">if</span> mode == tf.estimator.ModeKeys.TRAIN:</div><div class=\"line\">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class=\"number\">0.001</span>)</div><div class=\"line\">    train_op = optimizer.minimize(</div><div class=\"line\">        loss=loss,</div><div class=\"line\">        global_step=tf.train.get_global_step())</div><div class=\"line\">    <span class=\"keyword\">return</span> tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Add evaluation metrics (for EVAL mode)</span></div><div class=\"line\">  eval_metric_ops = &#123;</div><div class=\"line\">      <span class=\"string\">\"accuracy\"</span>: tf.metrics.accuracy(</div><div class=\"line\">          labels=labels, predictions=predictions[<span class=\"string\">\"classes\"</span>])&#125;</div><div class=\"line\">  <span class=\"keyword\">return</span> tf.estimator.EstimatorSpec(</div><div class=\"line\">      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(unused_argv)</span>:</span></div><div class=\"line\">  <span class=\"comment\"># Load training and eval data</span></div><div class=\"line\">  mnist = tf.contrib.learn.datasets.load_dataset(<span class=\"string\">\"mnist\"</span>)</div><div class=\"line\">  train_data = mnist.train.images  <span class=\"comment\"># Returns np.array</span></div><div class=\"line\">  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)</div><div class=\"line\">  eval_data = mnist.test.images  <span class=\"comment\"># Returns np.array</span></div><div class=\"line\">  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Create the Estimator</span></div><div class=\"line\">  mnist_classifier = tf.estimator.Estimator(</div><div class=\"line\">      model_fn=cnn_model_fn, model_dir=<span class=\"string\">\"/tmp/mnist_convnet_model\"</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Set up logging for predictions</span></div><div class=\"line\">  <span class=\"comment\"># Log the values in the \"Softmax\" tensor with label \"probabilities\"</span></div><div class=\"line\">  tensors_to_log = &#123;<span class=\"string\">\"probabilities\"</span>: <span class=\"string\">\"softmax_tensor\"</span>&#125;</div><div class=\"line\">  logging_hook = tf.train.LoggingTensorHook(</div><div class=\"line\">      tensors=tensors_to_log, every_n_iter=<span class=\"number\">50</span>)</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Train the model</span></div><div class=\"line\">  train_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class=\"line\">      x=&#123;<span class=\"string\">\"x\"</span>: train_data&#125;,</div><div class=\"line\">      y=train_labels,</div><div class=\"line\">      batch_size=<span class=\"number\">100</span>,</div><div class=\"line\">      num_epochs=<span class=\"keyword\">None</span>,</div><div class=\"line\">      shuffle=<span class=\"keyword\">True</span>)</div><div class=\"line\">  mnist_classifier.train(</div><div class=\"line\">      input_fn=train_input_fn,</div><div class=\"line\">      steps=<span class=\"number\">20000</span>,</div><div class=\"line\">      hooks=[logging_hook])</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Evaluate the model and print results</span></div><div class=\"line\">  eval_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class=\"line\">      x=&#123;<span class=\"string\">\"x\"</span>: eval_data&#125;,</div><div class=\"line\">      y=eval_labels,</div><div class=\"line\">      num_epochs=<span class=\"number\">1</span>,</div><div class=\"line\">      shuffle=<span class=\"keyword\">False</span>)</div><div class=\"line\">  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)</div><div class=\"line\">  print(eval_results)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</div><div class=\"line\">  tf.app.run()</div></pre></td></tr></table></figure></p>\n<p>目前我没弄懂的一点在于，这个框架没用session 也没用eager mode是怎么跑起来的， 如果我想可视化地观察一下这个卷积神经网络的结构又该怎么做呢？</p>\n<p>有点明白了，官方的doc当中有这么一句话：<br>Estimators build the graph for you. In other words, you don’t have to build the graph.  </p>\n<p>其实在一开始应该早就说明白过了，tensorflow的api是分层级的:<br><img src=\"./images/tf/tf_api.png\" alt=\"\"></p>\n<p>如上图estimator 和eager mode是同一层级的，它会自动的帮你构建整个图</p>\n<p>TODO: 试着跑一遍代码，用log记录下图的结构，然后在tensorboard里面打开康康。  </p>\n"},{"title":"Image Style Transfer based on CNN","date":"2018-04-15T12:18:00.000Z","mathjax":true,"_content":"## 实验提要\n刚做完CS20的assignmet 2，因为是第一个tensorflow项目，虽然很多不知道怎么做借鉴了别人的代码，整个代码框架大致是搞懂了，姑且留个记录。\n\n整个实验基本上是对[A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf)\n这篇文章的一个实现。实验提供了一些框架代码，可以在[git上这里](https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/02_style_transfer)找到\n\n## 原论文以及主要观点\n### 特点\nA Neural Algorithm of Artistic Style 这篇文章发表2016，还算比较新的文章。 \n文章的主要点在于它发现了在CNN当中图片的内容和图片的风格是可以分离的，因而可以独立的处理这些表示生成新的有意义的图片（虽然我也没完全弄懂他的意思），原文如下：\n\n> “The key finding of this paper is that the representations of content and style in the Convolutional Neural Network are separable. That is, we can manipulate both representations independently to produce new, perceptually meaningful images.”\n\n### VGG-Network 结构\n文章使用的实现方法基于VGG-Network，在cs231n的[这个课件](http://cs231n.github.io/convolutional-networks/)里有对VGG-Net的简要介绍    \n\n> VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, **features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end.** Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.\n\nVGGnet的网络参数如图所示  \n\n![VGGNet achitecture](./images/tf/VGGNet.png)\n\n### 基于VGGnet 的实现\n文章使用了VGGNet当中的16层卷积层和5层pooling层,去掉了全连接层，并使用average pooling策略替换max pooling策略\n\n#### lose function\n关于怎么定义loss function,想法比较自然  \n在图像内容附近通过白噪声初始化一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正。  \n**content loss**  \n设置一个白点噪声的初始图像和原图像输入网络，在某一层的输出$l$处,F和P分别为其特征表述，则取其方差为content loss\n\n$$ L_{content}(\\vec p,\\vec x, l) = \\frac{1}{2}\\sum_{i,j}(F_{ij}^{l}-P_{ij}^{l})^2 $$\n \n**Gram矩阵**\n\nGram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）  \n协方差矩阵可写成：\n\n$$ \\sum  = E[(X-E(X))(X-E(X))^T]$$\nGram矩阵可写成\n\n$$ G = A * A^{T} $$\n\n**style loss**  \n\n在CNN每一层反馈的基础上，对每一层的激励结果求其Gram矩阵,同样是对生成图像和原图像，在某一层l生成的两个Gram矩阵G、A  \n这一层loss贡献为：\n\n$$ E_l = \\frac{1}{4N_l^2M_l^2}\\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$$\n\n对每一层的loss进行加权求和，得到总的loss为\n\n$$ L_{style}(\\vec a,\\vec x) = \\sum_{l=0}^Lw_lE_l$$\n\n\n\n给定content loss和style loss分别的权重为$\\alpha$和$\\beta$，总的优化目标为\n\n$$ L_{total}(\\vec p,\\vec a,\\vec x)=\\alpha L_{content}(\\vec p,\\vec x)+\\beta L_{style}(\\vec a,\\vec x)$$\n\n**思考**  \n有关于为什么要使用gram matrix来度量风格，当同一个维度上面的值相乘的时候原来越小酒变得更小，原来越大就变得越大，二不同维度上的关系也在相乘的表达当中表示出来,因而gram matrix能有效度量各个维度自己的特性以及各个维度之间的关系\n\n## 基于tensorflow的实现\n### 代码框架\n* utils.py  一些辅助函数\n* load_vgg.py  从已经训练好的参数当中加载vggnet\n* style_transfer.py 构建风格转化的模型\n\n### load_vgg.py\n这个模块中的主要任务是搭建vggnet，在load方法当中调用conv2d_relu生成卷积层，调用avgpool生成pooling层\n```python\ndef conv2d_relu(self, prev_layer, layer_idx, layer_name):\n    with tf.variable_scope(layer_name):\n                w, b = self._weights(layer_idx, layer_name)\n                w = tf.constant(w, name=\"weight\")\n                b = tf.constant(b, name=\"bais\")\n                conv2d = tf.nn.conv2d(input = prev_layer,\n                                    filter = w,\n                                    strides = [1,1,1,1],\n                                    padding = \"SAME\",\n                                    name = layer_name)\n                out = tf.nn.relu(conv2d + b)\n        setattr(self, layer_name, out)\n\ndef avgpool(self, prev_layer, layer_name):\n\n        with tf.variable_scope(layer_name):\n            out = tf.nn.avg_pool(prev_layer,\n                                ksize=[1,2,2,1],\n                                strides=[1,2,2,1],\n                                padding=\"SAME\")\n\n        setattr(self, layer_name, out)\n\ndef load(self):\n        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n        self.avgpool(self.conv1_2, 'avgpool1')\n        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n        self.avgpool(self.conv2_2, 'avgpool2')\n        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n        self.avgpool(self.conv3_4, 'avgpool3')\n        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n        self.avgpool(self.conv4_4, 'avgpool4')\n        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n        self.avgpool(self.conv5_4, 'avgpool5')\n```\n有关conv2d的参数解释见之前笔记和[这里](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)\n\n### style_transfer\n\n总体分为两部，第一步创建tensorflow图结构，这其中包括：\n1. 使用create_input创建空白图作为输入\n2. 加载vggnet结构\n3. 创建loss\n4. 根据loss创建optimizer\n5. 创建统计数据\n```python\ndef build(self):\n    self.create_input()\n    self.load_vgg()\n    self.losses()\n    self.optimize()\n    self.create_summary()\n```\n\n第二步执行训练:  \n1. 初始化全局变量sess.run(tf.global_variables_initializer())\n2. 创建FileWriter (用于TensorBoard)\n3. 创建输入  sess.run(self.input_img.assign(self.initial_img))\n4. 创建checkpoint检查是否要恢复\n5. 循环迭代n次\n6. 最优化opt\n7. 每特定次循环计算保存summary，保存断点\n```python\n    def train(self, n_iters):\n        skip_step = 1\n        with tf.Session() as sess:\n            # 1. initialize\n            sess.run(tf.global_variables_initializer())\n            # 2. create writer\n            writer = tf.summary.FileWriter(\"graphs/style_transfer\", sess.graph)\n            # 3. assign input\n            sess.run(self.input_img.assign(self.initial_img))\n            # 4. create checkpoint & restore previous\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/style_transfer/checkpoint'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n\n            initial_step = self.gstep.eval()\n            start_time = time.time()\n            # 5. iterate for n_iters time\n            for index in range(initial_step, n_iters):\n                if index >= 5 and index < 20:\n                    skip_step = 10\n                elif index >= 20:\n                    skip_step = 20\n                # 6. run optimization\n                sess.run(self.opt)\n                # 7. add summary info \\ save checkpoint every number of certain layers\n                if (index + 1) % skip_step == 0:\n                    gen_image, total_loss, summary = sess.run([self.input_img,\n                                                            self.total_loss,\n                                                            self.summary_op])\n                    gen_image = gen_image + self.vgg.mean_pixels \n                    writer.add_summary(summary, global_step=index)\n                #...\n                if (index + 1) % 20 == 0:\n                    saver.save (sess, 'checkpoints/style_stranfer/style_transfer', index)\n\n```\n\n\n### 个人在做完之后的一点思考\n首先这个任务和传统的学习任务不一样。这次学习的对象是需要生成的图像，待生成的图像像素点作为变量在最优化的时候同时被训练。而网络的模型采用他人训练好的参数。","source":"_posts/machinelearning/tensorflow_notes/style_transfer.md","raw":"---\ntitle: Image Style Transfer based on CNN\ndate: 2018-04-15 20:18:00\ntags: [CNN，tensorflow]\nmathjax: true\n---\n## 实验提要\n刚做完CS20的assignmet 2，因为是第一个tensorflow项目，虽然很多不知道怎么做借鉴了别人的代码，整个代码框架大致是搞懂了，姑且留个记录。\n\n整个实验基本上是对[A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf)\n这篇文章的一个实现。实验提供了一些框架代码，可以在[git上这里](https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/02_style_transfer)找到\n\n## 原论文以及主要观点\n### 特点\nA Neural Algorithm of Artistic Style 这篇文章发表2016，还算比较新的文章。 \n文章的主要点在于它发现了在CNN当中图片的内容和图片的风格是可以分离的，因而可以独立的处理这些表示生成新的有意义的图片（虽然我也没完全弄懂他的意思），原文如下：\n\n> “The key finding of this paper is that the representations of content and style in the Convolutional Neural Network are separable. That is, we can manipulate both representations independently to produce new, perceptually meaningful images.”\n\n### VGG-Network 结构\n文章使用的实现方法基于VGG-Network，在cs231n的[这个课件](http://cs231n.github.io/convolutional-networks/)里有对VGG-Net的简要介绍    \n\n> VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, **features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end.** Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.\n\nVGGnet的网络参数如图所示  \n\n![VGGNet achitecture](./images/tf/VGGNet.png)\n\n### 基于VGGnet 的实现\n文章使用了VGGNet当中的16层卷积层和5层pooling层,去掉了全连接层，并使用average pooling策略替换max pooling策略\n\n#### lose function\n关于怎么定义loss function,想法比较自然  \n在图像内容附近通过白噪声初始化一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正。  \n**content loss**  \n设置一个白点噪声的初始图像和原图像输入网络，在某一层的输出$l$处,F和P分别为其特征表述，则取其方差为content loss\n\n$$ L_{content}(\\vec p,\\vec x, l) = \\frac{1}{2}\\sum_{i,j}(F_{ij}^{l}-P_{ij}^{l})^2 $$\n \n**Gram矩阵**\n\nGram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）  \n协方差矩阵可写成：\n\n$$ \\sum  = E[(X-E(X))(X-E(X))^T]$$\nGram矩阵可写成\n\n$$ G = A * A^{T} $$\n\n**style loss**  \n\n在CNN每一层反馈的基础上，对每一层的激励结果求其Gram矩阵,同样是对生成图像和原图像，在某一层l生成的两个Gram矩阵G、A  \n这一层loss贡献为：\n\n$$ E_l = \\frac{1}{4N_l^2M_l^2}\\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$$\n\n对每一层的loss进行加权求和，得到总的loss为\n\n$$ L_{style}(\\vec a,\\vec x) = \\sum_{l=0}^Lw_lE_l$$\n\n\n\n给定content loss和style loss分别的权重为$\\alpha$和$\\beta$，总的优化目标为\n\n$$ L_{total}(\\vec p,\\vec a,\\vec x)=\\alpha L_{content}(\\vec p,\\vec x)+\\beta L_{style}(\\vec a,\\vec x)$$\n\n**思考**  \n有关于为什么要使用gram matrix来度量风格，当同一个维度上面的值相乘的时候原来越小酒变得更小，原来越大就变得越大，二不同维度上的关系也在相乘的表达当中表示出来,因而gram matrix能有效度量各个维度自己的特性以及各个维度之间的关系\n\n## 基于tensorflow的实现\n### 代码框架\n* utils.py  一些辅助函数\n* load_vgg.py  从已经训练好的参数当中加载vggnet\n* style_transfer.py 构建风格转化的模型\n\n### load_vgg.py\n这个模块中的主要任务是搭建vggnet，在load方法当中调用conv2d_relu生成卷积层，调用avgpool生成pooling层\n```python\ndef conv2d_relu(self, prev_layer, layer_idx, layer_name):\n    with tf.variable_scope(layer_name):\n                w, b = self._weights(layer_idx, layer_name)\n                w = tf.constant(w, name=\"weight\")\n                b = tf.constant(b, name=\"bais\")\n                conv2d = tf.nn.conv2d(input = prev_layer,\n                                    filter = w,\n                                    strides = [1,1,1,1],\n                                    padding = \"SAME\",\n                                    name = layer_name)\n                out = tf.nn.relu(conv2d + b)\n        setattr(self, layer_name, out)\n\ndef avgpool(self, prev_layer, layer_name):\n\n        with tf.variable_scope(layer_name):\n            out = tf.nn.avg_pool(prev_layer,\n                                ksize=[1,2,2,1],\n                                strides=[1,2,2,1],\n                                padding=\"SAME\")\n\n        setattr(self, layer_name, out)\n\ndef load(self):\n        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n        self.avgpool(self.conv1_2, 'avgpool1')\n        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n        self.avgpool(self.conv2_2, 'avgpool2')\n        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n        self.avgpool(self.conv3_4, 'avgpool3')\n        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n        self.avgpool(self.conv4_4, 'avgpool4')\n        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n        self.avgpool(self.conv5_4, 'avgpool5')\n```\n有关conv2d的参数解释见之前笔记和[这里](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)\n\n### style_transfer\n\n总体分为两部，第一步创建tensorflow图结构，这其中包括：\n1. 使用create_input创建空白图作为输入\n2. 加载vggnet结构\n3. 创建loss\n4. 根据loss创建optimizer\n5. 创建统计数据\n```python\ndef build(self):\n    self.create_input()\n    self.load_vgg()\n    self.losses()\n    self.optimize()\n    self.create_summary()\n```\n\n第二步执行训练:  \n1. 初始化全局变量sess.run(tf.global_variables_initializer())\n2. 创建FileWriter (用于TensorBoard)\n3. 创建输入  sess.run(self.input_img.assign(self.initial_img))\n4. 创建checkpoint检查是否要恢复\n5. 循环迭代n次\n6. 最优化opt\n7. 每特定次循环计算保存summary，保存断点\n```python\n    def train(self, n_iters):\n        skip_step = 1\n        with tf.Session() as sess:\n            # 1. initialize\n            sess.run(tf.global_variables_initializer())\n            # 2. create writer\n            writer = tf.summary.FileWriter(\"graphs/style_transfer\", sess.graph)\n            # 3. assign input\n            sess.run(self.input_img.assign(self.initial_img))\n            # 4. create checkpoint & restore previous\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/style_transfer/checkpoint'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n\n            initial_step = self.gstep.eval()\n            start_time = time.time()\n            # 5. iterate for n_iters time\n            for index in range(initial_step, n_iters):\n                if index >= 5 and index < 20:\n                    skip_step = 10\n                elif index >= 20:\n                    skip_step = 20\n                # 6. run optimization\n                sess.run(self.opt)\n                # 7. add summary info \\ save checkpoint every number of certain layers\n                if (index + 1) % skip_step == 0:\n                    gen_image, total_loss, summary = sess.run([self.input_img,\n                                                            self.total_loss,\n                                                            self.summary_op])\n                    gen_image = gen_image + self.vgg.mean_pixels \n                    writer.add_summary(summary, global_step=index)\n                #...\n                if (index + 1) % 20 == 0:\n                    saver.save (sess, 'checkpoints/style_stranfer/style_transfer', index)\n\n```\n\n\n### 个人在做完之后的一点思考\n首先这个任务和传统的学习任务不一样。这次学习的对象是需要生成的图像，待生成的图像像素点作为变量在最优化的时候同时被训练。而网络的模型采用他人训练好的参数。","slug":"machinelearning/tensorflow_notes/style_transfer","published":1,"updated":"2018-04-16T06:28:57.477Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56as0022acwoneozpbmh","content":"<h2 id=\"实验提要\"><a href=\"#实验提要\" class=\"headerlink\" title=\"实验提要\"></a>实验提要</h2><p>刚做完CS20的assignmet 2，因为是第一个tensorflow项目，虽然很多不知道怎么做借鉴了别人的代码，整个代码框架大致是搞懂了，姑且留个记录。</p>\n<p>整个实验基本上是对<a href=\"https://arxiv.org/pdf/1508.06576.pdf\" target=\"_blank\" rel=\"external\">A Neural Algorithm of Artistic Style</a><br>这篇文章的一个实现。实验提供了一些框架代码，可以在<a href=\"https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/02_style_transfer\" target=\"_blank\" rel=\"external\">git上这里</a>找到</p>\n<h2 id=\"原论文以及主要观点\"><a href=\"#原论文以及主要观点\" class=\"headerlink\" title=\"原论文以及主要观点\"></a>原论文以及主要观点</h2><h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><p>A Neural Algorithm of Artistic Style 这篇文章发表2016，还算比较新的文章。<br>文章的主要点在于它发现了在CNN当中图片的内容和图片的风格是可以分离的，因而可以独立的处理这些表示生成新的有意义的图片（虽然我也没完全弄懂他的意思），原文如下：</p>\n<blockquote>\n<p>“The key finding of this paper is that the representations of content and style in the Convolutional Neural Network are separable. That is, we can manipulate both representations independently to produce new, perceptually meaningful images.”</p>\n</blockquote>\n<h3 id=\"VGG-Network-结构\"><a href=\"#VGG-Network-结构\" class=\"headerlink\" title=\"VGG-Network 结构\"></a>VGG-Network 结构</h3><p>文章使用的实现方法基于VGG-Network，在cs231n的<a href=\"http://cs231n.github.io/convolutional-networks/\" target=\"_blank\" rel=\"external\">这个课件</a>里有对VGG-Net的简要介绍    </p>\n<blockquote>\n<p>VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, <strong>features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end.</strong> Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.</p>\n</blockquote>\n<p>VGGnet的网络参数如图所示  </p>\n<p><img src=\"./images/tf/VGGNet.png\" alt=\"VGGNet achitecture\"></p>\n<h3 id=\"基于VGGnet-的实现\"><a href=\"#基于VGGnet-的实现\" class=\"headerlink\" title=\"基于VGGnet 的实现\"></a>基于VGGnet 的实现</h3><p>文章使用了VGGNet当中的16层卷积层和5层pooling层,去掉了全连接层，并使用average pooling策略替换max pooling策略</p>\n<h4 id=\"lose-function\"><a href=\"#lose-function\" class=\"headerlink\" title=\"lose function\"></a>lose function</h4><p>关于怎么定义loss function,想法比较自然<br>在图像内容附近通过白噪声初始化一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正。<br><strong>content loss</strong><br>设置一个白点噪声的初始图像和原图像输入网络，在某一层的输出$l$处,F和P分别为其特征表述，则取其方差为content loss</p>\n<p>$$ L_{content}(\\vec p,\\vec x, l) = \\frac{1}{2}\\sum_{i,j}(F_{ij}^{l}-P_{ij}^{l})^2 $$</p>\n<p><strong>Gram矩阵</strong></p>\n<p>Gram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）<br>协方差矩阵可写成：</p>\n<p>$$ \\sum  = E[(X-E(X))(X-E(X))^T]$$<br>Gram矩阵可写成</p>\n<p>$$ G = A * A^{T} $$</p>\n<p><strong>style loss</strong>  </p>\n<p>在CNN每一层反馈的基础上，对每一层的激励结果求其Gram矩阵,同样是对生成图像和原图像，在某一层l生成的两个Gram矩阵G、A<br>这一层loss贡献为：</p>\n<p>$$ E_l = \\frac{1}{4N_l^2M_l^2}\\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$$</p>\n<p>对每一层的loss进行加权求和，得到总的loss为</p>\n<p>$$ L_{style}(\\vec a,\\vec x) = \\sum_{l=0}^Lw_lE_l$$</p>\n<p>给定content loss和style loss分别的权重为$\\alpha$和$\\beta$，总的优化目标为</p>\n<p>$$ L_{total}(\\vec p,\\vec a,\\vec x)=\\alpha L_{content}(\\vec p,\\vec x)+\\beta L_{style}(\\vec a,\\vec x)$$</p>\n<p><strong>思考</strong><br>有关于为什么要使用gram matrix来度量风格，当同一个维度上面的值相乘的时候原来越小酒变得更小，原来越大就变得越大，二不同维度上的关系也在相乘的表达当中表示出来,因而gram matrix能有效度量各个维度自己的特性以及各个维度之间的关系</p>\n<h2 id=\"基于tensorflow的实现\"><a href=\"#基于tensorflow的实现\" class=\"headerlink\" title=\"基于tensorflow的实现\"></a>基于tensorflow的实现</h2><h3 id=\"代码框架\"><a href=\"#代码框架\" class=\"headerlink\" title=\"代码框架\"></a>代码框架</h3><ul>\n<li>utils.py  一些辅助函数</li>\n<li>load_vgg.py  从已经训练好的参数当中加载vggnet</li>\n<li>style_transfer.py 构建风格转化的模型</li>\n</ul>\n<h3 id=\"load-vgg-py\"><a href=\"#load-vgg-py\" class=\"headerlink\" title=\"load_vgg.py\"></a>load_vgg.py</h3><p>这个模块中的主要任务是搭建vggnet，在load方法当中调用conv2d_relu生成卷积层，调用avgpool生成pooling层<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv2d_relu</span><span class=\"params\">(self, prev_layer, layer_idx, layer_name)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">with</span> tf.variable_scope(layer_name):</div><div class=\"line\">                w, b = self._weights(layer_idx, layer_name)</div><div class=\"line\">                w = tf.constant(w, name=<span class=\"string\">\"weight\"</span>)</div><div class=\"line\">                b = tf.constant(b, name=<span class=\"string\">\"bais\"</span>)</div><div class=\"line\">                conv2d = tf.nn.conv2d(input = prev_layer,</div><div class=\"line\">                                    filter = w,</div><div class=\"line\">                                    strides = [<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>],</div><div class=\"line\">                                    padding = <span class=\"string\">\"SAME\"</span>,</div><div class=\"line\">                                    name = layer_name)</div><div class=\"line\">                out = tf.nn.relu(conv2d + b)</div><div class=\"line\">        setattr(self, layer_name, out)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">avgpool</span><span class=\"params\">(self, prev_layer, layer_name)</span>:</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">with</span> tf.variable_scope(layer_name):</div><div class=\"line\">            out = tf.nn.avg_pool(prev_layer,</div><div class=\"line\">                                ksize=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>],</div><div class=\"line\">                                strides=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>],</div><div class=\"line\">                                padding=<span class=\"string\">\"SAME\"</span>)</div><div class=\"line\"></div><div class=\"line\">        setattr(self, layer_name, out)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.conv2d_relu(self.input_img, <span class=\"number\">0</span>, <span class=\"string\">'conv1_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv1_1, <span class=\"number\">2</span>, <span class=\"string\">'conv1_2'</span>)</div><div class=\"line\">        self.avgpool(self.conv1_2, <span class=\"string\">'avgpool1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool1, <span class=\"number\">5</span>, <span class=\"string\">'conv2_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv2_1, <span class=\"number\">7</span>, <span class=\"string\">'conv2_2'</span>)</div><div class=\"line\">        self.avgpool(self.conv2_2, <span class=\"string\">'avgpool2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool2, <span class=\"number\">10</span>, <span class=\"string\">'conv3_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv3_1, <span class=\"number\">12</span>, <span class=\"string\">'conv3_2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv3_2, <span class=\"number\">14</span>, <span class=\"string\">'conv3_3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv3_3, <span class=\"number\">16</span>, <span class=\"string\">'conv3_4'</span>)</div><div class=\"line\">        self.avgpool(self.conv3_4, <span class=\"string\">'avgpool3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool3, <span class=\"number\">19</span>, <span class=\"string\">'conv4_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv4_1, <span class=\"number\">21</span>, <span class=\"string\">'conv4_2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv4_2, <span class=\"number\">23</span>, <span class=\"string\">'conv4_3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv4_3, <span class=\"number\">25</span>, <span class=\"string\">'conv4_4'</span>)</div><div class=\"line\">        self.avgpool(self.conv4_4, <span class=\"string\">'avgpool4'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool4, <span class=\"number\">28</span>, <span class=\"string\">'conv5_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv5_1, <span class=\"number\">30</span>, <span class=\"string\">'conv5_2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv5_2, <span class=\"number\">32</span>, <span class=\"string\">'conv5_3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv5_3, <span class=\"number\">34</span>, <span class=\"string\">'conv5_4'</span>)</div><div class=\"line\">        self.avgpool(self.conv5_4, <span class=\"string\">'avgpool5'</span>)</div></pre></td></tr></table></figure></p>\n<p>有关conv2d的参数解释见之前笔记和<a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\" target=\"_blank\" rel=\"external\">这里</a></p>\n<h3 id=\"style-transfer\"><a href=\"#style-transfer\" class=\"headerlink\" title=\"style_transfer\"></a>style_transfer</h3><p>总体分为两部，第一步创建tensorflow图结构，这其中包括：</p>\n<ol>\n<li>使用create_input创建空白图作为输入</li>\n<li>加载vggnet结构</li>\n<li>创建loss</li>\n<li>根据loss创建optimizer</li>\n<li>创建统计数据<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">build</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    self.create_input()</div><div class=\"line\">    self.load_vgg()</div><div class=\"line\">    self.losses()</div><div class=\"line\">    self.optimize()</div><div class=\"line\">    self.create_summary()</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>第二步执行训练:  </p>\n<ol>\n<li>初始化全局变量sess.run(tf.global_variables_initializer())</li>\n<li>创建FileWriter (用于TensorBoard)</li>\n<li>创建输入  sess.run(self.input_img.assign(self.initial_img))</li>\n<li>创建checkpoint检查是否要恢复</li>\n<li>循环迭代n次</li>\n<li>最优化opt</li>\n<li>每特定次循环计算保存summary，保存断点<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">(self, n_iters)</span>:</span></div><div class=\"line\">    skip_step = <span class=\"number\">1</span></div><div class=\"line\">    <span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">        <span class=\"comment\"># 1. initialize</span></div><div class=\"line\">        sess.run(tf.global_variables_initializer())</div><div class=\"line\">        <span class=\"comment\"># 2. create writer</span></div><div class=\"line\">        writer = tf.summary.FileWriter(<span class=\"string\">\"graphs/style_transfer\"</span>, sess.graph)</div><div class=\"line\">        <span class=\"comment\"># 3. assign input</span></div><div class=\"line\">        sess.run(self.input_img.assign(self.initial_img))</div><div class=\"line\">        <span class=\"comment\"># 4. create checkpoint &amp; restore previous</span></div><div class=\"line\">        saver = tf.train.Saver()</div><div class=\"line\">        ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class=\"string\">'checkpoints/style_transfer/checkpoint'</span>))</div><div class=\"line\">        <span class=\"keyword\">if</span> ckpt <span class=\"keyword\">and</span> ckpt.model_checkpoint_path:</div><div class=\"line\">            saver.restore(sess, ckpt.model_checkpoint_path)</div><div class=\"line\"></div><div class=\"line\">        initial_step = self.gstep.eval()</div><div class=\"line\">        start_time = time.time()</div><div class=\"line\">        <span class=\"comment\"># 5. iterate for n_iters time</span></div><div class=\"line\">        <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> range(initial_step, n_iters):</div><div class=\"line\">            <span class=\"keyword\">if</span> index &gt;= <span class=\"number\">5</span> <span class=\"keyword\">and</span> index &lt; <span class=\"number\">20</span>:</div><div class=\"line\">                skip_step = <span class=\"number\">10</span></div><div class=\"line\">            <span class=\"keyword\">elif</span> index &gt;= <span class=\"number\">20</span>:</div><div class=\"line\">                skip_step = <span class=\"number\">20</span></div><div class=\"line\">            <span class=\"comment\"># 6. run optimization</span></div><div class=\"line\">            sess.run(self.opt)</div><div class=\"line\">            <span class=\"comment\"># 7. add summary info \\ save checkpoint every number of certain layers</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (index + <span class=\"number\">1</span>) % skip_step == <span class=\"number\">0</span>:</div><div class=\"line\">                gen_image, total_loss, summary = sess.run([self.input_img,</div><div class=\"line\">                                                        self.total_loss,</div><div class=\"line\">                                                        self.summary_op])</div><div class=\"line\">                gen_image = gen_image + self.vgg.mean_pixels </div><div class=\"line\">                writer.add_summary(summary, global_step=index)</div><div class=\"line\">            <span class=\"comment\">#...</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (index + <span class=\"number\">1</span>) % <span class=\"number\">20</span> == <span class=\"number\">0</span>:</div><div class=\"line\">                saver.save (sess, <span class=\"string\">'checkpoints/style_stranfer/style_transfer'</span>, index)</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"个人在做完之后的一点思考\"><a href=\"#个人在做完之后的一点思考\" class=\"headerlink\" title=\"个人在做完之后的一点思考\"></a>个人在做完之后的一点思考</h3><p>首先这个任务和传统的学习任务不一样。这次学习的对象是需要生成的图像，待生成的图像像素点作为变量在最优化的时候同时被训练。而网络的模型采用他人训练好的参数。</p>\n","excerpt":"","more":"<h2 id=\"实验提要\"><a href=\"#实验提要\" class=\"headerlink\" title=\"实验提要\"></a>实验提要</h2><p>刚做完CS20的assignmet 2，因为是第一个tensorflow项目，虽然很多不知道怎么做借鉴了别人的代码，整个代码框架大致是搞懂了，姑且留个记录。</p>\n<p>整个实验基本上是对<a href=\"https://arxiv.org/pdf/1508.06576.pdf\">A Neural Algorithm of Artistic Style</a><br>这篇文章的一个实现。实验提供了一些框架代码，可以在<a href=\"https://github.com/chiphuyen/stanford-tensorflow-tutorials/tree/master/assignments/02_style_transfer\">git上这里</a>找到</p>\n<h2 id=\"原论文以及主要观点\"><a href=\"#原论文以及主要观点\" class=\"headerlink\" title=\"原论文以及主要观点\"></a>原论文以及主要观点</h2><h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><p>A Neural Algorithm of Artistic Style 这篇文章发表2016，还算比较新的文章。<br>文章的主要点在于它发现了在CNN当中图片的内容和图片的风格是可以分离的，因而可以独立的处理这些表示生成新的有意义的图片（虽然我也没完全弄懂他的意思），原文如下：</p>\n<blockquote>\n<p>“The key finding of this paper is that the representations of content and style in the Convolutional Neural Network are separable. That is, we can manipulate both representations independently to produce new, perceptually meaningful images.”</p>\n</blockquote>\n<h3 id=\"VGG-Network-结构\"><a href=\"#VGG-Network-结构\" class=\"headerlink\" title=\"VGG-Network 结构\"></a>VGG-Network 结构</h3><p>文章使用的实现方法基于VGG-Network，在cs231n的<a href=\"http://cs231n.github.io/convolutional-networks/\">这个课件</a>里有对VGG-Net的简要介绍    </p>\n<blockquote>\n<p>VGGNet. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the VGGNet. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, <strong>features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end.</strong> Their pretrained model is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M). Most of these parameters are in the first fully connected layer, and it was since found that these FC layers can be removed with no performance downgrade, significantly reducing the number of necessary parameters.</p>\n</blockquote>\n<p>VGGnet的网络参数如图所示  </p>\n<p><img src=\"./images/tf/VGGNet.png\" alt=\"VGGNet achitecture\"></p>\n<h3 id=\"基于VGGnet-的实现\"><a href=\"#基于VGGnet-的实现\" class=\"headerlink\" title=\"基于VGGnet 的实现\"></a>基于VGGnet 的实现</h3><p>文章使用了VGGNet当中的16层卷积层和5层pooling层,去掉了全连接层，并使用average pooling策略替换max pooling策略</p>\n<h4 id=\"lose-function\"><a href=\"#lose-function\" class=\"headerlink\" title=\"lose function\"></a>lose function</h4><p>关于怎么定义loss function,想法比较自然<br>在图像内容附近通过白噪声初始化一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正。<br><strong>content loss</strong><br>设置一个白点噪声的初始图像和原图像输入网络，在某一层的输出$l$处,F和P分别为其特征表述，则取其方差为content loss</p>\n<p>$$ L_{content}(\\vec p,\\vec x, l) = \\frac{1}{2}\\sum_{i,j}(F_{ij}^{l}-P_{ij}^{l})^2 $$</p>\n<p><strong>Gram矩阵</strong></p>\n<p>Gram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵）<br>协方差矩阵可写成：</p>\n<p>$$ \\sum  = E[(X-E(X))(X-E(X))^T]$$<br>Gram矩阵可写成</p>\n<p>$$ G = A * A^{T} $$</p>\n<p><strong>style loss</strong>  </p>\n<p>在CNN每一层反馈的基础上，对每一层的激励结果求其Gram矩阵,同样是对生成图像和原图像，在某一层l生成的两个Gram矩阵G、A<br>这一层loss贡献为：</p>\n<p>$$ E_l = \\frac{1}{4N_l^2M_l^2}\\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$$</p>\n<p>对每一层的loss进行加权求和，得到总的loss为</p>\n<p>$$ L_{style}(\\vec a,\\vec x) = \\sum_{l=0}^Lw_lE_l$$</p>\n<p>给定content loss和style loss分别的权重为$\\alpha$和$\\beta$，总的优化目标为</p>\n<p>$$ L_{total}(\\vec p,\\vec a,\\vec x)=\\alpha L_{content}(\\vec p,\\vec x)+\\beta L_{style}(\\vec a,\\vec x)$$</p>\n<p><strong>思考</strong><br>有关于为什么要使用gram matrix来度量风格，当同一个维度上面的值相乘的时候原来越小酒变得更小，原来越大就变得越大，二不同维度上的关系也在相乘的表达当中表示出来,因而gram matrix能有效度量各个维度自己的特性以及各个维度之间的关系</p>\n<h2 id=\"基于tensorflow的实现\"><a href=\"#基于tensorflow的实现\" class=\"headerlink\" title=\"基于tensorflow的实现\"></a>基于tensorflow的实现</h2><h3 id=\"代码框架\"><a href=\"#代码框架\" class=\"headerlink\" title=\"代码框架\"></a>代码框架</h3><ul>\n<li>utils.py  一些辅助函数</li>\n<li>load_vgg.py  从已经训练好的参数当中加载vggnet</li>\n<li>style_transfer.py 构建风格转化的模型</li>\n</ul>\n<h3 id=\"load-vgg-py\"><a href=\"#load-vgg-py\" class=\"headerlink\" title=\"load_vgg.py\"></a>load_vgg.py</h3><p>这个模块中的主要任务是搭建vggnet，在load方法当中调用conv2d_relu生成卷积层，调用avgpool生成pooling层<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv2d_relu</span><span class=\"params\">(self, prev_layer, layer_idx, layer_name)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">with</span> tf.variable_scope(layer_name):</div><div class=\"line\">                w, b = self._weights(layer_idx, layer_name)</div><div class=\"line\">                w = tf.constant(w, name=<span class=\"string\">\"weight\"</span>)</div><div class=\"line\">                b = tf.constant(b, name=<span class=\"string\">\"bais\"</span>)</div><div class=\"line\">                conv2d = tf.nn.conv2d(input = prev_layer,</div><div class=\"line\">                                    filter = w,</div><div class=\"line\">                                    strides = [<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>],</div><div class=\"line\">                                    padding = <span class=\"string\">\"SAME\"</span>,</div><div class=\"line\">                                    name = layer_name)</div><div class=\"line\">                out = tf.nn.relu(conv2d + b)</div><div class=\"line\">        setattr(self, layer_name, out)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">avgpool</span><span class=\"params\">(self, prev_layer, layer_name)</span>:</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">with</span> tf.variable_scope(layer_name):</div><div class=\"line\">            out = tf.nn.avg_pool(prev_layer,</div><div class=\"line\">                                ksize=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>],</div><div class=\"line\">                                strides=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>],</div><div class=\"line\">                                padding=<span class=\"string\">\"SAME\"</span>)</div><div class=\"line\"></div><div class=\"line\">        setattr(self, layer_name, out)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.conv2d_relu(self.input_img, <span class=\"number\">0</span>, <span class=\"string\">'conv1_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv1_1, <span class=\"number\">2</span>, <span class=\"string\">'conv1_2'</span>)</div><div class=\"line\">        self.avgpool(self.conv1_2, <span class=\"string\">'avgpool1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool1, <span class=\"number\">5</span>, <span class=\"string\">'conv2_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv2_1, <span class=\"number\">7</span>, <span class=\"string\">'conv2_2'</span>)</div><div class=\"line\">        self.avgpool(self.conv2_2, <span class=\"string\">'avgpool2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool2, <span class=\"number\">10</span>, <span class=\"string\">'conv3_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv3_1, <span class=\"number\">12</span>, <span class=\"string\">'conv3_2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv3_2, <span class=\"number\">14</span>, <span class=\"string\">'conv3_3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv3_3, <span class=\"number\">16</span>, <span class=\"string\">'conv3_4'</span>)</div><div class=\"line\">        self.avgpool(self.conv3_4, <span class=\"string\">'avgpool3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool3, <span class=\"number\">19</span>, <span class=\"string\">'conv4_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv4_1, <span class=\"number\">21</span>, <span class=\"string\">'conv4_2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv4_2, <span class=\"number\">23</span>, <span class=\"string\">'conv4_3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv4_3, <span class=\"number\">25</span>, <span class=\"string\">'conv4_4'</span>)</div><div class=\"line\">        self.avgpool(self.conv4_4, <span class=\"string\">'avgpool4'</span>)</div><div class=\"line\">        self.conv2d_relu(self.avgpool4, <span class=\"number\">28</span>, <span class=\"string\">'conv5_1'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv5_1, <span class=\"number\">30</span>, <span class=\"string\">'conv5_2'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv5_2, <span class=\"number\">32</span>, <span class=\"string\">'conv5_3'</span>)</div><div class=\"line\">        self.conv2d_relu(self.conv5_3, <span class=\"number\">34</span>, <span class=\"string\">'conv5_4'</span>)</div><div class=\"line\">        self.avgpool(self.conv5_4, <span class=\"string\">'avgpool5'</span>)</div></pre></td></tr></table></figure></p>\n<p>有关conv2d的参数解释见之前笔记和<a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\">这里</a></p>\n<h3 id=\"style-transfer\"><a href=\"#style-transfer\" class=\"headerlink\" title=\"style_transfer\"></a>style_transfer</h3><p>总体分为两部，第一步创建tensorflow图结构，这其中包括：</p>\n<ol>\n<li>使用create_input创建空白图作为输入</li>\n<li>加载vggnet结构</li>\n<li>创建loss</li>\n<li>根据loss创建optimizer</li>\n<li>创建统计数据<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">build</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    self.create_input()</div><div class=\"line\">    self.load_vgg()</div><div class=\"line\">    self.losses()</div><div class=\"line\">    self.optimize()</div><div class=\"line\">    self.create_summary()</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>第二步执行训练:  </p>\n<ol>\n<li>初始化全局变量sess.run(tf.global_variables_initializer())</li>\n<li>创建FileWriter (用于TensorBoard)</li>\n<li>创建输入  sess.run(self.input_img.assign(self.initial_img))</li>\n<li>创建checkpoint检查是否要恢复</li>\n<li>循环迭代n次</li>\n<li>最优化opt</li>\n<li>每特定次循环计算保存summary，保存断点<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">(self, n_iters)</span>:</span></div><div class=\"line\">    skip_step = <span class=\"number\">1</span></div><div class=\"line\">    <span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</div><div class=\"line\">        <span class=\"comment\"># 1. initialize</span></div><div class=\"line\">        sess.run(tf.global_variables_initializer())</div><div class=\"line\">        <span class=\"comment\"># 2. create writer</span></div><div class=\"line\">        writer = tf.summary.FileWriter(<span class=\"string\">\"graphs/style_transfer\"</span>, sess.graph)</div><div class=\"line\">        <span class=\"comment\"># 3. assign input</span></div><div class=\"line\">        sess.run(self.input_img.assign(self.initial_img))</div><div class=\"line\">        <span class=\"comment\"># 4. create checkpoint &amp; restore previous</span></div><div class=\"line\">        saver = tf.train.Saver()</div><div class=\"line\">        ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class=\"string\">'checkpoints/style_transfer/checkpoint'</span>))</div><div class=\"line\">        <span class=\"keyword\">if</span> ckpt <span class=\"keyword\">and</span> ckpt.model_checkpoint_path:</div><div class=\"line\">            saver.restore(sess, ckpt.model_checkpoint_path)</div><div class=\"line\"></div><div class=\"line\">        initial_step = self.gstep.eval()</div><div class=\"line\">        start_time = time.time()</div><div class=\"line\">        <span class=\"comment\"># 5. iterate for n_iters time</span></div><div class=\"line\">        <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> range(initial_step, n_iters):</div><div class=\"line\">            <span class=\"keyword\">if</span> index &gt;= <span class=\"number\">5</span> <span class=\"keyword\">and</span> index &lt; <span class=\"number\">20</span>:</div><div class=\"line\">                skip_step = <span class=\"number\">10</span></div><div class=\"line\">            <span class=\"keyword\">elif</span> index &gt;= <span class=\"number\">20</span>:</div><div class=\"line\">                skip_step = <span class=\"number\">20</span></div><div class=\"line\">            <span class=\"comment\"># 6. run optimization</span></div><div class=\"line\">            sess.run(self.opt)</div><div class=\"line\">            <span class=\"comment\"># 7. add summary info \\ save checkpoint every number of certain layers</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (index + <span class=\"number\">1</span>) % skip_step == <span class=\"number\">0</span>:</div><div class=\"line\">                gen_image, total_loss, summary = sess.run([self.input_img,</div><div class=\"line\">                                                        self.total_loss,</div><div class=\"line\">                                                        self.summary_op])</div><div class=\"line\">                gen_image = gen_image + self.vgg.mean_pixels </div><div class=\"line\">                writer.add_summary(summary, global_step=index)</div><div class=\"line\">            <span class=\"comment\">#...</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (index + <span class=\"number\">1</span>) % <span class=\"number\">20</span> == <span class=\"number\">0</span>:</div><div class=\"line\">                saver.save (sess, <span class=\"string\">'checkpoints/style_stranfer/style_transfer'</span>, index)</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"个人在做完之后的一点思考\"><a href=\"#个人在做完之后的一点思考\" class=\"headerlink\" title=\"个人在做完之后的一点思考\"></a>个人在做完之后的一点思考</h3><p>首先这个任务和传统的学习任务不一样。这次学习的对象是需要生成的图像，待生成的图像像素点作为变量在最优化的时候同时被训练。而网络的模型采用他人训练好的参数。</p>\n"},{"title":"异或运算的一个性质","date":"2017-08-12T16:03:34.000Z","_content":"\n## 一个结论\n1 ^ 2 ^ 3 ^ 4.....^ n是可以在O（1）时间内计算出来的\n参考如下代码\n```c++\nll xor_n(ll n)\n{\n ll t = n & 3;\n if (t & 1) return t / 2LL ^ 1;\n return t / 2LL ^ n;\n}\n```","source":"_posts/acm/markdown/math/有关异或运算.md","raw":"---\ntitle: 异或运算的一个性质\ndate: 2017-08-13 00:03:34\ncategories: ACM\ntags:  [数论,异或]\n---\n\n## 一个结论\n1 ^ 2 ^ 3 ^ 4.....^ n是可以在O（1）时间内计算出来的\n参考如下代码\n```c++\nll xor_n(ll n)\n{\n ll t = n & 3;\n if (t & 1) return t / 2LL ^ 1;\n return t / 2LL ^ n;\n}\n```","slug":"acm/markdown/math/有关异或运算","published":1,"updated":"2017-08-27T11:43:53.003Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56gp002tacwogf4epved","content":"<h2 id=\"一个结论\"><a href=\"#一个结论\" class=\"headerlink\" title=\"一个结论\"></a>一个结论</h2><p>1 ^ 2 ^ 3 ^ 4…..^ n是可以在O（1）时间内计算出来的<br>参考如下代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\">ll <span class=\"title\">xor_n</span><span class=\"params\">(ll n)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\"> ll t = n &amp; <span class=\"number\">3</span>;</div><div class=\"line\"> <span class=\"keyword\">if</span> (t &amp; <span class=\"number\">1</span>) <span class=\"keyword\">return</span> t / <span class=\"number\">2L</span>L ^ <span class=\"number\">1</span>;</div><div class=\"line\"> <span class=\"keyword\">return</span> t / <span class=\"number\">2L</span>L ^ n;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","excerpt":"","more":"<h2 id=\"一个结论\"><a href=\"#一个结论\" class=\"headerlink\" title=\"一个结论\"></a>一个结论</h2><p>1 ^ 2 ^ 3 ^ 4…..^ n是可以在O（1）时间内计算出来的<br>参考如下代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\">ll <span class=\"title\">xor_n</span><span class=\"params\">(ll n)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\"> ll t = n &amp; <span class=\"number\">3</span>;</div><div class=\"line\"> <span class=\"keyword\">if</span> (t &amp; <span class=\"number\">1</span>) <span class=\"keyword\">return</span> t / <span class=\"number\">2L</span>L ^ <span class=\"number\">1</span>;</div><div class=\"line\"> <span class=\"keyword\">return</span> t / <span class=\"number\">2L</span>L ^ n;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n"},{"title":"欧拉函数及一些性质","date":"2017-08-20T04:03:34.000Z","_content":"\n\n## 唯一分解定理\n\n## 欧拉函数的一些性质\n\n\n**一些公式**  \n1. 若p q互质则有  \n```math\n    phi(N)=phi(p)*phi(q)  \n    \n    (N=p*q)\n```\n2. 当b是质数，a%b=0 则\n```math\n    phi(ab) = phi(a)*b\n```\n\n\n**递推式**   \n对于质数p满足p|x\n1. 若p^2|x不成立,因x/p互质故有：\n```math\n    phi(x)=phi(x/p)*(p-1)\n```\n2. 若p^2|x成立,p|(x/p)且p为质数\n```math\n    phi(x)=phi(x/p)*p\n```\n\n**公式求欧拉函数：**\n    \n```math\nphi(N) = n*(1+1/p1)(1+1/p2)...(1+1/pk)\n```\n其中\n\n```math\nN = p1^a*p2^b*...pk^x\n```\n\n因而可以写出如下的代码用公式求欧拉函数值\n```c++\n    for(int i=1; i<=MAXN; i++)\n        phi[i] = i;\n    for(int i=2; i<=MAXN; i++)\n        if(phi[i]==i){\n            for(int j=i; j<=MAXN; j+=i)\n                phi[j] = phi[j]/i*(i-1);\n        }\n```\n\n\n**lightoj-1370:** \n \n    结论： phi(x)~x之间一定存在一个质数\n    \n\n","source":"_posts/acm/markdown/math/欧拉函数.md","raw":"---\ntitle: 欧拉函数及一些性质\ndate: 2017-8-20 12:03:34\ncategories: ACM\ntags:  [数论,欧拉函数]\n---\n\n\n## 唯一分解定理\n\n## 欧拉函数的一些性质\n\n\n**一些公式**  \n1. 若p q互质则有  \n```math\n    phi(N)=phi(p)*phi(q)  \n    \n    (N=p*q)\n```\n2. 当b是质数，a%b=0 则\n```math\n    phi(ab) = phi(a)*b\n```\n\n\n**递推式**   \n对于质数p满足p|x\n1. 若p^2|x不成立,因x/p互质故有：\n```math\n    phi(x)=phi(x/p)*(p-1)\n```\n2. 若p^2|x成立,p|(x/p)且p为质数\n```math\n    phi(x)=phi(x/p)*p\n```\n\n**公式求欧拉函数：**\n    \n```math\nphi(N) = n*(1+1/p1)(1+1/p2)...(1+1/pk)\n```\n其中\n\n```math\nN = p1^a*p2^b*...pk^x\n```\n\n因而可以写出如下的代码用公式求欧拉函数值\n```c++\n    for(int i=1; i<=MAXN; i++)\n        phi[i] = i;\n    for(int i=2; i<=MAXN; i++)\n        if(phi[i]==i){\n            for(int j=i; j<=MAXN; j+=i)\n                phi[j] = phi[j]/i*(i-1);\n        }\n```\n\n\n**lightoj-1370:** \n \n    结论： phi(x)~x之间一定存在一个质数\n    \n\n","slug":"acm/markdown/math/欧拉函数","published":1,"updated":"2017-08-27T11:42:27.120Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56gp002uacwo56pqxhdd","content":"<h2 id=\"唯一分解定理\"><a href=\"#唯一分解定理\" class=\"headerlink\" title=\"唯一分解定理\"></a>唯一分解定理</h2><h2 id=\"欧拉函数的一些性质\"><a href=\"#欧拉函数的一些性质\" class=\"headerlink\" title=\"欧拉函数的一些性质\"></a>欧拉函数的一些性质</h2><p><strong>一些公式</strong>  </p>\n<ol>\n<li><p>若p q互质则有  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(N)=phi(p)*phi(q)  </div><div class=\"line\"></div><div class=\"line\">(N=p*q)</div></pre></td></tr></table></figure>\n</li>\n<li><p>当b是质数，a%b=0 则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(ab) = phi(a)*b</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><strong>递推式</strong><br>对于质数p满足p|x</p>\n<ol>\n<li><p>若p^2|x不成立,因x/p互质故有：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(x)=phi(x/p)*(p-1)</div></pre></td></tr></table></figure>\n</li>\n<li><p>若p^2|x成立,p|(x/p)且p为质数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(x)=phi(x/p)*p</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><strong>公式求欧拉函数：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(N) = n*(1+1/p1)(1+1/p2)...(1+1/pk)</div></pre></td></tr></table></figure>\n<p>其中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">N = p1^a*p2^b*...pk^x</div></pre></td></tr></table></figure>\n<p>因而可以写出如下的代码用公式求欧拉函数值<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=MAXN; i++)</div><div class=\"line\">    phi[i] = i;</div><div class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=MAXN; i++)</div><div class=\"line\">    <span class=\"keyword\">if</span>(phi[i]==i)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=i; j&lt;=MAXN; j+=i)</div><div class=\"line\">            phi[j] = phi[j]/i*(i<span class=\"number\">-1</span>);</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure></p>\n<p><strong>lightoj-1370:</strong> </p>\n<pre><code>结论： phi(x)~x之间一定存在一个质数\n</code></pre>","excerpt":"","more":"<h2 id=\"唯一分解定理\"><a href=\"#唯一分解定理\" class=\"headerlink\" title=\"唯一分解定理\"></a>唯一分解定理</h2><h2 id=\"欧拉函数的一些性质\"><a href=\"#欧拉函数的一些性质\" class=\"headerlink\" title=\"欧拉函数的一些性质\"></a>欧拉函数的一些性质</h2><p><strong>一些公式</strong>  </p>\n<ol>\n<li><p>若p q互质则有  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(N)=phi(p)*phi(q)  </div><div class=\"line\"></div><div class=\"line\">(N=p*q)</div></pre></td></tr></table></figure>\n</li>\n<li><p>当b是质数，a%b=0 则</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(ab) = phi(a)*b</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><strong>递推式</strong><br>对于质数p满足p|x</p>\n<ol>\n<li><p>若p^2|x不成立,因x/p互质故有：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(x)=phi(x/p)*(p-1)</div></pre></td></tr></table></figure>\n</li>\n<li><p>若p^2|x成立,p|(x/p)且p为质数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(x)=phi(x/p)*p</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><strong>公式求欧拉函数：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">phi(N) = n*(1+1/p1)(1+1/p2)...(1+1/pk)</div></pre></td></tr></table></figure>\n<p>其中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">N = p1^a*p2^b*...pk^x</div></pre></td></tr></table></figure>\n<p>因而可以写出如下的代码用公式求欧拉函数值<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>; i&lt;=MAXN; i++)</div><div class=\"line\">    phi[i] = i;</div><div class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=MAXN; i++)</div><div class=\"line\">    <span class=\"keyword\">if</span>(phi[i]==i)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=i; j&lt;=MAXN; j+=i)</div><div class=\"line\">            phi[j] = phi[j]/i*(i<span class=\"number\">-1</span>);</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure></p>\n<p><strong>lightoj-1370:</strong> </p>\n<pre><code>结论： phi(x)~x之间一定存在一个质数\n</code></pre>"},{"title":"素数线性筛法","date":"2017-08-20T04:03:34.000Z","_content":"\n时间复杂度O（N）\n```c++\nbool isprime[10000005];\nint prime[1000004];\nint cnt = 0;\n\nvoid sift(int n)\n{\n    memset(isprime,true,sizeof(isprime));\n    for(int i=2; i<=n; i++){\n\n        if(isprime[i])\n            prime[cnt++] = i;\n        for(int j=0; j<cnt&&prime[j]*i<=n; j++){\n            isprime[prime[j]*i] = false;\n            if(i%prime[j]==0) break;\n        }\n    }\n}\n```","source":"_posts/acm/markdown/math/素数线性筛法.md","raw":"---\ntitle: 素数线性筛法\ndate: 2017-8-20 12:03:34\ncategories: ACM\ntags:  [数论,线性筛法]\n---\n\n时间复杂度O（N）\n```c++\nbool isprime[10000005];\nint prime[1000004];\nint cnt = 0;\n\nvoid sift(int n)\n{\n    memset(isprime,true,sizeof(isprime));\n    for(int i=2; i<=n; i++){\n\n        if(isprime[i])\n            prime[cnt++] = i;\n        for(int j=0; j<cnt&&prime[j]*i<=n; j++){\n            isprime[prime[j]*i] = false;\n            if(i%prime[j]==0) break;\n        }\n    }\n}\n```","slug":"acm/markdown/math/素数线性筛法","published":1,"updated":"2017-08-27T11:43:11.635Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56h4002wacwo4dzxmtdv","content":"<p>时间复杂度O（N）<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">bool</span> isprime[<span class=\"number\">10000005</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> prime[<span class=\"number\">1000004</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> cnt = <span class=\"number\">0</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sift</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(isprime,<span class=\"literal\">true</span>,<span class=\"keyword\">sizeof</span>(isprime));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=n; i++)&#123;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">if</span>(isprime[i])</div><div class=\"line\">            prime[cnt++] = i;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; j&lt;cnt&amp;&amp;prime[j]*i&lt;=n; j++)&#123;</div><div class=\"line\">            isprime[prime[j]*i] = <span class=\"literal\">false</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(i%prime[j]==<span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","excerpt":"","more":"<p>时间复杂度O（N）<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">bool</span> isprime[<span class=\"number\">10000005</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> prime[<span class=\"number\">1000004</span>];</div><div class=\"line\"><span class=\"keyword\">int</span> cnt = <span class=\"number\">0</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">sift</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(isprime,<span class=\"literal\">true</span>,<span class=\"keyword\">sizeof</span>(isprime));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">2</span>; i&lt;=n; i++)&#123;</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">if</span>(isprime[i])</div><div class=\"line\">            prime[cnt++] = i;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; j&lt;cnt&amp;&amp;prime[j]*i&lt;=n; j++)&#123;</div><div class=\"line\">            isprime[prime[j]*i] = <span class=\"literal\">false</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(i%prime[j]==<span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n"},{"title":"二分图最大匹配的匈牙利算法和性质","date":"2017-08-20T04:03:34.000Z","_content":"\n# 二分图最大匹配\n\n## 最大匹配的匈牙利算法\n### 最大匹配：\n在G的一个子图M中，M的边集中的任意两条边都不依附于 同一个顶点，则称M是一个匹配。选择这样的边数最大的子集称为图的最大匹配问题,最大匹配的边数称为最大匹配数.如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备匹配。如果在左右两边加上源汇点后，图G等价于一个网络流，最大匹配问题可以转为最大流的问题。解决此问的匈牙利算法的本质就是寻找最大流的增广路径。  \n\n模板如下\n```c++\n/*\n    匈牙利算法\n    解决最大匹配问题\n    临接表版本\n*/\nstruct edge{\n    int to,next;\n}edge[MAXN];\nint head[MAXN],tot;\nvoid init()\n{\n    tot = 0;\n    memset(head,-1,sizeof(head));\n}\n\nvoid addedge(int u,int v)\n{\n    edge[tot].to = v;   edge[tot].next = head[u];\n    head[u] = tot++;\n}\nint linker[MAXN];\nint used[MAXN];\nint uN;         //点的编号0~uN-1\n\nbool dfs(int u)\n{\n    for(int i=head[u]; i!=-1; i=edge[i].next)\n    {\n        int v = edge[i].to;\n        if(!used[v])\n        {\n            used[v] = true;\n            if(linker[v]==-1 || dfs(linker[v])){\n                linker[v] = u;\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(linker,-1,sizeof(linker));\n    for(itn u=0; u<uN; u++){\n        memset(used,false,sizeof(used));\n        if(dfs(u))  res++;\n    }\n    return res;\n}\n\n/*\n邻接矩阵的匈牙利算法\n最小点覆盖等价于最大匹配，对每一个X集合未覆盖点出发进行一次匈牙利树扩展（dfs（））最后X内未标记和Y内已标记的集合组成最小覆盖\nmin_cover用来通过扩展匈牙利树寻找最小点覆盖\n*/\nint R,C,N;\nint uN,vN;\nint G[MAXN][MAXN];\nint Left[MAXN];\nint Right[MAXN];\nbool S[MAXN],T[MAXN];\n\nbool dfs(int u)\n{\n    S[u] = true;\n    for(int v=1; v<=vN;v++)\n    if(G[u][v] && !T[v]){\n        T[v] = true;\n        if(Left[v] == -1 || dfs(Left[v])){\n            Right[u] = v;\n            Left[v] = u;\n            return true;\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(Left,-1,sizeof(Left));\n    memset(Right,-1,sizeof(Right));\n    for(int u=1; u<=uN; u++){\n        memset(T,0,sizeof(T));\n        if(dfs(u)) res++;\n    }\n    return res;\n}\n\nint min_cover(vector<int> &X,vector<int> &Y)\n{\n    int ans = hungary();\n    X.clear();  Y.clear();\n    memset(S,0,sizeof(S));\n    memset(T,0,sizeof(T));\n    for(int i=1;i<=uN;i++)\n        if(Right[i]==-1) dfs(i);\n    for(int i=1;i<=uN;i++)\n        if(!S[i]) X.pb(i);\n    for(int j=1;j<=vN;j++)\n        if(T[j]) Y.pb(j);\n    return ans;\n}\n```\n\n\n## 二分图的一些特有性质\n### 最小覆盖\n1. **最小定点覆盖**:  \n    最小顶点覆盖是指最少的顶点数使得二分图G中的每条边都至少与其中一个点相关联，二分图的最小顶点覆盖数=二分图的最大匹配数。  \n**最小定点覆盖的证明**：  \n首先，最小点集覆盖一定>=最大匹配，因为假设最大匹配为n，那么我们就得到了n条互不相邻的边，光覆盖这些边就要用到n个点。现在我们来思考为什么最小点击覆盖一定<=最大匹配。任何一种n个点的最小点击覆盖，一定可以转化成一个n的最大匹配。因为最小点集覆盖中的每个点都能找到至少一条只有一个端点在点集中的边（如果找不到则说明该点所有的边的另外一个端点都被覆盖，所以该点则没必要被覆盖，和它在最小点集覆盖中相矛盾），只要每个端点都选择一个这样的边，就必然能转化为一个匹配数与点集覆盖的点数相等的匹配方案。所以最大匹配至少为最小点集覆盖数，即最小点击覆盖一定<=最大匹配。综上，二者相等。\n\n2. **最小边覆盖**：  \n    最小路径覆盖也称为最小边覆盖，是指用尽量少的不相交简单路径覆盖二分图中的所有顶点。二分图的最小路径覆盖数=|V|-二分图的最大匹配数。  \n    **最小边覆盖的证明**：  \n不妨设最小定点覆盖为X一共V个点，那么，最小边覆盖一定》=V-X。原因在于，首先根据最小点覆盖覆盖所有边的性质，最小点覆盖没取到的V-X个点两两无边相连，**也就是说他们是一个独立子集**，那么最小边覆盖要取到所有点的话就需要这V-X个点每个点取一条边。同时V-X又是取得到的，由于原图最小顶点覆盖就是最大二分匹配，每次取边的是后总是遵循是匹配边的话取匹配边，否则任取。那么结果一定取到了所有定点 \n\n\n\n**从二分最大匹配找到最小点覆盖**    \n需要借助匈牙利树： 设二分图两个集合为X Y  \n从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖\n\n### 最大独立集\n**最大独立集=V-最小覆盖集=V-最大匹配**  \n\n![](/images/二分图.png)    \n上图，我们用两个红色的点覆盖了所有边。我们证明的前提条件是已经达到最小覆盖。\n即条件1.已经覆盖所有边，条件2.所用的点数最小  \n**首先我们来证明蓝色点组成的是一个独立集：**   \n如果有两个蓝色点间有边相连，那么这条边则没有被覆盖，则与条件1矛盾。因此是独立集。  \n**再来证明这个独立集最大：**  \n如果我们要再增加这个独立集中的点，则需要把某个红点变成蓝点。而由最小覆盖数=最大匹配数的证明我们知道，每一个红点是最大匹配中的一个匹配点，也就是说每个红点至少连接了一条边。因此当我们将某个红点变成蓝点时，我们需要牺牲的蓝点的个数是大于等于1的。也就是说，我们最多只能找到数量相等的其他独立集，而无法找到数量更大的。因此蓝色点集必定为最大独立集。 蓝色点数 =总点数 - 红色点数，即最大独立集=总数-最小覆盖集。\n\n    ","source":"_posts/acm/markdown/图论/二分图.md","raw":"---\ntitle: 二分图最大匹配的匈牙利算法和性质\ndate: 2017-8-20 12:03:34\ncategories: ACM\ntags:  [二分图]\n---\n\n# 二分图最大匹配\n\n## 最大匹配的匈牙利算法\n### 最大匹配：\n在G的一个子图M中，M的边集中的任意两条边都不依附于 同一个顶点，则称M是一个匹配。选择这样的边数最大的子集称为图的最大匹配问题,最大匹配的边数称为最大匹配数.如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备匹配。如果在左右两边加上源汇点后，图G等价于一个网络流，最大匹配问题可以转为最大流的问题。解决此问的匈牙利算法的本质就是寻找最大流的增广路径。  \n\n模板如下\n```c++\n/*\n    匈牙利算法\n    解决最大匹配问题\n    临接表版本\n*/\nstruct edge{\n    int to,next;\n}edge[MAXN];\nint head[MAXN],tot;\nvoid init()\n{\n    tot = 0;\n    memset(head,-1,sizeof(head));\n}\n\nvoid addedge(int u,int v)\n{\n    edge[tot].to = v;   edge[tot].next = head[u];\n    head[u] = tot++;\n}\nint linker[MAXN];\nint used[MAXN];\nint uN;         //点的编号0~uN-1\n\nbool dfs(int u)\n{\n    for(int i=head[u]; i!=-1; i=edge[i].next)\n    {\n        int v = edge[i].to;\n        if(!used[v])\n        {\n            used[v] = true;\n            if(linker[v]==-1 || dfs(linker[v])){\n                linker[v] = u;\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(linker,-1,sizeof(linker));\n    for(itn u=0; u<uN; u++){\n        memset(used,false,sizeof(used));\n        if(dfs(u))  res++;\n    }\n    return res;\n}\n\n/*\n邻接矩阵的匈牙利算法\n最小点覆盖等价于最大匹配，对每一个X集合未覆盖点出发进行一次匈牙利树扩展（dfs（））最后X内未标记和Y内已标记的集合组成最小覆盖\nmin_cover用来通过扩展匈牙利树寻找最小点覆盖\n*/\nint R,C,N;\nint uN,vN;\nint G[MAXN][MAXN];\nint Left[MAXN];\nint Right[MAXN];\nbool S[MAXN],T[MAXN];\n\nbool dfs(int u)\n{\n    S[u] = true;\n    for(int v=1; v<=vN;v++)\n    if(G[u][v] && !T[v]){\n        T[v] = true;\n        if(Left[v] == -1 || dfs(Left[v])){\n            Right[u] = v;\n            Left[v] = u;\n            return true;\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(Left,-1,sizeof(Left));\n    memset(Right,-1,sizeof(Right));\n    for(int u=1; u<=uN; u++){\n        memset(T,0,sizeof(T));\n        if(dfs(u)) res++;\n    }\n    return res;\n}\n\nint min_cover(vector<int> &X,vector<int> &Y)\n{\n    int ans = hungary();\n    X.clear();  Y.clear();\n    memset(S,0,sizeof(S));\n    memset(T,0,sizeof(T));\n    for(int i=1;i<=uN;i++)\n        if(Right[i]==-1) dfs(i);\n    for(int i=1;i<=uN;i++)\n        if(!S[i]) X.pb(i);\n    for(int j=1;j<=vN;j++)\n        if(T[j]) Y.pb(j);\n    return ans;\n}\n```\n\n\n## 二分图的一些特有性质\n### 最小覆盖\n1. **最小定点覆盖**:  \n    最小顶点覆盖是指最少的顶点数使得二分图G中的每条边都至少与其中一个点相关联，二分图的最小顶点覆盖数=二分图的最大匹配数。  \n**最小定点覆盖的证明**：  \n首先，最小点集覆盖一定>=最大匹配，因为假设最大匹配为n，那么我们就得到了n条互不相邻的边，光覆盖这些边就要用到n个点。现在我们来思考为什么最小点击覆盖一定<=最大匹配。任何一种n个点的最小点击覆盖，一定可以转化成一个n的最大匹配。因为最小点集覆盖中的每个点都能找到至少一条只有一个端点在点集中的边（如果找不到则说明该点所有的边的另外一个端点都被覆盖，所以该点则没必要被覆盖，和它在最小点集覆盖中相矛盾），只要每个端点都选择一个这样的边，就必然能转化为一个匹配数与点集覆盖的点数相等的匹配方案。所以最大匹配至少为最小点集覆盖数，即最小点击覆盖一定<=最大匹配。综上，二者相等。\n\n2. **最小边覆盖**：  \n    最小路径覆盖也称为最小边覆盖，是指用尽量少的不相交简单路径覆盖二分图中的所有顶点。二分图的最小路径覆盖数=|V|-二分图的最大匹配数。  \n    **最小边覆盖的证明**：  \n不妨设最小定点覆盖为X一共V个点，那么，最小边覆盖一定》=V-X。原因在于，首先根据最小点覆盖覆盖所有边的性质，最小点覆盖没取到的V-X个点两两无边相连，**也就是说他们是一个独立子集**，那么最小边覆盖要取到所有点的话就需要这V-X个点每个点取一条边。同时V-X又是取得到的，由于原图最小顶点覆盖就是最大二分匹配，每次取边的是后总是遵循是匹配边的话取匹配边，否则任取。那么结果一定取到了所有定点 \n\n\n\n**从二分最大匹配找到最小点覆盖**    \n需要借助匈牙利树： 设二分图两个集合为X Y  \n从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖\n\n### 最大独立集\n**最大独立集=V-最小覆盖集=V-最大匹配**  \n\n![](/images/二分图.png)    \n上图，我们用两个红色的点覆盖了所有边。我们证明的前提条件是已经达到最小覆盖。\n即条件1.已经覆盖所有边，条件2.所用的点数最小  \n**首先我们来证明蓝色点组成的是一个独立集：**   \n如果有两个蓝色点间有边相连，那么这条边则没有被覆盖，则与条件1矛盾。因此是独立集。  \n**再来证明这个独立集最大：**  \n如果我们要再增加这个独立集中的点，则需要把某个红点变成蓝点。而由最小覆盖数=最大匹配数的证明我们知道，每一个红点是最大匹配中的一个匹配点，也就是说每个红点至少连接了一条边。因此当我们将某个红点变成蓝点时，我们需要牺牲的蓝点的个数是大于等于1的。也就是说，我们最多只能找到数量相等的其他独立集，而无法找到数量更大的。因此蓝色点集必定为最大独立集。 蓝色点数 =总点数 - 红色点数，即最大独立集=总数-最小覆盖集。\n\n    ","slug":"acm/markdown/图论/二分图","published":1,"updated":"2017-09-14T06:04:35.976Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56h4002yacwo16i7dyoq","content":"<h1 id=\"二分图最大匹配\"><a href=\"#二分图最大匹配\" class=\"headerlink\" title=\"二分图最大匹配\"></a>二分图最大匹配</h1><h2 id=\"最大匹配的匈牙利算法\"><a href=\"#最大匹配的匈牙利算法\" class=\"headerlink\" title=\"最大匹配的匈牙利算法\"></a>最大匹配的匈牙利算法</h2><h3 id=\"最大匹配：\"><a href=\"#最大匹配：\" class=\"headerlink\" title=\"最大匹配：\"></a>最大匹配：</h3><p>在G的一个子图M中，M的边集中的任意两条边都不依附于 同一个顶点，则称M是一个匹配。选择这样的边数最大的子集称为图的最大匹配问题,最大匹配的边数称为最大匹配数.如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备匹配。如果在左右两边加上源汇点后，图G等价于一个网络流，最大匹配问题可以转为最大流的问题。解决此问的匈牙利算法的本质就是寻找最大流的增广路径。  </p>\n<p>模板如下<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">    匈牙利算法</div><div class=\"line\">    解决最大匹配问题</div><div class=\"line\">    临接表版本</div><div class=\"line\">*/</div><div class=\"line\"><span class=\"keyword\">struct</span> edge&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> to,next;</div><div class=\"line\">&#125;edge[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> head[MAXN],tot;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    tot = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(head,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(head));</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">addedge</span><span class=\"params\">(<span class=\"keyword\">int</span> u,<span class=\"keyword\">int</span> v)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    edge[tot].to = v;   edge[tot].next = head[u];</div><div class=\"line\">    head[u] = tot++;</div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">int</span> linker[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> used[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> uN;         <span class=\"comment\">//点的编号0~uN-1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=head[u]; i!=<span class=\"number\">-1</span>; i=edge[i].next)</div><div class=\"line\">    &#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> v = edge[i].to;</div><div class=\"line\">        <span class=\"keyword\">if</span>(!used[v])</div><div class=\"line\">        &#123;</div><div class=\"line\">            used[v] = <span class=\"literal\">true</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(linker[v]==<span class=\"number\">-1</span> || dfs(linker[v]))&#123;</div><div class=\"line\">                linker[v] = u;</div><div class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">hungary</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(linker,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(linker));</div><div class=\"line\">    <span class=\"keyword\">for</span>(itn u=<span class=\"number\">0</span>; u&lt;uN; u++)&#123;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(used,<span class=\"literal\">false</span>,<span class=\"keyword\">sizeof</span>(used));</div><div class=\"line\">        <span class=\"keyword\">if</span>(dfs(u))  res++;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> res;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">邻接矩阵的匈牙利算法</div><div class=\"line\">最小点覆盖等价于最大匹配，对每一个X集合未覆盖点出发进行一次匈牙利树扩展（dfs（））最后X内未标记和Y内已标记的集合组成最小覆盖</div><div class=\"line\">min_cover用来通过扩展匈牙利树寻找最小点覆盖</div><div class=\"line\">*/</div><div class=\"line\"><span class=\"keyword\">int</span> R,C,N;</div><div class=\"line\"><span class=\"keyword\">int</span> uN,vN;</div><div class=\"line\"><span class=\"keyword\">int</span> G[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Left[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Right[MAXN];</div><div class=\"line\"><span class=\"keyword\">bool</span> S[MAXN],T[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    S[u] = <span class=\"literal\">true</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> v=<span class=\"number\">1</span>; v&lt;=vN;v++)</div><div class=\"line\">    <span class=\"keyword\">if</span>(G[u][v] &amp;&amp; !T[v])&#123;</div><div class=\"line\">        T[v] = <span class=\"literal\">true</span>;</div><div class=\"line\">        <span class=\"keyword\">if</span>(Left[v] == <span class=\"number\">-1</span> || dfs(Left[v]))&#123;</div><div class=\"line\">            Right[u] = v;</div><div class=\"line\">            Left[v] = u;</div><div class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">hungary</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Left,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Left));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Right,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Right));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> u=<span class=\"number\">1</span>; u&lt;=uN; u++)&#123;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">        <span class=\"keyword\">if</span>(dfs(u)) res++;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> res;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">min_cover</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;X,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;Y)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = hungary();</div><div class=\"line\">    X.clear();  Y.clear();</div><div class=\"line\">    <span class=\"built_in\">memset</span>(S,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(S));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(Right[i]==<span class=\"number\">-1</span>) dfs(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(!S[i]) X.pb(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>;j&lt;=vN;j++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(T[j]) Y.pb(j);</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"二分图的一些特有性质\"><a href=\"#二分图的一些特有性质\" class=\"headerlink\" title=\"二分图的一些特有性质\"></a>二分图的一些特有性质</h2><h3 id=\"最小覆盖\"><a href=\"#最小覆盖\" class=\"headerlink\" title=\"最小覆盖\"></a>最小覆盖</h3><ol>\n<li><p><strong>最小定点覆盖</strong>:<br> 最小顶点覆盖是指最少的顶点数使得二分图G中的每条边都至少与其中一个点相关联，二分图的最小顶点覆盖数=二分图的最大匹配数。<br><strong>最小定点覆盖的证明</strong>：<br>首先，最小点集覆盖一定&gt;=最大匹配，因为假设最大匹配为n，那么我们就得到了n条互不相邻的边，光覆盖这些边就要用到n个点。现在我们来思考为什么最小点击覆盖一定&lt;=最大匹配。任何一种n个点的最小点击覆盖，一定可以转化成一个n的最大匹配。因为最小点集覆盖中的每个点都能找到至少一条只有一个端点在点集中的边（如果找不到则说明该点所有的边的另外一个端点都被覆盖，所以该点则没必要被覆盖，和它在最小点集覆盖中相矛盾），只要每个端点都选择一个这样的边，就必然能转化为一个匹配数与点集覆盖的点数相等的匹配方案。所以最大匹配至少为最小点集覆盖数，即最小点击覆盖一定&lt;=最大匹配。综上，二者相等。</p>\n</li>\n<li><p><strong>最小边覆盖</strong>：<br> 最小路径覆盖也称为最小边覆盖，是指用尽量少的不相交简单路径覆盖二分图中的所有顶点。二分图的最小路径覆盖数=|V|-二分图的最大匹配数。<br> <strong>最小边覆盖的证明</strong>：<br>不妨设最小定点覆盖为X一共V个点，那么，最小边覆盖一定》=V-X。原因在于，首先根据最小点覆盖覆盖所有边的性质，最小点覆盖没取到的V-X个点两两无边相连，<strong>也就是说他们是一个独立子集</strong>，那么最小边覆盖要取到所有点的话就需要这V-X个点每个点取一条边。同时V-X又是取得到的，由于原图最小顶点覆盖就是最大二分匹配，每次取边的是后总是遵循是匹配边的话取匹配边，否则任取。那么结果一定取到了所有定点 </p>\n</li>\n</ol>\n<p><strong>从二分最大匹配找到最小点覆盖</strong><br>需要借助匈牙利树： 设二分图两个集合为X Y<br>从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖</p>\n<h3 id=\"最大独立集\"><a href=\"#最大独立集\" class=\"headerlink\" title=\"最大独立集\"></a>最大独立集</h3><p><strong>最大独立集=V-最小覆盖集=V-最大匹配</strong>  </p>\n<p><img src=\"/images/二分图.png\" alt=\"\"><br>上图，我们用两个红色的点覆盖了所有边。我们证明的前提条件是已经达到最小覆盖。<br>即条件1.已经覆盖所有边，条件2.所用的点数最小<br><strong>首先我们来证明蓝色点组成的是一个独立集：</strong><br>如果有两个蓝色点间有边相连，那么这条边则没有被覆盖，则与条件1矛盾。因此是独立集。<br><strong>再来证明这个独立集最大：</strong><br>如果我们要再增加这个独立集中的点，则需要把某个红点变成蓝点。而由最小覆盖数=最大匹配数的证明我们知道，每一个红点是最大匹配中的一个匹配点，也就是说每个红点至少连接了一条边。因此当我们将某个红点变成蓝点时，我们需要牺牲的蓝点的个数是大于等于1的。也就是说，我们最多只能找到数量相等的其他独立集，而无法找到数量更大的。因此蓝色点集必定为最大独立集。 蓝色点数 =总点数 - 红色点数，即最大独立集=总数-最小覆盖集。</p>\n","excerpt":"","more":"<h1 id=\"二分图最大匹配\"><a href=\"#二分图最大匹配\" class=\"headerlink\" title=\"二分图最大匹配\"></a>二分图最大匹配</h1><h2 id=\"最大匹配的匈牙利算法\"><a href=\"#最大匹配的匈牙利算法\" class=\"headerlink\" title=\"最大匹配的匈牙利算法\"></a>最大匹配的匈牙利算法</h2><h3 id=\"最大匹配：\"><a href=\"#最大匹配：\" class=\"headerlink\" title=\"最大匹配：\"></a>最大匹配：</h3><p>在G的一个子图M中，M的边集中的任意两条边都不依附于 同一个顶点，则称M是一个匹配。选择这样的边数最大的子集称为图的最大匹配问题,最大匹配的边数称为最大匹配数.如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备匹配。如果在左右两边加上源汇点后，图G等价于一个网络流，最大匹配问题可以转为最大流的问题。解决此问的匈牙利算法的本质就是寻找最大流的增广路径。  </p>\n<p>模板如下<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">    匈牙利算法</div><div class=\"line\">    解决最大匹配问题</div><div class=\"line\">    临接表版本</div><div class=\"line\">*/</span></div><div class=\"line\"><span class=\"keyword\">struct</span> edge&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> to,next;</div><div class=\"line\">&#125;edge[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> head[MAXN],tot;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    tot = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(head,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(head));</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">addedge</span><span class=\"params\">(<span class=\"keyword\">int</span> u,<span class=\"keyword\">int</span> v)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    edge[tot].to = v;   edge[tot].next = head[u];</div><div class=\"line\">    head[u] = tot++;</div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"keyword\">int</span> linker[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> used[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> uN;         <span class=\"comment\">//点的编号0~uN-1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=head[u]; i!=<span class=\"number\">-1</span>; i=edge[i].next)</div><div class=\"line\">    &#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> v = edge[i].to;</div><div class=\"line\">        <span class=\"keyword\">if</span>(!used[v])</div><div class=\"line\">        &#123;</div><div class=\"line\">            used[v] = <span class=\"literal\">true</span>;</div><div class=\"line\">            <span class=\"keyword\">if</span>(linker[v]==<span class=\"number\">-1</span> || dfs(linker[v]))&#123;</div><div class=\"line\">                linker[v] = u;</div><div class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">hungary</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(linker,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(linker));</div><div class=\"line\">    <span class=\"keyword\">for</span>(itn u=<span class=\"number\">0</span>; u&lt;uN; u++)&#123;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(used,<span class=\"literal\">false</span>,<span class=\"keyword\">sizeof</span>(used));</div><div class=\"line\">        <span class=\"keyword\">if</span>(dfs(u))  res++;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> res;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">邻接矩阵的匈牙利算法</div><div class=\"line\">最小点覆盖等价于最大匹配，对每一个X集合未覆盖点出发进行一次匈牙利树扩展（dfs（））最后X内未标记和Y内已标记的集合组成最小覆盖</div><div class=\"line\">min_cover用来通过扩展匈牙利树寻找最小点覆盖</div><div class=\"line\">*/</span></div><div class=\"line\"><span class=\"keyword\">int</span> R,C,N;</div><div class=\"line\"><span class=\"keyword\">int</span> uN,vN;</div><div class=\"line\"><span class=\"keyword\">int</span> G[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Left[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Right[MAXN];</div><div class=\"line\"><span class=\"keyword\">bool</span> S[MAXN],T[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    S[u] = <span class=\"literal\">true</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> v=<span class=\"number\">1</span>; v&lt;=vN;v++)</div><div class=\"line\">    <span class=\"keyword\">if</span>(G[u][v] &amp;&amp; !T[v])&#123;</div><div class=\"line\">        T[v] = <span class=\"literal\">true</span>;</div><div class=\"line\">        <span class=\"keyword\">if</span>(Left[v] == <span class=\"number\">-1</span> || dfs(Left[v]))&#123;</div><div class=\"line\">            Right[u] = v;</div><div class=\"line\">            Left[v] = u;</div><div class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">hungary</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Left,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Left));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Right,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Right));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> u=<span class=\"number\">1</span>; u&lt;=uN; u++)&#123;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">        <span class=\"keyword\">if</span>(dfs(u)) res++;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> res;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">min_cover</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;X,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;Y)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = hungary();</div><div class=\"line\">    X.clear();  Y.clear();</div><div class=\"line\">    <span class=\"built_in\">memset</span>(S,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(S));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(Right[i]==<span class=\"number\">-1</span>) dfs(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(!S[i]) X.pb(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>;j&lt;=vN;j++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(T[j]) Y.pb(j);</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"二分图的一些特有性质\"><a href=\"#二分图的一些特有性质\" class=\"headerlink\" title=\"二分图的一些特有性质\"></a>二分图的一些特有性质</h2><h3 id=\"最小覆盖\"><a href=\"#最小覆盖\" class=\"headerlink\" title=\"最小覆盖\"></a>最小覆盖</h3><ol>\n<li><p><strong>最小定点覆盖</strong>:<br> 最小顶点覆盖是指最少的顶点数使得二分图G中的每条边都至少与其中一个点相关联，二分图的最小顶点覆盖数=二分图的最大匹配数。<br><strong>最小定点覆盖的证明</strong>：<br>首先，最小点集覆盖一定&gt;=最大匹配，因为假设最大匹配为n，那么我们就得到了n条互不相邻的边，光覆盖这些边就要用到n个点。现在我们来思考为什么最小点击覆盖一定&lt;=最大匹配。任何一种n个点的最小点击覆盖，一定可以转化成一个n的最大匹配。因为最小点集覆盖中的每个点都能找到至少一条只有一个端点在点集中的边（如果找不到则说明该点所有的边的另外一个端点都被覆盖，所以该点则没必要被覆盖，和它在最小点集覆盖中相矛盾），只要每个端点都选择一个这样的边，就必然能转化为一个匹配数与点集覆盖的点数相等的匹配方案。所以最大匹配至少为最小点集覆盖数，即最小点击覆盖一定&lt;=最大匹配。综上，二者相等。</p>\n</li>\n<li><p><strong>最小边覆盖</strong>：<br> 最小路径覆盖也称为最小边覆盖，是指用尽量少的不相交简单路径覆盖二分图中的所有顶点。二分图的最小路径覆盖数=|V|-二分图的最大匹配数。<br> <strong>最小边覆盖的证明</strong>：<br>不妨设最小定点覆盖为X一共V个点，那么，最小边覆盖一定》=V-X。原因在于，首先根据最小点覆盖覆盖所有边的性质，最小点覆盖没取到的V-X个点两两无边相连，<strong>也就是说他们是一个独立子集</strong>，那么最小边覆盖要取到所有点的话就需要这V-X个点每个点取一条边。同时V-X又是取得到的，由于原图最小顶点覆盖就是最大二分匹配，每次取边的是后总是遵循是匹配边的话取匹配边，否则任取。那么结果一定取到了所有定点 </p>\n</li>\n</ol>\n<p><strong>从二分最大匹配找到最小点覆盖</strong><br>需要借助匈牙利树： 设二分图两个集合为X Y<br>从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖</p>\n<h3 id=\"最大独立集\"><a href=\"#最大独立集\" class=\"headerlink\" title=\"最大独立集\"></a>最大独立集</h3><p><strong>最大独立集=V-最小覆盖集=V-最大匹配</strong>  </p>\n<p><img src=\"/images/二分图.png\" alt=\"\"><br>上图，我们用两个红色的点覆盖了所有边。我们证明的前提条件是已经达到最小覆盖。<br>即条件1.已经覆盖所有边，条件2.所用的点数最小<br><strong>首先我们来证明蓝色点组成的是一个独立集：</strong><br>如果有两个蓝色点间有边相连，那么这条边则没有被覆盖，则与条件1矛盾。因此是独立集。<br><strong>再来证明这个独立集最大：</strong><br>如果我们要再增加这个独立集中的点，则需要把某个红点变成蓝点。而由最小覆盖数=最大匹配数的证明我们知道，每一个红点是最大匹配中的一个匹配点，也就是说每个红点至少连接了一条边。因此当我们将某个红点变成蓝点时，我们需要牺牲的蓝点的个数是大于等于1的。也就是说，我们最多只能找到数量相等的其他独立集，而无法找到数量更大的。因此蓝色点集必定为最大独立集。 蓝色点数 =总点数 - 红色点数，即最大独立集=总数-最小覆盖集。</p>\n"},{"title":"稀疏表","date":"2017-08-20T04:03:34.000Z","_content":"\n## Spared Table （用于解决多种RMQ问题）\n模板：\n（解决区间极小值）\n```c++\n/*\nST用来O（nlogn）时间预处理，O（1）时间查询最大最小值\n*/\n#include <iostream>  \n#include <math.h>  \nusing namespace std;  \n  \n/*方程 \nF[i,j]:区间[i,i + 2^j - 1]的最小值，此时区间长度为2^j \nF[i,j] = min(F[i,j - 1],F[i + 2^(j - 1),j - 1]) \nF[i,0] = nArr[i];*/  \n  \nconst int MAXN = 10010;\nint rmq[2*MAXN];//rmq数组,就是欧拉序列对应的深度序列\n  \nstruct ST\n{\n    int mm[2*MAXN];//意思是向下取log2(k)\n    int dp[2*MAXN][20];//最小值对应的下标\n    void init(int n)\n    {\n        mm[0] = -1;\n        for(int i = 1;i <= n;i++)\n        {\n            mm[i] = ((i&(i-1)) == 0)?mm[i-1]+1:mm[i-1];\n            dp[i][0] = i;\n        }\n        for(int j = 1; j <= mm[n];j++)\n            for(int i = 1; i + (1<<j) - 1 <= n; i++)\n                dp[i][j] = rmq[dp[i][j-1]] <\n                rmq[dp[i+(1<<(j-1))][j-1]]?dp[i][j-1]:dp[i+(1<<(j-1))][j-1];\n    }\n    int query(int a,int b)//查询[a,b]之间最小值的下标\n    {\n        if(a > b)swap(a,b);\n        int k = mm[b-a+1];\n        return rmq[dp[a][k]] <= \n        rmq[dp[b-(1<<k)+1][k]]?dp[a][k]:dp[b-(1<<k)+1][k];\n    }\n};\n```\n\n例：hdu-5726 解决区间最小公倍数\n","source":"_posts/acm/markdown/数据结构/稀疏表.md","raw":"---\ntitle: 稀疏表\ndate: 2017-8-20 12:03:34\ncategories: ACM\ntags:  [RMQ,稀疏表]\n---\n\n## Spared Table （用于解决多种RMQ问题）\n模板：\n（解决区间极小值）\n```c++\n/*\nST用来O（nlogn）时间预处理，O（1）时间查询最大最小值\n*/\n#include <iostream>  \n#include <math.h>  \nusing namespace std;  \n  \n/*方程 \nF[i,j]:区间[i,i + 2^j - 1]的最小值，此时区间长度为2^j \nF[i,j] = min(F[i,j - 1],F[i + 2^(j - 1),j - 1]) \nF[i,0] = nArr[i];*/  \n  \nconst int MAXN = 10010;\nint rmq[2*MAXN];//rmq数组,就是欧拉序列对应的深度序列\n  \nstruct ST\n{\n    int mm[2*MAXN];//意思是向下取log2(k)\n    int dp[2*MAXN][20];//最小值对应的下标\n    void init(int n)\n    {\n        mm[0] = -1;\n        for(int i = 1;i <= n;i++)\n        {\n            mm[i] = ((i&(i-1)) == 0)?mm[i-1]+1:mm[i-1];\n            dp[i][0] = i;\n        }\n        for(int j = 1; j <= mm[n];j++)\n            for(int i = 1; i + (1<<j) - 1 <= n; i++)\n                dp[i][j] = rmq[dp[i][j-1]] <\n                rmq[dp[i+(1<<(j-1))][j-1]]?dp[i][j-1]:dp[i+(1<<(j-1))][j-1];\n    }\n    int query(int a,int b)//查询[a,b]之间最小值的下标\n    {\n        if(a > b)swap(a,b);\n        int k = mm[b-a+1];\n        return rmq[dp[a][k]] <= \n        rmq[dp[b-(1<<k)+1][k]]?dp[a][k]:dp[b-(1<<k)+1][k];\n    }\n};\n```\n\n例：hdu-5726 解决区间最小公倍数\n","slug":"acm/markdown/数据结构/稀疏表","published":1,"updated":"2017-08-27T11:44:29.254Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56jq003cacwomc4usa4p","content":"<h2 id=\"Spared-Table-（用于解决多种RMQ问题）\"><a href=\"#Spared-Table-（用于解决多种RMQ问题）\" class=\"headerlink\" title=\"Spared Table （用于解决多种RMQ问题）\"></a>Spared Table （用于解决多种RMQ问题）</h2><p>模板：<br>（解决区间极小值）<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">ST用来O（nlogn）时间预处理，O（1）时间查询最大最小值</div><div class=\"line\">*/</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span>  </span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;math.h&gt;</span>  </span></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"comment\">/*方程 </span></div><div class=\"line\">F[i,j]:区间[i,i + 2^j - 1]的最小值，此时区间长度为2^j </div><div class=\"line\">F[i,j] = min(F[i,j - 1],F[i + 2^(j - 1),j - 1]) </div><div class=\"line\">F[i,0] = nArr[i];*/  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> MAXN = <span class=\"number\">10010</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> rmq[<span class=\"number\">2</span>*MAXN];<span class=\"comment\">//rmq数组,就是欧拉序列对应的深度序列</span></div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">struct</span> ST</div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> mm[<span class=\"number\">2</span>*MAXN];<span class=\"comment\">//意思是向下取log2(k)</span></div><div class=\"line\">    <span class=\"keyword\">int</span> dp[<span class=\"number\">2</span>*MAXN][<span class=\"number\">20</span>];<span class=\"comment\">//最小值对应的下标</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span></div><div class=\"line\">    &#123;</div><div class=\"line\">        mm[<span class=\"number\">0</span>] = <span class=\"number\">-1</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;i &lt;= n;i++)</div><div class=\"line\">        &#123;</div><div class=\"line\">            mm[i] = ((i&amp;(i<span class=\"number\">-1</span>)) == <span class=\"number\">0</span>)?mm[i<span class=\"number\">-1</span>]+<span class=\"number\">1</span>:mm[i<span class=\"number\">-1</span>];</div><div class=\"line\">            dp[i][<span class=\"number\">0</span>] = i;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j = <span class=\"number\">1</span>; j &lt;= mm[n];j++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i + (<span class=\"number\">1</span>&lt;&lt;j) - <span class=\"number\">1</span> &lt;= n; i++)</div><div class=\"line\">                dp[i][j] = rmq[dp[i][j<span class=\"number\">-1</span>]] &lt;</div><div class=\"line\">                rmq[dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>]]?dp[i][j<span class=\"number\">-1</span>]:dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">query</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span><span class=\"comment\">//查询[a,b]之间最小值的下标</span></span></div><div class=\"line\">    &#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(a &gt; b)swap(a,b);</div><div class=\"line\">        <span class=\"keyword\">int</span> k = mm[b-a+<span class=\"number\">1</span>];</div><div class=\"line\">        <span class=\"keyword\">return</span> rmq[dp[a][k]] &lt;= </div><div class=\"line\">        rmq[dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k]]?dp[a][k]:dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k];</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>例：hdu-5726 解决区间最小公倍数</p>\n","excerpt":"","more":"<h2 id=\"Spared-Table-（用于解决多种RMQ问题）\"><a href=\"#Spared-Table-（用于解决多种RMQ问题）\" class=\"headerlink\" title=\"Spared Table （用于解决多种RMQ问题）\"></a>Spared Table （用于解决多种RMQ问题）</h2><p>模板：<br>（解决区间极小值）<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">ST用来O（nlogn）时间预处理，O（1）时间查询最大最小值</div><div class=\"line\">*/</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span>  </span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;math.h&gt;</span>  </span></div><div class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"comment\">/*方程 </div><div class=\"line\">F[i,j]:区间[i,i + 2^j - 1]的最小值，此时区间长度为2^j </div><div class=\"line\">F[i,j] = min(F[i,j - 1],F[i + 2^(j - 1),j - 1]) </div><div class=\"line\">F[i,0] = nArr[i];*/</span>  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> MAXN = <span class=\"number\">10010</span>;</div><div class=\"line\"><span class=\"keyword\">int</span> rmq[<span class=\"number\">2</span>*MAXN];<span class=\"comment\">//rmq数组,就是欧拉序列对应的深度序列</span></div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">struct</span> ST</div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> mm[<span class=\"number\">2</span>*MAXN];<span class=\"comment\">//意思是向下取log2(k)</span></div><div class=\"line\">    <span class=\"keyword\">int</span> dp[<span class=\"number\">2</span>*MAXN][<span class=\"number\">20</span>];<span class=\"comment\">//最小值对应的下标</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></div><div class=\"line\">    </span>&#123;</div><div class=\"line\">        mm[<span class=\"number\">0</span>] = <span class=\"number\">-1</span>;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;i &lt;= n;i++)</div><div class=\"line\">        &#123;</div><div class=\"line\">            mm[i] = ((i&amp;(i<span class=\"number\">-1</span>)) == <span class=\"number\">0</span>)?mm[i<span class=\"number\">-1</span>]+<span class=\"number\">1</span>:mm[i<span class=\"number\">-1</span>];</div><div class=\"line\">            dp[i][<span class=\"number\">0</span>] = i;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j = <span class=\"number\">1</span>; j &lt;= mm[n];j++)</div><div class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i + (<span class=\"number\">1</span>&lt;&lt;j) - <span class=\"number\">1</span> &lt;= n; i++)</div><div class=\"line\">                dp[i][j] = rmq[dp[i][j<span class=\"number\">-1</span>]] &lt;</div><div class=\"line\">                rmq[dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>]]?dp[i][j<span class=\"number\">-1</span>]:dp[i+(<span class=\"number\">1</span>&lt;&lt;(j<span class=\"number\">-1</span>))][j<span class=\"number\">-1</span>];</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">query</span><span class=\"params\">(<span class=\"keyword\">int</span> a,<span class=\"keyword\">int</span> b)</span><span class=\"comment\">//查询[a,b]之间最小值的下标</span></div><div class=\"line\">    </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(a &gt; b)swap(a,b);</div><div class=\"line\">        <span class=\"keyword\">int</span> k = mm[b-a+<span class=\"number\">1</span>];</div><div class=\"line\">        <span class=\"keyword\">return</span> rmq[dp[a][k]] &lt;= </div><div class=\"line\">        rmq[dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k]]?dp[a][k]:dp[b-(<span class=\"number\">1</span>&lt;&lt;k)+<span class=\"number\">1</span>][k];</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>例：hdu-5726 解决区间最小公倍数</p>\n"},{"title":"Uva-11354 最小瓶颈树+LCA倍增法维护最大值","date":"2017-08-27T04:03:34.000Z","_content":"\n# Uva-11354\n题意：  \n给你一个无向图，N个节点M条边，边权为d，对Q组询问a b,问能取到的从a到b路径上的最小值。\n\n题解：  \n首先总是要取最小的值，则可以先用kruskal求最小生成树（也就是最小瓶颈树），即在树上求任意两点之间路径边权值的最小值。可以用倍增求解LCA的方法，**在保存p[i][j]（节点i的向上2^i个祖先） 的同时维护mlen[i][j]（节点i向上2^i条边的最大值）**\n\n```c++\n#include <iostream>\n#include <cstdio>\n#include <cctype>\n#include <algorithm>\n#include <cstring>\n#include <string>\n#include <cmath>\n#include <vector>\n#include <set>\n#include <stack>\n#include <sstream>\n#include <queue>\n#include <map>\n#include <functional>\n#include <bitset>\n\nusing namespace std;\n#define pb push_back\n#define mk make_pair\n#define ll long long\n#define ull unsigned long long\n#define pii pair<int, int>\n#define mkp make_pair\n#define fst first\n#define scd second\n#define ALL(A) A.begin(), A.end()\n#define REP(i,n) for(int (i)=0;(i)<(int)(n);(i)++)\n#define REP1(i, n) for(int (i)=1;(i)<=(int)(n);(i)++)\n#define fastio ios::sync_with_stdio(0), cin.tie(0)\n#define frein freopen(\"in.txt\", \"r\", stdin)\n#define freout freopen(\"out.txt\", \"w\", stdout)\n#define freout1 freopen(\"out1.txt\", \"w\", stdout)\n#define PI M_PI\n#define MAXN 100000\n#define xork(a,b) ((b&1)?(a):(0))\n#define sc(n) scanf(\"%d\",&(n))\n\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\nstruct edge{\n    int from,to;\n    int v;\n    bool operator<(const edge &a)const{\n        return v<a.v;\n    }\n};\n\nvector<edge> E;\nvector<vector<pii> >G(MAXN);\nint d[MAXN],len[MAXN];\nint p[MAXN][20],mlen[MAXN][20];\nint f[MAXN];\nint N,M;\n\nint getf(int v){\n    if(f[v]==v) return v;\n    else return f[v] = getf(f[v]);\n}\n\nbool Merge(int v1,int v2){\n    int f1 = getf(v1);\n    int f2 = getf(v2);\n    if(f1 == f2){\n        return false;\n    }\n    f[f1] = f2;\n    return true;\n}\n\nvoid kruskal()\n{\n    for(int i=0; i<=N; i++)\n        f[i] = i;\n    int cnt = 0;\n    for(int i=0; i<E.size(); i++){\n        if(cnt>=N-1)    break;\n        int f = E[i].from;\n        int t = E[i].to;\n        if(Merge(f,t)){\n            cnt++;\n            G[f].pb(mkp(t,E[i].v));\n            G[t].pb(mkp(f,E[i].v));\n//            cout<<f<<\" \"<<t<<\" \"<<E[i].v<<endl;\n        }\n    }\n}\n\nvoid dfs(int v,int pre,int depth)\n{\n    d[v] = depth;\n    for(int i=0; i<G[v].size(); i++){\n        int t = G[v][i].first;\n        int val = G[v][i].second;\n        if(t==pre)  continue;\n        dfs(t,v,depth+1);\n        //len[t] = val;\n        p[t][0] = v;\n        mlen[t][0] = val;\n    }\n}\n\nvoid lca_init(int n)\n{\n//    for(int i=1; i<=n; i++)\n//        printf(\"mlen[%d][0] = %d\\n\",i,mlen[i][0]);\n    for(int j=1; (1<<j)<=n; j++){\n        for(int i=1; i<=n; i++){\n            p[i][j] = p[p[i][j-1]][j-1];\n            mlen[i][j] = max(mlen[i][j-1],mlen[p[i][j-1]][j-1]);\n            //printf(\"mlen[%d][%d] = %d\\n\",i,j,mlen[i][j]);\n        }\n    }\n}\n\nint query(int a,int b)\n{\n    //printf(\"Query a:%d b%d\\n\",a,b);\n    if(d[a]>d[b])  swap(a,b);\n    int f = d[b] - d[a];\n    int maxe = -1;\n    for(int i=0; (1<<i)<=f; i++)\n        if(f&(1<<i)){\n            maxe = max(maxe,mlen[b][i]);\n            b = p[b][i];\n        }\n    //printf(\"maxe = %d\\n\",maxe);\n    if(a!=b){\n        for(int i=(int)log2(N);i>=0; i--){\n            if(p[a][i]!=p[b][i]){\n                maxe = max(maxe,max(mlen[b][i],mlen[a][i]));\n                a = p[a][i];    b = p[b][i];\n            }\n            //printf(\"maxe = %d\\n\",maxe);\n        }\n        maxe = max(maxe,mlen[a][0]);    //和求LCA不同，这里要同时对两个节点更新最大值\n        maxe = max(maxe,mlen[b][0]);\n        //printf(\"a = %d  maxe = %d\\n\",a,maxe);\n    }\n    return maxe;\n}\n\nint main()\n{\n    //freout;\n    bool flag = false;\n    while(~scanf(\"%d%d\",&N,&M)){\n        if(flag) puts(\"\");\n        flag = true;\n        E.clear();\n        for(int i=1; i<=N; i++)\n            G[i].clear();\n        for(int i=0; i<M; i++){\n            edge t;\n            scanf(\"%d%d%d\",&t.from,&t.to,&t.v);\n            E.pb(t);\n        }\n        sort(E.begin(),E.end());\n        kruskal();\n        dfs(1,-1,0);\n        lca_init(N);\n        int Q;\n        sc(Q);\n        for(int i=0; i<Q; i++){\n            int a,b;\n            sc(a); sc(b);\n            printf(\"%d\\n\",query(a,b));\n        }\n    }\n}\n\n```","source":"_posts/acm/题解/图论/Uva-11354 最小瓶颈树+LCA倍增法维护最大值.md","raw":"---\ntitle: Uva-11354 最小瓶颈树+LCA倍增法维护最大值\ndate: 2017-8-27 12:03:34\ncategories: ACM\ntags:  [最小瓶颈树,kruskal,倍增法,LCA]\n---\n\n# Uva-11354\n题意：  \n给你一个无向图，N个节点M条边，边权为d，对Q组询问a b,问能取到的从a到b路径上的最小值。\n\n题解：  \n首先总是要取最小的值，则可以先用kruskal求最小生成树（也就是最小瓶颈树），即在树上求任意两点之间路径边权值的最小值。可以用倍增求解LCA的方法，**在保存p[i][j]（节点i的向上2^i个祖先） 的同时维护mlen[i][j]（节点i向上2^i条边的最大值）**\n\n```c++\n#include <iostream>\n#include <cstdio>\n#include <cctype>\n#include <algorithm>\n#include <cstring>\n#include <string>\n#include <cmath>\n#include <vector>\n#include <set>\n#include <stack>\n#include <sstream>\n#include <queue>\n#include <map>\n#include <functional>\n#include <bitset>\n\nusing namespace std;\n#define pb push_back\n#define mk make_pair\n#define ll long long\n#define ull unsigned long long\n#define pii pair<int, int>\n#define mkp make_pair\n#define fst first\n#define scd second\n#define ALL(A) A.begin(), A.end()\n#define REP(i,n) for(int (i)=0;(i)<(int)(n);(i)++)\n#define REP1(i, n) for(int (i)=1;(i)<=(int)(n);(i)++)\n#define fastio ios::sync_with_stdio(0), cin.tie(0)\n#define frein freopen(\"in.txt\", \"r\", stdin)\n#define freout freopen(\"out.txt\", \"w\", stdout)\n#define freout1 freopen(\"out1.txt\", \"w\", stdout)\n#define PI M_PI\n#define MAXN 100000\n#define xork(a,b) ((b&1)?(a):(0))\n#define sc(n) scanf(\"%d\",&(n))\n\nll mod = 10000;\nll INF = 1LL<<60LL;\nconst double eps = 1e-8;\ntemplate<typename T> T gcd(T a,T b)\n{if(!b)return a;return gcd(b,a%b);}\nstruct edge{\n    int from,to;\n    int v;\n    bool operator<(const edge &a)const{\n        return v<a.v;\n    }\n};\n\nvector<edge> E;\nvector<vector<pii> >G(MAXN);\nint d[MAXN],len[MAXN];\nint p[MAXN][20],mlen[MAXN][20];\nint f[MAXN];\nint N,M;\n\nint getf(int v){\n    if(f[v]==v) return v;\n    else return f[v] = getf(f[v]);\n}\n\nbool Merge(int v1,int v2){\n    int f1 = getf(v1);\n    int f2 = getf(v2);\n    if(f1 == f2){\n        return false;\n    }\n    f[f1] = f2;\n    return true;\n}\n\nvoid kruskal()\n{\n    for(int i=0; i<=N; i++)\n        f[i] = i;\n    int cnt = 0;\n    for(int i=0; i<E.size(); i++){\n        if(cnt>=N-1)    break;\n        int f = E[i].from;\n        int t = E[i].to;\n        if(Merge(f,t)){\n            cnt++;\n            G[f].pb(mkp(t,E[i].v));\n            G[t].pb(mkp(f,E[i].v));\n//            cout<<f<<\" \"<<t<<\" \"<<E[i].v<<endl;\n        }\n    }\n}\n\nvoid dfs(int v,int pre,int depth)\n{\n    d[v] = depth;\n    for(int i=0; i<G[v].size(); i++){\n        int t = G[v][i].first;\n        int val = G[v][i].second;\n        if(t==pre)  continue;\n        dfs(t,v,depth+1);\n        //len[t] = val;\n        p[t][0] = v;\n        mlen[t][0] = val;\n    }\n}\n\nvoid lca_init(int n)\n{\n//    for(int i=1; i<=n; i++)\n//        printf(\"mlen[%d][0] = %d\\n\",i,mlen[i][0]);\n    for(int j=1; (1<<j)<=n; j++){\n        for(int i=1; i<=n; i++){\n            p[i][j] = p[p[i][j-1]][j-1];\n            mlen[i][j] = max(mlen[i][j-1],mlen[p[i][j-1]][j-1]);\n            //printf(\"mlen[%d][%d] = %d\\n\",i,j,mlen[i][j]);\n        }\n    }\n}\n\nint query(int a,int b)\n{\n    //printf(\"Query a:%d b%d\\n\",a,b);\n    if(d[a]>d[b])  swap(a,b);\n    int f = d[b] - d[a];\n    int maxe = -1;\n    for(int i=0; (1<<i)<=f; i++)\n        if(f&(1<<i)){\n            maxe = max(maxe,mlen[b][i]);\n            b = p[b][i];\n        }\n    //printf(\"maxe = %d\\n\",maxe);\n    if(a!=b){\n        for(int i=(int)log2(N);i>=0; i--){\n            if(p[a][i]!=p[b][i]){\n                maxe = max(maxe,max(mlen[b][i],mlen[a][i]));\n                a = p[a][i];    b = p[b][i];\n            }\n            //printf(\"maxe = %d\\n\",maxe);\n        }\n        maxe = max(maxe,mlen[a][0]);    //和求LCA不同，这里要同时对两个节点更新最大值\n        maxe = max(maxe,mlen[b][0]);\n        //printf(\"a = %d  maxe = %d\\n\",a,maxe);\n    }\n    return maxe;\n}\n\nint main()\n{\n    //freout;\n    bool flag = false;\n    while(~scanf(\"%d%d\",&N,&M)){\n        if(flag) puts(\"\");\n        flag = true;\n        E.clear();\n        for(int i=1; i<=N; i++)\n            G[i].clear();\n        for(int i=0; i<M; i++){\n            edge t;\n            scanf(\"%d%d%d\",&t.from,&t.to,&t.v);\n            E.pb(t);\n        }\n        sort(E.begin(),E.end());\n        kruskal();\n        dfs(1,-1,0);\n        lca_init(N);\n        int Q;\n        sc(Q);\n        for(int i=0; i<Q; i++){\n            int a,b;\n            sc(a); sc(b);\n            printf(\"%d\\n\",query(a,b));\n        }\n    }\n}\n\n```","slug":"acm/题解/图论/Uva-11354 最小瓶颈树+LCA倍增法维护最大值","published":1,"updated":"2017-08-27T12:00:00.258Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56jq003dacwox42hp4qh","content":"<h1 id=\"Uva-11354\"><a href=\"#Uva-11354\" class=\"headerlink\" title=\"Uva-11354\"></a>Uva-11354</h1><p>题意：<br>给你一个无向图，N个节点M条边，边权为d，对Q组询问a b,问能取到的从a到b路径上的最小值。</p>\n<p>题解：<br>首先总是要取最小的值，则可以先用kruskal求最小生成树（也就是最小瓶颈树），即在树上求任意两点之间路径边权值的最小值。可以用倍增求解LCA的方法，<strong>在保存p[i][j]（节点i的向上2^i个祖先） 的同时维护mlen[i][j]（节点i向上2^i条边的最大值）</strong></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\">#include &lt;cstdio&gt;</div><div class=\"line\">#include &lt;cctype&gt;</div><div class=\"line\">#include &lt;algorithm&gt;</div><div class=\"line\">#include &lt;cstring&gt;</div><div class=\"line\">#include &lt;string&gt;</div><div class=\"line\">#include &lt;cmath&gt;</div><div class=\"line\">#include &lt;vector&gt;</div><div class=\"line\">#include &lt;set&gt;</div><div class=\"line\">#include &lt;stack&gt;</div><div class=\"line\">#include &lt;sstream&gt;</div><div class=\"line\">#include &lt;queue&gt;</div><div class=\"line\">#include &lt;map&gt;</div><div class=\"line\">#include &lt;functional&gt;</div><div class=\"line\">#include &lt;bitset&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\">#define pb push_back</div><div class=\"line\">#define mk make_pair</div><div class=\"line\">#define ll long long</div><div class=\"line\">#define ull unsigned long long</div><div class=\"line\">#define pii pair&lt;int, int&gt;</div><div class=\"line\">#define mkp make_pair</div><div class=\"line\">#define fst first</div><div class=\"line\">#define scd second</div><div class=\"line\">#define ALL(A) A.begin(), A.end()</div><div class=\"line\">#define REP(i,n) for(int (i)=0;(i)&lt;(int)(n);(i)++)</div><div class=\"line\">#define REP1(i, n) for(int (i)=1;(i)&lt;=(int)(n);(i)++)</div><div class=\"line\">#define fastio ios::sync_with_stdio(0), cin.tie(0)</div><div class=\"line\">#define frein freopen(\"in.txt\", \"r\", stdin)</div><div class=\"line\">#define freout freopen(\"out.txt\", \"w\", stdout)</div><div class=\"line\">#define freout1 freopen(\"out1.txt\", \"w\", stdout)</div><div class=\"line\">#define PI M_PI</div><div class=\"line\">#define MAXN 100000</div><div class=\"line\">#define xork(a,b) ((b&amp;1)?(a):(0))</div><div class=\"line\">#define sc(n) scanf(\"%d\",&amp;(n))</div><div class=\"line\"></div><div class=\"line\">ll mod = 10000;</div><div class=\"line\">ll INF = 1LL&lt;&lt;60LL;</div><div class=\"line\">const double eps = 1e-8;</div><div class=\"line\">template&lt;typename T&gt; T gcd(T a,T b)</div><div class=\"line\">&#123;if(!b)return a;return gcd(b,a%b);&#125;</div><div class=\"line\">struct edge&#123;</div><div class=\"line\">    int from,to;</div><div class=\"line\">    int v;</div><div class=\"line\">    bool operator&lt;(const edge &amp;a)const&#123;</div><div class=\"line\">        return v&lt;a.v;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">vector&lt;edge&gt; E;</div><div class=\"line\">vector&lt;vector&lt;pii&gt; &gt;G(MAXN);</div><div class=\"line\">int d[MAXN],len[MAXN];</div><div class=\"line\">int p[MAXN][20],mlen[MAXN][20];</div><div class=\"line\">int f[MAXN];</div><div class=\"line\">int N,M;</div><div class=\"line\"></div><div class=\"line\">int getf(int v)&#123;</div><div class=\"line\">    if(f[v]==v) return v;</div><div class=\"line\">    else return f[v] = getf(f[v]);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">bool Merge(int v1,int v2)&#123;</div><div class=\"line\">    int f1 = getf(v1);</div><div class=\"line\">    int f2 = getf(v2);</div><div class=\"line\">    if(f1 == f2)&#123;</div><div class=\"line\">        return false;</div><div class=\"line\">    &#125;</div><div class=\"line\">    f[f1] = f2;</div><div class=\"line\">    return true;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void kruskal()</div><div class=\"line\">&#123;</div><div class=\"line\">    for(int i=0; i&lt;=N; i++)</div><div class=\"line\">        f[i] = i;</div><div class=\"line\">    int cnt = 0;</div><div class=\"line\">    for(int i=0; i&lt;E.size(); i++)&#123;</div><div class=\"line\">        if(cnt&gt;=N-1)    break;</div><div class=\"line\">        int f = E[i].from;</div><div class=\"line\">        int t = E[i].to;</div><div class=\"line\">        if(Merge(f,t))&#123;</div><div class=\"line\">            cnt++;</div><div class=\"line\">            G[f].pb(mkp(t,E[i].v));</div><div class=\"line\">            G[t].pb(mkp(f,E[i].v));</div><div class=\"line\">//            cout&lt;&lt;f&lt;&lt;\" \"&lt;&lt;t&lt;&lt;\" \"&lt;&lt;E[i].v&lt;&lt;endl;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void dfs(int v,int pre,int depth)</div><div class=\"line\">&#123;</div><div class=\"line\">    d[v] = depth;</div><div class=\"line\">    for(int i=0; i&lt;G[v].size(); i++)&#123;</div><div class=\"line\">        int t = G[v][i].first;</div><div class=\"line\">        int val = G[v][i].second;</div><div class=\"line\">        if(t==pre)  continue;</div><div class=\"line\">        dfs(t,v,depth+1);</div><div class=\"line\">        //len[t] = val;</div><div class=\"line\">        p[t][0] = v;</div><div class=\"line\">        mlen[t][0] = val;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void lca_init(int n)</div><div class=\"line\">&#123;</div><div class=\"line\">//    for(int i=1; i&lt;=n; i++)</div><div class=\"line\">//        printf(\"mlen[%d][0] = %d\\n\",i,mlen[i][0]);</div><div class=\"line\">    for(int j=1; (1&lt;&lt;j)&lt;=n; j++)&#123;</div><div class=\"line\">        for(int i=1; i&lt;=n; i++)&#123;</div><div class=\"line\">            p[i][j] = p[p[i][j-1]][j-1];</div><div class=\"line\">            mlen[i][j] = max(mlen[i][j-1],mlen[p[i][j-1]][j-1]);</div><div class=\"line\">            //printf(\"mlen[%d][%d] = %d\\n\",i,j,mlen[i][j]);</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int query(int a,int b)</div><div class=\"line\">&#123;</div><div class=\"line\">    //printf(\"Query a:%d b%d\\n\",a,b);</div><div class=\"line\">    if(d[a]&gt;d[b])  swap(a,b);</div><div class=\"line\">    int f = d[b] - d[a];</div><div class=\"line\">    int maxe = -1;</div><div class=\"line\">    for(int i=0; (1&lt;&lt;i)&lt;=f; i++)</div><div class=\"line\">        if(f&amp;(1&lt;&lt;i))&#123;</div><div class=\"line\">            maxe = max(maxe,mlen[b][i]);</div><div class=\"line\">            b = p[b][i];</div><div class=\"line\">        &#125;</div><div class=\"line\">    //printf(\"maxe = %d\\n\",maxe);</div><div class=\"line\">    if(a!=b)&#123;</div><div class=\"line\">        for(int i=(int)log2(N);i&gt;=0; i--)&#123;</div><div class=\"line\">            if(p[a][i]!=p[b][i])&#123;</div><div class=\"line\">                maxe = max(maxe,max(mlen[b][i],mlen[a][i]));</div><div class=\"line\">                a = p[a][i];    b = p[b][i];</div><div class=\"line\">            &#125;</div><div class=\"line\">            //printf(\"maxe = %d\\n\",maxe);</div><div class=\"line\">        &#125;</div><div class=\"line\">        maxe = max(maxe,mlen[a][0]);    //和求LCA不同，这里要同时对两个节点更新最大值</div><div class=\"line\">        maxe = max(maxe,mlen[b][0]);</div><div class=\"line\">        //printf(\"a = %d  maxe = %d\\n\",a,maxe);</div><div class=\"line\">    &#125;</div><div class=\"line\">    return maxe;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()</div><div class=\"line\">&#123;</div><div class=\"line\">    //freout;</div><div class=\"line\">    bool flag = false;</div><div class=\"line\">    while(~scanf(\"%d%d\",&amp;N,&amp;M))&#123;</div><div class=\"line\">        if(flag) puts(\"\");</div><div class=\"line\">        flag = true;</div><div class=\"line\">        E.clear();</div><div class=\"line\">        for(int i=1; i&lt;=N; i++)</div><div class=\"line\">            G[i].clear();</div><div class=\"line\">        for(int i=0; i&lt;M; i++)&#123;</div><div class=\"line\">            edge t;</div><div class=\"line\">            scanf(\"%d%d%d\",&amp;t.from,&amp;t.to,&amp;t.v);</div><div class=\"line\">            E.pb(t);</div><div class=\"line\">        &#125;</div><div class=\"line\">        sort(E.begin(),E.end());</div><div class=\"line\">        kruskal();</div><div class=\"line\">        dfs(1,-1,0);</div><div class=\"line\">        lca_init(N);</div><div class=\"line\">        int Q;</div><div class=\"line\">        sc(Q);</div><div class=\"line\">        for(int i=0; i&lt;Q; i++)&#123;</div><div class=\"line\">            int a,b;</div><div class=\"line\">            sc(a); sc(b);</div><div class=\"line\">            printf(\"%d\\n\",query(a,b));</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","excerpt":"","more":"<h1 id=\"Uva-11354\"><a href=\"#Uva-11354\" class=\"headerlink\" title=\"Uva-11354\"></a>Uva-11354</h1><p>题意：<br>给你一个无向图，N个节点M条边，边权为d，对Q组询问a b,问能取到的从a到b路径上的最小值。</p>\n<p>题解：<br>首先总是要取最小的值，则可以先用kruskal求最小生成树（也就是最小瓶颈树），即在树上求任意两点之间路径边权值的最小值。可以用倍增求解LCA的方法，<strong>在保存p[i][j]（节点i的向上2^i个祖先） 的同时维护mlen[i][j]（节点i向上2^i条边的最大值）</strong></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\">#include &lt;cstdio&gt;</div><div class=\"line\">#include &lt;cctype&gt;</div><div class=\"line\">#include &lt;algorithm&gt;</div><div class=\"line\">#include &lt;cstring&gt;</div><div class=\"line\">#include &lt;string&gt;</div><div class=\"line\">#include &lt;cmath&gt;</div><div class=\"line\">#include &lt;vector&gt;</div><div class=\"line\">#include &lt;set&gt;</div><div class=\"line\">#include &lt;stack&gt;</div><div class=\"line\">#include &lt;sstream&gt;</div><div class=\"line\">#include &lt;queue&gt;</div><div class=\"line\">#include &lt;map&gt;</div><div class=\"line\">#include &lt;functional&gt;</div><div class=\"line\">#include &lt;bitset&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\">#define pb push_back</div><div class=\"line\">#define mk make_pair</div><div class=\"line\">#define ll long long</div><div class=\"line\">#define ull unsigned long long</div><div class=\"line\">#define pii pair&lt;int, int&gt;</div><div class=\"line\">#define mkp make_pair</div><div class=\"line\">#define fst first</div><div class=\"line\">#define scd second</div><div class=\"line\">#define ALL(A) A.begin(), A.end()</div><div class=\"line\">#define REP(i,n) for(int (i)=0;(i)&lt;(int)(n);(i)++)</div><div class=\"line\">#define REP1(i, n) for(int (i)=1;(i)&lt;=(int)(n);(i)++)</div><div class=\"line\">#define fastio ios::sync_with_stdio(0), cin.tie(0)</div><div class=\"line\">#define frein freopen(\"in.txt\", \"r\", stdin)</div><div class=\"line\">#define freout freopen(\"out.txt\", \"w\", stdout)</div><div class=\"line\">#define freout1 freopen(\"out1.txt\", \"w\", stdout)</div><div class=\"line\">#define PI M_PI</div><div class=\"line\">#define MAXN 100000</div><div class=\"line\">#define xork(a,b) ((b&amp;1)?(a):(0))</div><div class=\"line\">#define sc(n) scanf(\"%d\",&amp;(n))</div><div class=\"line\"></div><div class=\"line\">ll mod = 10000;</div><div class=\"line\">ll INF = 1LL&lt;&lt;60LL;</div><div class=\"line\">const double eps = 1e-8;</div><div class=\"line\">template&lt;typename T&gt; T gcd(T a,T b)</div><div class=\"line\">&#123;if(!b)return a;return gcd(b,a%b);&#125;</div><div class=\"line\">struct edge&#123;</div><div class=\"line\">    int from,to;</div><div class=\"line\">    int v;</div><div class=\"line\">    bool operator&lt;(const edge &amp;a)const&#123;</div><div class=\"line\">        return v&lt;a.v;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">vector&lt;edge&gt; E;</div><div class=\"line\">vector&lt;vector&lt;pii&gt; &gt;G(MAXN);</div><div class=\"line\">int d[MAXN],len[MAXN];</div><div class=\"line\">int p[MAXN][20],mlen[MAXN][20];</div><div class=\"line\">int f[MAXN];</div><div class=\"line\">int N,M;</div><div class=\"line\"></div><div class=\"line\">int getf(int v)&#123;</div><div class=\"line\">    if(f[v]==v) return v;</div><div class=\"line\">    else return f[v] = getf(f[v]);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">bool Merge(int v1,int v2)&#123;</div><div class=\"line\">    int f1 = getf(v1);</div><div class=\"line\">    int f2 = getf(v2);</div><div class=\"line\">    if(f1 == f2)&#123;</div><div class=\"line\">        return false;</div><div class=\"line\">    &#125;</div><div class=\"line\">    f[f1] = f2;</div><div class=\"line\">    return true;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void kruskal()</div><div class=\"line\">&#123;</div><div class=\"line\">    for(int i=0; i&lt;=N; i++)</div><div class=\"line\">        f[i] = i;</div><div class=\"line\">    int cnt = 0;</div><div class=\"line\">    for(int i=0; i&lt;E.size(); i++)&#123;</div><div class=\"line\">        if(cnt&gt;=N-1)    break;</div><div class=\"line\">        int f = E[i].from;</div><div class=\"line\">        int t = E[i].to;</div><div class=\"line\">        if(Merge(f,t))&#123;</div><div class=\"line\">            cnt++;</div><div class=\"line\">            G[f].pb(mkp(t,E[i].v));</div><div class=\"line\">            G[t].pb(mkp(f,E[i].v));</div><div class=\"line\">//            cout&lt;&lt;f&lt;&lt;\" \"&lt;&lt;t&lt;&lt;\" \"&lt;&lt;E[i].v&lt;&lt;endl;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void dfs(int v,int pre,int depth)</div><div class=\"line\">&#123;</div><div class=\"line\">    d[v] = depth;</div><div class=\"line\">    for(int i=0; i&lt;G[v].size(); i++)&#123;</div><div class=\"line\">        int t = G[v][i].first;</div><div class=\"line\">        int val = G[v][i].second;</div><div class=\"line\">        if(t==pre)  continue;</div><div class=\"line\">        dfs(t,v,depth+1);</div><div class=\"line\">        //len[t] = val;</div><div class=\"line\">        p[t][0] = v;</div><div class=\"line\">        mlen[t][0] = val;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void lca_init(int n)</div><div class=\"line\">&#123;</div><div class=\"line\">//    for(int i=1; i&lt;=n; i++)</div><div class=\"line\">//        printf(\"mlen[%d][0] = %d\\n\",i,mlen[i][0]);</div><div class=\"line\">    for(int j=1; (1&lt;&lt;j)&lt;=n; j++)&#123;</div><div class=\"line\">        for(int i=1; i&lt;=n; i++)&#123;</div><div class=\"line\">            p[i][j] = p[p[i][j-1]][j-1];</div><div class=\"line\">            mlen[i][j] = max(mlen[i][j-1],mlen[p[i][j-1]][j-1]);</div><div class=\"line\">            //printf(\"mlen[%d][%d] = %d\\n\",i,j,mlen[i][j]);</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int query(int a,int b)</div><div class=\"line\">&#123;</div><div class=\"line\">    //printf(\"Query a:%d b%d\\n\",a,b);</div><div class=\"line\">    if(d[a]&gt;d[b])  swap(a,b);</div><div class=\"line\">    int f = d[b] - d[a];</div><div class=\"line\">    int maxe = -1;</div><div class=\"line\">    for(int i=0; (1&lt;&lt;i)&lt;=f; i++)</div><div class=\"line\">        if(f&amp;(1&lt;&lt;i))&#123;</div><div class=\"line\">            maxe = max(maxe,mlen[b][i]);</div><div class=\"line\">            b = p[b][i];</div><div class=\"line\">        &#125;</div><div class=\"line\">    //printf(\"maxe = %d\\n\",maxe);</div><div class=\"line\">    if(a!=b)&#123;</div><div class=\"line\">        for(int i=(int)log2(N);i&gt;=0; i--)&#123;</div><div class=\"line\">            if(p[a][i]!=p[b][i])&#123;</div><div class=\"line\">                maxe = max(maxe,max(mlen[b][i],mlen[a][i]));</div><div class=\"line\">                a = p[a][i];    b = p[b][i];</div><div class=\"line\">            &#125;</div><div class=\"line\">            //printf(\"maxe = %d\\n\",maxe);</div><div class=\"line\">        &#125;</div><div class=\"line\">        maxe = max(maxe,mlen[a][0]);    //和求LCA不同，这里要同时对两个节点更新最大值</div><div class=\"line\">        maxe = max(maxe,mlen[b][0]);</div><div class=\"line\">        //printf(\"a = %d  maxe = %d\\n\",a,maxe);</div><div class=\"line\">    &#125;</div><div class=\"line\">    return maxe;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()</div><div class=\"line\">&#123;</div><div class=\"line\">    //freout;</div><div class=\"line\">    bool flag = false;</div><div class=\"line\">    while(~scanf(\"%d%d\",&amp;N,&amp;M))&#123;</div><div class=\"line\">        if(flag) puts(\"\");</div><div class=\"line\">        flag = true;</div><div class=\"line\">        E.clear();</div><div class=\"line\">        for(int i=1; i&lt;=N; i++)</div><div class=\"line\">            G[i].clear();</div><div class=\"line\">        for(int i=0; i&lt;M; i++)&#123;</div><div class=\"line\">            edge t;</div><div class=\"line\">            scanf(\"%d%d%d\",&amp;t.from,&amp;t.to,&amp;t.v);</div><div class=\"line\">            E.pb(t);</div><div class=\"line\">        &#125;</div><div class=\"line\">        sort(E.begin(),E.end());</div><div class=\"line\">        kruskal();</div><div class=\"line\">        dfs(1,-1,0);</div><div class=\"line\">        lca_init(N);</div><div class=\"line\">        int Q;</div><div class=\"line\">        sc(Q);</div><div class=\"line\">        for(int i=0; i&lt;Q; i++)&#123;</div><div class=\"line\">            int a,b;</div><div class=\"line\">            sc(a); sc(b);</div><div class=\"line\">            printf(\"%d\\n\",query(a,b));</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>"},{"title":"Uva-14149 二分图匹配求最小点覆盖","date":"2017-08-28T04:03:34.000Z","_content":"\n# Uva-14149\n## 题意：   \n给一个R*C的矩形网格，每一个小格子内可能有点，求最小选多少行多少列可以覆盖所有的点，并输出这些行和列\n\n\n## 题解：\n由于类似一个覆盖问题，可以想办法根据矩阵的二维性质构造一个二分图求最小覆盖 。  \n那么使每一行为一个点集每一列为一个点集，(x,y)有点则在x和y之间连一条线。那么最后只需要选点覆盖所有线就行。  \n二分匹配->最小点覆盖  \n要具体求出哪些点参考以下结论\n### 一个结论\n**从二分最大匹配找到最小点覆盖**    \n需要借助匈牙利树： 设二分图两个集合为X Y  \n从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖\n\n```c++\nint R,C,N;\nint uN,vN;\nint G[MAXN][MAXN];\nint Left[MAXN];\nint Right[MAXN];\nbool S[MAXN],T[MAXN];\n\nbool dfs(int u)\n{\n    S[u] = true;\n    for(int v=1; v<=vN;v++)\n    if(G[u][v] && !T[v]){\n        T[v] = true;\n        if(Left[v] == -1 || dfs(Left[v])){\n            Right[u] = v;\n            Left[v] = u;\n            return true;\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(Left,-1,sizeof(Left));\n    memset(Right,-1,sizeof(Right));\n    for(int u=1; u<=uN; u++){\n        memset(T,0,sizeof(T));\n        if(dfs(u)) res++;\n    }\n    return res;\n}\n\nint min_cover(vector<int> &X,vector<int> &Y)\n{\n    int ans = hungary();\n    X.clear();  Y.clear();\n    memset(S,0,sizeof(S));\n    memset(T,0,sizeof(T));\n    for(int i=1;i<=uN;i++)\n        if(Right[i]==-1) dfs(i);\n    for(int i=1;i<=uN;i++)\n        if(!S[i]) X.pb(i);\n    for(int j=1;j<=vN;j++)\n        if(T[j]) Y.pb(j);\n    return ans;\n}\n\nint main()\n{\n    vector<int> x,y;\n    while(scanf(\"%d%d%d\",&R,&C,&N)){\n        if(R==0 && C==0 && N==0)\n            break;\n        uN = R; vN = C;\n        memset(G,0,sizeof(G));\n        for(int i=0; i<N; i++){\n            int y,x;\n            sc(y); sc(x);\n            G[y][x] = 1;\n        }\n        int ans = min_cover(x,y);\n        printf(\"%d\",ans);\n        for(int i=0; i<x.size(); i++)\n            printf(\" r%d\",x[i]);\n        for(int i=0; i<y.size(); i++)\n            printf(\" c%d\",y[i]);\n        printf(\"\\n\");\n    }\n}\n```","source":"_posts/acm/题解/图论/二分图/Uva-14149 二分图匹配求最小点覆盖.md","raw":"---\ntitle: Uva-14149 二分图匹配求最小点覆盖\ndate: 2017-8-28 12:03:34\ncategories: ACM\ntags:  [二分图,最小点覆盖]\n---\n\n# Uva-14149\n## 题意：   \n给一个R*C的矩形网格，每一个小格子内可能有点，求最小选多少行多少列可以覆盖所有的点，并输出这些行和列\n\n\n## 题解：\n由于类似一个覆盖问题，可以想办法根据矩阵的二维性质构造一个二分图求最小覆盖 。  \n那么使每一行为一个点集每一列为一个点集，(x,y)有点则在x和y之间连一条线。那么最后只需要选点覆盖所有线就行。  \n二分匹配->最小点覆盖  \n要具体求出哪些点参考以下结论\n### 一个结论\n**从二分最大匹配找到最小点覆盖**    \n需要借助匈牙利树： 设二分图两个集合为X Y  \n从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖\n\n```c++\nint R,C,N;\nint uN,vN;\nint G[MAXN][MAXN];\nint Left[MAXN];\nint Right[MAXN];\nbool S[MAXN],T[MAXN];\n\nbool dfs(int u)\n{\n    S[u] = true;\n    for(int v=1; v<=vN;v++)\n    if(G[u][v] && !T[v]){\n        T[v] = true;\n        if(Left[v] == -1 || dfs(Left[v])){\n            Right[u] = v;\n            Left[v] = u;\n            return true;\n        }\n    }\n    return false;\n}\n\nint hungary()\n{\n    int res = 0;\n    memset(Left,-1,sizeof(Left));\n    memset(Right,-1,sizeof(Right));\n    for(int u=1; u<=uN; u++){\n        memset(T,0,sizeof(T));\n        if(dfs(u)) res++;\n    }\n    return res;\n}\n\nint min_cover(vector<int> &X,vector<int> &Y)\n{\n    int ans = hungary();\n    X.clear();  Y.clear();\n    memset(S,0,sizeof(S));\n    memset(T,0,sizeof(T));\n    for(int i=1;i<=uN;i++)\n        if(Right[i]==-1) dfs(i);\n    for(int i=1;i<=uN;i++)\n        if(!S[i]) X.pb(i);\n    for(int j=1;j<=vN;j++)\n        if(T[j]) Y.pb(j);\n    return ans;\n}\n\nint main()\n{\n    vector<int> x,y;\n    while(scanf(\"%d%d%d\",&R,&C,&N)){\n        if(R==0 && C==0 && N==0)\n            break;\n        uN = R; vN = C;\n        memset(G,0,sizeof(G));\n        for(int i=0; i<N; i++){\n            int y,x;\n            sc(y); sc(x);\n            G[y][x] = 1;\n        }\n        int ans = min_cover(x,y);\n        printf(\"%d\",ans);\n        for(int i=0; i<x.size(); i++)\n            printf(\" r%d\",x[i]);\n        for(int i=0; i<y.size(); i++)\n            printf(\" c%d\",y[i]);\n        printf(\"\\n\");\n    }\n}\n```","slug":"acm/题解/图论/二分图/Uva-14149 二分图匹配求最小点覆盖","published":1,"updated":"2017-08-27T11:50:40.335Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg1v56kl003racwo7ipj5wm2","content":"<h1 id=\"Uva-14149\"><a href=\"#Uva-14149\" class=\"headerlink\" title=\"Uva-14149\"></a>Uva-14149</h1><h2 id=\"题意：\"><a href=\"#题意：\" class=\"headerlink\" title=\"题意：\"></a>题意：</h2><p>给一个R*C的矩形网格，每一个小格子内可能有点，求最小选多少行多少列可以覆盖所有的点，并输出这些行和列</p>\n<h2 id=\"题解：\"><a href=\"#题解：\" class=\"headerlink\" title=\"题解：\"></a>题解：</h2><p>由于类似一个覆盖问题，可以想办法根据矩阵的二维性质构造一个二分图求最小覆盖 。<br>那么使每一行为一个点集每一列为一个点集，(x,y)有点则在x和y之间连一条线。那么最后只需要选点覆盖所有线就行。<br>二分匹配-&gt;最小点覆盖<br>要具体求出哪些点参考以下结论</p>\n<h3 id=\"一个结论\"><a href=\"#一个结论\" class=\"headerlink\" title=\"一个结论\"></a>一个结论</h3><p><strong>从二分最大匹配找到最小点覆盖</strong><br>需要借助匈牙利树： 设二分图两个集合为X Y<br>从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> R,C,N;</div><div class=\"line\"><span class=\"keyword\">int</span> uN,vN;</div><div class=\"line\"><span class=\"keyword\">int</span> G[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Left[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Right[MAXN];</div><div class=\"line\"><span class=\"keyword\">bool</span> S[MAXN],T[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    S[u] = <span class=\"literal\">true</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> v=<span class=\"number\">1</span>; v&lt;=vN;v++)</div><div class=\"line\">    <span class=\"keyword\">if</span>(G[u][v] &amp;&amp; !T[v])&#123;</div><div class=\"line\">        T[v] = <span class=\"literal\">true</span>;</div><div class=\"line\">        <span class=\"keyword\">if</span>(Left[v] == <span class=\"number\">-1</span> || dfs(Left[v]))&#123;</div><div class=\"line\">            Right[u] = v;</div><div class=\"line\">            Left[v] = u;</div><div class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">hungary</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Left,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Left));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Right,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Right));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> u=<span class=\"number\">1</span>; u&lt;=uN; u++)&#123;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">        <span class=\"keyword\">if</span>(dfs(u)) res++;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> res;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">min_cover</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;X,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;Y)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = hungary();</div><div class=\"line\">    X.clear();  Y.clear();</div><div class=\"line\">    <span class=\"built_in\">memset</span>(S,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(S));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(Right[i]==<span class=\"number\">-1</span>) dfs(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(!S[i]) X.pb(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>;j&lt;=vN;j++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(T[j]) Y.pb(j);</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; x,y;</div><div class=\"line\">    <span class=\"keyword\">while</span>(<span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d%d%d\"</span>,&amp;R,&amp;C,&amp;N))&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(R==<span class=\"number\">0</span> &amp;&amp; C==<span class=\"number\">0</span> &amp;&amp; N==<span class=\"number\">0</span>)</div><div class=\"line\">            <span class=\"keyword\">break</span>;</div><div class=\"line\">        uN = R; vN = C;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(G,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(G));</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;N; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> y,x;</div><div class=\"line\">            sc(y); sc(x);</div><div class=\"line\">            G[y][x] = <span class=\"number\">1</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">int</span> ans = min_cover(x,y);</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,ans);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;x.size(); i++)</div><div class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\" r%d\"</span>,x[i]);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;y.size(); i++)</div><div class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\" c%d\"</span>,y[i]);</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","excerpt":"","more":"<h1 id=\"Uva-14149\"><a href=\"#Uva-14149\" class=\"headerlink\" title=\"Uva-14149\"></a>Uva-14149</h1><h2 id=\"题意：\"><a href=\"#题意：\" class=\"headerlink\" title=\"题意：\"></a>题意：</h2><p>给一个R*C的矩形网格，每一个小格子内可能有点，求最小选多少行多少列可以覆盖所有的点，并输出这些行和列</p>\n<h2 id=\"题解：\"><a href=\"#题解：\" class=\"headerlink\" title=\"题解：\"></a>题解：</h2><p>由于类似一个覆盖问题，可以想办法根据矩阵的二维性质构造一个二分图求最小覆盖 。<br>那么使每一行为一个点集每一列为一个点集，(x,y)有点则在x和y之间连一条线。那么最后只需要选点覆盖所有线就行。<br>二分匹配-&gt;最小点覆盖<br>要具体求出哪些点参考以下结论</p>\n<h3 id=\"一个结论\"><a href=\"#一个结论\" class=\"headerlink\" title=\"一个结论\"></a>一个结论</h3><p><strong>从二分最大匹配找到最小点覆盖</strong><br>需要借助匈牙利树： 设二分图两个集合为X Y<br>从X中所有未覆盖点出发进行扩展匈牙利树，标记树当中的所有点，则X当中的未标记点和Y当中的已标记点组成了所求的最小覆盖</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">int</span> R,C,N;</div><div class=\"line\"><span class=\"keyword\">int</span> uN,vN;</div><div class=\"line\"><span class=\"keyword\">int</span> G[MAXN][MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Left[MAXN];</div><div class=\"line\"><span class=\"keyword\">int</span> Right[MAXN];</div><div class=\"line\"><span class=\"keyword\">bool</span> S[MAXN],T[MAXN];</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> u)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    S[u] = <span class=\"literal\">true</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> v=<span class=\"number\">1</span>; v&lt;=vN;v++)</div><div class=\"line\">    <span class=\"keyword\">if</span>(G[u][v] &amp;&amp; !T[v])&#123;</div><div class=\"line\">        T[v] = <span class=\"literal\">true</span>;</div><div class=\"line\">        <span class=\"keyword\">if</span>(Left[v] == <span class=\"number\">-1</span> || dfs(Left[v]))&#123;</div><div class=\"line\">            Right[u] = v;</div><div class=\"line\">            Left[v] = u;</div><div class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">hungary</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> res = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Left,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Left));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Right,<span class=\"number\">-1</span>,<span class=\"keyword\">sizeof</span>(Right));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> u=<span class=\"number\">1</span>; u&lt;=uN; u++)&#123;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">        <span class=\"keyword\">if</span>(dfs(u)) res++;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> res;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">min_cover</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;X,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;Y)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> ans = hungary();</div><div class=\"line\">    X.clear();  Y.clear();</div><div class=\"line\">    <span class=\"built_in\">memset</span>(S,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(S));</div><div class=\"line\">    <span class=\"built_in\">memset</span>(T,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(T));</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(Right[i]==<span class=\"number\">-1</span>) dfs(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">1</span>;i&lt;=uN;i++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(!S[i]) X.pb(i);</div><div class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">1</span>;j&lt;=vN;j++)</div><div class=\"line\">        <span class=\"keyword\">if</span>(T[j]) Y.pb(j);</div><div class=\"line\">    <span class=\"keyword\">return</span> ans;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; x,y;</div><div class=\"line\">    <span class=\"keyword\">while</span>(<span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d%d%d\"</span>,&amp;R,&amp;C,&amp;N))&#123;</div><div class=\"line\">        <span class=\"keyword\">if</span>(R==<span class=\"number\">0</span> &amp;&amp; C==<span class=\"number\">0</span> &amp;&amp; N==<span class=\"number\">0</span>)</div><div class=\"line\">            <span class=\"keyword\">break</span>;</div><div class=\"line\">        uN = R; vN = C;</div><div class=\"line\">        <span class=\"built_in\">memset</span>(G,<span class=\"number\">0</span>,<span class=\"keyword\">sizeof</span>(G));</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;N; i++)&#123;</div><div class=\"line\">            <span class=\"keyword\">int</span> y,x;</div><div class=\"line\">            sc(y); sc(x);</div><div class=\"line\">            G[y][x] = <span class=\"number\">1</span>;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"keyword\">int</span> ans = min_cover(x,y);</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,ans);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;x.size(); i++)</div><div class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\" r%d\"</span>,x[i]);</div><div class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;y.size(); i++)</div><div class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\" c%d\"</span>,y[i]);</div><div class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjg1v55ca0006acwort35j5hh","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v55d5000cacwoca2vs99a"},{"post_id":"cjg1v55az0001acwommwk1pbl","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v55d5000eacwotnzgvton"},{"post_id":"cjg1v55ca0007acwo5ca4jabo","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v55d5000gacwogu0qeqjb"},{"post_id":"cjg1v55d5000bacwooxophwa1","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v55d5000iacwop6bm4k75"},{"post_id":"cjg1v55bf0002acwo2mqflq27","category_id":"cjg1v55cq0008acwoytyu75my","_id":"cjg1v55dl000kacwo5f25p8lg"},{"post_id":"cjg1v55y5000oacwo4lv4yerh","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v55z0000uacwohnu8n2kj"},{"post_id":"cjg1v55yk000qacworptfc5f2","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v55z0000wacwoa9eoh2ya"},{"post_id":"cjg1v566u0011acwos7tp180t","category_id":"cjg1v56720012acwoybwigjn7","_id":"cjg1v567a0015acwoskqrie46"},{"post_id":"cjg1v568m0018acwo4l25tmsd","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v5692001cacwoo41r77fd"},{"post_id":"cjg1v568m0019acwomj52grt2","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v5692001eacwos7unxxp4"},{"post_id":"cjg1v5692001bacwow9kuei5g","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v569i001hacwopa7bk3wg"},{"post_id":"cjg1v5692001dacwoua6b4l2b","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v569x001kacwovle83izy"},{"post_id":"cjg1v569i001facwofhcivjrv","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v569x001oacwoyiaylav0"},{"post_id":"cjg1v569i001jacwoyhhetdxe","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v569x001racwom01q98u2"},{"post_id":"cjg1v569x001macwor6ld2x8t","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56ad001vacwo4u4y8q3r"},{"post_id":"cjg1v56gp002tacwogf4epved","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56h4002xacwonw4xys1j"},{"post_id":"cjg1v56gp002uacwo56pqxhdd","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56hk002zacwo7jfgb9mu"},{"post_id":"cjg1v56h4002wacwo4dzxmtdv","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56hk0031acwoxkor9one"},{"post_id":"cjg1v56h4002yacwo16i7dyoq","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56hk0033acwozatys3xx"},{"post_id":"cjg1v56jq003cacwomc4usa4p","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56jq003facwowtagsldj"},{"post_id":"cjg1v56jq003dacwox42hp4qh","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56jq003gacwopmlskiqh"},{"post_id":"cjg1v56kl003racwo7ipj5wm2","category_id":"cjg1v55bf0003acwoeb9usd1m","_id":"cjg1v56kl003tacwo0xlw8axe"}],"PostTag":[{"post_id":"cjg1v55az0001acwommwk1pbl","tag_id":"cjg1v55bu0004acwoz9e97fuy","_id":"cjg1v55cq000aacwoyxs59yjp"},{"post_id":"cjg1v55bf0002acwo2mqflq27","tag_id":"cjg1v55cq0009acwo4djntbq2","_id":"cjg1v55d5000facwoe0320sc7"},{"post_id":"cjg1v55ca0006acwort35j5hh","tag_id":"cjg1v55d5000dacwov03rg2pu","_id":"cjg1v55d5000jacwos0g0bsrh"},{"post_id":"cjg1v55ca0007acwo5ca4jabo","tag_id":"cjg1v55d5000hacwo70oo1x6j","_id":"cjg1v55dl000macwo8d9brdsl"},{"post_id":"cjg1v55d5000bacwooxophwa1","tag_id":"cjg1v55dl000lacwol4q68xdt","_id":"cjg1v55dl000nacwoxq8uwsjn"},{"post_id":"cjg1v55y5000oacwo4lv4yerh","tag_id":"cjg1v55z0000sacwoy9d8htql","_id":"cjg1v55zf000zacwo2oclsj80"},{"post_id":"cjg1v55yk000qacworptfc5f2","tag_id":"cjg1v55z0000xacwo5jevqrj6","_id":"cjg1v55zf0010acwobazm9pyf"},{"post_id":"cjg1v566u0011acwos7tp180t","tag_id":"cjg1v56760013acwoz0uuhmbh","_id":"cjg1v567a0016acwojpsm7rfy"},{"post_id":"cjg1v566u0011acwos7tp180t","tag_id":"cjg1v56760014acwoxz0c9458","_id":"cjg1v567a0017acwokl8k8v12"},{"post_id":"cjg1v568m0018acwo4l25tmsd","tag_id":"cjg1v568m001aacwo2pwb5uyi","_id":"cjg1v569i001iacwo38abcuu5"},{"post_id":"cjg1v569i001facwofhcivjrv","tag_id":"cjg1v568m001aacwo2pwb5uyi","_id":"cjg1v569x001lacwom20lir3o"},{"post_id":"cjg1v569i001facwofhcivjrv","tag_id":"cjg1v55d5000hacwo70oo1x6j","_id":"cjg1v569x001pacwom790kq3k"},{"post_id":"cjg1v568m0019acwomj52grt2","tag_id":"cjg1v569i001gacwo8ec0siq8","_id":"cjg1v569x001sacwot8yzf49j"},{"post_id":"cjg1v569x001macwor6ld2x8t","tag_id":"cjg1v568m001aacwo2pwb5uyi","_id":"cjg1v56ad001wacwo2lphezxr"},{"post_id":"cjg1v5692001bacwow9kuei5g","tag_id":"cjg1v569x001nacwo1gmscudw","_id":"cjg1v56as0021acwoi34mrwes"},{"post_id":"cjg1v5692001bacwow9kuei5g","tag_id":"cjg1v55d5000hacwo70oo1x6j","_id":"cjg1v56as0023acwo2i0lh88d"},{"post_id":"cjg1v5692001bacwow9kuei5g","tag_id":"cjg1v56ad001uacwo88btjk6x","_id":"cjg1v56as0025acwogxn9z0lu"},{"post_id":"cjg1v5692001dacwoua6b4l2b","tag_id":"cjg1v56ad001zacwoc9lxizd4","_id":"cjg1v56b80027acwoqh9jqmoe"},{"post_id":"cjg1v5692001dacwoua6b4l2b","tag_id":"cjg1v56as0024acwoor85r3zd","_id":"cjg1v56b80028acwor53pah0u"},{"post_id":"cjg1v569i001jacwoyhhetdxe","tag_id":"cjg1v56ad001zacwoc9lxizd4","_id":"cjg1v56b8002aacwoubnggdxd"},{"post_id":"cjg1v569i001jacwoyhhetdxe","tag_id":"cjg1v55d5000hacwo70oo1x6j","_id":"cjg1v56b8002bacwotei44jjl"},{"post_id":"cjg1v569x001qacwo12qoi16v","tag_id":"cjg1v56b80029acwo94wl63dm","_id":"cjg1v56b8002dacwowd1m4utx"},{"post_id":"cjg1v56ad001tacwoqr3mfqa4","tag_id":"cjg1v56b80029acwo94wl63dm","_id":"cjg1v56bo002facwosmc40202"},{"post_id":"cjg1v56ad001xacwoc8soe86s","tag_id":"cjg1v56b80029acwo94wl63dm","_id":"cjg1v56bo002hacwo15srmsc0"},{"post_id":"cjg1v56ad001yacwoe54ryp05","tag_id":"cjg1v56bo002gacwola9ncb59","_id":"cjg1v56bo002kacwocen9fn5g"},{"post_id":"cjg1v56ad001yacwoe54ryp05","tag_id":"cjg1v56bo002iacwou6001n7i","_id":"cjg1v56bo002lacwoxaztwciq"},{"post_id":"cjg1v56as0020acwo0yk8bnep","tag_id":"cjg1v56b80029acwo94wl63dm","_id":"cjg1v56bo002pacwo5hnwwjud"},{"post_id":"cjg1v56as0020acwo0yk8bnep","tag_id":"cjg1v56bo002macwov0a9ql2k","_id":"cjg1v56bo002qacwol5r28bvp"},{"post_id":"cjg1v56as0020acwo0yk8bnep","tag_id":"cjg1v56bo002nacworajzj0o4","_id":"cjg1v56bo002racwojrak39qd"},{"post_id":"cjg1v56as0022acwoneozpbmh","tag_id":"cjg1v56bo002oacwovavi50v9","_id":"cjg1v56bo002sacwoez4l4hqa"},{"post_id":"cjg1v56gp002tacwogf4epved","tag_id":"cjg1v56ad001zacwoc9lxizd4","_id":"cjg1v56hk0032acwomsbeskd7"},{"post_id":"cjg1v56gp002tacwogf4epved","tag_id":"cjg1v56gp002vacwod7pfpqgp","_id":"cjg1v56hk0034acwooi471of2"},{"post_id":"cjg1v56gp002uacwo56pqxhdd","tag_id":"cjg1v56ad001zacwoc9lxizd4","_id":"cjg1v56hk0036acwol7xtuqbj"},{"post_id":"cjg1v56gp002uacwo56pqxhdd","tag_id":"cjg1v56hk0030acwoyt41gzsh","_id":"cjg1v56i00037acwoa2c66en9"},{"post_id":"cjg1v56h4002wacwo4dzxmtdv","tag_id":"cjg1v56ad001zacwoc9lxizd4","_id":"cjg1v56i00039acwogqnata8a"},{"post_id":"cjg1v56h4002wacwo4dzxmtdv","tag_id":"cjg1v56hk0035acwoe1axx6lg","_id":"cjg1v56i0003aacwohqap7j2w"},{"post_id":"cjg1v56h4002yacwo16i7dyoq","tag_id":"cjg1v56i00038acwo59rsovzd","_id":"cjg1v56i0003bacwof19gkopg"},{"post_id":"cjg1v56jq003cacwomc4usa4p","tag_id":"cjg1v56jq003eacwoqlzxzjhj","_id":"cjg1v56k6003jacwojxnpj3zl"},{"post_id":"cjg1v56jq003cacwomc4usa4p","tag_id":"cjg1v56jq003hacwoewxz80zm","_id":"cjg1v56k6003kacwobrg18t6p"},{"post_id":"cjg1v56jq003dacwox42hp4qh","tag_id":"cjg1v56k6003iacwokncshorz","_id":"cjg1v56k6003nacwon43mg0cn"},{"post_id":"cjg1v56jq003dacwox42hp4qh","tag_id":"cjg1v56k6003lacwo6j2egd3t","_id":"cjg1v56k6003oacwo4ytbd5ga"},{"post_id":"cjg1v56jq003dacwox42hp4qh","tag_id":"cjg1v56k6003macwo2f8m2sxb","_id":"cjg1v56k6003pacwonrl787r8"},{"post_id":"cjg1v56jq003dacwox42hp4qh","tag_id":"cjg1v55dl000lacwol4q68xdt","_id":"cjg1v56k6003qacwomsw2yqu8"},{"post_id":"cjg1v56kl003racwo7ipj5wm2","tag_id":"cjg1v56i00038acwo59rsovzd","_id":"cjg1v56kl003uacwolvy3phka"},{"post_id":"cjg1v56kl003racwo7ipj5wm2","tag_id":"cjg1v56kl003sacwosxo6a0sc","_id":"cjg1v56kl003vacwoilbr0z1s"}],"Tag":[{"name":"2SAT","_id":"cjg1v55bu0004acwoz9e97fuy"},{"name":"随想","_id":"cjg1v55cq0009acwo4djntbq2"},{"name":"网络流","_id":"cjg1v55d5000dacwov03rg2pu"},{"name":"题解","_id":"cjg1v55d5000hacwo70oo1x6j"},{"name":"LCA","_id":"cjg1v55dl000lacwol4q68xdt"},{"name":"计算几何","_id":"cjg1v55z0000sacwoy9d8htql"},{"name":"高斯消元","_id":"cjg1v55z0000xacwo5jevqrj6"},{"name":"数据挖掘","_id":"cjg1v56760013acwoz0uuhmbh"},{"name":"图","_id":"cjg1v56760014acwoxz0c9458"},{"name":"博弈论","_id":"cjg1v568m001aacwo2pwb5uyi"},{"name":"动态规划","_id":"cjg1v569i001gacwo8ec0siq8"},{"name":"比赛","_id":"cjg1v569x001nacwo1gmscudw"},{"name":"三元环","_id":"cjg1v56ad001uacwo88btjk6x"},{"name":"数论","_id":"cjg1v56ad001zacwoc9lxizd4"},{"name":"快速幂","_id":"cjg1v56as0024acwoor85r3zd"},{"name":"tensorflow","_id":"cjg1v56b80029acwo94wl63dm"},{"name":"CNN","_id":"cjg1v56bo002gacwola9ncb59"},{"name":"DeepLearning","_id":"cjg1v56bo002iacwou6001n7i"},{"name":"CV","_id":"cjg1v56bo002macwov0a9ql2k"},{"name":"ML","_id":"cjg1v56bo002nacworajzj0o4"},{"name":"CNN，tensorflow","_id":"cjg1v56bo002oacwovavi50v9"},{"name":"异或","_id":"cjg1v56gp002vacwod7pfpqgp"},{"name":"欧拉函数","_id":"cjg1v56hk0030acwoyt41gzsh"},{"name":"线性筛法","_id":"cjg1v56hk0035acwoe1axx6lg"},{"name":"二分图","_id":"cjg1v56i00038acwo59rsovzd"},{"name":"RMQ","_id":"cjg1v56jq003eacwoqlzxzjhj"},{"name":"稀疏表","_id":"cjg1v56jq003hacwoewxz80zm"},{"name":"最小瓶颈树","_id":"cjg1v56k6003iacwokncshorz"},{"name":"kruskal","_id":"cjg1v56k6003lacwo6j2egd3t"},{"name":"倍增法","_id":"cjg1v56k6003macwo2f8m2sxb"},{"name":"最小点覆盖","_id":"cjg1v56kl003sacwosxo6a0sc"}]}}